{
    "nb": 19,
    "resource": "FAMPAT",
    "executedQuery": "(110469676 OR 105386908 OR 102706978 OR 87092902 OR 61119843 OR 986998 OR 109971718 OR 106808912 OR 104539134 OR 100568507 OR 89087032 OR 83378996 OR 61864928 OR 45764655 OR 15079695 OR 15017914 OR 106243695 OR 105331626 OR 102302504)/FAN",
    "queryId": "@X2985B5EE_4C3A_4834_96A8_CE0FE81D72BB",
    "message": null,
    "fields": [
        {
            "name": "PN",
            "display": "Patent Number",
            "type": "text",
            "subFields": []
        },
        {
            "name": "FAN",
            "display": "Family Number",
            "type": "text",
            "subFields": []
        },
        {
            "name": "TI",
            "display": "Title",
            "type": "text",
            "subFields": []
        },
        {
            "name": "AB",
            "display": "Abstract",
            "type": "text",
            "subFields": []
        },
        {
            "name": "ADB",
            "display": "Advantages / Prev. Drawbacks",
            "type": "text",
            "subFields": []
        },
        {
            "name": "CLMS",
            "display": "Claims",
            "type": "text",
            "subFields": []
        },
        {
            "name": "DESC",
            "display": "Description",
            "type": "text",
            "subFields": []
        },
        {
            "name": "CTGN",
            "display": "Normalized Citing Patents",
            "type": "text",
            "subFields": []
        },
        {
            "name": "CTN",
            "display": "Normalized Cited Patents",
            "type": "text",
            "subFields": []
        },
        {
            "name": "EPRD",
            "display": "Earliest Priority Date",
            "type": "text",
            "subFields": []
        },
        {
            "name": "EAPD",
            "display": "Earliest filing date",
            "type": "text",
            "subFields": []
        },
        {
            "name": "EPN",
            "display": "EPN",
            "type": "text",
            "subFields": []
        },
        {
            "name": "FNUM",
            "display": "FNUM",
            "type": "text",
            "subFields": []
        },
        {
            "name": "V_APL",
            "display": "V_APL",
            "type": "text",
            "subFields": []
        },
        {
            "name": "LAPD",
            "display": "Latest family filing date",
            "type": "text",
            "subFields": []
        },
        {
            "name": "EPD",
            "display": "Earliest publication date",
            "type": "text",
            "subFields": []
        },
        {
            "name": "PA",
            "display": "Original or current assignee",
            "type": "text",
            "subFields": []
        },
        {
            "name": "PAAD",
            "display": "Applicant Address",
            "type": "text",
            "subFields": []
        },
        {
            "name": "PTCC",
            "display": "PTCC",
            "type": "text",
            "subFields": []
        },
        {
            "name": "LIC",
            "display": "License Interest Name",
            "type": "text",
            "subFields": []
        },
        {
            "name": "OPPI",
            "display": "OPPI",
            "type": "text",
            "subFields": []
        },
        {
            "name": "STDN",
            "display": "STDN",
            "type": "text",
            "subFields": []
        },
        {
            "name": "NPN",
            "display": "Number of Patents",
            "type": "text",
            "subFields": []
        },
        {
            "name": "NPR",
            "display": "NPR",
            "type": "text",
            "subFields": []
        },
        {
            "name": "ICLM",
            "display": "Independent claims",
            "type": "text",
            "subFields": []
        },
        {
            "name": "IC",
            "display": "Intl. classification",
            "type": "text",
            "subFields": []
        },
        {
            "name": "PERMALINK",
            "display": "Permanent Link",
            "type": "link",
            "subFields": []
        },
        {
            "name": "TECD",
            "display": "Technology Domain",
            "type": "text",
            "subFields": []
        },
        {
            "name": "APID",
            "display": "AP unique ID",
            "type": "text",
            "subFields": []
        }
    ],
    "documents": [
        {
            "FNUM": "APAGE=12<br/>NBPC=2<br/>PNAAGE=1<br/>NBPA=1; <br/>ALLCT=2; SCT=0; NSCT=2; <br/>ALLCTG=0; SCTG=0; NSCTG=0; <br/>AFS=2; ACC=1; AMCC=0; <br/>IMPI=0.0; MACI=0.79; PASI=0.98; PAVI=0.41; ",
            "PTCC": "(EP4394693)<br/>CC=EP EED=2042-12-29 STATUS=PENDING APID=171019682 APD=2022-12-29 XPN=EP4394693 PD=2024-07-03 EPD=2024-07-03 LPD=2024-07-03 <br/><br/>(WO2024141849)<br/>CC=WO EED=2026-06-29 STATUS=PENDING APID=171028101 APD=2023-12-18 XPN=WO2024141849 PD=2024-07-04 EPD=2024-07-04 LPD=2024-07-04 <br/>CC=EP EED=2043-12-18 STATUS=PENDING APID=171028101 XPN=WO2024141849 <br/>",
            "EPN": "EP4394693",
            "CTGN": "",
            "LAPD": "2023-12-18",
            "STDN": "",
            "NPN": "2",
            "DESC": "<p><heading><b><u>Technical field</u></b></heading></p><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and a system for detecting damages to mechanical components, in particular aircraft components, by multispectral image processing.</p><p><heading><b><u>Background</u></b></heading></p><p><span class=\"paragraph-number\">[0002]   </span>As is well known, the need to detect the presence of anomalies (in the sense of damages, also known as deteriorations) of mechanical components of aircraft in order to ensure flight safety is particularly felt in the aviation sector.</p><p><span class=\"paragraph-number\">[0003]   </span>Typically, the search for possible anomalies of the components of an aircraft is carried out by highly specialized personnel, who carry out a visual and/or acoustic inspection of the components. In particular, in the case of acoustic inspection, the component under examination is repeatedly struck with a mechanical striker (for example, a hammer), so as to generate an acoustic response to the impact; based on this acoustic response, the person in charge of the inspection can detect the possible presence of an anomaly of the component, such as for example the presence of a detachment or a delamination. The acoustic inspection, also known as \"tapping test\", therefore requires the presence of trained personnel, provided with a corresponding technical preparation and considerable practical experience; moreover, this procedure cannot be automated and is inevitably subject to uncertainties linked to the skill of the personnel performing it and to human error.</p><p><span class=\"paragraph-number\">[0004]   </span>As far as visual inspection is concerned, however, it is also inevitably subject to uncertainties linked to the skill of the personnel performing it and to human error. In this regard, the result of the inspection may easily be distorted by the presence, on the component, of dirt, or by any reflections caused by lighting.</p><p><heading><b><u>Summary</u></b></heading></p><p><span class=\"paragraph-number\">[0005]   </span>Aim of the present invention is therefore to provide a solution which at least partly overcomes the drawbacks of the known art.</p><p><span class=\"paragraph-number\">[0006]   </span>According to the present invention there is provided a method and a system for detecting damages as defined in the appended claims.</p><p><heading><b><u>Brief description of the Figures</u></b></heading></p><p><span class=\"paragraph-number\">[0007]   </span>For a better understanding of this invention, some embodiments thereof will now be disclosed, for merely illustrative and non-limiting purposes, with reference to the enclosed drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1</figref> shows a block diagram of an anomaly detection system;</li><br/><li> <figref>Figures 2</figref>, <figref>5</figref>, <figref>11, 16</figref>, <figref>17 and 19</figref> show flowcharts according to the present method;</li><br/><li> <figref>Figure 3</figref> shows images of a component acquired in different spectral bands;</li><br/><li> <figref>Figure 4</figref> shows a three-dimensional multispectral and a two-dimensional mask image;</li><br/><li> <figref>Figure 6</figref> shows an image of the component acquired in the absence of illumination;</li><br/><li> <figref>Figure 7</figref> shows images of a sample acquired in different spectral bands;</li><br/><li> <figref>Figure 8</figref> shows block diagrams of portions of a first and a second neural network;</li><br/><li> <figref>Figure 9</figref> shows a block diagram of data structures generated by execution of a first and a second neural network;</li><br/><li> <figref>Figure 10</figref> shows a block diagram of data structures generated by execution of a first and a second neural network, during a training step;</li><br/><li> <figref>Figures 12 and 13</figref> show two images in the visible band;</li><br/><li> <figref>Figure 14</figref> shows a binary image deriving from the image shown in <figref>Figure 12</figref>;</li><br/><li> <figref>Figure 15</figref> shows a smoothed image deriving from the binary image shown in <figref>Figure 14</figref>; and</li><br/><li> <figref>Figure 18</figref> schematically shows a two-dimensional mask, a three-dimensional matrix and a vector.</li></ul></p><p><heading><b><u>Description of embodiments</u></b></heading></p><p><span class=\"paragraph-number\">[0008]   </span>The present method for detecting damages to a component of an aircraft is described, by way of example, with reference to a detection system 10 shown in <figref>Figure 1</figref>, which is shown as operating, for example, on a component 1, of which it is not known a priori whether it is healthy or damaged. In particular, the detection system 10 comprises a lighting device 12, an image acquisition device 14 and a computer 16.</p><p><span class=\"paragraph-number\">[0009]   </span>The lighting device 12 is controllable so as to illuminate the component 1 with a plurality of radiations having respective spectral bands, hereinafter referred to as lighting beams. In particular, the lighting beams are in a number equal to NUM_BW; by way of example only, in the following it is assumed NUM_BW=9. The spectral bands may have amplitude for example equal to 20nm and extend in respective ranges which are centred for example around the values: 720nm, 655nm, 614nm, 585nm, 520nm, 490nm, 465nm, 440nm and 420nm.</p><p><span class=\"paragraph-number\">[0010]   </span>In particular, as shown in <figref>Figure 2</figref>, for each lighting beam, the lighting device 12 illuminates (block 100) the component 1 by means of the lighting beam, while the image acquisition device 14 acquires (block 102) a corresponding image of the component 1, illuminated by the lighting beam; this image is therefore an image that refers to a single spectral band and is sent from the image acquisition device 14 to the computer 16. In this way, the computer 16 acquires the nine images of the component, as shown in <figref>Figure 3</figref>, wherein the images are denoted with 20; moreover, in the following reference is made to the images 20 as to the preliminary images 20.</p><p><span class=\"paragraph-number\">[0011]   </span>In greater detail, the lighting device 12 and the image acquisition device 14 may be controlled by the computer 16, in order to time the illumination of the component 1 with the acquisition of the preliminary images 20, in a manner known per se.</p><p><span class=\"paragraph-number\">[0012]   </span>Each of the preliminary images 20 is formed by a respective matrix of pixels; for example, the nine preliminary images 20 are assumed to have dimensions equal to NxM (e.g., N=1200 and M=1920). Furthermore, the pixels of each preliminary image 20 are indicative of corresponding light intensity values in the spectral band to which the preliminary image 20 refers.</p><p><span class=\"paragraph-number\">[0013]   </span>Subsequently, the computer 16 generates (block 104, <figref>Figure 2</figref>) a multispectral image 25 (an example shown in <figref>Figure 4</figref>), based on the nine preliminary images 20.</p><p><span class=\"paragraph-number\">[0014]   </span>For example, in order to generate the multispectral image 25, the computer 16 may control the lighting device 12 and the image acquisition device 14 to perform the operations shown in <figref>Figure 5</figref>.</p><p><span class=\"paragraph-number\">[0015]   </span>In detail, the computer 16 switches off the lighting device 12 and controls the image acquisition device 14 so as to acquire (block 200, <figref>Figure 5</figref>) a first reference image 27 (an example shown in <figref>Figure 6</figref>) of the component 1.</p><p><span class=\"paragraph-number\">[0016]   </span>The first reference image 27 is therefore an image of the component 1 obtained when the lighting device 12 is switched off, thus depending on any spurious radiation coming from the environment in which the component 1 is arranged. In this regard, in the present description it is assumed that the component 1 maintains a same arrangement with respect to the lighting device 12 and the image acquisition device 14; consequently, the arrangement that the component 1 has during the acquisition of the first reference image 27 is the same as the one the component 1 has during the acquisition of the nine preliminary images 20.</p><p><span class=\"paragraph-number\">[0017]   </span>Subsequently, the computer 16 subtracts (block 202, <figref>Figure 5</figref>) from each preliminary image 20 the first reference image 27, so as to generate a corresponding intermediate image (not shown), which refers to the same spectral band of the corresponding preliminary image 20.</p><p><span class=\"paragraph-number\">[0018]   </span>Thereafter, the computer 16 controls the lighting device 12 and the image acquisition device 14 so as to acquire (block 204, <figref>Fig. 5</figref>) nine images 29 (shown in <figref>Fig. 7</figref>) of a reference sample (not shown), hereinafter referred to as the sample images 29. For example, the sample is formed by a flat surface with high reflectivity (e.g., greater than 990) in all spectral bands.</p><p><span class=\"paragraph-number\">[0019]   </span>In greater detail, each sample image 29 refers to a corresponding spectral band.</p><p><span class=\"paragraph-number\">[0020]   </span>Subsequently, the computer 16 subtracts (block 206, <figref>Figure 5</figref>) from each sample image 29 the first reference image 27, so as to generate a corresponding image (not shown), hereinafter referred to as the standard image; each standard image refers to the same spectral band of the corresponding sample image 29.</p><p><span class=\"paragraph-number\">[0021]   </span>Subsequently, the computer 29 divides (block 208, <figref>Figure 5</figref>) each intermediate image by the corresponding standard image, so as to generate a corresponding processed image 30 (nine shown in <figref>Figure 4</figref>), which refers to the same spectral band to which the intermediate image and the standard image refer. In this way nine processed images 30 are obtained, each of which refers to a corresponding spectral band. In greater detail, considering any processed image 30, the light intensity of each pixel of the processed image 30 is equal to the ratio of the light intensity of the corresponding pixel of the corresponding intermediate image to the light intensity of the corresponding pixel of the corresponding standard image.</p><p><span class=\"paragraph-number\">[0022]   </span>Subsequently, the computer 16 aggregates (block 210, <figref>Figure 5</figref>) the nine processed images 30, so as to form the aforementioned multispectral image 25.</p><p><span class=\"paragraph-number\">[0023]   </span>For example, the aggregation occurs such that the multispectral image 25 is a three-dimensional matrix of pixels having dimensions 9xNxM. In other words, by indexing with k,i,j the three dimensions of the multispectral image 25, the pixels of the multispectral image 25 can be indicated by the notation MS[k,i,j]; moreover, if k=k* (with k* equal to any integer between 1 and 9), MS[k*,i,j] is equal to the k*-th processed image 30. In addition, assuming k=1, ..., 9, i=i* and j=j* (with i* an integer in the range [1-1200] and j* an integer in the range [1-1920]), the nine pixels M[k,i*,j*] refer to the same portion of the component 1.</p><p><span class=\"paragraph-number\">[0024]   </span>Subsequently, the computer 16 applies to the multispectral image 25 a first neural network 40, which is a convolutional neural network and, as shown qualitatively and by way of example only in <figref>Figure 8</figref>, comprises a sequence of a plurality of convolutional layers; without losing any generality, in the example shown in <figref>Figure 8</figref> there are a first, second, third and fourth convolutional layers 41, 42, 43, 44, connected in sequence.</p><p><span class=\"paragraph-number\">[0025]   </span>In a manner known per se, each of the first, second, third and fourth hidden layers 41-44 provides for the execution of: one or more convolution operations, based on a number of respective filters, each convolution operation being followed by an activation operation and by an optional normalization operation; and pooling operations (optional).</p><p><span class=\"paragraph-number\">[0026]   </span>In practice, the multispectral image 25 is processed (block 212, <figref>Figure 5</figref>) by the sequence of the first, second, third and fourth convolutional layers 41-44 of the first neural network 40. To this end, the multispectral image 25 is provided in input to the first convolutional layer 41 of the first neural network 40.</p><p><span class=\"paragraph-number\">[0027]   </span>As shown qualitatively in <figref>Figure 9</figref>, the execution of the operations of each of the first, second, third and fourth convolutional layers 41-44 of the first neural network 40 leads to the generation of a corresponding three-dimensional matrix of numerical elements, which in <figref>Figure 9</figref> are respectively denoted with 51, 52, 53 and 54.</p><p><span class=\"paragraph-number\">[0028]   </span>In particular, referring to the feature matrix 54 to indicate the three-dimensional matrix generated by the fourth convolutional layer 44 of the first neural network 40, it has for example dimensions equal to 1024×(N/8)×(M/8), in the hypothesis in which the fourth convolutional layer 44 has a number of respective filters equal to 1024.</p><p><span class=\"paragraph-number\">[0029]   </span>The first neural network 40 further comprises a convolution filter 55 (shown in <figref>Figure 9</figref>), which has a dimension 1x1. Consequently, the computer 16 applies (block 214, <figref>Figure 5</figref>) to the feature matrix 54 the convolution filter 55, so as to obtain a two-dimensional matrix 62 (shown for example both in <figref>Figure 4</figref> and, in a simplified way, in <figref>Figure 9</figref>), which has dimensions for example equal to (N/8)x(M/8). Hereinafter, the two-dimensional matrix 62 is referred to as the mask 62.</p><p><span class=\"paragraph-number\">[0030]   </span>In detail, the first neural network 40 is such that each pixel of the mask 62 refers to a corresponding portion of the component 1, i.e. refers to a corresponding portion of the multispectral image 25, understood as a corresponding subset of pixels of the multispectral image 25, said subset of pixels including the pixels relative to said portion of the component 1 of each of the nine processed images 30, which in turn correspond to the corresponding pixels of the nine preliminary images 20, since there is a bi-unique relationship between each pixel of each processed image 30 and the corresponding pixel of the corresponding preliminary image 20.</p><p><span class=\"paragraph-number\">[0031]   </span>In particular, referring to MASK[J,K] for indicating the pixel of the mask 62 having coordinates J and K, such pixel from the mask 62 may refer to the group of pixels MS[i,j,k], with i=1, 2, ..., 9, j=J, J+1,...J+7 and j=K, K+1, ...K+7, as shown qualitatively in <figref>Figure 4</figref> with reference to the pixel MASK[1,1]. In other words, in this case each pixel of the mask 62 refers to a corresponding portion of the component 1 which is represented, in each of the processed images 30 of the multispectral image 25, by a corresponding group of sixty-four pixels.</p><p><span class=\"paragraph-number\">[0032]   </span>In addition, the pixels of the mask 62 have values ranging between zero and one. In particular, the value of each pixel of the mask 62 is an estimate of the probability that the portion of the component 1 to which that pixel refers is healthy or has a damaging. In other words, the mask 62 represents a segmentation of the multispectral image 25, as estimated by the first neural network 40.</p><p><span class=\"paragraph-number\">[0033]   </span>Thereafter, the computer 16 aggregates (block 216, <figref>Figure 5</figref>) the feature matrix 54 and the mask 62, so as to generate an updated matrix 65, shown by way of example in <figref>Figure 9</figref>. In practice, by observing that the feature matrix 54 is formed by a number NUM of two-dimensional matrices (in the example, it is assumed NUM=1024) having the same dimensions as the mask 62, the updated matrix 65 comprises i) the same two-dimensional matrices as the feature matrix 54 (in number equal to NUM), and further comprises, as NUM +1-th two-dimensional matrix, the mask 62.</p><p><span class=\"paragraph-number\">[0034]   </span>Subsequently, the computer 16 applies to the updated matrix 65 a second neural network 70, which forms, together with the first neural network 40, a third neural network 75.</p><p><span class=\"paragraph-number\">[0035]   </span>As shown qualitatively and by way of example only in <figref>Figure 8</figref>, the second neural network 70 comprises a respective sequence of a plurality of convolutional layers; without losing any generality, in the example shown in <figref>Figure 8</figref> there are a first, second, third and fourth convolutional layers 71, 72, 73, 74, connected in sequence.</p><p><span class=\"paragraph-number\">[0036]   </span>In a manner known per se, each of the first, second, third and fourth convolutional layers 71-74 provides for the execution of: a number of convolution operations, based on a number of respective filters, each convolution operation being followed by an activation operation and by an optional normalization operation; and pooling operations (optional).</p><p><span class=\"paragraph-number\">[0037]   </span>In practice, the updated matrix 65 is processed (block 218, <figref>Figure 5</figref>) by the sequence of the first, second, third and fourth convolutional layers 71-74 of the second neural network 70. To this end, the updated matrix 65 is provided in input to the first convolutional layer 71 of the second neural network 70.</p><p><span class=\"paragraph-number\">[0038]   </span>As shown qualitatively in <figref>Figure 9</figref>, the execution of the operations of each of the first, second, third and fourth convolutional layers 71-74 of the second neural network 70 leads to the generation of a corresponding three-dimensional matrix of numerical elements, which in <figref>Figure 9</figref> are respectively denoted with 81, 82, 83 and 84.</p><p><span class=\"paragraph-number\">[0039]   </span>In particular, referring to the classification matrix 84 to indicate the three-dimensional matrix generated by the fourth convolutional layer 74 of the second neural network 70, it has for example dimensions equal to 32x10x10, in the hypothesis in which the fourth convolutional layer 74 has a number of respective filters equal to thirty-two. In other words, in this example, the classification matrix 84 is formed by thirty-two two-dimensional matrices having dimensions 10x10.</p><p><span class=\"paragraph-number\">[0040]   </span>The second neural network 70 further provides that, for each two-dimensional matrix of the classification matrix 84, the mean value of the relative pixels is calculated and the maximum value between the pixels of the two-dimensional matrix is extracted (block 220, <figref>Figure 5</figref>). In <figref>Figure 9</figref>, such operations of calculating the mean value and of extracting the maximum value are indicated respectively with the blocks 90 and 91, which form a pooling step. In addition, these operations lead to the generation of a mean value vector (denoted with 92 in <figref>Figure 9</figref>) and a maximum value vector (denoted with 93 in <figref>Figure 9</figref>); both the mean value vector and the maximum value vector have thirty-two elements.</p><p><span class=\"paragraph-number\">[0041]   </span>The second neural network 70 further provides for the mean value of the pixels of the mask 62 to be calculated and the maximum value among the pixels of the mask 62 to be extracted (block 222, <figref>Figure 5</figref>). In <figref>Figure 9</figref>, such operations of calculating the mean value and of extracting the maximum value of the mask 62 are denoted respectively with blocks 94 and 95, which form a further pooling step. Furthermore, such operations lead to the generation of a first data structure 96, which stores the mean value of the mask 62, and of a second data structure 97, which stores the maximum value of the mask 62.</p><p><span class=\"paragraph-number\">[0042]   </span>The second neural network 70 further provides that the mean value vector 92, the maximum value vector 93 and the first and second first data structures 96, 97 are aggregated (block 224, <figref>Figure 5</figref>), so as to form a macrovector 98 (shown in <figref>Figure 9</figref>), which in the present example is formed by a number of elements equal to sixty-six.</p><p><span class=\"paragraph-number\">[0043]   </span>The second neural network 70 further provides to supply the macrovector 98 to a fully connected layer 99 (shown in <figref>Figure 9</figref>), which has a number of input nodes (not shown) equal to sixty-six and an output node, which generates (block 226 of <figref>Figure 5</figref>) an estimate 999 of the probability that the component 1 is damaged.</p><p><span class=\"paragraph-number\">[0044]   </span>Based on the estimate 999, the computer 16 detects (block 228, <figref>Figure 5</figref>) if the component 1 is healthy or damaged. For example, the calculator 16 detects the presence of a damage, if the estimate 999 is greater than or equal to a first threshold, whereas it detects that the component 1 is healthy if the estimate 999 is lower than the first threshold. Furthermore, in the event that the computer 16 has detected the presence of a damage, the computer 16 identifies (block 230, <figref>Figure 5</figref>) the damaged portion of the component 1, based on the mask 62; to this end, the computer 16 identifies as damaged portion of the component 1 the set of the portions of the component 1 that correspond to pixels of the mask 62 having values higher than a second threshold. For example, <figref>Figure 18</figref> shows a further example of the mask 62, in which a damaged zone 299 is highlighted, which is formed by pixels of the mask 62 exceeding the second threshold and thus corresponds to the damaged portion of the component 1; although in such an example the damaged zone 299 is formed by a single set of adjacent pixels, it is possible that the damaged zone 299 includes multiple damaged sub-zones, each of which is formed by a corresponding set of adjacent pixels of the mask 62, the damaged sub-zones being separated from each other. In <figref>Figure 18</figref> it is furthermore highlighted the correspondence between the damaged zone 299 and the damaged portion of the component 1, which is represented, in each of the processed images 30 of the multispectral image 25, by a corresponding set of pixels, denoted with 399, i.e. by a corresponding sub-portion of the processed image 30. In the following reference is made to the sets of pixels 399 as the single band representation 399 of the damaged zone 299. In the case (not shown) where the damaged zone 299 includes multiple separate sets of pixels, each single band representation 399 is also formed by multiple separate sets of pixels.</p><p><span class=\"paragraph-number\">[0045]   </span>In order to optimize performance, the first and second neural networks 40, 70 may be trained in the following manner, which assumes having a plurality of multispectral training images 125 (one shown schematically in <figref>Figure 10</figref>), each of which refers to a respective training component (not shown), not necessarily equal to the component 1, and is formed by a three-dimensional matrix having dimensions 9xNxM.</p><p><span class=\"paragraph-number\">[0046]   </span>In greater detail, each training multispectral image 125 is generated in the same manner as described with reference to the multispectral image 25 and refers to a component of an aircraft which may be of the same type as the aforementioned component 1 or may be a different component; moreover, the component to which each training multispectral image 125 refers may be healthy or may have one or more damaged portions. In addition, by indicating with TM the matrix of pixels of a generic multispectral training image 125 and assuming k=1, ..., 9, i=i* and j=j* (with i* an integer in the range [1-1200] and j* an integer in the range [1-1920]), the nine pixels TM[k,i*,j*] refer to a same portion of the training component to which the multispectral training image 125 refers.</p><p><span class=\"paragraph-number\">[0047]   </span>In detail, the multispectral training images 125 are divided in an arbitrary manner in order to form respectively a training set and a validation set. Next, the operations shown in <figref>Figure 11</figref> are performed.</p><p><span class=\"paragraph-number\">[0048]   </span>For each training multispectral image 125 of the training set, the computer 16 generates (block 300 of <figref>Figure 11</figref>) a corresponding reduced image 400. An example of a reduced image 400 is shown in <figref>Figure 12</figref>; by way of example only, the reduced image 400 shown in <figref>Figure 12</figref> refers to a training component whose preliminary image (denoted with 120) in the band centred on 490nm, which is part of the respective multispectral image 125, is shown in <figref>Figure 13</figref>.</p><p><span class=\"paragraph-number\">[0049]   </span>In greater detail, the reduced image 400 is obtained for example by performing down-sizing operations known per se, so that the reduced image 400 has the same dimensions as the mask 62 (in the present example N/8 × M/8). For example, by indicating with RED[i,j] the matrix of pixels of the reduced image 400 and by indicating with VIS[i,j] the matrix of pixels of the preliminary image 120, it is possible that the reduced image 400 is obtained by a so-called resizing based on a bilinear interpolation of the preliminary image 120. Thus, the reduced image 400 is a smaller version of the preliminary image 120 and remains intelligible to an observer. In this regard, the fact that the preliminary image 120 is in the band centred on 490nm is irrelevant; the preliminary image 120 may be in any one of the nine spectral bands.</p><p><span class=\"paragraph-number\">[0050]   </span>Thereafter, the computer 16 is commanded by a user so as to generate (block 302 of <figref>Figure 11</figref>), starting from each reduced image 400, a corresponding binary image 410, which has the same dimensions as the reduced image 400 (an example shown in <figref>Figure 14</figref>). In particular, each pixel of the binary image 410 is alternatively equal to `0' or '1', depending on whether the pixel of the binary image 410 refers to a respectively healthy or damaged portion of the training component.</p><p><span class=\"paragraph-number\">[0051]   </span>In greater detail, as visible in <figref>Figure 14</figref>, an observer may control the computer 16 so as to assign to sets of adjacent pixels of the binary image 410 the value '1', if the observer believes that such sets of pixels refer to damaged portions of the training component, the remaining pixels of the binary image 410 being set equal to '0'. In this way, if the training component is damaged, the binary image 410 has one or more damaged zones 412 (one indicated in <figref>Figure 14</figref>), i.e., groups of adjacent pixels with a value equal to '1', hereinafter referred to as the damaged training zones 412. The edges of each damaged training zone 412 are sharp, i.e. they are characterized by a transition from `1' to '0' between adjacent pixels.</p><p><span class=\"paragraph-number\">[0052]   </span>Subsequently, starting from each binary image 410, the computer 16 generates (block 304 of <figref>Figure 11</figref>) a corresponding smoothed image 420, an example of which, relative to the binary image 410 shown in <figref>Figure 14</figref>, is shown in <figref>Figure 15</figref>.</p><p><span class=\"paragraph-number\">[0053]   </span>In detail, for each binary image 410, the corresponding smoothed image 420 is the same as the binary image 410, if it is free of damaged training zones 412. Instead, if the binary image 410 comprises at least one damaged training zone 412, the computer 16 performs the following operations: processes the binary image 410 so as to enlarge the extension of each damaged training zone 412 (optional operation); and subsequently applies a Gaussian filter (e.g. having dimensions 7x7) to the previously processed binary image 410.</p><p><span class=\"paragraph-number\">[0054]   </span>For example, in order to enlarge the extension of each damaged training zone 412, the computer 16 may modify the arrangement of the relative edge, for example by setting equal to `1' the pixels of the binary image 410 that were previously equal to `0' and that are distant from the edge by a distance (measured according to a predetermined metric) not exceeding a distance threshold. For example, for a generic pixel, the distance may be calculated as the number of adjacent pixels defining the shortest path that connects the pixel with any pixel of the edge of the damaged training zone 412. For the purposes of this method, the processing operation to increase the extension of each damaged training zone 412 and the relative details are irrelevant. The Gaussian filtering operation may thus also be applied directly to the binary image 410. The same Gaussian filtering operation, which allows to minimize any labelling errors (i.e., assignment errors of the value '0' or of the value '1') at the edges of the damaged training zones 412, is however optional; variants are therefore possible in which, instead of the smoothed images 420, the binary images 410 are used. In addition, regardless of the possible enlargement of the damaged training zones 412 and/or the application of the Gaussian filter, it is possible that the binary images 410 are obtained starting from the corresponding preliminary images 120, instead of the corresponding reduced images 400, and subsequently are subjected to a down-sizing operation, so as to assume the same dimensions as the masks 62.</p><p><span class=\"paragraph-number\">[0055]   </span>Next, the first neural network 40 and the second neural network 70 are trained in a supervised manner.</p><p><span class=\"paragraph-number\">[0056]   </span>In particular, the computer 16 trains (block 306, <figref>Figure 11</figref>) the first and second neural networks 40 based on the training multispectral images 125, the corresponding smoothed images 420 and respective labels, which are alternatively equal to zero, if the smoothed image 420 is free of damaged zones, or it is equal to one, if the smoothed image 420 has at least one damaged zone.</p><p><span class=\"paragraph-number\">[0057]   </span>In greater detail, the training of the first and second neural networks 40, 70 may take place as described below and as shown in <figref>Figure 16</figref>. In particular, in a manner known per se, the training multispectral images 125 of the training set are subdivided into a set of training batches; such set of training batches forms an epoch; moreover, the operations performed for each training multispectral image 125 of each training batch are described below, unless otherwise specified, although such operations are performed for all training multispectral images 125 of the training batch.</p><p><span class=\"paragraph-number\">[0058]   </span>The computer 16 initializes in a manner known per se the values of the parameters of the first and second neural networks 40, 70 and subsequently applies (block 500, <figref>Figure 16</figref>) the first neural network 40 to the multispectral training image 125, so as to obtain a corresponding mask, referred to as the training mask 162 (one schematically shown in <figref>Figure 10</figref>). Furthermore, the computer 16 calculates (block 502, <figref>Figure 16</figref>) a corresponding error contribution, as a function of the difference between the training mask 162 and the corresponding smoothed image 420, which acts as a labelled training mask; in the following this error contribution is referred to as the segmentation error contribution. For example, the segmentation error contribution may be equal to the so-called focal loss calculated based on the smoothed image 420 and on the training mask 162; the adoption of a different metric is however possible.</p><p><span class=\"paragraph-number\">[0059]   </span>Subsequently, the computer 16 aggregates the training mask 162 with the feature matrix (not shown) provided by the first neural network 40 following application of the latter to the multispectral training image 125, in the same manner described with reference to block 216 of <figref>Figure 5</figref>, in order to obtain a corresponding updated matrix, referred to as the updated training matrix 165 (one shown in <figref>Figure 10</figref>). In addition, the computer applies (block 504, <figref>Figure 16</figref>) the second neural network 70 to the training mask 162 and to the updated training matrix 165, so as to obtain a corresponding estimate 1000 (shown in <figref>Figure 10</figref>) of the probability that the training component to which the training multispectral image 125 refers is damaged. Below reference is made to the estimate 1000 as the training estimate 1000.</p><p><span class=\"paragraph-number\">[0060]   </span>In a manner known per se, the computer 16 calculates (block 506, <figref>Figure 16</figref>) a further error contribution, as a function of the difference between the training estimate 1000 and the label relative to the multispectral training image 125. Below reference is made to this further error contribution as the decision error contribution. For example, the decision error contribution may be directly proportional to the difference between the aforementioned label and the training estimate 1000.</p><p><span class=\"paragraph-number\">[0061]   </span>Based on the decision error contributions and on the segmentation error contributions obtained for all training multispectral images 125 of the training batch, the computer 16 calculates (block 508, <figref>Figure 16</figref>) the value of an error function, described in greater detail below, and subsequently updates (block 510, <figref>Figure 16</figref>) the values of the parameters of the first and second neural networks 40, 70, as a function of the value of the error function.</p><p><span class=\"paragraph-number\">[0062]   </span>For example, in a manner known per se, updating the values of the parameters of the first and second neural networks 40, 70 may envisage calculating the gradient of the error function with respect to each parameter and subsequently updating the value of each parameter based on the corresponding gradient.</p><p><span class=\"paragraph-number\">[0063]   </span>As shown qualitatively in <figref>Figure 16</figref>, the computer may then iterate the operations referred to in blocks 500-510 for the multispectral training images 125 of the next training batch. Once the training batches are finished, the computer 16 calculates (block 512, <figref>Figure 16</figref>) an estimate of the goodness of the training, for example based on the multispectral images 125 of the aforementioned validation set, of the updated values of the parameters of the first and second neural networks 40, 70 and of a predetermined metric.</p><p><span class=\"paragraph-number\">[0064]   </span>Subsequently, as shown in <figref>Figure 17</figref>, once the training batches are finished, i.e. once the epoch is finished, the computer 16 updates (block 600, <figref>Figure 17</figref>) the error function, as explained in greater detail below, and reshuffle the multispectral training images 125 of the training set so as to form (block 602, <figref>Figure 17</figref>) a set of new training batches, which form a new epoch. Subsequently, the computer 16 iterates (block 604) the operations shown in <figref>Figure 16</figref>, based on the new training batches, at the end of which the computer 16 has updated values of the parameters of the first and second neural networks 40, 70 and of a corresponding estimate of the goodness of training of the first and second neural networks 40, 70.</p><p><span class=\"paragraph-number\">[0065]   </span>The operations referred to in blocks 600-604 are iterated a predetermined number of times and subsequently the computer 16 selects (block 606, <figref>Figure 17</figref>) the values of the parameters of the first and second neural networks 40, 70 that correspond to the best one among the previously calculated training goodness estimates.</p><p><span class=\"paragraph-number\">[0066]   </span>In more detail, with regard to the operations of updating the error function referred to in block 600, they may take place as follows.</p><p><span class=\"paragraph-number\">[0067]   </span>As described above, the operations at blocks 502, 506, and 508, relative to the calculation of segmentation error contributions, to the calculation of the decision error contributions, and to the calculation of the value of the error function, are iterated for each epoch. Furthermore, the error function updating operations at block 600 are such that the calculation of the value of the error function at block 508 is performed so as to vary, between one epoch and the next, the weights that, within the error function, are assigned to the corresponding segmentation error contributions and to the corresponding decision error contributions.</p><p><span class=\"paragraph-number\">[0068]   </span>For example, and without losing any generality, the calculation of the value of the error function mentioned about block 508 may be performed according to the function: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 67mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010623665&ekey=2254&cc=EP&producerName=imgb0001.tif&width=67mm&height=6mm\"/></maths></p><p> wherein: the index `e' indicates the epoch, 'b' indicates a generic training batch of the e-th epoch; f(CS<sub>b</sub>) indicates the value of a first predetermined function calculated based on the segmentation error contributions of the b-th training batch; f'(CD<sub>b</sub>) indicates the value of a second predetermined function calculated based on the decision error contributions of the b-th training batch; and λ<sub>e</sub> indicates a parameter, which may for example be initially equal to one and may subsequently be decreased at each epoch during the operations at block 600, so as to gradually increase the weight of the decision error contributions within the calculation of the value of the error function.</p><p><span class=\"paragraph-number\">[0069]   </span>In practice, the training described allows to avoid that the training, initially inaccurate, of the first neural network 40 negatively impacts the training of the second neural network 70, since the weight of the decision error contributions increases as the epochs elapse, i.e. as the training of the first neural network 40 improves.</p><p><span class=\"paragraph-number\">[0070]   </span>Variants are however possible in which the first and second neural networks 40, 70 are trained separately. In such a case, the first neural network 40 may be trained based on a first partial error function, which depends on the segmentation error contributions only. Once the training of the first neural network 40 is finished, and then once the values of the parameters of the first neural network 40 are established, the second neural network 70 is trained based on a second partial error function, which depends on decision error contributions only; moreover, during the training of the second neural network 70, the values of the parameters of the first neural network 40 do not change.</p><p><span class=\"paragraph-number\">[0071]   </span>Regardless of the implementation details relative to the training of the third neural network 75, understood as a set of the first and second neural networks 40, 70, the structure of the third neural network 75 causes the mask 62 provided by the first neural network 40 to provide a spatial indication of the arrangement, in the component 1, of portions that might be damaged, which are the portions of the component 1 relative to pixels of the mask 62 that exceed the aforementioned second threshold; such spatial and potential damaging indication is interpreted by the computer 16 in the light of the corresponding estimate 999, which confirms whether or not the portions of the component 1 indicated by the mask 62 are actually damaged.</p><p><span class=\"paragraph-number\">[0072]   </span>In other words, each pixel of the mask 62 represents a corresponding first-level estimate, which is indicative of a probability that the portion of the component 1 to which the pixel refers is damaged, said probability being estimated by the first neural network 40. The estimate 999 generated by the second neural network 70 represents a second-level estimate, which is indicative of a probability that the component 1 is damaged, i.e. has at least a damaged portion, said probability being precisely estimated by the second neural network 70. Accordingly, if the estimate 999 does not exceed the first threshold, the calculator 116 detects that the component 1 is healthy, regardless of the values of the pixels of the mask 62. In this way, the presence of the second neural network 70 allows to reduce the false positives generated by the first neural network 40.</p><p><span class=\"paragraph-number\">[0073]   </span>Furthermore, the fact that the mask 62 is provided in input to the second neural network 70 causes the information provided by the mask 62 relative to the portions of the component 1 that might be damaged to be weighed by the second neural network 70 and to thus contribute to the generation of the estimate 999, improving the accuracy of the latter.</p><p><span class=\"paragraph-number\">[0074]   </span>According to a variant of the present method, in case the computer 16 has detected, based on the estimate 999, the presence of a damage in the component 1, the computer 16 may perform the operations shown in <figref>Figure 19</figref>.</p><p><span class=\"paragraph-number\">[0075]   </span>In particular, the computer 16 calculates (block 700, <figref>Figure 19</figref>) a spectral signature of the damaged zone 299, and therefore of the damaged portion of the component 1. To this end, referring for example to the case shown in <figref>Figure 18</figref>, the computer 12 calculates, for each single band representation 399 of the damaged zone 299 of the mask 62, the corresponding mean of the values of the pixels of the single band representation 399; in the example shown in <figref>Figure 18</figref>, such means are denoted with C1, C2, C3..., C9. The set of the calculated nine means forms a vector VX, which is referred to as the spectral signature VX of the damaged portion of the component 1.</p><p><span class=\"paragraph-number\">[0076]   </span>In practice, the spectral signature VX depends on the reflectivity values in the spectral bands of the material forming the damaged portion of the component 1. Regarding such a material, it may for example be rust or a metallic material (e.g. steel), which, in the absence of damaging, is coated by a paint, but is exposed to the lighting beams due to the damaging (e.g. a scratch) to the component 1.</p><p><span class=\"paragraph-number\">[0077]   </span>Subsequently, the computer 16 identifies (block 702, <figref>Figure 19</figref>) the material of the damaged portion of the component 1, based on the spectral signature VX and a set of known spectral signatures.</p><p><span class=\"paragraph-number\">[0078]   </span>In particular, one or more known spectral signatures may have been obtained in the same manner described with reference to spectral signature VX, but relatively to training components with damaged portions formed from known material (e.g., rust or metallic materials). It is also possible that the set of known spectral signatures comprises differently generated spectral signatures; for example, it is possible that the nine values of a known spectral signature of a material (e.g., an oily material or a fat) are obtained by calculating the mean values of the processed images 30 of a sample of such known material.</p><p><span class=\"paragraph-number\">[0079]   </span>In practice, from a mathematical point of view, known spectral signatures form a sort of basis for the space of the spectral signatures. Consequently, the operations at block 702 may, for example, envisage carrying out a linear regression of the spectral signature VX, so as to obtain VX=α<sub>1</sub>*VN<sub>1</sub>+α<sub>2</sub>*VN<sub>2</sub>+... α<sub>u</sub>*VN<sub>u</sub>, wherein 'u' indicates the number of known spectral signatures, which are indicated by VN<sub>1</sub>, VN<sub>2</sub>,... VN<sub>u</sub>, while α<sub>1</sub>, ... α<sub>u</sub> indicate corresponding coefficients. The calculator 16 may then select, for example, the material relative to the known spectral signature having the highest coefficient α among the coefficients α<sub>1</sub>, ... α<sub>u</sub>.</p><p><span class=\"paragraph-number\">[0080]   </span>As still shown in <figref>Figure 19</figref>, the computer 16 may further signal (block 704, <figref>Figure 19</figref>) to a user, in a manner known per se, the identified material, to allow further assessments of the actual severity of the damaging by a user. It is also possible that, if the known spectral signatures do not comprise the spectral signature of the material in question, and therefore if the identification at block 702 is not reliable (for example because the coefficients a have approximately equal values to each other), the computer 16 signals this situation, so that further analysis is carried out.</p><p><span class=\"paragraph-number\">[0081]   </span>The advantages that this solution allows obtaining emerge clearly from the previous description.</p><p><span class=\"paragraph-number\">[0082]   </span>In particular, the present method makes it possible to detect the presence of surface defects of a component, under conditions of uncontrolled light. In addition, the present method has proved effective even in the presence of dirt or paint on the surface of the component.</p><p><span class=\"paragraph-number\">[0083]   </span>Still, this system is characterized by low costs and high automation possibilities.</p><p><span class=\"paragraph-number\">[0084]   </span>Finally, it is evident that modifications and variations can be made to the method and the system described and shown herein without, however, departing from the scope of the present invention, as defined in the appended Claims.</p><p><span class=\"paragraph-number\">[0085]   </span>For example, the number of spectral bands NUM_BW may differ from what described.</p><p><span class=\"paragraph-number\">[0086]   </span>The first and second neural networks 40, 70 may be different from those described; for example, they may include a different number of layers. In addition, the first and second neural networks 40, 70 may be trained differently from what described.</p><p><span class=\"paragraph-number\">[0087]   </span>In general, the generation of the multispectral images may differ from what described, in which case the generation of the training multispectral images adapts accordingly. It is also possible that the multispectral images are formed directly by the preliminary images, without further processing of the latter, although this may result in a reduction in accuracy.</p><p><span class=\"paragraph-number\">[0088]   </span>It is also possible that, in order to reduce the computational complexity, the values of N and M are reduced, in which case it is possible that, for each component to be analysed, it is necessary to acquire multiple multispectral images, which refer to different portions of the component; each multispectral image is however analysed in the same way as described above.</p><p><span class=\"paragraph-number\">[0089]   </span>In addition, the order in which some of the above-mentioned operations are performed may differ from what described.</p><p><span class=\"paragraph-number\">[0090]   </span>Finally, the present method and the present detection system can also be applied to mechanical components other than the mechanical components of an aircraft; for example, they can be applied for the structural monitoring of a wind turbine or of a civil infrastructure, and more generally for monitoring the health status of any mechanical part.</p>",
            "CLMS": "(EP4394693)<br/><p>1. A method implemented by computer (16) for detecting a damage to a component (1), comprising:<br/> - applying (212) a first neural network (40) to at least one multispectral image (25) of the component (1), formed by a plurality of images (30) of the component (1) in corresponding spectral bands, to generate a corresponding mask (62), which includes a respective plurality of pixels, each pixel of the mask (62) being relative to a corresponding portion of the component (1), the first neural network (40) being further configured such that each pixel of the mask (62) represents a corresponding first-level estimate, which is indicative of a probability that the portion of the component (1) to which the pixel refers is damaged;<br/>said method further comprising:<br/> - applying a second neural network (70) to a data structure (65) that is a function of the mask (62), to generate a second-level estimate (999), which is indicative of a probability that the component (1) is damaged; and<br/> - detecting (228) whether the component (1) is healthy or damaged, based on the second-level estimate (999).</p><p>2. The method according to claim 1, wherein applying (212) a first neural network (40) to at least one multispectral image (25) comprises generating a feature matrix (54) starting from the multispectral image (25); and wherein the first neural network (40) is configured such that the mask (62) is a function of the feature matrix (54); and wherein said data structure (65) is a function of the mask (62) and of the feature matrix (54).</p><p>3. The method according to claim 2, wherein the first neural network (40) comprises a number of respective convolutional layers (41,42,43,44) sequentially connected and configured to generate the feature matrix (54) starting from the multispectral image (25).</p><p>4. The method according to claim 2 or 3, wherein the first neural network (52) comprises a convolutional filter (52) configured to generate the mask (62) starting from the feature matrix (54).</p><p>5. The method according to any one of the preceding claims, wherein the second neural network (70) comprises:<br/> - a convolutional step (71,72,73,74), configured to generate a data matrix (84) as a function of the data structure (65);<br/> - a first pooling step (90,91) configured to generate a data vector (92,93) starting from the data matrix (84);<br/> - a second pooling step (94,95) configured to generate at least one numerical value (96,97) starting from the mask (62) ;<br/> - an aggregation step (98) configured to generate a macrovector (98) by aggregating the data vector (92,93) and said at least one numerical value (96,97); and<br/> - a fully connected step (99) configured to generate said second-level estimate (999), as a function of the macrovector (98).</p><p>6. The method according to any one of the preceding claims, further comprising, if it has been detected (228) that the component (1) is damaged, identifying (230) a damaged portion of the component (1), based on the mask (62).</p><p>7. The method according to claim 6 further comprising:<br/> - determining a damaged zone (299) of the mask (62), which is formed by the pixels of the mask (62) that respect a threshold condition, the damaged zone (299) corresponding, for each image (30) of the component (1), to a corresponding sub-portion (399) of the image (30);<br/> - calculating (700) a spectral signature of the damaged zone (299), the spectral signature being formed by a corresponding numerical vector (VX) including a value for each image (30), said value being a function of the pixels of the corresponding sub-portion (399) of the image (30); and<br/> - identifying (702) a material forming the damaged portion of the component (1), among a plurality of known materials, based on the spectral signature (VX) and on a plurality of known spectral signatures, which are relative to said known materials.</p><p>8. The method according to claim 7, wherein, for each image (30), the corresponding value of the numerical vector (VX) is equal to the mean of the pixels of the sub-portion (399) of the image (30).</p><p>9. The method according to any one of the preceding claims, wherein the first and second neural networks (40,70) have been trained based on multispectral training images (125) relative to training components, based on corresponding labelled training masks (420) and based on corresponding labels, each label indicating if the training component is healthy or damaged.</p><p>10. The method according to claim 9, wherein each labelled training mask (420) comprises respective pixels, each of which is relative to a corresponding portion of the corresponding training component and has a value that depends on whether the corresponding portion of the training component is healthy or damaged.</p><p>11. The method according to claim 10, wherein each labelled training mask (420) has dimensions equal to the mask (62) and is obtained by performing the operations of:<br/> - generating (303) a corresponding binary image (410), each pixel being alternatively equal to a first value (`0'), if the corresponding portion of the training component is healthy, or to a second value ('1'), if the corresponding portion of the training component is damaged; and<br/> - generating the labelled training mask (420) as a function of the binary image (410).</p><p>12. The method according to any one of claims 9 to 11, wherein the first and second neural networks (40,70) have respective parameters and have been trained by performing the step of forming (602) a succession of epochs of batches of training multispectral images (125) and, for each batch of each epoch:<br/> - applying (500) the first neural network (40) to each multispectral training image (125) of the batch, so as to obtain a corresponding training mask (162), and calculating (502) a corresponding segmentation error contribution, as a function of the training mask (162) and of the corresponding labelled training mask (420);<br/> - for each multispectral training image (125) of the batch, applying (504) the second neural network (70) to a training data structure (165) that is a function of the corresponding training mask (162), so as to generate a second-level training estimate (1000), which is indicative of a probability that the corresponding training component (125) is damaged, and calculating (506) a decision error contribution, as a function of the difference between the second-level training estimate (1000) and the corresponding label;<br/> - calculating (508) the value of an error function that depends on the decision error contributions and on the segmentation error contributions relative to the batch according to respective weights;<br/> - updating (510) the values of the parameters of the first and second neural networks (40,70) based on the calculated value of the error function;<br/>and wherein, during the succession of the epochs, the weight of the decision error contributions increases.</p><p>13. A processing system comprising means (16) configured to carry out the method according to any one of claims 1 to 12.</p><p>14. A system comprising:<br/> - the processing system (16) according to claim 13;<br/> - a lighting device (12) configured to illuminate the component (1) with lighting beams having wavelengths ranging, for each lighting beam, in a corresponding spectral band; and<br/> - an acquisition device (14), coupled to the processing system (16) and configured to acquire preliminary images (20) of the component (1), in corresponding spectral bands, said multispectral image (25) being a function of the preliminary images (20).</p><p>15. A computer program comprising instructions which, when the program is executed by a computer (16), cause the execution, by the computer (16), of the method according to any one of claims 1 to 12.</p><p>16. A computer medium readable by a computer (16), on which the computer program according to claim 15 is stored.</p>",
            "NPR": "1",
            "APID": "171019682",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G06N-003/045<br/>G06N-003/084<br/>G06T-007/00<br/>G06T-007/11",
            "ID": "110469676",
            "AB": "(EP4394693)<br/>Method implemented by computer (16) for detecting a damage to a component (1), including: applying (212) a first neural network (40) to at least one multispectral image (25) of the component (1), formed by a plurality of images (30) of the component (1) in corresponding spectral bands, to generate a corresponding mask (62), which includes a respective plurality of pixels, each pixel of the mask (62) being relative to a corresponding portion of the component (1), the first neural network (40) being further such that each pixel of the mask (62) represents a corresponding first-level estimate, which is indicative of a probability that the portion of the component (1) to which the pixel refers is damaged; applying a second neural network (70) to a data structure (65) that is a function of the mask (62), to generate a second-level estimate (999), which is indicative of a probability that the component (1) is damaged; and detecting (228) whether the component (1) is healthy or damaged, based on the second-level estimate (999).",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=WKcTA28FXZueccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2022-12-29",
            "PA": "LEONARDO",
            "PAAD": "(EP4394693)<br/>(PUB:EP-4394693A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/><br/>(WO2024141849)<br/>(PUB:WO-2024/141849A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 ROMA , POSTCODE=00195 , COUNTRY=IT<br/>",
            "FAN": "110469676",
            "TI": "Method and system for detecting surface damages to mechanical components, in particular components of aircraft, by multispectral image processing",
            "TECD": "Computer technology",
            "EPD": "2024-07-03",
            "ICLM": "(EP4394693)<br/><p>1. A method implemented by computer (16) for detecting a damage to a component (1), comprising: - applying (212) a first neural network (40) to at least one multispectral image (25) of the component (1), formed by a plurality of images (30) of the component (1) in corresponding spectral bands, to generate a corresponding mask (62), which includes a respective plurality of pixels, each pixel of the mask (62) being relative to a corresponding portion of the component (1), the first neural network (40) being further configured such that each pixel of the mask (62) represents a corresponding first-level estimate, which is indicative of a probability that the portion of the component (1) to which the pixel refers is damaged; said method further comprising: - applying a second neural network (70) to a data structure (65) that is a function of the mask (62), to generate a second-level estimate (999), which is indicative of a probability that the component (1) is damaged; and - detecting (228) whether the component (1) is healthy or damaged, based on the second-level estimate (999).</p>",
            "CTN": "(EP4394693)<br/>US20200175669 89081662 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>XP037053353 none WHO=EXAMINER SELF=N CAT=X CAT=I<br/>CN111325713 89393005 WHO=EXAMINER SELF=N CAT=X CAT=I<br/><br/>(WO2024141849)<br/>US20200175669 89081662 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>XP037053353 none WHO=EXAMINER SELF=N CAT=X CAT=I<br/>CN111325713 89393005 WHO=EXAMINER SELF=N CAT=X CAT=I",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2026-06-29",
                    "XAP": "2023WO-IB62864",
                    "APD": "2023-12-18",
                    "APID": "171028101",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2024141849&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=6DNzxrOiQ6Yk9Tjvv2KXa7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2024/141849",
                            "KIND": "A1",
                            "XPN": "WO2024141849",
                            "V_PNID": "WO-2024/141849A1-3",
                            "DATE": "2024-07-04",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDYG+fNjF0eB90P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2024141849&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=6DNzxrOiQ6Yk9Tjvv2KXa7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2042-12-29",
                    "XAP": "2022EP-0217219",
                    "APD": "2022-12-29",
                    "APID": "171019682",
                    "REG_LINK": "https://register.epo.org/application?number=EP22217219",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=WKcTA28FXZueccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4394693",
                            "KIND": "A1",
                            "XPN": "EP4394693",
                            "V_PNID": "EP-4394693A1-8",
                            "DATE": "2024-07-03",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x6Q+XtQs/xC8/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4394693&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=WKcTA28FXZueccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4394693_A1",
            "EPRD": "2022-12-29",
            "PN": "EP4394693           A1 2024-07-03 [EP4394693]<br/>WO2024/141849       A1 2024-07-04 [WO2024141849]",
            "ADB": "(EP4394693)<br/><p>In particular, the present method makes it possible to detect the presence of surface defects of a component, under conditions of uncontrolled light.</p><p>As is well known, the need to detect the presence of anomalies (in the sense of damages, also known as deteriorations) of mechanical components of aircraft in order to ensure flight safety is particularly felt in the aviation sector.</p><p>It is also possible that, if the known spectral signatures do not comprise the spectral signature of the material in question, and therefore if the identification at block 702 is not reliable (for example because the coefficients a have approximately equal values to each other), the computer 16 signals this situation, so that further analysis is carried out.</p><p>The acoustic inspection, also known as \"tapping test\", therefore requires the presence of trained personnel, provided with a corresponding technical preparation and considerable practical experience; moreover, this procedure cannot be automated and is inevitably subject to uncertainties linked to the skill of the personnel performing it and to human error.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=2<br/>PNAAGE=1<br/>NBPA=1; <br/>ALLCT=1; SCT=0; NSCT=1; <br/>ALLCTG=0; SCTG=0; NSCTG=0; <br/>AFS=2; ACC=1; AMCC=0; <br/>IMPI=0.0; MACI=0.79; PASI=0.98; PAVI=0.41; ",
            "PTCC": "(EP4375657)<br/>CC=EP EED=2042-11-28 STATUS=PENDING APID=170344506 APD=2022-11-28 XPN=EP4375657 PD=2024-05-29 EPD=2024-05-29 LPD=2024-05-29 <br/><br/>(WO2024116035)<br/>CC=WO EED=2026-05-28 STATUS=PENDING APID=170458022 APD=2023-11-23 XPN=WO2024116035 PD=2024-06-06 EPD=2024-06-06 LPD=2024-06-06 <br/>CC=EP EED=2043-11-23 STATUS=PENDING APID=170458022 XPN=WO2024116035 <br/>",
            "EPN": "EP4375657",
            "CTGN": "",
            "LAPD": "2023-11-23",
            "STDN": "",
            "NPN": "2",
            "DESC": "<p><heading><b><u>Technical field</u></b></heading></p><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and to a system for detecting anomalies of mechanical components, in particular aircraft components, by classifying spectrograms of acoustic signals.</p><p><heading><b><u>Background</u></b></heading></p><p><span class=\"paragraph-number\">[0002]   </span>As is known, in the aeronautical field the need is particularly felt to detect the presence of anomalies (understood as damage or defects) of aircraft mechanical components, in order to ensure the safety of flights. To such end, for example, the so-called non-destructive controls are known, which allow evaluating the general conditions of the components of an aircraft in a relatively short time.</p><p><span class=\"paragraph-number\">[0003]   </span>For example, some non-destructive controls provide for the research of possible anomalies of the components of an aircraft to be carried out by highly specialized personnel that carries out a visual and/or acoustic inspection of the components.</p><p><span class=\"paragraph-number\">[0004]   </span>In particular, in the case of acoustic inspection, the component under examination is repeatedly hit with a mechanical striking tool (for example, a hammer made of aluminium), so as to generate an acoustic response to the striking. On the basis of such acoustic response, as perceived by ear, the person in charge of the inspection can detect, on the basis of his/her experience, the possible presence of an anomaly of the component (for example, a portion of fuselage or a blade of a helicopter), such as for example the presence of an unbonded area or a delamination.</p><p><span class=\"paragraph-number\">[0005]   </span>Therefore, the acoustic inspection, also known as tapping test, requires the presence of trained personnel, provided with a corresponding technical preparation and with a remarkable practical experience. Furthermore, such procedure cannot be automated and is inevitably subject to uncertainties connected to the ability of the personnel carrying it out and to human error. To such regard, for example, it is possible for human factors (tiredness, distraction, etc.) or environmental conditions (for example, the presence of background noises) to negatively influence the capability of the personnel in charge of the inspection to detect anomalies.</p><p><heading><b><u>Summary</u></b></heading></p><p><span class=\"paragraph-number\">[0006]   </span>The object of the present invention is thus to provide a solution that overcomes at least in part the drawbacks of the prior art.</p><p><span class=\"paragraph-number\">[0007]   </span>According to the present invention a method and a system for detecting anomalies are provided, as defined in the appended claims.</p><p><heading><b><u>Brief description of the figures</u></b></heading></p><p><span class=\"paragraph-number\">[0008]   </span>In order to better understand the present invention, embodiments thereof will now be described, by way of mere non-limiting example, with reference to the accompanying drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1</figref> shows a front view of a part of a component of an aircraft;</li><br/><li> <figref>Figure 2</figref> shows a block diagram of a system for detecting anomalies;</li><br/><li> <figref>Figure 3</figref> shows block diagrams of convolutional neural networks;</li><br/><li> <figref>Figures 4</figref>, <figref>9</figref> and <figref>11</figref> show flow diagrams of training operations according to the present method;</li><br/><li> <figref>Figure 5</figref> shows an enlarged front view of a portion of the part of component shown in <figref>Figure 1</figref>;</li><br/><li> <figref>Figure 6</figref> shows a representation of a spectrogram;</li><br/><li> <figref>Figure 7</figref> shows a flow diagram of operations for generating spectrograms;</li><br/><li> <figref>Figure 8</figref> shows a scheme of the structure of a spectrogram;</li><br/><li> <figref>Figure 10</figref> shows a scheme of a confusion matrix; and</li><br/><li> <figref>Figure 12</figref> shows a flow diagram of operations according to the present method.</li></ul></p><p><heading><b><u>Description of embodiments</u></b></heading></p><p><span class=\"paragraph-number\">[0009]   </span>The present method for detecting anomalies of a component of an aircraft is described, by way of example, with reference to the component 1 shown in <figref>Figure 1</figref> and to the detection system 10 shown in <figref>Figure 2</figref>, which is shown as operating, for example, on the component 1; as is specifically explained in the following, the detection system 10 comprises a striking device 12, a microphone 14 and a computer 16.</p><p><span class=\"paragraph-number\">[0010]   </span>That having been said, the present method for detecting anomalies provides for having a multiclass classifier 50 (shown in <figref>Figure 3</figref>), which in the following is referred to as the zone classifier 50, and a plurality of classifiers 70 (one shown in <figref>Figure 3</figref>), which in the following are referred to as the binary classifiers 70, since they are configured to classify on two classes, as is explained in the following.</p><p><span class=\"paragraph-number\">[0011]   </span>The zone classifier 50 and the binary classifiers 70 may be trained in the manner described with reference to <figref>Figure 4</figref>.</p><p><span class=\"paragraph-number\">[0012]   </span>Specifically, the training of the zone classifier 50 provides for having a plurality of components identical to the component 1, without deteriorations, and which in the following are referred to as the training components. Furthermore, as is shown in <figref>Figure 4</figref>, the training provides for determining (block 100, <figref>Figure 4</figref>) a plurality of portions 2 (visible in <figref>Figure 1</figref>) of the component 1, which in the following are referred to as the subregions 2.</p><p><span class=\"paragraph-number\">[0013]   </span>Practically, the component 1 is divided into the subregions 2, each one of which has a respective outer surface S<sub>2</sub>, which in the following is referred to as the subregion surface S<sub>2</sub>. Without any loss of generality, the subregions 2 are adjacent to one another and not overlapped, so that, referring to the outer surface S<sub>1</sub> for indicating the overall outer surface of the component 1, each point of the outer surface S<sub>1</sub> belongs to a corresponding subregion surface S<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0014]   </span>More specifically, the division of the component 1 into the respective subregions 2 may occur, for example, on the basis of the inner structure of the component 1, for example so that, considering any subregion 2 and referring to the cross-sections thereof for indicating the cross-sections of the subregion 2 taken along planes perpendicular to a same direction of reference, such cross-sections are identical to one another. Still by way of mere example, in the case when the component 1 is formed by different lattice structures (not shown) covered by a metal surface, one or more subregions 2 may be delimited so that each one covers a corresponding lattice structure. Still by way of example, it is possible for one or more subregions 2 to be delimited depending on the shape of the component 1, for example so that the edges of the subregion 2 coincide with regions where a thickness variation of the component 1 or a camber variation of the outer surface S<sub>1</sub> of the component 1 occurs. Generally, however, the criteria adopted for determining the boundaries of the subregions 2 of the component 1 can be different with respect to what described and are irrelevant for the implementation of the present method. Furthermore, since the training components are identical to the component 1, the division into the subregions 2 is also applied to each training component.</p><p><span class=\"paragraph-number\">[0015]   </span>The subregions 2 are stored in the computer 16 and are for example in a number equal to NUM_SUBREG.</p><p><span class=\"paragraph-number\">[0016]   </span>Subsequently, the outer surface S<sub>1</sub> is divided into a set of respective subportions 6, which in the following are referred to as the base areas 6. In particular, a grid 8 formed by the base areas 6 (a portion of grid is qualitatively shown in <figref>Figure 5</figref>) is determined (block 102, <figref>Figure 4</figref>); by way of mere example, each base area 6 may have an extension equal to approximately 1cm<sup>2</sup>.</p><p><span class=\"paragraph-number\">[0017]   </span>More specifically, even if in <figref>Figure 5</figref> the grid 8 of base areas 6 extends only on part of the outer surface S<sub>1</sub> of the component 1, the grid 8 of base areas 6 fully covers the outer surface S<sub>1</sub>. Furthermore, even if in <figref>Figure 5</figref> the base areas 6 are shown as having an approximately square shape and are arranged so as to form a matrix, they may have a different shape, besides shapes different from one another; also the arrangement of the base areas 6 may be different. In first approximation, and for the purposes of the present method, the base areas 6 are comparable to punctiform areas and can be struck individually.</p><p><span class=\"paragraph-number\">[0018]   </span>Since the training components are identical to the component 1, the grid 8 of base areas 6 also applies to the outer surface of each training component.</p><p><span class=\"paragraph-number\">[0019]   </span>That having been said, for each one of the above-mentioned training components, a corresponding plurality of spectrograms (an example is shown in <figref>Figure 6</figref>) is generated (block 104, <figref>Figure 4</figref>) for each one of the subregions 2, as is described in the following.</p><p><span class=\"paragraph-number\">[0020]   </span>Specifically, for each training component, and for each subregion 2 of the training component, for each base area 6 that belongs to the subregion 2 the operations shown in <figref>Figure 7</figref> are performed.</p><p><span class=\"paragraph-number\">[0021]   </span>In particular, the base area 6 is struck (block 200, <figref>Figure 7</figref>) by the striking device 12, so as to generate a corresponding acoustic signal, which is acquired (block 202, <figref>Figure 7</figref>) by means of the microphone 14.</p><p><span class=\"paragraph-number\">[0022]   </span>More specifically, the acoustic signal extends on a corresponding time interval having a duration T (for example equal to two seconds), identical for all the acoustic signals; furthermore, the base area 6 is struck for example periodically, with a frequency equal to 3Hz. Optionally, the acoustic signals may be acquired in a synchronous manner by striking the respective base areas 6, so that, during each time interval of an acoustic signal, a same number of strikes of the base area 6 takes place; optionally, the time arrangement of the strikes may be the same for all the acoustic signals. In other words, the acoustic signal is acquired during the periodic striking of the base area 6.</p><p><span class=\"paragraph-number\">[0023]   </span>By way of example, the acquisition of each acoustic signal provides for the sampling (for example, with a precision of sixteen bits per sample) of the acoustic signal with a sampling frequency for example equal to 44kHz. Consequently, in a manner known per se the acquisition of each acoustic signal entails the transduction of the acoustic signal in a corresponding electric signal and the sampling of the electric signal, therefore it entails the generation of a sampled electric signal, whose samples represent corresponding samples of the acoustic signal.</p><p><span class=\"paragraph-number\">[0024]   </span>Subsequently, in a manner known per se, the computer 16 calculates (block 204, <figref>Figure 7</figref>), for each acquired acoustic signal, the corresponding spectrogram, on the basis of the corresponding sampled electric signal.</p><p><span class=\"paragraph-number\">[0025]   </span>As is qualitatively shown in <figref>Figure 8</figref>, each spectrogram is formed by a value matrix; each row of the spectrogram refers to a corresponding spectral interval (two indicated by Δf<sub>1</sub> and Δf<sub>n</sub> respectively), whereas each column refers to a corresponding time sub-interval of the time interval on which the acoustic signal extends. The time sub-intervals of the time interval on which the acoustic signal extends may have a same duration Δt, for example equal to 40ms; the spectral intervals may be non-uniform, therefore they may be generated on the basis for example of a logarithmic curve, instead of a linear curve.</p><p><span class=\"paragraph-number\">[0026]   </span>Given a column of the spectrogram, each value of the column is indicative of the energy content of the portion of acoustic signal relative to the corresponding time sub-interval that falls within the corresponding spectral interval. For example, the values of each column of the spectrogram are equal to the modulus of the samples of the discrete Fourier transform of the samples of the sampled electric signal that fall within the corresponding time sub-interval; it is further possible, in each column of the spectrogram, for each element of the column to be obtained as the result of a numeric filtering of several (for example, three) adjacent samples of the above-mentioned discrete Fourier transform.</p><p><span class=\"paragraph-number\">[0027]   </span>By way of example, the spectrograms may be the so-called MEL spectrograms.</p><p><span class=\"paragraph-number\">[0028]   </span>Still with reference to <figref>Figure 4</figref>, the computer 16 stores (block 106, <figref>Figure 4</figref>) the spectrograms and the association present between each spectrogram and the corresponding subregion 2, i.e. the subregion 2 to which the base area 6, which has been struck during the acquisition of the acoustic signal to which the spectrogram refers, belongs. Practically, the computer 16 stores, for each spectrogram, a corresponding label, which represents a corresponding class which indicates the subregion 2 to which the spectrogram refers.</p><p><span class=\"paragraph-number\">[0029]   </span>Then, the computer 16 trains (block 108, <figref>Figure 4</figref>) the zone classifier 50, on the basis of the spectrograms and of the relative labels, in a supervised manner. As is explained more specifically in the following, the zone classifier 50 is a multiclass classifier; for example, the zone classifier 50 is a convolutional neural network, as is shown in <figref>Figure 3</figref>.</p><p><span class=\"paragraph-number\">[0030]   </span>Specifically, the zone classifier 50 comprises a feature extraction stage 52, which includes a sequence of one or more hidden layers; in particular, by way of mere example, <figref>Figure 3</figref> shows a first hidden layer and a second hidden layer, indicated by 54 and 54' respectively. Furthermore, both the first and the second hidden layers 54, 54' comprise a respective convolution stage (indicated by 56 and 56' respectively) and a subsequent respective pooling stage (indicated by 58 and 58' respectively).</p><p><span class=\"paragraph-number\">[0031]   </span>The convolution stages 56, 56' are configured to perform, starting from the data present on the respective inputs, convolution, activation and (optionally) normalization operations, on the basis of respective filters, in a manner known per se. In particular, the convolution stage 56 of the first hidden layer 54 receives at the input single spectrograms, whereas the convolution stage 56' of the second hidden layer 54' receives at the input the output of the pooling stage 58 of the first hidden layer 54. To such regard, the pooling stages 58, 58' are configured to perform pooling operations on the outputs of the corresponding convolution stages 56, 56'.</p><p><span class=\"paragraph-number\">[0032]   </span>The feature extraction stage 52 further comprises a flatten layer 60, which is configured to perform flattening operations on the output of the pooling stage 58' of the second hidden layer 54'.</p><p><span class=\"paragraph-number\">[0033]   </span>The zone classifier 50 further comprises a fully connected layer 61, shown in a simplified and qualitative manner, which receives the output of the flatten layer 60 and classifies it on a number of classes equal to the number NUM_SUBREG of subregions 2; each class is thus associated with a corresponding subregion 2. For simplicity of display, in <figref>Figure 3</figref> a number NUM_SUBREG of subregions 2 equal to four was assumed; the four subregions 2 are indicated by SUBREGION A, SUBREGION B, SUBREGION C, SUBREGION D.</p><p><span class=\"paragraph-number\">[0034]   </span>Specifically, the training of the zone classifier 50 may occur as is shown in <figref>Figure 9</figref>.</p><p><span class=\"paragraph-number\">[0035]   </span>In particular, starting from the spectrograms relative to the training components stored in the computer 16, the computer 16 selects (block 300, <figref>Figure 9</figref>) a first subset, a second subset and a third subset, which may be disjoined from one another, i.e. may not share any spectrogram. In the following, reference is made to the first, to the second and to the third subsets of spectrograms as the training set, the validation set and the test set respectively.</p><p><span class=\"paragraph-number\">[0036]   </span>Subsequently, on the basis of the training set and of the relative labels, the computer 16 performs (block 302, <figref>Figure 9</figref>) a training of the zone classifier 50. Such training occurs in a manner known per se and is of supervised type, as is mentioned in the foregoing. For example, the training may provide for iterating sequences of operations of:</p><p><ol compact=\"compact\"><li> i) updating the values of the parameters of the zone classifier 50 (understood as the weights and the biases of the filters of the convolution stages 56, 56' and of the fully connected layer 61), on the basis of at least part of the spectrograms of the training set, of the relative labels and of the so-called hyperparameters of the zone classifier 50, such as for example the so-called learning rate or the type of activation function;</li><br/><li> ii) classifying, on the basis of the updated values of the parameters of the zone classifier 50, the spectrograms of the validation set;</li><br/><li> iii) checking the respect, by the classifications of the spectrograms of the validation set, of a predetermined stop condition, of known type; and</li><br/><li> iv) in case of lack of respect of the stop condition, changing of the value of at least one hyperparameter and iteration of the previous operations i-iii).</li></ol></p><p><span class=\"paragraph-number\">[0037]   </span>The iteration of the above-mentioned sequences of operations thus ends when the classifications of the validation set respect the stop condition. For example, the stop condition may take place when an error function, indicative of the differences between the classifications of the spectrograms of the validation set and the actual classes goes below a pre-established threshold.</p><p><span class=\"paragraph-number\">[0038]   </span>Then, the computer 16 applies (block 304, <figref>Figure 9</figref>) the zone classifier 50, as obtained following the operations mentioned in block 302 (therefore, with the values of the respective parameters as available at the end of the operations mentioned in block 302) to the spectrograms of the test set, so as to classify them.</p><p><span class=\"paragraph-number\">[0039]   </span>Furthermore, the computer 16 calculates (block 306, <figref>Figure 9</figref>) the confusion matrix of the classifications obtained by means of the operations mentioned in block 304.</p><p><span class=\"paragraph-number\">[0040]   </span>The confusion matrix has dimensions NUM_SUBREG x NUM_SUBREG. By way of mere example, <figref>Figure 10</figref> shows an example of confusion matrix relative to the case NUM_SUBREG=4, where the classes are indicated by 1, 2, 3, 4 respectively; the elements are indexed as CM<sub>ij</sub>, where 'i' indicates the row and 'j' indicates the column; furthermore, the rows of the confusion matrix represent the so-called ground truth, i.e. the actual classes of the spectrograms, understood as the subregions 2 to which the spectrograms actually refer, whereas the columns represent the classification obtained through the zone classifier 50. In other words, the element CM<sub>ij</sub> represents the number of spectrograms relative to the i-th subregion 2 classified as relative to the j-th subregion 2, therefore it is indicative of a probability of the zone classifier 50 to confuse the i-th subregion 2 with the j-th subregion 2.</p><p><span class=\"paragraph-number\">[0041]   </span>On the basis of the confusion matrix, the computer 16 detects (block 308, <figref>Figure 9</figref>) the possible presence of one or more N-tuples (with N integer greater or equal to two) of classes such that, for each N-tuple, the numbers of spectrograms associated with the classes of the N-tuple that have been classified in a confused manner with respect to one another, i.e. the values of the elements CM<sub>ij</sub> with 'i' and 'j' different from one another and indicative of classes of the N-tuple, respect an aggregation criterion.</p><p><span class=\"paragraph-number\">[0042]   </span>For example, the computer 16 may analyse the confusion matrix by rows, initially assuming that the classes do not form any N-tuple. That having been said, considering the i-th class (with 'i' assuming in succession the values 1, 2, 3 and 4), the computer 16 detects if the i-th class already belongs to an N-tuple, in which case it increases the value of 'i' by one, so as to analyse the following row, and thus the following class, otherwise, before increasing the value of 'i', the computer 16 checks if there is one or more m-th classes (with 'm' different from `i') such that CM<sub>im</sub> &gt; TH (with TH indicating a threshold value), in which case the computer 16 alternatively:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> if none of such m-th classes already belongs to a previously detected N-tuple, associates the i-th class to such m-th classes, so that the i-th class forms, together with such m-th classes, a new N-tuple of classes; or</li><br/><li> if one or more of such m-th classes belong to already previously detected N-tuples, associates the i-th class to one of such already previously detected N-tuples, increasing by one the dimension of such N-tuple; in particular, in case such already previously detected N-tuples are in a number greater than one, the computer 16 may choose with which of such already detected N-tuples to associate the i-th class (for example, it may select the N-tuple with more classes, so as to maximise the dimensions of the N-tuples, or the N-tuple which includes the m-th class so that CM<sub>im</sub> assumes the maximum value).</li></ul></p><p><span class=\"paragraph-number\">[0043]   </span>In any case, the criteria for determining the dimensions of the N-tuples and of the classes forming them may vary with respect to what described. For example, the confusion matrix may be analysed by the computer 16 in a different manner with respect to what described. Furthermore, variations are possible in which the N-tuples of classes are determined assuming that the confusion matrix is in first approximation symmetric, in which case the computer 16 may analyse only a subset of the confusion matrix. Furthermore, variations are possible so that the number N is predefined; for example, if N=2, it is possible, considering a u-th class and a p-th class, for the computer 16 to detect a pair of classes if the element CM<sub>up</sub> and/or the element CM<sub>pu</sub> of the confusion matrix exceed the threshold value.</p><p><span class=\"paragraph-number\">[0044]   </span>Subsequently, for each N-tuple of classes detected during the operations mentioned in block 308, the computer 16 aggregates (block 310, <figref>Figure 9</figref>) the classes of the N-tuple; in other words, the computer 16 aggregates the subregions 2 (in a number equal to N) associated with the classes of the N-tuple, so as to form a single region (understood as aggregation of subregions), which is associated (block 312, <figref>Figure 9</figref>) by the computer 16 with a corresponding label, i.e. a corresponding class. For example, <figref>Figure 3</figref> qualitatively shows the aggregation of the classes relative to the SUBREGION A and to the SUBREGION B.</p><p><span class=\"paragraph-number\">[0045]   </span>Then, on the basis of the subregions 2 and of the possible aggregations carried out during the operations mentioned in block 310, the computer identifies (block 314, <figref>Figure 9</figref>) a plurality of zones 9 (shown in <figref>Figure 4</figref>) of the component 1, which are stored by the computer 16.</p><p><span class=\"paragraph-number\">[0046]   </span>In particular, each subregion 2 that has not been aggregated during the operations mentioned in block 310 forms a corresponding zone 9, which is associated with the label of the subregion 2; furthermore, each set of subregions 2 aggregated to one another forms a corresponding zone 9, which is associated with the label of the aggregation of subregions 2.</p><p><span class=\"paragraph-number\">[0047]   </span>By way of mere example, <figref>Figure 5</figref> highlights a first zone (indicated by 9'), which coincides with a corresponding subregion 2 which has not undergone any aggregation, and a second zone (indicated by 9\"), which coincides with the aggregation of a corresponding pair of subregions 2. Still by way of example, <figref>Figure 3</figref> shows how the aggregation of the classes relative to the SUBREGION A and to the SUBREGION B leads to the definition of a class relative to a ZONE A, whereas the classes of the SUBREGIONS C and D coincide with the classes of a ZONE C and of a ZONE D respectively.</p><p><span class=\"paragraph-number\">[0048]   </span>The aggregation of the classes mentioned in block 310 enables the fully connected layer 61 of the zone classifier 50 to classify on a set of classes equal to the number of zones 9, which in the following is referred to as the number NUM_Z. Practically, the zone classifier 50 is initially configured to classify on a number of classes (which are also referred to as the subregion classes) equal to the number NUM_SUBREG of subregions 2; following the aggregation of the classes mentioned in block 310, the zone classifier 50 is configured to classify on a number of classes (which are also referred to as the zone classes) equal to the number NUM_Z.</p><p><span class=\"paragraph-number\">[0049]   </span>For practical purposes, the zones 9 of the component 1 are regions of the component 1, each one of which generates, when mechanically struck in a respective base area 6, an acoustic signal whose spectrogram can be classified by the zone classifier 50 as relative to an acoustic signal generated by striking a portion of the region.</p><p><span class=\"paragraph-number\">[0050]   </span>The training of the zone classifier 50 is thus ended.</p><p><span class=\"paragraph-number\">[0051]   </span>Again with reference to <figref>Figure 4</figref>, once ended the operations mentioned in block 108, the computer 16 trains (block 110) the above-mentioned binary classifiers 70, which are in a number equal to NUM_Z; each binary classifier 70 is thus associated with a corresponding zone 9 of the component 1.</p><p><span class=\"paragraph-number\">[0052]   </span>As more specifically explained in the following, each binary classifier 70 is trained so as to classify spectrograms generated by striking the corresponding zone 9, so that the classification alternatively indicates if the zone 9 is undamaged or damaged.</p><p><span class=\"paragraph-number\">[0053]   </span>Specifically, considering a generic binary classifier 70, associated with a k-th zone 9 of the component 1, the computer 16 performs the operations shown in <figref>Figure 11</figref>.</p><p><span class=\"paragraph-number\">[0054]   </span>The computer 16 selects (block 400, <figref>Figure 11</figref>) the spectrograms of the above-mentioned training set relative to the k-th zone 9, which form a set of first training observations, and furthermore selects the spectrograms of the training set relative to zones 9 different from the k-th zone 9, which form a set of second training observations. As specifically explained in the following, the acoustic signals coming from zones 9 different from the k-th zone 9 are considered as generated by damaged versions of the k-th zone 9, so as to obviate the difficulty of finding real damaged versions of the k-th zone 9. Variations are anyway possible in which the set of second training observations also, or exclusively, comprises spectrograms obtained starting from acoustic signals generated by one or more damaged versions of the k-th zone 9, i.e. by components in which the k-th zone is damaged, and/or spectrograms obtained starting from acoustic signals generated by one or more damaged versions of w-th zones 9 (with w different from k), i.e. by components in which the w-th zone is damaged. Furthermore, the computer 15 selects (block 402, <figref>Figure 11</figref>) the spectrograms of the above-mentioned validation set relative to the k-th zone 9, which form a set of first validation observations, and furthermore selects the spectrograms of the validation set relative to zones 9 different from the k-th zone 9, which form a set of second validation observations. Variations are anyway possible in which the set of second validation observations also, or exclusively, comprises spectrograms obtained starting from acoustic signals generated by one or more damaged versions of the k-the zone 9 and/or by one or more damaged versions of w-th zones 9 (with w different from k), i.e. by components in which the w-th zone is damaged.</p><p><span class=\"paragraph-number\">[0055]   </span>Then, the computer 16 initialises (block 404, <figref>Figure 11</figref>) the binary classifier 70, which, as is shown in <figref>Figure 3</figref>, is formed by a convolutional neural network and includes a respective feature extraction stage 72 and at least one fully connected layer 81, which includes two output nodes, associated with the \"undamaged zone\" class and with the \"damaged zone\" class respectively.</p><p><span class=\"paragraph-number\">[0056]   </span>In particular, the binary classifier 70 is initialised so that the respective feature extraction stage 72 is identical to the feature extraction stage 52 of the zone classifier 50. In other words, the feature extraction stage 72 of the binary classifier 70 has the same structure of the feature extraction stage 52 of the zone classifier 50; furthermore, the initial values of the parameters (i.e. of the weights and of the biases of the filters) of the feature extraction stage 72 of the binary classifier 70 are equal to the values of the corresponding parameters of the feature extraction stage 52 of the zone classifier 50.</p><p><span class=\"paragraph-number\">[0057]   </span>The fully connected layer 81 of the binary classifier 70 may be initialised in a manner known per se, irrespective of the fully connected layer 61 of the zone classifier 50.</p><p><span class=\"paragraph-number\">[0058]   </span>Practically, the binary classifiers 70 are initialised in an identical manner, irrespective of the zones 9 of the component 1 to which they refer.</p><p><span class=\"paragraph-number\">[0059]   </span>Again with reference to <figref>Figure 11</figref>, after initialising the binary classifier 70, the computer 16 trains (block 406, <figref>Figure 11</figref>) the binary classifier 70, associating with the first training and validation observations a first class, indicative of the fact that the spectrogram relates to an undamaged version of the zone to which the binary classifier 70 refers, and associating with the second training and validation observations a second class, indicative of the fact that the spectrogram relates to a damaged version of the zone to which the binary classifier 70 refers.</p><p><span class=\"paragraph-number\">[0060]   </span>The training enables the feature extraction stage 72 of the binary classifier 70 to differentiate the values of the respective parameters from the values of the parameters of the feature extraction stage 52 of the zone classifier 50.</p><p><span class=\"paragraph-number\">[0061]   </span>Practically, the Applicant observed that, by initialising the binary classifiers 70 as is described in the foregoing, it is possible to improve the relative performances, with regard to the actual capability to distinguish between an undamaged zone and a damaged zone. Variations are anyway possible in which the binary classifiers 70 are initialised in a manner known per se, irrespective of the zone classifier 50.</p><p><span class=\"paragraph-number\">[0062]   </span>Once the zone classifier 50 and the binary classifiers 70 have been trained, it is possible to use the detection system 10 for detecting the possible presence of anomalies in an unknown component of the same type of the component 1, but of which it is not known a priori if it is undamaged or damaged. To such end, the operations shown in <figref>Figure 12</figref> are performed.</p><p><span class=\"paragraph-number\">[0063]   </span>Specifically, the striking device 12 is actuated so as to strike (block 500, <figref>Figure 12</figref>) a base area 6 of the unknown component, which in the following is referred to as the unknown area, so as to generate a corresponding acoustic signal which is acquired (block 502, <figref>Figure 12</figref>) by the computer 16 through the microphone 14; on the basis of the acquired acoustic signal, the computer 16 calculates (block 504, <figref>Figure 12</figref>) the corresponding spectrogram, which in the following is referred to as the unknown spectrogram, since the state (undamaged/damaged) of the unknown area is not known a priori; furthermore, in the following reference is made to the unknown zone to refer to the zone 9 of the unknown component to which the unknown area belongs.</p><p><span class=\"paragraph-number\">[0064]   </span>Subsequently, the computer 16 applies (block 506, <figref>Figure 12</figref>) to the unknown spectrogram the zone classifier 50, so as to classify the unknown zone. Practically, the zone classifier 50 allows identifying, between the zones 9 of the component 1, the zone 9 that corresponds to the unknown zone.</p><p><span class=\"paragraph-number\">[0065]   </span>Then, the computer 16 selects (block 507, <figref>Figure 12</figref>), between the binary classifiers 70, the binary classifier 70 relative to the identified zone.</p><p><span class=\"paragraph-number\">[0066]   </span>Then, the computer 16 applies (block 508, <figref>Figure 12</figref>) to the unknown spectrogram the selected binary classifier 70, which alternatively classifies the unknown spectrogram as i) belonging to the respective first class, which indicates that the unknown spectrogram relates to an acoustic signal generated by striking an undamaged version of the identified zone 9, or as belonging to the respective second class, which indicates that the unknown spectrogram relates to an acoustic signal generated by striking a damaged version of the identified zone 9.</p><p><span class=\"paragraph-number\">[0067]   </span>In the case when the spectrogram has been classified as belonging to the second class, the computer 16 detects (block 510, <figref>Figure 12</figref>) the presence of an anomaly, i.e. of a damage/deterioration, in the unknown zone of the unknown component; in such case, in a manner known per se the computer 16 may generate a corresponding signalling.</p><p><span class=\"paragraph-number\">[0068]   </span>By iterating the operations shown in <figref>Figure 12</figref> in different base areas 6 and in different zones 9 of the unknown component, it is possible to detect the possible presence of anomalies in each zone 9 of the unknown component.</p><p><span class=\"paragraph-number\">[0069]   </span>In particular, in the case when all the spectrograms relative to a zone 9 of the unknown component have been classified as belonging to the respective first class, the zone 9 is undamaged; alternatively, if one or more of the spectrograms relative to the zone 9 of the unknown component have been classified as belonging to the respective second class, the zone is damaged.</p><p><span class=\"paragraph-number\">[0070]   </span>In the case when, given a zone 9, spectrograms relative only to a subset of the base areas 6 of the zone 9 are classified, the precision of the detection can decrease.</p><p><span class=\"paragraph-number\">[0071]   </span>The advantages that the present solution allows obtaining clearly emerge from the preceding description.</p><p><span class=\"paragraph-number\">[0072]   </span>In particular, the present method allows automating the detection of anomalies of aircraft mechanical components, as well as localising possible anomalies at the level of single zones of the mechanical components. Still, the present method allows excluding the presence of a trained operator.</p><p><span class=\"paragraph-number\">[0073]   </span>Finally, it is clear that modifications and variations can be made to the method and to the system for detecting anomalies as described and illustrated herein, without thereby departing from the scope of protection of the present invention, as defined in the appended claims.</p><p><span class=\"paragraph-number\">[0074]   </span>For example, the zone classifier and/or the binary classifiers can be formed by classifiers of different type with respect to what described.</p><p><span class=\"paragraph-number\">[0075]   </span>Furthermore, although in the preceding description it was assumed, for sake of simplicity, that the grid 8 of base areas 6, and thus the definition of the shape and of the arrangement of the areas which are hit by the striking device 12, is the same for the component 1, the training components and the unknown component, it is possible for the grid of base areas of one or more of the training components, as well of the unknown component, to differ from the grid 8 of base areas 6 of the component 1. In other words, for the purposes of the present method, it is not necessary, given a zone 9 of the component 1, for the corresponding zone of the unknown component and/or the corresponding zones of one or more of the training components to be struck in the same points, although this may entail an improvement of the performances.</p><p><span class=\"paragraph-number\">[0076]   </span>Furthermore, in the case when the detection system 10 is configured so that the operations mentioned in block 500 are carried out on an unknown area of which the zone of belonging is known a priori, it is possible to omit the operations mentioned in block 506. In such case, the unknown spectrogram is not classified by the zone classifier 50, but is classified only by the binary classifier 70 relative to the zone to which the unknown area belongs, which is selected by the computer 16 depending on the zone of belonging.</p><p><span class=\"paragraph-number\">[0077]   </span>With regard to the binary classifiers 70, as is mentioned in the foregoing, they may be trained without being previously initialised on the basis of the zone classifier 50.</p><p><span class=\"paragraph-number\">[0078]   </span>Additionally, the detection and aggregation operations of the N-tuple of classes mentioned in blocks 308, 310 are optional. In other words, it is possible for each zone 9 to coincide with a corresponding subregion 2, in such case the zone classifier 50 is configured to classify on a number of classes equal to NUM_SUBREG, and furthermore the number of binary classifiers 70 is equal to NUM_SUBREG. This entails an increase in the number of binary classifiers 70 and therefore an increase in the computational burden required for training them.</p><p><span class=\"paragraph-number\">[0079]   </span>Additionally, before calculating the spectrograms, the computer 16 may perform so-called denoising operations, i.e. noise filtering operations, of the sampled electric signals deriving from the transduction of the acoustic signals, in which case the spectrograms are calculated on the basis of the sampled electric signals available after the filtering of the noise.</p><p><span class=\"paragraph-number\">[0080]   </span>Similarly, it is possible for the computer 16 to perform standardisation operations of the spectrograms and for the operations described in the foregoing to be performed starting from the standardised spectrograms. To such end, the computer 16 may calculate the mean and the standard deviation of the elements of the spectrograms relative to the training components, and subsequently may subtract the mean from each one of such spectrograms, besides from the unknown spectrograms; furthermore, the computer 16 may divide the elements of the spectrograms relative to the training components and the unknown spectrograms for the standard deviation. Other types of standardisation or normalisation are anyway possible.</p><p><span class=\"paragraph-number\">[0081]   </span>Finally, the present method and the present system for detecting anomalies can also be applied to mechanical components different from the aircraft mechanical components; for example, they can be applied for structurally monitoring a wind blade or a civil infrastructure, and more generally for monitoring the health status of any whatsoever mechanical piece.</p>",
            "CLMS": "(EP4375657)<br/><p>1. A method implemented by a computer (16) for detecting anomalies of an unknown component, comprising determining (314) a plurality of zones (9) of the unknown component and carrying out at least once the steps of:<br/> - generating (500, 502, 504) a spectrogram relative to an acoustic signal generated by striking a portion (6) of a zone (9) of the unknown component;<br/> - among a plurality of binary classifiers (70) each one relative to a corresponding zone (9) of the unknown component, selecting (507) the binary classifier (70) relative to the struck zone, each one of said binary classifiers (70) being configured to classify spectrograms relative to acoustic signals generated by striking the corresponding zone on two respective classes indicative of a spectrogram relative to an acoustic signal generated by striking an undamaged version or a damaged version of the corresponding zone (9) respectively;<br/> - through the selected binary classifier, performing (508) a classification of said spectrogram in one of the respective two classes; and<br/> - detecting (510) the presence of an anomaly in said struck zone of the unknown component, on the basis of the classification performed by the selected binary classifier.</p><p>2. The method according to claim 1, wherein each binary classifier (70) has been trained in a supervised manner on the basis of:<br/> - respective first training spectrograms, relative to acoustic signals generated by striking portions (6) of the corresponding zones (9) of training components identical to the unknown component and without any damage, said first training spectrograms being associated with the corresponding first class; and<br/> - respective second training spectrograms, relative to acoustic signals generated by striking portions (6) of the corresponding zones (9) of training components identical to the unknown component and with damages in said corresponding zones and/or by striking portions (6) of zones (9) different from the corresponding zone (9) of training components identical to the unknown component and without any damage and/or by striking portions (6) of zones (9) different from the corresponding zone (9) of training components identical to the unknown component and with damages in said zones (9) different from the corresponding zone (9), said second training spectrograms being associated with the corresponding second class.</p><p>3. The method according to any one of the preceding claims, wherein selecting (507) the binary classifier (70) relative to the struck zone comprises:<br/> - classifying (506), by means of a multiclass classifier (50), the spectrogram in a corresponding class among a plurality of zone classes equal to the number of zones (9) of the unknown component, each one of said zone classes being indicative of a spectrogram relative to an acoustic signal generated by striking a corresponding zone; and<br/> - selecting (507) the binary classifier (70) on the basis of the classification performed by the multiclass classifier (50).</p><p>4. The method according to claim 3, wherein the multiclass classifier (50) has been trained by performing the steps of:<br/> - determining (100) a plurality of subregions (2) of the unknown component; and subsequently<br/> - training (108) the multiclass classifier (50) on the basis of a set of training spectrograms relative to acoustic signals generated by striking portions (6) of the subregions (2) of training components identical to the unknown component and without any damage, each training spectrogram of said set being associated with a corresponding subregion class (2) indicative of the subregion (2) to which the training spectrogram refers, so that the multiclass classifier (50) is configured to perform classifications on a number of subregion classes equal to the number of subregions (2), each one of said subregion classes being indicative of a spectrogram relative to an acoustic signal generated by striking the corresponding subregion (2); and subsequently<br/> - defining (308,310,312,314) the zone classes so that each zone class is identical to a corresponding subregion class or is indicative of a corresponding set of subregion classes, and subsequently configuring the zone classifier (50) so that it performs classifications on said plurality of zone classes.</p><p>5. The method according to claim 4, wherein said step of defining (308,310,312,314) the zone classes comprises:<br/> - classifying (304) through the zone classifier (50) a plurality of test spectrograms relative to acoustic signals generated by striking portions (6) of the subregions (2) of training components identical to the unknown component and without any damage, so that each test spectrogram is classified in a corresponding subregion class;<br/> - calculating (306) a confusion matrix of the classifications of the test spectrograms; and<br/> - on the basis of the confusion matrix, detecting (308) the presence of sets of two or more subregions (2) such that the test spectrograms relative to said two or more subregions (2) have been classified in a confused manner between one another in a manner that respects a threshold condition; and<br/> - for each detected set of subregions (2), aggregating (310) the corresponding subregion classes so as to form a corresponding zone class; and<br/> - for each subregion (2) which does not belong to any detected set of subregions (2), setting (314) a corresponding zone class equal to the subregion class.</p><p>6. The method according to claim 4 or 5, wherein, in the respective training, each binary classifier (70) has been initialized on the basis of the zone classifier (50).</p><p>7. The method according to claim 6, wherein the zone classifier (50) and the binary classifiers (70) are convolutional neural networks, each one of which comprises a respective feature extraction stage (52,72); and wherein the binary classifiers (70) have been initialized so that the respective feature extraction stages (72) are identical to the feature extraction stage (52) of the zone classifier (50) .</p><p>8. The method for detecting anomalies comprising the steps of:<br/> - performing the method implemented by a computer (16) according to any one of the preceding claims;<br/> - performing (500) said strike of a portion (6) of a zone (9) of the unknown component;<br/>and wherein generating (502,504) a spectrogram depending on the acoustic signal comprises:<br/> - acquiring (502) the acoustic signal; and<br/> - calculating (504) the spectrogram on the basis of the acquired acoustic signal.</p><p>9. The method for detecting anomalies according to claim 8, wherein said strike is performed periodically.</p><p>10. A processing system comprising means (16) configured to perform the method according to any one of the claims from 1 to 7.</p><p>11. The system comprising:<br/> - the processing system (16) according to claim 10;<br/> - a striking device (12) configured to mechanically strike single portions (6) of zones (9) of the unknown component, so as to generate corresponding acoustic signals; and<br/> - a microphone (14), coupled to the processing system (16) and configured to acquire the acoustic signals.</p><p>12. A computer program comprising instructions that, when the program is performed by a computer (16), cause the computer (16) to perform the method according to any one of the claims from 1 to 7.</p><p>13. A computer medium readable by a computer (16), on which the computer program is stored according to claim 12.</p>",
            "NPR": "1",
            "APID": "170344506",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G01N-029/04<br/>G01N-029/44",
            "ID": "109971718",
            "AB": "(EP4375657)<br/>A method implemented by means of computer (16) so as to detect anomalies of an unknown component, including determining (314) a plurality of zones (9) of the unknown component and performing at least once the steps of: generating (500, 502, 504) a spectrogram relative to an acoustic signal generated by striking a portion (6) of a zone (9) of the unknown component; between a plurality of binary classifiers (70) each one relative to a corresponding zone (9) of the unknown component, selecting (507) the binary classifier (70) relative to the struck zone, each one of said binary classifiers (70) classifying spectrograms relative to acoustic signals generated by striking the corresponding zone on respective two classes indicative of a spectrogram relative to an acoustic signal generated by striking an undamaged version or a damaged version of the corresponding zone (9) respectively; by means of the selected binary classifier, performing (508) a classification of the spectrogram in one of the respective two classes; and detecting (510) the presence of an anomaly in the struck zone of the unknown component, on the basis of the classification performed by the selected binary classifier.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nmMS01bK%252FpTdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2022-11-28",
            "PA": "LEONARDO",
            "PAAD": "(EP4375657)<br/>(PUB:EP-4375657A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/><br/>(WO2024116035)<br/>(PUB:WO-2024/116035A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 ROMA , POSTCODE=00195 , COUNTRY=IT<br/>",
            "FAN": "109971718",
            "TI": "Method and system for detecting anomalies of mechanical components, in particular aircraft components, by classifying spectrograms of acoustic signals",
            "TECD": "Measurement",
            "EPD": "2024-05-29",
            "ICLM": "(EP4375657)<br/><p>1. A method implemented by a computer (16) for detecting anomalies of an unknown component, comprising determining (314) a plurality of zones (9) of the unknown component and carrying out at least once the steps of: - generating (500, 502, 504) a spectrogram relative to an acoustic signal generated by striking a portion (6) of a zone (9) of the unknown component; - among a plurality of binary classifiers (70) each one relative to a corresponding zone (9) of the unknown component, selecting (507) the binary classifier (70) relative to the struck zone, each one of said binary classifiers (70) being configured to classify spectrograms relative to acoustic signals generated by striking the corresponding zone on two respective classes indicative of a spectrogram relative to an acoustic signal generated by striking an undamaged version or a damaged version of the corresponding zone (9) respectively; - through the selected binary classifier, performing (508) a classification of said spectrogram in one of the respective two classes; and - detecting (510) the presence of an anomaly in said struck zone of the unknown component, on the basis of the classification performed by the selected binary classifier.</p>",
            "CTN": "(EP4375657)<br/>XP032908643 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>US20080144927 6546017 WHO=EXAMINER SELF=N CAT=X<br/><br/>(WO2024116035)<br/>XP032908643 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>US20080144927 6546017 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2026-05-28",
                    "XAP": "2023WO-IB61847",
                    "APD": "2023-11-23",
                    "APID": "170458022",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2024116035&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=vtvr11aaWXaz3XALdCSsvrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2024/116035",
                            "KIND": "A1",
                            "XPN": "WO2024116035",
                            "V_PNID": "WO-2024/116035A1-3",
                            "DATE": "2024-06-06",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCAGTz8iI+UO6t0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2024116035&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=vtvr11aaWXaz3XALdCSsvrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2042-11-28",
                    "XAP": "2022EP-0209811",
                    "APD": "2022-11-28",
                    "APID": "170344506",
                    "REG_LINK": "https://register.epo.org/application?number=EP22209811",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nmMS01bK%252FpTdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4375657",
                            "KIND": "A1",
                            "XPN": "EP4375657",
                            "V_PNID": "EP-4375657A1-8",
                            "DATE": "2024-05-29",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x4mwuLqSMGBXPEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4375657&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nmMS01bK%252FpTdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4375657_A1",
            "EPRD": "2022-11-28",
            "PN": "EP4375657           A1 2024-05-29 [EP4375657]<br/>WO2024/116035       A1 2024-06-06 [WO2024116035]",
            "ADB": "(EP4375657)<br/><p>In other words, for the purposes of the present method, it is not necessary, given a zone 9 of the component 1, for the corresponding zone of the unknown component and/or the corresponding zones of one or more of the training components to be struck in the same points, although this may entail an improvement of the performances.</p><p>Furthermore, such procedure cannot be automated and is inevitably subject to uncertainties connected to the ability of the personnel carrying it out and to human error.</p><p>That having been said, considering the i-th class (with 'i' assuming in succession the values 1, 2, 3 and 4), the computer 16 detects if the i-th class already belongs to an N-tuple, in which case it increases the value of 'i' by one, so as to analyse the following row, and thus the following class, otherwise, before increasing the value of 'i', the computer 16 checks if there is one or more m-th classes (with 'm' different from 'i') such that CMim > TH (with TH indicating a threshold value), in which case the computer 16 alternatively: if none of such m-th classes already belongs to a previously detected N-tuple, associates the i-th class to such m-th classes, so that the i-th class forms, together with such m-th classes, a new N-tuple of classes; or if one or more of such m-th classes belong to already previously detected N-tuples, associates the i-th class to one of such already previously detected N-tuples, increasing by one the dimension of such N-tuple; in particular, in case such already previously detected N-tuples are in a number greater than one, the computer 16 may choose with which of such already detected N-tuples to associate the i-th class (for example, it may select the N-tuple with more classes, so as to maximise the dimensions of the N-tuples, or the N-tuple which includes the m-th class so that CMim assumes the maximum value).</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=5<br/>PNAAGE=6<br/>NBPA=1; <br/>ALLCT=3; SCT=0; NSCT=3; <br/>ALLCTG=2; SCTG=0; NSCTG=2; <br/>AFS=10; ACC=9; AMCC=3; <br/>IGEN=0.0; IORG=0.56; IRAD=0.96; <br/>IMPI=4.11; MACI=1.52; PASI=3.66; PAVI=3.81; ",
            "PTCC": "(EP4342040)<br/>CC=EP EED=2043-04-05 STATUS=GRANTED APID=169163809 APD=2023-04-05 XPN=EP4342040 PD=2024-03-27 PD=2024-08-14 EPD=2024-03-27 LPD=2024-08-14 PDG=2024-08-14 <br/>CC=CH EED=2043-04-05 STATUS=GRANTED APID=169163809 XPN=EP4342040 PDG=2024-08-14 <br/>CC=DE EED=2043-04-05 STATUS=GRANTED APID=169163809 XPN=EP4342040 PDG=2024-08-14 <br/>CC=EP EED=2043-04-05 STATUS=PENDING APID=169323878 APD=2023-04-05 XPN=EP4346030 PD=2024-04-03 PD=2024-04-10 EPD=2024-04-03 LPD=2024-04-10 <br/>CC=GB EED=2043-04-05 STATUS=GRANTED APID=169163809 XPN=EP4342040 PDG=2024-08-14 <br/>CC=IE EED=2043-04-05 STATUS=GRANTED APID=169163809 XPN=EP4342040 PDG=2024-08-14 <br/>CC=NL EED=2043-04-05 STATUS=GRANTED APID=169163809 XPN=EP4342040 PDG=2024-08-14 <br/><br/>(EP4346030)<br/>CC=EP EED=2043-04-05 STATUS=PENDING APID=169323878 APD=2023-04-05 XPN=EP4346030 PD=2024-04-03 PD=2024-04-10 EPD=2024-04-03 LPD=2024-04-10 <br/>CC=DE EED=2043-04-05 STATUS=PENDING APID=169323878 XPN=EP4346030 <br/>CC=EP EED=2043-04-05 STATUS=GRANTED APID=169163809 APD=2023-04-05 XPN=EP4342040 PD=2024-03-27 PD=2024-08-14 EPD=2024-03-27 LPD=2024-08-14 PDG=2024-08-14 <br/><br/>(WO2023194921)<br/>CC=WO EED=2025-10-05 STATUS=PENDING APID=166241012 APD=2023-04-05 XPN=WO2023194921 PD=2023-10-12 EPD=2023-10-12 LPD=2023-10-12 <br/>CC=AU EED=2043-04-05 STATUS=PENDING APID=167963516 APD=2023-04-05 XPN=AU2023250253 PD=2024-01-18 EPD=2024-01-18 LPD=2024-01-18 <br/>CC=CA EED=2043-04-05 STATUS=PENDING APID=167840558 APD=2023-04-05 XPN=CA3223916 PD=2023-10-12 EPD=2023-10-12 LPD=2023-10-12 <br/>CC=EP EED=2043-04-05 STATUS=GRANTED APID=169163809 APD=2023-04-05 XPN=EP4342040 PD=2024-03-27 PD=2024-08-14 EPD=2024-03-27 LPD=2024-08-14 PDG=2024-08-14 <br/>CC=IL EED=2043-04-05 STATUS=PENDING APID=168330517 APD=2023-12-21 XPN=IL-309629 PD=2024-02-01 EPD=2024-02-01 LPD=2024-02-01 <br/>CC=US EED=2043-04-05 STATUS=PENDING APID=166241012 XPN=WO2023194921 <br/><br/>(IL-309629)<br/>CC=IL EED=2043-04-05 STATUS=PENDING APID=168330517 APD=2023-12-21 XPN=IL-309629 PD=2024-02-01 EPD=2024-02-01 LPD=2024-02-01 <br/><br/>(AU2023250253)<br/>CC=AU EED=2043-04-05 STATUS=PENDING APID=167963516 APD=2023-04-05 XPN=AU2023250253 PD=2024-01-18 EPD=2024-01-18 LPD=2024-01-18 <br/><br/>(CA3223916)<br/>CC=CA EED=2043-04-05 STATUS=PENDING APID=167840558 APD=2023-04-05 XPN=CA3223916 PD=2023-10-12 EPD=2023-10-12 LPD=2023-10-12 <br/>",
            "EPN": "CA3223916",
            "CTGN": "(WO2023194921)<br/>CN117856023 109249355 WHO=EXAMINER SELF=N CAT=A<br/>CN118763492 111762140 WHO=EXAMINER SELF=N CAT=A",
            "LAPD": "2023-04-05",
            "STDN": "",
            "NPN": "6",
            "DESC": "<p><heading><b><u>Cross-Reference to Related Applications</u></b></heading></p><p><span class=\"paragraph-number\">[0001]   </span>This Patent Application claims priority from <patcit dnum=\"EP22425015\" dnum-type=\"L\">European Patent Application No. 22425015.9 filed on April 5, 2022</patcit> and from <patcit dnum=\"IT102022000013186\">Italian Patent Application No. 102022000013186 filed on June 22, 2022</patcit>.</p><p><heading><b><u>Technical Field of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates to a coherent beam combination (CBC) system and to a control method thereof.</p><p><heading><b><u>State of the Art</u></b></heading></p><p><span class=\"paragraph-number\">[0003]   </span>As is known, coherent beam combination is a technique that is used to obtain a high power laser beam from a low power laser source.</p><p><span class=\"paragraph-number\">[0004]   </span>A known coherent beam combination comprises a laser source that generates a primary laser beam, a splitter that splits the primary laser beam into N secondary beams, an amplifying body having N channels, one for each secondary beam, and a recombination unit that recombines the N secondary beams, thereby forming an output beam focused on a target.</p><p><span class=\"paragraph-number\">[0005]   </span>In fact, the possibility to obtain a high-power laser beam from the amplification of a single laser source is limited by non-linear optical effects and thermal effects.</p><p><span class=\"paragraph-number\">[0006]   </span>On the other hand, in a coherent beam combination system, the N channels are individually amplified and then recombined with each other.</p><p><span class=\"paragraph-number\">[0007]   </span>This allows to use the recombination of the amplified beams to obtain a high power output.</p><p><span class=\"paragraph-number\">[0008]   </span>If the amplified beams are coherent one with the other, the amplified beams interfere with each other. In particular, it is desired that the amplified beams interfere constructively with each other.</p><p><span class=\"paragraph-number\">[0009]   </span>In fact, in a theoretical case, if the amplified beams are coherent with each other and have a mutual phase-shift equal to zero or a multiple of 2π, then the recombined beam has a peak intensity proportional to N<sup>2</sup>, wherein N is the number of channels of the CBC system.</p><p><span class=\"paragraph-number\">[0010]   </span>On the other hand, if the beams are not coherent with each other, the intensity of the recombined beam is just proportional to N.</p><p><span class=\"paragraph-number\">[0011]   </span>However, maintaining the amplified beams coherent with each other and phase-locked with each other require an accurate control of the phase of the amplified beams.</p><p><span class=\"paragraph-number\">[0012]   </span>Examples of known CBC systems are disclosed for example in <nplcit npl-type=\"b\">MA PENGFEI ET AL: \"7.1 kW coherent beam combining system based on a seven-channel fiber amplifier array\",OPTICS AND LASER TECHNOLOGY, ELSEVIER SCIENCE PUBLISHERS BV., AMSTERDAM, NL, vol. 140, 28 February 2021</nplcit>;</p><p><span class=\"paragraph-number\">[0013]   </span><patcit dnum=\"US2013315271A1\">US 2013/315271 A1</patcit>;</p><p><span class=\"paragraph-number\">[0014]   </span><nplcit npl-type=\"b\">YU C.X. ET AL: \"Coherent combining of a 4 kW, eight-element fiber amplifier array\",OPTICS LETTERS, OPTICAL SOCIETY OF AMERICA, US, vol. 36, no. 14, 15 July 2011, pages 2686-2688</nplcit>; and</p><p><span class=\"paragraph-number\">[0015]   </span><patcit dnum=\"US2009134310A1\">US 2009/134310 A1</patcit>.</p><p><span class=\"paragraph-number\">[0016]   </span>The Applicant has verified that known CBC systems may have a low efficiency with respect to the theoretical case.</p><p><heading><b><u>Subject and Summary of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0017]   </span>The aim of the present invention is to overcome the disadvantages of the prior art.</p><p><span class=\"paragraph-number\">[0018]   </span>The present invention relates to a coherent beam combination system and to a control method thereof, as claimed in the appended claims.</p><p><heading><b><u>Brief Description of the Drawings</u></b></heading></p><p><span class=\"paragraph-number\">[0019]   </span><ul compact=\"compact\" list-style=\"none\"><li> <figref>Figure 1</figref> shows a block diagram of a coherent combination system, according to an embodiment of the present invention.</li><br/><li> <figref>Figure 2</figref> shows in detail the block diagram of a portion of the present CBC system, according to an embodiment.</li><br/><li> <figref>Figure 3</figref> shows in detail the block diagram of a different portion of the present CBC system, according to an embodiment.</li><br/><li> <figref>Figure 4</figref> shows a detailed block diagram of another portion of the CBC system of <figref>Figure 1</figref>, according to an embodiment.</li><br/><li> <figref>Figure 5</figref> shows a flow chart of a phase-locking method for controlling the CBC system of <figref>Figure 1</figref>.</li><br/><li> <figref>Figure 5A</figref> shows a flow chart of an optimization algorithm of the phase-locking method of <figref>Figure 5</figref>, according to an embodiment.</li><br/><li> <figref>Figures 5B and 5C</figref> show schematic top plan views of an intensity sensor of the CBC system of <figref>Figure 1</figref>, in use, in two different conditions of use.</li><br/><li> <figref>Figure 6</figref> shows a flow chart of a delay equalization method for controlling the CBC system of <figref>Figure 1</figref>.</li><br/><li> <figref>Figure 7</figref> shows an example of the intensity distribution of a recombined laser beam obtainable by the CBC system of <figref>Figure 1</figref>.</li><br/><li> <figref>Figure 8</figref> shows a processor module of the CBC system of <figref>Figure 1</figref>, according to an embodiment.</li><br/><li> <figref>Figure 9</figref> shows a flow chart of a simulation method for controlling the CBC system of <figref>Figure 1</figref>.</li></ul></p><p><heading><b><u>Detailed Description of Preferred Embodiments of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0020]   </span>The following description is provided to enable a person skilled in the art to make and use the invention. Various modifications to the embodiments will be readily apparent to those skilled in the art, without departing from the scope of the claimed invention. Thus, the present invention is not intended to be limited to the embodiments shown, but is to be accorded the widest scope consistent with the features defined in the appended claims.</p><p><span class=\"paragraph-number\">[0021]   </span>Unless otherwise defined, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the embodiments disclosed belongs. In the case of conflict, the present specification, including definitions, will control. In addition, the examples are illustrative only and not intended to be limiting.</p><p><span class=\"paragraph-number\">[0022]   </span>For the purposes of promoting understanding of the embodiments described herein, reference will be made to certain embodiments and specific language will be used to describe the same. The terminology used herein is for the purpose of describing particular embodiments only, and is not intended to limit the scope of the present disclosure.</p><p><span class=\"paragraph-number\">[0023]   </span><figref>Figure 1</figref> shows a block diagram of a coherent beam combination (CBC) system 1 configured to provide an output recombined beam 2 having a high peak intensity, for example up to tens of kW, directed onto a target T.</p><p><span class=\"paragraph-number\">[0024]   </span>The CBC system 1 may be used for example for space debris removal, spectroscopy and laser-shaping applications, Point-to-Point communication in air (such as air-air, ground-air, air-space, ground-space), as a counter for Unmanned Aerial System, improvised explosive devices or as a dazzling system.</p><p><span class=\"paragraph-number\">[0025]   </span>The CBC system 1 comprises a laser source 3, a beam broadener 5 and a splitter 7, optically coupled with each other, in particular through an optical fibre.</p><p><span class=\"paragraph-number\">[0026]   </span>The laser source 3 generates a primary laser beam 8 having a narrow linewidth, for example below 20 kHz, the beam broadener 5 generates a broadened beam 10 from the primary laser beam 8, and the splitter 7 splits the broadened beam 10 into N secondary beams, of which here only a first, a second, a third and a fourth secondary beam 12A, 12B, 12C, 12D are shown.</p><p><span class=\"paragraph-number\">[0027]   </span>The CBC system 1 further comprises a main body 15, optically coupled with the splitter 7, and a focusing optics 17, optically coupled with the main body 15.</p><p><span class=\"paragraph-number\">[0028]   </span>The main body 15 comprises a plurality of channels, one for each secondary beam. In detail, with reference to <figref>Figure 1</figref>, the main body 15 has a first, a second, a third and a fourth channel 20A, 20B, 20C, 20D, each receiving a respecting secondary beam 12A, 12B, 12C, 12D and providing a respective intermediate beam 21A, 21B, 21C, 21D.</p><p><span class=\"paragraph-number\">[0029]   </span>The focusing optics 17 receives the intermediate beams 21A-21D and is configured to recombine the intermediate beams 21A-21D and generate the recombined output beam 2 directed onto the target T.</p><p><span class=\"paragraph-number\">[0030]   </span>The focusing optics 17, as discussed in detail hereinafter with respect to <figref>Figure 4</figref>, directs part of the intermediate beams 21A-21D towards an intensity sensor, here a photodiode 23, and towards an image sensor, here a CCD camera 24.</p><p><span class=\"paragraph-number\">[0031]   </span>In this embodiment, the photodiode 23 is coupled to a motor 25, for example a piezoelectric actuator, which is configured to move the photodiode 23 along one or more axis, in particular here along three orthogonal axis X, Y, Z.</p><p><span class=\"paragraph-number\">[0032]   </span>The CBC system 1 further comprises a control unit 26 including a phase-locking unit or module 30 and a delay compensation unit or module 31.</p><p><span class=\"paragraph-number\">[0033]   </span>In this embodiment, the laser source 3 is a fibre laser, in particular a single-mode DFB fibre laser having a low-intensity noise and a high beam quality, for example with an M<sup>2</sup> factor smaller than 1.05.</p><p><span class=\"paragraph-number\">[0034]   </span>The laser source 3 is substantially a monochromatic laser, for example having a wavelength of 1064 nm. However, the wavelength of the primary beam 8 generated by the laser source 3 may be different, depending on the specific application.</p><p><span class=\"paragraph-number\">[0035]   </span>According to an embodiment, the laser source 3 may be configured to provide a variable-wavelength the primary beam 8.</p><p><span class=\"paragraph-number\">[0036]   </span>The laser source 3 may be a continuous wave laser source or a pulsed laser source, here a continuous wave laser source.</p><p><span class=\"paragraph-number\">[0037]   </span>The beam broadener 5, for example a chirp modulator, a sinusoidal modulator or a noise modulator, enlarges the linewidth of the primary beam 8. For example, the broadened beam 10 may have a linewidth of about tens of GHz, in particular up to 50 GHz.</p><p><span class=\"paragraph-number\">[0038]   </span><figref>Figure 2</figref> shows an embodiment of the beam broadener 5, here a noise-modulated broadener, comprising a phase modulator 35, in particular an electro-optical modulator, coupled between the laser source 3 and the splitter 7 and driven by an rf input signal RF<sub>in</sub>.</p><p><span class=\"paragraph-number\">[0039]   </span>In detail, the beam broadener 5 comprises a noise generator 36 that generates a noise signal NS, for example a noise waveform or a pseudorandom binary sequence (PRBS), an rf amplifier 37 amplifying the noise signal NS and a low-pass filter 38 that filters the amplified noise signal, thereby generating the rf input signal RF<sub>in</sub>.</p><p><span class=\"paragraph-number\">[0040]   </span>The low-pass filter 38 allows to set the bandwidth of the rf input signal RF<sub>in</sub> and, therefore, the optical bandwidth modification of the primary beam 8.</p><p><span class=\"paragraph-number\">[0041]   </span>According to an embodiment, the low-pass filter 38 may also comprise signal-shaping modules to modify the spectral shape of the rf input signal RF<sub>in</sub>, depending on the specific application.</p><p><span class=\"paragraph-number\">[0042]   </span>The beam broadener 5 also comprises a termination load 39, which receives an rf output signal RF<sub>out</sub> generated by the phase modulator 35 starting from the rf input signal RF<sub>in</sub>. The termination load 39 may be used for impedance matching and as a heatsink, to dissipate the heat generated by the rf input signal RF<sub>in</sub> in the phase modulator 35.</p><p><span class=\"paragraph-number\">[0043]   </span>The channels 20A-20D of the main body 15 each comprise an amplifier 40, a phase modulator 42, an optical delay line 44, and an aperture combiner 46, optically coupled with each other, in particular here through a respective optical fibre.</p><p><span class=\"paragraph-number\">[0044]   </span>The amplifier 40 of each channel 20A-20D is coupled to a respective optic fibre extending from the splitter 7 and carrying the respective secondary beam 12A-12D. The amplifiers 40 of each channel 20A-20D amplify the respective secondary beam 12A-12D.</p><p><span class=\"paragraph-number\">[0045]   </span>The amplifiers 40 each have a respective gain, for example fixed or variable, comprised, for example, between 10 and 10<sup>9</sup>.</p><p><span class=\"paragraph-number\">[0046]   </span>The control unit 26, in particular here the delay equalization unit 31, may provide a signal S to the amplifiers 40, which control one or more parameters of the amplifiers 40.</p><p><span class=\"paragraph-number\">[0047]   </span>In detail, the signal S comprises a plurality of beam-control signals s<sub>1</sub>, s<sub>2</sub>, s<sub>3</sub>, s<sub>4</sub>, one for each amplifier 40.</p><p><span class=\"paragraph-number\">[0048]   </span>For example, the beam-control signals s<sub>1</sub>, s<sub>2</sub>, s<sub>3</sub>, s<sub>4</sub> may each control the gain of the amplifier 40 of a respective channel 20A-20D.</p><p><span class=\"paragraph-number\">[0049]   </span>According to an embodiment, the beam-control signals s<sub>1</sub>, s<sub>2</sub>, s<sub>3</sub>, s<sub>4</sub> may each command the switching on and the switching off of the respective amplifier 40, thereby commanding the activation and de-activation of the respective channel 20A-20D.The phase modulators 42, for example each formed by an electro-optical modulator or a fibre stretcher, receive a phase control signal U, for example a voltage signal, from the phase-locking unit 30.</p><p><span class=\"paragraph-number\">[0050]   </span>In detail, the phase modulator of each channel 20A-20D receives a respective phase control signal u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub>, for example a voltage signal, from the phase-locking unit 30.</p><p><span class=\"paragraph-number\">[0051]   </span>The phase control signals u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub> control the phase variations undergone by the secondary beams 12A-12D that, after being amplified by the respective amplifier 40, propagates through the respective phase modulator 42.</p><p><span class=\"paragraph-number\">[0052]   </span>The phase modulators 42 may for example be manufactured as a waveguide, by using a proton-exchanged process, in order to obtain a high stability even at high optical power.</p><p><span class=\"paragraph-number\">[0053]   </span>The optical delay lines 44 are variable delay lines that set the length of the optical path of the respective channel 20A-20D and receive a delay control signal D from the delay equalization unit 31. In detail, the optical delay lines 44 receive each a respective delay control signal d<sub>1</sub>, d<sub>2</sub>, d<sub>3</sub>, d<sub>4</sub> from the delay equalization unit 31.</p><p><span class=\"paragraph-number\">[0054]   </span>In practice, the delay control signals d<sub>1</sub>, d<sub>2</sub>, d<sub>3</sub>, d<sub>4</sub> may each tune the physical length of the respective optical delay line 44 and/or may change the refractive index of the respective optical delay line 44.</p><p><span class=\"paragraph-number\">[0055]   </span>For example, the optical delay lines 44 may be fibre stretchers or folded delay lines.</p><p><span class=\"paragraph-number\">[0056]   </span>According to an embodiment, the optical delay lines 44 may each comprise a fibre input coupled to the respective phase modulator 42, a fibre output coupled to the beam combiner 45 and a movable opto-mechanical element, such as a retroreflector, arranged between the fibre input and the fibre output that reflects the respective secondary beam 12A-12D coming from the fibre input towards the fibre output. By moving the movable retroreflector it is possible to change the length of the path travelled by the respective secondary beam 12A-12D and, therefore, the length of the optical path of the respective channel 20A-20D.</p><p><span class=\"paragraph-number\">[0057]   </span>For example, if the optical delay lines 44 comprise said movable opto-mechanical element, the delay control signals d<sub>1</sub>, d<sub>2</sub>, d<sub>3</sub>, d<sub>4</sub> may control an actuator, for example a piezoelectric actuator, configured to move the movable opto-mechanical element.</p><p><span class=\"paragraph-number\">[0058]   </span>The beam combiner 45 has a back coupling portion 45A, receiving the secondary beams 12A-12D propagating from the optical delay lines 44, and a front coupling portion 45B having a plurality of apertures 46, each providing a respective intermediate beam 21A-21D.</p><p><span class=\"paragraph-number\">[0059]   </span>The apertures 46 are arranged, on the front coupling portion 45B, in a tiled-aperture configuration, in particular in a honeycomb configuration, which allows a high scalability in the number of channels.</p><p><span class=\"paragraph-number\">[0060]   </span>However, the apertures 46 may be arranged, on the coupling portion 45B, in a different configuration, depending on the specific application and/or on the desired filling factor.</p><p><span class=\"paragraph-number\">[0061]   </span>By way of example only, <figref>Figure 3</figref> shows an example of the coupling portion 45B, in a case wherein the CBC system 1 has nineteen apertures 46 arranged in a honeycomb configuration.</p><p><span class=\"paragraph-number\">[0062]   </span>The apertures 46 have a circular cross section having a diameter d defining the beam waist of the intermediate beams 21A-21D.</p><p><span class=\"paragraph-number\">[0063]   </span>In the honeycomb configuration, two adjacent apertures 46A, 46B are arranged at a distance 1, for example measured between the centres of the two adjacent apertures 46A, 46B.</p><p><span class=\"paragraph-number\">[0064]   </span>Still with reference to the exemplificative configuration of <figref>Figure 3</figref>, the apertures 46 are arranged along an axis X in order to form a plurality of rows mutually spaced along an axis Y perpendicular to the axis X.</p><p><span class=\"paragraph-number\">[0065]   </span>In this embodiment, two rows that are adjacent along the axis Y are arranged at a distance h measured in a direction parallel to the axis Y. For example, the distance h may be measured between the centres of two apertures of two adjacent rows.</p><p><span class=\"paragraph-number\">[0066]   </span>The distance h may be expressed as a function of the distance 1 by the formula: <i>h</i> = </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 15mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0001.tif&width=15mm&height=6mm\"/></maths></p><p>.</p><p><span class=\"paragraph-number\">[0067]   </span>Again with reference to <figref>Figure 1</figref>, the beam combiner 45 comprises a plurality of opto-mechanical elements 47, one for each channel 20A-20D, which couples the respective secondary beam 12A-12D propagating from the delay line 44 to the aperture 46.</p><p><span class=\"paragraph-number\">[0068]   </span>In detail, each opto-mechanical element 47 comprises a fibre connector 48 and an optical element 49, arranged at the respective aperture 46.</p><p><span class=\"paragraph-number\">[0069]   </span>The fibre connector 48 is coupled to the optical fibre extending from the optical delay line 44. The secondary beams 12A-12D coming from the optical delay lines 44 propagate in free space between the fibre connector 48 and the respective optical element 49.</p><p><span class=\"paragraph-number\">[0070]   </span>The optical element 49, for example a converging lens, collimates the respective secondary beam 12A-12D propagating from the fibre connector 48, thereby generating the respective intermediate beam 21A-21D.</p><p><span class=\"paragraph-number\">[0071]   </span>For example, the fibre connector 48 may be placed at the focus plane of the respective optical element 49.</p><p><span class=\"paragraph-number\">[0072]   </span>Moreover, in this embodiment, each opto-mechanical element 47 further comprises an intensity mask 50 arranged between the respective fibre connector 48 and the respective optical element 49.</p><p><span class=\"paragraph-number\">[0073]   </span>The intensity mask 50 may reduce the beam waist of the beam propagating from the fibre connector 48 and the optical element 49, so that only a portion of the secondary beam 21A-21D, for example comprised between 95% and 100%, in particular of about 95%, is transmitted and forms the respective intermediate beam 21A-21D, while the remaining portion, for example comprised between 5% and 0%, in particular of about 5%, of the respective secondary beam 21A-21D is blocked.</p><p><span class=\"paragraph-number\">[0074]   </span>The intensity mask 50 allows to optimise the filling factor of the apertures 46 on the front coupling portion 45B of the beam combiner 45.</p><p><span class=\"paragraph-number\">[0075]   </span><figref>Figure 4</figref> shows the CBC system 1, wherein a detailed embodiment of the focusing optics 17 is illustrated.</p><p><span class=\"paragraph-number\">[0076]   </span>The focusing optics 17 defines a primary optical path 53, which directs a first portion of the intermediate beams 21A-21D towards the target T, and a secondary optical path 54, which directs a second portion of the intermediate beams 21A-21D towards the photodiode 23 and the CCD camera 24.</p><p><span class=\"paragraph-number\">[0077]   </span>In detail, the primary optical path 53 of the focusing optics 17 forms a two-lens optical system comprising a convex lens 55 having a focus length f<sub>1</sub> and arranged in front of the front coupling face 45B of the beam combiner 45, and a concave lens 56 having a focus length f<sub>2</sub> and optically coupled to the first lens 55.</p><p><span class=\"paragraph-number\">[0078]   </span>The first and the second lenses 55, 56 allow the mutual recombination of the intermediate beams 21A-21D, thereby forming a recombined beam 75.</p><p><span class=\"paragraph-number\">[0079]   </span>The recombined beam 75 is generated by the interference of the intermediate beams 21A-21D. Therefore, the wavefront of the recombined beam 75 forms an interference pattern having a main lobe and one or more secondary lobes (as for example shown in <figref>Figure 7</figref>).</p><p><span class=\"paragraph-number\">[0080]   </span>Moreover, the position of the concave lens 56 along the primary optical path 53 may be changed, in use, so that the two-lens system formed by the convex lens 55 and the concave lens 56 has a variable focal length.</p><p><span class=\"paragraph-number\">[0081]   </span>For example, the focal length of the two-lens system may be changed depending on the distance of the target T from the CBC system 1.</p><p><span class=\"paragraph-number\">[0082]   </span>For example, the concave lens 56 may be coupled to a DC actuator, here not shown, configured to move the concave lens 56 in order to reduce or increase the distance between the convex lens 55 and the concave lens 56.</p><p><span class=\"paragraph-number\">[0083]   </span>In this embodiment, the focusing optics 17 further comprises a first mirror 58, arranged along the primary optical path 53 between the first lens 55 and the second lens 56, and a second mirror 59, arranged along the primary optical path 53 between the concave lens 56 and the target T.</p><p><span class=\"paragraph-number\">[0084]   </span>In practice, the first and the second mirrors 58, 59 are arranged so that the primary optical path 53 is folded, thereby reducing the occupancy of the CBC system 1.</p><p><span class=\"paragraph-number\">[0085]   </span>The focusing optics 17 also comprises a beam splitter 60 arranged along the primary optical path 53, in particular here between the concave lens 56 and the second mirror 59.</p><p><span class=\"paragraph-number\">[0086]   </span>The beam splitter 60 splits the recombined beam 75 propagating from the concave lens 56, thereby forming a sample beam 63 propagating along the secondary optical path 54.</p><p><span class=\"paragraph-number\">[0087]   </span>The beam splitter 60 samples a small portion, for example 1% or even less, of the recombined beam 75, depending on the power of the recombined beam 75, and the maximum optical power sustained by the photodiode 23 and the CCD camera 24.</p><p><span class=\"paragraph-number\">[0088]   </span>In detail, the secondary optical path 54 comprises a beam splitter 65, a CCD lens 66, a mirror 67 and a photodiode lens 68.</p><p><span class=\"paragraph-number\">[0089]   </span>The beam splitter 65 further splits the sample beam 63 so that a first portion is focused by the CCD lens 66 on the CCD camera 24 and a second portion is directed towards the photodiode 23 by the mirror 67 and focused thereto by the photodiode lens 68.</p><p><span class=\"paragraph-number\">[0090]   </span>The CCD lens 66 and the photodiode lens 68 may be chosen depending on a desired size of the main lobe of the portion of the recombined beam 75 that is directed towards the CCD camera 24 and, respectively, the photodiode 24. For example, the CCD lens 66 and the photodiode lens 68 may be chosen so that the size of the main lobe of the recombined beam 75 is equal to or smaller than the active area of the photodiode 23 and, respectively, of the CCD camera 24.</p><p><span class=\"paragraph-number\">[0091]   </span>In this embodiment, the secondary optical path 54 also comprises a pinhole 71 arranged between the photodiode lens 68 and the photodiode 23. The pinhole 71 has an aperture approximately equal to the size of the main lobe of the beam propagating from the photodiode lens 68. For example, the aperture of the pinhole 71 may be comprised between 10 µm and 100 µm, in particular of about 100 µm.</p><p><span class=\"paragraph-number\">[0092]   </span>In practice, the photodiode 23 may measure only the intensity of the main lobe of the beam propagating from the photodiode lens 68.</p><p><span class=\"paragraph-number\">[0093]   </span>The photodiode 23 provides an intensity signal INT, which is indicative of the intensity of the recombined beam 75, in particular here of the main lobe of the recombined beam 75. In fact, by knowing the splitting characteristics of the first and the second beam splitters 60, 65, the intensity signal INT may be used to obtain the intensity of the main lobe of the recombined beam 75.</p><p><span class=\"paragraph-number\">[0094]   </span>In use, the phase-locking unit 30 receives the intensity signal INT from the photodiode 23 and provides the phase-control signals U = {u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub>} to the phase modulators 42 of the channels 20A-20D.</p><p><span class=\"paragraph-number\">[0095]   </span>The phase-locking unit 30 performs a closed-loop optimization algorithm that modifies the phase-control signal U so to maximise the intensity measured by the photodiode 23.</p><p><span class=\"paragraph-number\">[0096]   </span><figref>Figure 5</figref> shows a flow chart of a method 90 performed by the phase-locking module 30 to maximise the intensity measured by the photodiode 23.</p><p><span class=\"paragraph-number\">[0097]   </span>At a step 91, the phase-locking module 30 receives a detection signal, here the intensity signal INT from the photodiode 23.</p><p><span class=\"paragraph-number\">[0098]   </span>At a step 92, the phase-locking module 30 calculates a cost function from the detection signal, wherein the cost function is a function of the intensity detected by the photodiode 23.</p><p><span class=\"paragraph-number\">[0099]   </span>At a step 93, the phase-locking module 30 performs an optimisation algorithm that is configured to maximise the intensity measured by the photodiode 23.</p><p><span class=\"paragraph-number\">[0100]   </span>At a step 94, the phase-locking module 30 provides a plurality of updated phase control signals to the phase modulators 42, based on an output of the optimization algorithm.</p><p><span class=\"paragraph-number\">[0101]   </span>According to an embodiment, as shown in <figref>Figure 5A</figref>, the phase-locking unit 30 performs, as optimization algorithm, a method 100 based on a Stochastic Parallel Gradient Descent (SPGD) algorithm.</p><p><span class=\"paragraph-number\">[0102]   </span>In an initialization step 103, the phase-locking unit 30 initializes the phase values of the secondary beams 12A-12D at an initial phase. In detail, the phase-locking 30 provides an initial phase signal U<sub>0</sub> to the phase modulators 42. For example, the initial phase signal U<sub>0</sub> may provide the same phase signal to the modulator 42 of each channel 20A-20D, i.e. U<sub>0</sub> = {u<sub>0</sub>, u<sub>0</sub>, u<sub>0</sub>, u<sub>0</sub>}.</p><p><span class=\"paragraph-number\">[0103]   </span>However, the phase-locking unit 30 may apply a different phase values to the phase modulators 42, depending on the specific application.</p><p><span class=\"paragraph-number\">[0104]   </span>The method 100 is an iterative method. Each iteration will be indicated by the index k. Moreover, in the following, the index j will be used to identify any one of the channels 20A-20D.</p><p><span class=\"paragraph-number\">[0105]   </span>At each iteration k, the phase-locking unit 30 generates, step 105, a phase-perturbation vector δu(k) = {δu<sub>1</sub>, δu<sub>2</sub>, δu<sub>3</sub>, δu<sub>4</sub>} comprising a plurality of perturbation voltages δu<sub>1</sub>, δu<sub>2</sub>, δu<sub>3</sub>, δu<sub>4</sub>, one for each phase modulator 42.</p><p><span class=\"paragraph-number\">[0106]   </span>In detail, the perturbation voltages δu<sub>1</sub>, δu<sub>2</sub>, δu<sub>3</sub>, δu<sub>4</sub> are generated according to a Bernoulli distribution having values v<sub>1</sub> and v<sub>2</sub> wherein v<sub>2</sub> is different from v<sub>1</sub> and wherein P(δu<sub>j</sub> = v<sub>1</sub>) = p and P(δu<sub>j</sub> = v<sub>2</sub>) = 1-p.</p><p><span class=\"paragraph-number\">[0107]   </span>Therefore, each perturbation voltage δu<sub>j</sub> may have either the value v<sub>1</sub> or v<sub>2</sub> with a probability p and, respectively, 1-p.</p><p><span class=\"paragraph-number\">[0108]   </span>According to an embodiment, the values v<sub>1</sub> and v<sub>2</sub> have the same modulus and opposite sign, i.e. v<sub>1</sub> = -v<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0109]   </span>According to an embodiment, p=0.5, so that P(δu<sub>j</sub> = v<sub>1</sub>) = P(δu<sub>j</sub> = v<sub>2</sub>) = 0.5.</p><p><span class=\"paragraph-number\">[0110]   </span>According to an embodiment, v<sub>1</sub> = -v<sub>2</sub> and p=0.5.</p><p><span class=\"paragraph-number\">[0111]   </span>Then, step 107, the phase phase-locking unit 30 provides a phase control signal U = U(k-1) + δu(k) = {u<sub>1</sub>(k-1) +δu<sub>1</sub>, u<sub>2</sub>(k-1)+δu<sub>2</sub>, u<sub>3</sub>(k-1)+δu<sub>3</sub>, u<sub>4</sub>(k-1)+δu<sub>4</sub>} to the phase modulators 42.</p><p><span class=\"paragraph-number\">[0112]   </span>In practice, the phase-locking unit 30 sums the phase-perturbation vector δu(k) to the phase control signal U(k-1) = {u<sub>1</sub>(k-1), u<sub>2</sub>(k-1), u<sub>3</sub>(k-1), u<sub>4</sub>(k-1)} that has been determined in the previous iteration k-1.</p><p><span class=\"paragraph-number\">[0113]   </span>At the first iteration, i.e. for k=1, the phase-perturbation vector δu(k) is summed to the initial phase signal U<sub>0</sub>.</p><p><span class=\"paragraph-number\">[0114]   </span>Therefore, at step 107 the phase modulators 42 change the phase values of the secondary beams 12A-12D propagating in the respective channels 20A-20D, with respect to the phase values provided in the previous iteration k-1.</p><p><span class=\"paragraph-number\">[0115]   </span>Since the phases of the secondary beams 12A-12D have been changed with respect to the previous iteration k-1, also the interference pattern formed by the recombination of the intermediate beams 21A-21D changes. Accordingly, the intensity of the main lobe measured by the photodiode 23 changes.</p><p><span class=\"paragraph-number\">[0116]   </span>The photodiode 23 measures a positive intensity I<sub>+, k</sub>, which is indicative of the intensity change in the recombined beam 75 caused by the phase control signal U(k-1) + δu(k).</p><p><span class=\"paragraph-number\">[0117]   </span>The phase locking unit 30, step 109, receives the intensity signal INT from the photodiode 23.</p><p><span class=\"paragraph-number\">[0118]   </span>The phase-locking unit 30 calculates, step 111, a positive cost function J<sub>+,k</sub> given by I<sub>+, k</sub>/I<sub>max</sub>, wherein I<sub>max</sub> is the maximum intensity that may be achieved if the intermediate beams 21A-21D are perfectly matched, i.e. if the mutual phase difference among the intermediate beams 21A-21D is 0 or an integer multiple of 2π.</p><p><span class=\"paragraph-number\">[0119]   </span>Then, step 113, the phase phase-locking unit 30 provides a phase control signal U<sub>c</sub> = U(k-1) - δu(k) = {u<sub>1</sub>(k-1)-δu<sub>1</sub>, u<sub>2</sub>(k-1)-δu<sub>2</sub>, u<sub>3</sub>(k-1)-δu<sub>3</sub>, u<sub>4</sub>(k-1)-δu<sub>4</sub>} to the phase modulators 42.</p><p><span class=\"paragraph-number\">[0120]   </span>In practice, the phase-locking unit 30 subtracts the phase-perturbation vector δu(k) from the phase control signal U(k-1) that has been determined in the previous iteration k-1.</p><p><span class=\"paragraph-number\">[0121]   </span>At the first iteration, i.e. for k=1, the phase-perturbation vector δu(k) is subtracted to the initial phase signal U<sub>0</sub>.</p><p><span class=\"paragraph-number\">[0122]   </span>Therefore, at step 113 the phase modulators 42 change the phase values of the secondary beams 12A-12D propagating in the respective channels 20A-20D, with respect to the phase values provided in the previous iteration k-1 and with respect to the phase provided at step 107.</p><p><span class=\"paragraph-number\">[0123]   </span>The photodiode 23 measures a negative intensity I<sub>-, k</sub>, which is indicative of the intensity change in the recombined signal caused by the phase control signal U(k-1) - δu(k).</p><p><span class=\"paragraph-number\">[0124]   </span>The phase locking unit 30, step 115, receives the intensity signal INT from the photodiode 23.</p><p><span class=\"paragraph-number\">[0125]   </span>The phase-locking unit 30 calculates, step 117, a negative cost function J<sub>-,k</sub> given by I<sub>-, k</sub>/I<sub>max</sub>.</p><p><span class=\"paragraph-number\">[0126]   </span>Then, step 119, the phase-locking unit 30, calculates a new phase control signal U(k) by updating the phase control signal U(k-1) based on the phase-perturbation vector δu(k) and the positive and negative cost functions J<sub>+,k</sub>, J<sub>-,k</sub>.</p><p><span class=\"paragraph-number\">[0127]   </span>In detail, in this embodiment, the new phase control signal U(k) is calculated as U(k) = U(k-1) + δu(k) · γ · δJ(k), wherein γ is a gain value and δJ(k) is the difference between the positive and the negative cost functions J<sub>+,k,</sub> J<sub>-,k</sub> e.g. δJ(k) = J<sub>+,k</sub> - J<sub>-,k</sub>.</p><p><span class=\"paragraph-number\">[0128]   </span>The gain value γ may be chosen by a user of the CBC system 1, for example during the calibration of the CBC system 1.</p><p><span class=\"paragraph-number\">[0129]   </span>The phase-locking unit 30, step 121, provides the new phase control signal U(k) to the phase modulators 42.</p><p><span class=\"paragraph-number\">[0130]   </span>Therefore, at step 121 the phase modulators 42 update the phase of the secondary beams 12A-12D, based on the new phase control signal U(k).</p><p><span class=\"paragraph-number\">[0131]   </span>The photodiode 23 measures a corrected intensity I<sub>corr, k</sub>, which is indicative of the change of intensity of the recombined signal 75 caused by the new phase control signal U(k).</p><p><span class=\"paragraph-number\">[0132]   </span>The phase locking unit 30, step 123, receives the intensity signal INT from the photodiode 23.</p><p><span class=\"paragraph-number\">[0133]   </span>The phase-locking unit 30 then calculates, step 125, a corrected cost function J<sub>corr,k</sub> as I<sub>corr, k</sub>/I<sub>max</sub>.</p><p><span class=\"paragraph-number\">[0134]   </span>The phase-locking unit 30 verifies, step 127, a convergence condition of the optimization method 100.</p><p><span class=\"paragraph-number\">[0135]   </span>In detail, in this embodiment, the phase-locking unit checks if the corrected cost function J<sub>corr,k</sub> is equal to or higher than a convergence threshold J<sub>th</sub>, which may be for example chosen by a user during a calibration step of the CBC system 1.</p><p><span class=\"paragraph-number\">[0136]   </span>If the convergence condition is not verified, i.e. here if the corrected cost function J<sub>corr,k</sub> is lower than the convergence threshold J<sub>th</sub> (branch N output from step 127), the phase-locking unit 30 returns to step 105 and generate a new random perturbation vector δu(k+1) for the next iteration k+1.</p><p><span class=\"paragraph-number\">[0137]   </span>The phase locking unit 30 then repeats all steps from 107 to 127.</p><p><span class=\"paragraph-number\">[0138]   </span>On the other hand, if the convergence condition is verified, branch Y output from step 127, the phase-locking unit 30 returns to step 123 and repeats steps 123, 125 and 127.</p><p><span class=\"paragraph-number\">[0139]   </span>In practice, if the convergence condition is verified, the phase-locking unit 30 keeps monitoring the cost function by acquiring the intensity signal INT (step 123) and by calculating the associated cost function (step 125), until the convergence condition is not verified anymore.</p><p><span class=\"paragraph-number\">[0140]   </span>For example, in response to the convergence condition being verified (branch Y output from step 127), the phase-locking unit 30 may immediately return to step 123 or may wait a time interval, which may be chosen depending on the specific application, before returning to step 123.</p><p><span class=\"paragraph-number\">[0141]   </span>During use, the phases of the secondary beams 12A-12D may be subject to unwanted changes caused by external factors. For example, a temperature drift may change the length of the optical fibres wherein the secondary beams 12A-12D propagate, thereby causing an unwanted phase shift among the secondary beams 12A-12D, which may degrade the mutual phase locking thereof.</p><p><span class=\"paragraph-number\">[0142]   </span>The method 100 allows to adjust the phases of the secondary beams 12A-12D in a closed loop, so that the intensity of the main lobe of the recombined beam 75 is kept at a maximum value.</p><p><span class=\"paragraph-number\">[0143]   </span>Moreover, the Applicant has verified that the method 100 allows also to reduce the power noise of the recombined beam 75 caused by optical phase fluctuations, in particular in a frequency range of said fluctuations comprised between 0 Hz and 2000 Hz.</p><p><span class=\"paragraph-number\">[0144]   </span>Moreover, the fact that the phase-locking unit 30 keeps monitoring the cost function even after the convergence condition has been satisfied (branch Y from step 127), allows the method 100 to achieve a high speed of convergence and at the same time to keep high the performance of the CBC system 1.</p><p><span class=\"paragraph-number\">[0145]   </span>The method 100 may also be used as a method to steer the output recombined beam 2, for example to track the target T if the target T has moved to a different position (as for example indicated by a dashed line in <figref>Figure 4</figref>).</p><p><span class=\"paragraph-number\">[0146]   </span><figref>Figure 5B</figref> shows an example of a schematic top plan view of the photodiode 23, wherein the beam spot 130 of the portion of the recombined beam 75 focused by the photodiode lens 68 falls completely within an active area 131 of the photodiode 23. In this case, by supposing that the phase-locking unit 30 has verified the convergence condition, the mutual phase shift among the secondary beams 12A-12D is optimised and the main lobe of the recombined beam 75 has a maximum intensity.</p><p><span class=\"paragraph-number\">[0147]   </span>If, as shown in <figref>Figure 5C</figref>, the photodiode 23 is moved along a first and a second axis X, Y, the beam spot 130 may fall only in part within the active area 131.</p><p><span class=\"paragraph-number\">[0148]   </span>The movement of the photodiode 23 is controlled by the motor 25, for example a piezoelectric actuator having a high accuracy, e.g. able to cause a displacement of the photodiode 23 comprised between 10 µm and 25 mm.</p><p><span class=\"paragraph-number\">[0149]   </span>The motor 25 may be controlled by the control unit 26.</p><p><span class=\"paragraph-number\">[0150]   </span>In response to the displacement of the photodiode 23, the photodiode 23 detects a reduction in the measured intensity.</p><p><span class=\"paragraph-number\">[0151]   </span>Accordingly, when the phase-locking unit 30 acquires the intensity signal INT (step 123) and calculates the cost function J (step 125), the convergence condition may not be verified anymore (step 127). Therefore, the phase-locking unit 30 returns to step 105 and performs one or more new iterations (from step 105 to step 127) until the convergence condition is satisfied.</p><p><span class=\"paragraph-number\">[0152]   </span>In fact, by changing the phase applied by the phase modulators 42, the phase-locking unit 30 is able to change the position of the recombined beam 75, in particular is able to move the main lobe of the recombined beam 75, for example until the beam spot 130 falls again completely within the active area 131.</p><p><span class=\"paragraph-number\">[0153]   </span>In practice, by moving the photodiode 23, it is possible to steer the recombined beam 75 and, therefore, the output recombined beam 2.</p><p><span class=\"paragraph-number\">[0154]   </span>The Applicant has verified that the method 100 allows to achieve a very fast and accurate beam steering, for example to accurately control the position of the output recombined beam 2 at the target T. For example, even when the target T is placed at a distance of about 100 m from the CBC system 1, by moving the photodiode 23 with the motor 25, the CBC system 1 may be able to adjust the position of beam, at the location of the target T, even by few micrometres.</p><p><span class=\"paragraph-number\">[0155]   </span>The optical delay lines 44 are variable delay lines.</p><p><span class=\"paragraph-number\">[0156]   </span><figref>Figure 6</figref> shows a flow chart of a method 150 performed by the delay optimization unit 31 for equalizing the optical paths of the secondary beams 12A-12D in the channels 20A-20D, according to an embodiment.</p><p><span class=\"paragraph-number\">[0157]   </span>The method 150 starts, step 151, if the delay optimization unit 31 verifies that the optical paths of the channels 20A-20D need to be equalized.</p><p><span class=\"paragraph-number\">[0158]   </span>For example, the method 150 may be performed during a calibration of the CBC system 1, for example before a first use of the CBC system 1, or may be performed periodically, during use, for example upon verification of a specific condition.</p><p><span class=\"paragraph-number\">[0159]   </span>The delay optimization unit 31 selects, step 153, one of the channels 20A-20D to be equalized and sets one of the channels 20A-20D as reference channel.</p><p><span class=\"paragraph-number\">[0160]   </span>For example, hereinafter, the first channel 20A is taken as the reference channel and the second channel 20B as the channel to be equalized.</p><p><span class=\"paragraph-number\">[0161]   </span>However, any of the channels 20A-20D may be taken as reference channel. For example, if the channels 20A-20D are arranged in a honeycomb structure in the aperture combiner 45, the channel whose aperture is arranged at the centre of the honeycomb structure may be taken as reference channel.</p><p><span class=\"paragraph-number\">[0162]   </span>At step 153, the delay optimization unit 31 selects the first channel 20A and the second channel 20B by turning off the third channel 20C and the fourth channel 20D.</p><p><span class=\"paragraph-number\">[0163]   </span>For example, the third channel 20C and the fourth channel 20D may be turned off by stopping the emission of the corresponding amplifier 40. For example, the delay optimization unit 31 may provide the signals s<sub>3</sub> and s<sub>4</sub> so that the respective amplifiers 40 block the propagation of the third and fourth intermediate beams 21C and 21D.</p><p><span class=\"paragraph-number\">[0164]   </span>Then, step 155, the delay optimization unit 31 determines a coarse estimate of the optical path difference between the second channel 20B and the reference channel 20A. For example, the coarse estimate may have an accuracy comprised between few centimetres and several meters of the optical path difference.</p><p><span class=\"paragraph-number\">[0165]   </span>In this embodiment, the delay optimization unit 31 performs a Frequency Modulation Continuous Wave (FMCW) technique to find the coarse estimate of the optical path difference between the second channel 20B and the reference channel 20A.</p><p><span class=\"paragraph-number\">[0166]   </span>In detail, the delay optimization unit 31 provides a chirp signal CHIRP to the laser source 3 and, in response thereto, acquires the intensity signal INT from the photodiode 23.</p><p><span class=\"paragraph-number\">[0167]   </span>The chirp signal CHIRP has a chirp frequency α that causes a temporal modulation of the wavelength of the primary beam 8, in particular causes the wavelength of the primary beam 8 to follow a triangular ramp.</p><p><span class=\"paragraph-number\">[0168]   </span>If there is a delay OPD<sub>2</sub> between the reference channel 20A and the second channel 20B, the intensity signal INT has a beat note at a beat frequency f<sub>b</sub>.</p><p><span class=\"paragraph-number\">[0169]   </span>The relation between the delay OPD<sub>2</sub> and the beat frequency f<sub>b</sub> is: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 24mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0002.tif&width=24mm&height=8mm\"/></maths></p><p><span class=\"paragraph-number\">[0170]   </span>wherein c is the speed of light in vacuum and n is the refractive index of the medium through which the first and the second secondary beams 12A, 12B.</p><p><span class=\"paragraph-number\">[0171]   </span>Then, step 157, the delay optimization unit 31 provides the delay control signal d<sub>2</sub> to the optical delay line 44 of the second channel 20B, in order to compensate for the delay OPD<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0172]   </span>In practice, the delay control signal d<sub>2</sub> shortens or stretches the optical path of the optical delay line 44 of the second channel 20B, in order to compensate for the delay OPD<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0173]   </span>For example, if the optical delay line 44 of the second channel 20B has a movable opto-mechanical element configured to change the length of the optical path of the optical delay line 44, then the delay control signal d<sub>2</sub> may control an actuator, for example a piezoelectric actuator, configured to move the optical delay line 44 of the second channel 20B.</p><p><span class=\"paragraph-number\">[0174]   </span>Then, the delay optimization unit 31 finds a fine estimate of the optical path difference between the second channel 20B and the reference channel 20A.</p><p><span class=\"paragraph-number\">[0175]   </span>In detail, step 159, the delay optimization unit 31 measures a fringe visibility V<sub>2</sub> from the image IMG received from the CCD camera 24.</p><p><span class=\"paragraph-number\">[0176]   </span>At step 159, only the first channel 20A and the second channel 20B are activated; therefore, the recombined beam 75 is formed by the interference between the first and the second intermediate beams 21A, 21B.</p><p><span class=\"paragraph-number\">[0177]   </span>Accordingly, the image IMG acquired by the CCD camera 24 represents the interference pattern between the first and the second intermediate beams 21A, 21B.</p><p><span class=\"paragraph-number\">[0178]   </span>The fringe visibility V<sub>2</sub> may be defined as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 20mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0003.tif&width=20mm&height=8mm\"/></maths></p><p> wherein I+ is the maximum value of intensity on the image IMG, e.g. the peak value of the main lobe of the interference pattern, and I<sub>-</sub> is the minimum value of intensity on the image IMG, e.g. a zero of the interference pattern.</p><p><span class=\"paragraph-number\">[0179]   </span>The delay optimization unit 31 checks, step 161, if the fringe visibility V<sub>2</sub> satisfies an interference-quality condition. In this embodiment, the delay optimization unit 31 checks if the fringe visibility V<sub>2</sub> is equal to or higher than a fringe visibility threshold V<sub>th</sub>, which may be chosen for example by a user during a calibration of the CBC system 1.</p><p><span class=\"paragraph-number\">[0180]   </span>In the negative case, branch N at output from step 161, the delay optimization unit 31 updates, step 163, the delay control signal d<sub>2</sub> that is provided to the optical delay line 44 of the second channel 20B, in order to increase the fringe visibility V<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0181]   </span>For example, the delay control signal d<sub>2</sub> is updated by using a known search or optimisation algorithm, such as a bisection algorithm.</p><p><span class=\"paragraph-number\">[0182]   </span>If the optical delay line 44 of the second channel 20B has a movable opto-mechanical element, then the delay control signal d<sub>2</sub> is updated so that the optical delay line 44 of the second channel 20B is moved by the respective actuator, in order to shorten, or stretch, the optical path of the secondary beam 12B accordingly.</p><p><span class=\"paragraph-number\">[0183]   </span>Then, the delay optimization unit 31 repeats step 159 to measure the updated fringe visibility V<sub>2</sub>, and step 161 to check if the interference-quality condition has been satisfied.</p><p><span class=\"paragraph-number\">[0184]   </span>When the interference-quality threshold has been reached, i.e. here when V<sub>2</sub> ≥ V<sub>th</sub>, branch Y at output from step 161, the delay optimization unit 31 returns to step 153 by selecting the j+1-th channel. The, in the example considered, the delay optimization unit 31 selects the third channel 20C.</p><p><span class=\"paragraph-number\">[0185]   </span>Therefore, the delay optimization unit 31 activates the third channel 20C and deactivate the second channel 20B.</p><p><span class=\"paragraph-number\">[0186]   </span>According to this embodiment, the first channel 20A is still used as reference channel.</p><p><span class=\"paragraph-number\">[0187]   </span>The delay optimization unit 31 then repeats the steps from 155 to 163 for the third channel 20C.</p><p><span class=\"paragraph-number\">[0188]   </span>After also the optical path of the third channel 20C has been equalized, the steps from 153 to 163 are repeated also for the fourth channels 20D.</p><p><span class=\"paragraph-number\">[0189]   </span><figref>Figure 7</figref> shows an experimental example of a 3D representation of the spatial distribution of the intensity of the portion of the sample beam 63 acquired by the CCD camera 24, in use. By taking into account the splitting characteristics of the first and the second beam splitters 60, 65, said distribution of intensity is indicative of the distribution of intensity of the recombined beam 75 and, therefore, of the output recombined beam 2 directed onto the target T.</p><p><span class=\"paragraph-number\">[0190]   </span>By measuring the peak intensity of the main lobe, either from the image IMG acquired by the CCD camera 24 or by the intensity signal INT provided by the photodiode 23, it is possible to find the efficiency of the CBC system 1 by calculating the ratio of the peak intensity of the recombined beam 75 over the peak intensity of a single intermediate beam 21A-21D, e.g. η = I<sub>max,CBC</sub>/I<sub>max, SB</sub>.</p><p><span class=\"paragraph-number\">[0191]   </span>Theoretically, the efficiency of the CBC system 1 should be equal to N<sup>2</sup>, with N being the number of channels.</p><p><span class=\"paragraph-number\">[0192]   </span>The Applicant has verified that the efficiency of the CBC system 1 may achieve a high value, close to the theoretical value.</p><p><span class=\"paragraph-number\">[0193]   </span>In particular, for a CBC system having a number of channels N=7, the Applicant has found an experimental efficiency of 38.5, with respect to the theoretical value of N<sup>2</sup>=49. Therefore, the CBC system may have an overall efficiency of about 79% with respect to the theoretical value.</p><p><span class=\"paragraph-number\">[0194]   </span>According to an embodiment, as shown in <figref>figure 8</figref>, the CBC system 1 may comprise also a temperature analysis unit or module 199 configured to perform a method, illustrated in <figref>Figure 9</figref> and indicated by 200, for simulating the effect of temperature variations on the CBC system 1, in particular of the temperature variations induced by the high optical power of the recombined beam 75.</p><p><span class=\"paragraph-number\">[0195]   </span>In detail, the method 200 may be performed on a specific component of the CBC system 1, in order to optimise the parameters of said specific component.</p><p><span class=\"paragraph-number\">[0196]   </span>In detail, the method 200 may be performed for any of the optical elements of the focusing optics 17. In fact, the recombined beam 75 may reach high optical power values, for example around tens of kW, that may cause high temperature variations in the optical elements of the focusing optics 17.</p><p><span class=\"paragraph-number\">[0197]   </span>According to the method 200, at a step 202, the temperature analysis unit 199 receives data indicative of the properties of the component under test (hereinafter c.u.t. data). The component under test may be, for example, the convex lens 55 or the concave lens 56, or any other of the optical components of the focusing optics 17 shown discussed with reference to <figref>Figure 4</figref>.</p><p><span class=\"paragraph-number\">[0198]   </span>Said c.u.t. data may comprise, for example, the geometry of the component under test, the optical properties, in particular absorption, and thermal properties of the substrate material of the component under test.</p><p><span class=\"paragraph-number\">[0199]   </span>At a step 204, the temperature analysis unit 199 receives laser data indicative of the properties of the laser beam to be analysed, i.e. here of the recombined beam 75, such as optical power, spot size and wavelength.</p><p><span class=\"paragraph-number\">[0200]   </span>Then, step 206, the temperature analysis unit 199 uses the c.u.t. data and the laser data as input to solve a 3D partial differential heat equation of the component under test and provides at output a temperature map representing the temperature variations induced in the component under test by the propagation of the laser beam.</p><p><span class=\"paragraph-number\">[0201]   </span>At a step 208, the temperature analysis unit 199 uses the temperature map as input to calculate the local variations of the refractive index of the component under test that are induced by the temperature variations. In detail, the unit 199 provides at output a map of the updated refractive index n(x, y, z, ΔT), e.g. given by n(x, y, z, ΔT) = n<sub>0</sub>(x, y, z) + Δn(x, y, z, ΔT), wherein the variation Δn of the refractive index as a function of a temperature variation ΔT depends on the substrate material of the component under test.</p><p><span class=\"paragraph-number\">[0202]   </span>Then, step 210, the unit 199 uses the updated refractive index n(x, y, z, ΔT) to find the phase variations Δφ induced by the variations in the refractive index. In detail, in this embodiment, the unit 199 calculates a 2D map of the phase variation through the formula: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 60mm; height: 9mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0004.tif&width=60mm&height=9mm\"/></maths></p><p>, wherein z is the propagation direction of the laser beam within the component under test and L is the length of the component under test along the propagation direction.</p><p><span class=\"paragraph-number\">[0203]   </span>The unit 199 converts, step 212, the phase variation Δφ(x, y, ΔT) in polar coordinates Δφ(r, θ, ΔT).</p><p><span class=\"paragraph-number\">[0204]   </span>In detail, the unit 199 decomposes the phase variation by using the Zernike polynomials Z as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 88mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0005.tif&width=88mm&height=5mm\"/></maths></p><p> wherein the indexes n, m refer to the radial and, respectively, the angular behaviour of the phase variation.</p><p><span class=\"paragraph-number\">[0205]   </span>The Zernike polynomials may also be expressed in terms of a single index </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 23mm; height: 12mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010665473&ekey=2045&cc=EP&producerName=imgb0006.tif&width=23mm&height=12mm\"/></maths></p><p>, so that each Zernike polynomial Z<sub>i</sub> is associated to a typical optical aberration and the corresponding coefficient represents the weight of said optical aberration in the decomposed wavefront. For example, i=0 represents the piston phase offset, i=1,2 the wavefront tilt, i=3,5 the astigmatism, i=4 the defocus, etc.</p><p><span class=\"paragraph-number\">[0206]   </span>Then, step 214, the unit 199 performs a simulation algorithm of the optical propagation of the laser beam in the CBC system 1. The algorithm for optical propagation, per se known in the art, receives as input a model of the CBC system 1, which for example may be previously stored in the unit 199 and provided by a user, and the Zernike polynomials Z<sub>i</sub> of the component under test.</p><p><span class=\"paragraph-number\">[0207]   </span>The simulation algorithm provides at output data of the optical properties of the recombined beam 75, such as wavefront properties of the recombined beam 75, after propagation in the CBC system 1, in particular after propagation through the component under test.</p><p><span class=\"paragraph-number\">[0208]   </span>Based on said output data, the unit 199 determines, step 216, the c.u.t. data, for example the material of the component under test, that optimise the optical properties of the recombined beam 75, for example that guarantee a lowest distortion of the wavefront of the recombined beam 75 and a lowest absorption of the recombined beam 75, depending on the specific application.</p><p><span class=\"paragraph-number\">[0209]   </span>In detail, the methods 90, 100, 150 and 200 all contribute to improve the performance of the CBC system 1 and to achieve a value of efficiency close to the theoretical value.</p><p><span class=\"paragraph-number\">[0210]   </span>Finally, it is clear that modifications and variations may be made to what has been described and illustrated herein, without thereby departing from the scope of the present invention, as defined in the annexed claims.</p><p><span class=\"paragraph-number\">[0211]   </span>For example, the number N of channels may be different from what discussed with reference to <figref>Figure 1</figref>; in particular, the CBC system 1 may have up to nineteen channels.</p><p><span class=\"paragraph-number\">[0212]   </span>For example, the phase-locking unit 30 may perform a different algorithm, such as a LOCSET algorithm.</p><p><span class=\"paragraph-number\">[0213]   </span>For example, the phase-locking unit 30 may be implemented using an FPGA, a multichannel DAC unit or a different hardware. For example, the phase-locking unit 30 may comprise a multichannel DAC unit, be coupled to the CCD camera and configured to extract the peak intensity from the image IMG.</p><p><span class=\"paragraph-number\">[0214]   </span>The sample beam 63 may be split directly from the intermediate beams 21A-21D, before being recombined. In this case, the focusing optics would comprise one or more beam splitters arranged between the front coupling portion 45B and the convex lens 55.</p><p><span class=\"paragraph-number\">[0215]   </span>In alternative, each opto-mechanical element may also comprise a respective fibre splitter that extracts a small portion of laser power, for example below 0.1%. In this case, each intermediate beam comprises a first portion that propagates through the aperture and is focused by the focusing optics on the target, and a second portion extracted by the fibre splitter that is focused by the focusing optics on the image sensor and/or the intensity sensor.</p><p><span class=\"paragraph-number\">[0216]   </span>The focusing optics 17 may have different optical elements with respect to what shown in <figref>Figure 4</figref>; for example, the mirror 58 and/or 59 may be absent, so that the optical path 53 is unfolded. Moreover, the lenses 55 and 56 may have different focal lengths and/or different shapes.</p><p><span class=\"paragraph-number\">[0217]   </span>The present coherent beam recombination system is configured to provide an output recombined beam and comprises:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> a laser source that provides a source beam having a linewidth;</li><br/><li> a beam broadener that is coupled to the laser source and is configured to provide a broadened beam having a larger linewidth than the source beam;</li><br/><li> a splitter configured to split the broadened beam into a plurality of secondary beams;</li><br/><li> a plurality of channels that are coupled to the splitter, each channel being configured to receive a respective secondary beam and to provide a respective intermediate beam, each channel comprising an optical amplifier, a phase modulator, an optical delay line and an opto-mechanical element that provides the respective intermediate beam;</li><br/><li> an optical sensor configured to provide a detection signal indicative of an intensity of a received optical beam;</li><br/><li> a focusing optics configured to receive the intermediate beams, to provide the output recombined beam from a first portion of each intermediate beam, and to provide a sampled recombined beam to the optical sensor from a second portion of each intermediate beam; and</li><br/><li> a control unit coupled to the optical sensor and the plurality of channels. The control unit comprises a phase-locking module that is configured to:</li><br/><li> provide a plurality of phase control signals, each to the phase modulator of a respective channel,</li><br/><li> receive the detection signal from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam;</li><br/><li> calculate a cost function from the detection signal, the cost function being a function of the intensity of the sampled recombined beam;</li><br/><li> perform an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and</li><br/><li> provide a plurality of updated phase control signals, based on a result of the optimization algorithm.</li></ul></p><p><span class=\"paragraph-number\">[0218]   </span>Besides, the present method for controlling a coherent beam recombination system is configured to provide an output recombined beam and comprises:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> a laser source that provides a source beam having a linewidth;</li><br/><li> a beam broadener that is coupled to the laser source and is configured to provide a broadened beam having a larger linewidth than the source beam;</li><br/><li> a splitter configured to split the broadened beam into a plurality of secondary beams;</li><br/><li> a plurality of channels that are coupled to the splitter, each channel being configured to receive a respective secondary beam and to provide a respective intermediate beam, each channel comprising an optical amplifier, a phase modulator, an optical delay line and an opto-mechanical element that provides the respective intermediate beam;<ul compact=\"compact\" list-style=\"dash\"><li>an optical sensor configured to provide a detection signal indicative of an intensity of a received optical beam;</li><br/><li> a focusing optics configured to receive the intermediate beams, to provide the output recombined beam from a first portion of each intermediate beam, and to provide a sampled recombined beam to the optical sensor from a second portion of each intermediate beam; and</li></ul></li><li> a control unit coupled to the optical sensor and the plurality of channels. The method may comprise, by a phase-locking module of the control unit:<ul compact=\"compact\" list-style=\"dash\"><li>providing a plurality of phase control signals, each to the phase modulator of a respective channel,</li><br/><li> receiving the detection signal from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam;</li><br/><li> calculating a cost function from the detection signal, the cost function being a function of the intensity of the sampled recombined beam;</li><br/><li> performing an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and</li><br/><li> providing a plurality of updated phase control signals, based on a result of the optimization algorithm.</li></ul></li></ul></p>",
            "CLMS": "(EP4342040)<br/><p>1. A coherent beam recombination system (1) configured to provide an output recombined beam (2), comprising:<br/> - a laser source (3) providing a source beam (8) having a linewidth;<br/> - a beam broadener (5) coupled to the laser source and configured to provide a broadened beam (10) having a larger linewidth than the source beam;<br/> - a splitter (7) configured to split the broadened beam into a plurality of secondary beams (12A-12D);<br/> - a plurality of channels (20A-20D) coupled to the splitter, each channel being configured to receive a respective secondary beam (12A-12D) and to provide a respective intermediate beam (21A-21D), each channel comprising an optical amplifier (40), a phase modulator (42), an optical delay line (44) and an opto-mechanical element (47) that provides the respective intermediate beam;<br/> - an optical sensor (23, 24) configured to provide a detection signal (INT, IMG) indicative of an intensity of a received optical beam;<br/> - a focusing optics (17) configured to receive the intermediate beams (21A-21D), to provide the output recombined beam (2) from a first portion of each intermediate beam, and to provide a sampled recombined beam (63) to the optical sensor from a second portion (63) of each intermediate beam; and<br/> - a control unit (30) coupled to the optical sensor and the plurality of channels,<br/>wherein the control unit comprises a phase-locking module (26) configured to:<br/> - provide a plurality of phase control signals (u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub>), each to the phase modulator (42) of a respective channel (20A-20D),<br/> - receive the detection signal (INT) from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam;<br/> - calculate a cost function (J) from the detection signal (INT), the cost function being a function of the intensity of the sampled recombined beam;<br/> - perform an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and<br/> - provide a plurality of updated phase control signals, based on a result of the optimization algorithm,<br/>wherein the optical delay lines are variable delay lines, each configured to modify the length of the optical path of the respective channel, the control unit (30) further comprising a delay-equalization module (31) coupled to the channels and the optical sensor, the delay-equalization module being configured to:<br/> - select (153) a channel to be optimized and a reference channel from the plurality of channels (20A-20D);<br/> - determine (155) a coarse estimate of an optical delay between the channel to be optimized and the reference channel, from the detection signal (INT);<br/> - provide (157) a delay-control signal (d<sub>2</sub>) to the optical delay line (44) of the channel to be optimized, based on said coarse estimate;<br/> - determine (159) a fine estimate of the optical delay between the channel to be optimized and the reference channel, from the detection signal (IMG);<br/> - update (161, 163) the delay-control signal (d<sub>2</sub>), based on said fine estimate.</p><p>2. The coherent beam recombination system according to the preceding claim, further comprising an actuator (25) coupled to the optical sensor (23) and configured to cause a displacement of the optical sensor.</p><p>3. The coherent beam recombination system according to claim 1 or 2, wherein the optimization algorithm is a Stochastic Parallel Gradient Descent algorithm.</p><p>4. The coherent beam recombination system according to any of the preceding claims, wherein the beam broadener (5) comprises a noise generator (36, 37, 38) providing a broadening signal, and a broadening phase modulator (35) receiving the source beam (8), providing the broadened beam (10), and controlled by the broadening signal.</p><p>5. The coherent beam recombination system according to any of the preceding claims, wherein each opto-mechanical element (47) has an aperture (46) providing the respective intermediate beam and comprises a respective intensity mask (50) configured to block the transmission of a portion of the respective secondary beam (12A-12D).</p><p>6. The coherent beam recombination system according to any of the preceding claims, wherein each opto-mechanical element (47) has an aperture (46) providing the respective intermediate beam, the apertures (46) being arranged in a tiled-aperture configuration.</p><p>7. The coherent beam recombination system according to any of the preceding claims, wherein the sampled recombined beam (63) forms an interference pattern having a main lobe, the optical sensor comprising a photodiode (23) coupled to a pinhole (71) having a size smaller than a size of the main lobe.</p><p>8. The coherent beam recombination system according to any of the preceding claims, wherein the delay-equalization module is coupled to the laser source (3) and is configured to perform a Frequency Modulation Continuous Wave technique to determine the coarse estimate of the optical delay between the channel to be optimized and the reference channel.</p><p>9. The coherent beam recombination system according to any of the preceding claims, wherein the optical sensor comprises an image sensor (24) configured to provide an image (IMG) of the sampled recombined beam, wherein the delay equalization module is further configured to:<br/> - receive the image (IMG) of the sampled recombined beam;<br/> - measure a fringe visibility of the sampled recombined beam from said image;<br/> - update the delay control signal (d<sub>2</sub>), if the fringe visibility is below a fringe visibility threshold.</p><p>10. A method for controlling a coherent beam recombination system (1) configured to provide an output recombined beam (2), wherein the coherent beam recombination system comprises:<br/> - a laser source (3) providing a source beam (8) having a linewidth;<br/> - a beam broadener (5) coupled to the laser source and configured to provide a broadened beam (10) having a larger linewidth than the source beam;<br/> - a splitter (7) configured to split the broadened beam into a plurality of secondary beams (12A-12D);<br/> - a plurality of channels (20A-20D) coupled to the splitter, each channel being configured to receive a respective secondary beam (12A-12D) and to provide a respective intermediate beam (21A-21D), each channel comprising an optical amplifier (40), a phase modulator (42), an optical delay line (44), and an opto-mechanical element (47) that provides the respective secondary beam;<br/> - an optical sensor (23, 24) configured to generate a detection signal (INT, IMG) indicative of an intensity of a received optical beam;<br/> - a focusing optics (17) configured to receive the intermediate beams (21A-21D), to provide the output recombined beam (2) from a first portion of each intermediate beam, and to provide a sampled recombined beam (63) to the optical sensor from a second portion (63) of each intermediate beam; and<br/> - a control unit (30),<br/>wherein the method comprises, by a phase-locking module (26) of the control unit:<br/> - providing a plurality of phase control signals (u<sub>1</sub>, u<sub>2</sub>, u<sub>3</sub>, u<sub>4</sub>), each to the phase modulator (42) of a respective channel (20A-20D),<br/> - receiving the detection signal (INT) from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam;<br/> - calculating a cost function (J) from the detection signal (INT), the cost function being a function of the intensity of the sampled recombined beam;<br/> - performing an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and<br/> - providing a plurality of updated phase control signals, based on a result of the optimization algorithm,<br/>wherein the optical delay lines are variable delay lines, each configured to modify the length of the optical path of the respective channel, the control unit (30) further comprising a delay-equalization module (31) coupled to the channels and the optical sensor, the method further comprising, by the delay-equalization module:<br/>  - selecting (153) a channel to be optimized and a reference channel from the plurality of channels (20A-20D);<br/>  - determining (155) a coarse estimate of an optical delay between the channel to be optimized and the reference channel, from the detection signal (INT);<br/>  - providing (157) a delay-control signal (d<sub>2</sub>) to the optical delay line (44) of the channel to be optimized, based on said coarse estimate;<br/>  - determining (159) a fine estimate of the optical delay between the channel to be optimized and the reference channel, from the detection signal (IMG);<br/>  - updating (161, 163) the delay-control signal (d<sub>2</sub>), based on said fine estimate.</p><p>11. The method according to the preceding claim, wherein the coherent beam recombination system further comprises an actuator (25) coupled to the optical sensor (23), wherein the optical sensor has an active area (131) receiving a spot of the sampled recombined beam, the method further comprising a step of beam steering including controlling, by the actuator, a displacement of the optical sensor, so that the spot of the sampled recombined beam partially falls outside the active area, thereby reducing the intensity of the sampled recombined beam detected by the optical sensor.</p><p>12. The method according to claim 10 or 11, the method further comprising, by the phase-locking unit (30):<br/> - acquiring (123) an updated detection signal;<br/> - calculating (125) an updated cost function;<br/> - verifying (127) if the updated cost function satisfies a convergence condition;<br/> - if the convergence condition is verified, acquiring a new detection signal and calculating a new updated cost function while the convergence condition is verified; and<br/> - if the convergence condition is not verified, performing a new iteration of the optimization algorithm and providing a plurality of new updated phase control signals based on a result of the new iteration.</p><p>13. The method according to any of claims 10-12, wherein the optimization algorithm is an iterative Stochastic Parallel Gradient Descent algorithm comprising, by the phase locking module, for each iteration:<br/> - generating (105) a plurality of random dephasing signals (δu(k)), one for each channel;<br/> - providing (107) a plurality of positive phase control signals, each to a respective phase modulator, each positive phase control signal being the sum between a respective actual phase control signal (U(k-1)) determined in a previous iteration and the respective random dephasing signal;<br/> - acquiring (109) a positive detection signal;<br/> - calculating (111) a positive cost function from the positive detection signal;<br/> - providing (113) a plurality of negative phase control signals, each to a respective phase modulator, each negative phase control signal being the difference between the respective actual phase control signal and the respective random dephasing signal;<br/> - acquiring (115) a negative detection signal;<br/> - calculating (117) a negative cost function from the negative detection signal;<br/>wherein the updated phase control signals are each a function of the respective current phase control signal, the respective random dephasing signal and a difference between the positive and the negative cost function.</p><p>14. The method according to any of claims 10-13, wherein the control unit further comprises a temperature simulation module (199) and the method further comprises, by the temperature simulation module, a step of simulating an optical component of the coherent recombination system including:<br/> - receiving first data indicative of a geometry and a material of the optical component;<br/> - receiving second data indicative of the properties of the laser beam interacting with the optical component;<br/> - determining, from the first and the second data, the phase variations induced by the optical component because of the interaction with the laser beam;<br/> - performing an algorithm for simulating the optical propagation within the coherent recombination system, the simulation algorithm receiving as input said phase variations and being configured to output the optical properties of the output recombined beam; and<br/> - determining optimized first data of the optical component, based on a result of the simulation algorithm.</p>",
            "NPR": "4",
            "APID": "169163809",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G02B-006/32<br/>G02B-006/38<br/>G02B-006/42<br/>G02B-027/09<br/>G02B-027/10<br/>H01S-003/00<br/>H01S-003/067<br/>H01S-003/10<br/>H01S-003/13<br/>H01S-003/23",
            "ID": "106808912",
            "AB": "(EP4342040)<br/>The coherent beam recombination (CBC) system (1) provides an output recombined beam (2) and comprises: a laser source (3) providing a source beam (8) with linewidth; a beam broadener (5) providing a broadened beam (10) from the source beam; a splitter (7) splitting the broadened beam into a plurality of secondary beams (12A-12D); a plurality of channels (20A-20D) coupled to the splitter. Each channel receives a respective secondary beam (12A-12D) and provides a respective intermediate beam (21A-21D). Each channel has an optical amplifier (40), a phase modulator (42), an optical delay line (44), and an opto-mechanical element (47). The CBC system further comprises an optical sensor (23, 24) that provides a detection signal (INT, IMG) indicative of an intensity of a received optical beam; a focusing optics (17) that receives the intermediate beams (21A- 21D), provides the output recombined beam (2) from a first portion of each intermediate beam, and provides a sampled recombined beam (63) to the optical sensor from a second portion (63) of each intermediate beam. The CBC system further comprises a control unit (30) coupled to the optical sensor and the plurality of channels. The control unit comprises a phase-locking module (26) configured to: provide a plurality of phase control signals (u1, u2, u3, u4) to the phase modulators (42); receive the detection signal (INT) from the optical sensor, indicative of an intensity of the sampled recombined beam; calculate a cost function (J) from the detection signal (INT), wherein the cost function is a function of the intensity of the sampled recombined beam; perform an optimization algorithm of the cost function, configured to maximise the intensity of the sample recombined beam; and provide a plurality of updated phase control signals, based on a result of the optimization algorithm.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=P2lelJoaNr3VNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2023-04-05",
            "PA": "LEONARDO",
            "PAAD": "(EP4342040)<br/>(PUB:EP-4342040B1-8)NAME=Leonardo S.p.A. Piazza Monte Grappa, 4 , CITY=00195 Roma , COUNTRY=IT , REG=101719841<br/><br/>(PUB:EP-4342040A1-8)NAME=Leonardo S.p.A. Piazza Monte Grappa, 4 , CITY=00195 Roma , COUNTRY=IT , REG=101719841<br/><br/><br/>(EP4346030)<br/>(PUB:EP-4346030A3-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/>(PUB:EP-4346030A2-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/><br/>(WO2023194921)<br/>(PUB:WO-2023/194921A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 Roma , POSTCODE=00195 , COUNTRY=IT<br/><br/><br/>(IL-309629)<br/>(PUB:IL-309629A-54)NAME=LEONARDO SPA PIAZZA MONTE GRAPPA 4, 00195 ROMA , COUNTRY=IT<br/><br/><br/>(CA3223916)<br/>(PUB:CA-3223916A1-14)NAME=LEONARDO S.P.A. PIAZZA MONTE GRAPPA, 4 I-00195 , CITY=ROMA , COUNTRY=IT<br/>",
            "FAN": "106808912",
            "TI": "Coherent beam combination system and control method thereof",
            "TECD": "Optics",
            "EPD": "2023-10-12",
            "ICLM": "(EP4342040)<br/><p>1. A coherent beam recombination system (1) configured to provide an output recombined beam (2), comprising: - a laser source (3) providing a source beam (8) having a linewidth; - a beam broadener (5) coupled to the laser source and configured to provide a broadened beam (10) having a larger linewidth than the source beam; - a splitter (7) configured to split the broadened beam into a plurality of secondary beams (12A-12D); - a plurality of channels (20A-20D) coupled to the splitter, each channel being configured to receive a respective secondary beam (12A-12D) and to provide a respective intermediate beam (21A-21D), each channel comprising an optical amplifier (40), a phase modulator (42), an optical delay line (44) and an opto-mechanical element (47) that provides the respective intermediate beam; - an optical sensor (23, 24) configured to provide a detection signal (INT, IMG) indicative of an intensity of a received optical beam; - a focusing optics (17) configured to receive the intermediate beams (21A-21D), to provide the output recombined beam (2) from a first portion of each intermediate beam, and to provide a sampled recombined beam (63) to the optical sensor from a second portion (63) of each intermediate beam; and - a control unit (30) coupled to the optical sensor and the plurality of channels, wherein the control unit comprises a phase-locking module (26) configured to: - provide a plurality of phase control signals (u1, u2, u3, u4), each to the phase modulator (42) of a respective channel (20A-20D), - receive the detection signal (INT) from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam; - calculate a cost function (J) from the detection signal (INT), the cost function being a function of the intensity of the sampled recombined beam; - perform an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and - provide a plurality of updated phase control signals, based on a result of the optimization algorithm, wherein the optical delay lines are variable delay lines, each configured to modify the length of the optical path of the respective channel, the control unit (30) further comprising a delay-equalization module (31) coupled to the channels and the optical sensor, the delay-equalization module being configured to: - select (153) a channel to be optimized and a reference channel from the plurality of channels (20A-20D); - determine (155) a coarse estimate of an optical delay between the channel to be optimized and the reference channel, from the detection signal (INT); - provide (157) a delay-control signal (d2) to the optical delay line (44) of the channel to be optimized, based on said coarse estimate; - determine (159) a fine estimate of the optical delay between the channel to be optimized and the reference channel, from the detection signal (IMG); - update (161, 163) the delay-control signal (d2), based on said fine estimate.</p><p>10. A method for controlling a coherent beam recombination system (1) configured to provide an output recombined beam (2), wherein the coherent beam recombination system comprises: - a laser source (3) providing a source beam (8) having a linewidth; - a beam broadener (5) coupled to the laser source and configured to provide a broadened beam (10) having a larger linewidth than the source beam; - a splitter (7) configured to split the broadened beam into a plurality of secondary beams (12A-12D); - a plurality of channels (20A-20D) coupled to the splitter, each channel being configured to receive a respective secondary beam (12A-12D) and to provide a respective intermediate beam (21A-21D), each channel comprising an optical amplifier (40), a phase modulator (42), an optical delay line (44), and an opto-mechanical element (47) that provides the respective secondary beam; - an optical sensor (23, 24) configured to generate a detection signal (INT, IMG) indicative of an intensity of a received optical beam; - a focusing optics (17) configured to receive the intermediate beams (21A-21D), to provide the output recombined beam (2) from a first portion of each intermediate beam, and to provide a sampled recombined beam (63) to the optical sensor from a second portion (63) of each intermediate beam; and - a control unit (30), wherein the method comprises, by a phase-locking module (26) of the control unit: - providing a plurality of phase control signals (u1, u2, u3, u4), each to the phase modulator (42) of a respective channel (20A-20D), - receiving the detection signal (INT) from the optical sensor, the detection signal being indicative of an intensity of the sampled recombined beam; - calculating a cost function (J) from the detection signal (INT), the cost function being a function of the intensity of the sampled recombined beam; - performing an optimization algorithm of the cost function, the optimization algorithm being configured to maximise the intensity of the sample recombined beam; and - providing a plurality of updated phase control signals, based on a result of the optimization algorithm, wherein the optical delay lines are variable delay lines, each configured to modify the length of the optical path of the respective channel, the control unit (30) further comprising a delay-equalization module (31) coupled to the channels and the optical sensor, the method further comprising, by the delay-equalization module: - selecting (153) a channel to be optimized and a reference channel from the plurality of channels (20A-20D); - determining (155) a coarse estimate of an optical delay between the channel to be optimized and the reference channel, from the detection signal (INT); - providing (157) a delay-control signal (d2) to the optical delay line (44) of the channel to be optimized, based on said coarse estimate; - determining (159) a fine estimate of the optical delay between the channel to be optimized and the reference channel, from the detection signal (IMG); - updating (161, 163) the delay-control signal (d2), based on said fine estimate.</p>",
            "CTN": "(EP4342040)<br/>US20130315271 61224882 WHO=EXAMINER SELF=N CAT=A<br/>US20090134310 43755595 WHO=EXAMINER SELF=N CAT=A<br/>US20220094128 99167438 WHO=EXAMINER SELF=N CAT=A<br/>US20130315271 61224882 WHO=APPLICANT SELF=N<br/>US20090134310 43755595 WHO=APPLICANT SELF=N<br/><br/>(EP4346030)<br/>US20130315271 61224882 WHO=EXAMINER SELF=N CAT=A<br/>US20090134310 43755595 WHO=EXAMINER SELF=N CAT=A<br/>US20220094128 99167438 WHO=EXAMINER SELF=N CAT=A<br/>XP086561509 none WHO=EXAMINER SELF=N CAT=A<br/>XP001564142 none WHO=EXAMINER SELF=N CAT=A<br/>XP020203682 none WHO=EXAMINER SELF=N CAT=A<br/>XP011523034 none WHO=EXAMINER SELF=N CAT=A<br/>XP060143601 none WHO=EXAMINER SELF=N CAT=A<br/>XP011254853 none WHO=EXAMINER SELF=N CAT=A<br/><br/>(WO2023194921)<br/>XP086561509 none WHO=EXAMINER SELF=N CAT=A<br/>US20130315271 61224882 WHO=EXAMINER SELF=N CAT=A<br/>XP001564142 none WHO=EXAMINER SELF=N CAT=A<br/>XP020203682 none WHO=EXAMINER SELF=N CAT=A<br/>XP011523034 none WHO=EXAMINER SELF=N CAT=A<br/>US20090134310 43755595 WHO=EXAMINER SELF=N CAT=A<br/>US20220094128 99167438 WHO=EXAMINER SELF=N CAT=A<br/>XP060143601 none WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2025-10-05",
                    "XAP": "2023WO-IB53454",
                    "APD": "2023-04-05",
                    "APID": "166241012",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2023194921&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=5cIu8F%252FVigvevdJpxVsWArmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2023/194921",
                            "KIND": "A1",
                            "XPN": "WO2023194921",
                            "V_PNID": "WO-2023/194921A1-3",
                            "DATE": "2023-10-12",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCCXYBLsq8gSvN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2023194921&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=5cIu8F%252FVigvevdJpxVsWArmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2043-04-05",
                            "XAP": "2023EP-0720182",
                            "APD": "2023-04-05",
                            "APID": "169163809",
                            "REG_LINK": "https://register.epo.org/application?number=EP23720182",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=P2lelJoaNr3VNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP4342040",
                                    "KIND": "B1",
                                    "XPN": "EP4342040",
                                    "V_PNID": "EP-4342040B1-8",
                                    "DATE": "2024-08-14",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x6pv1XozaCxdKxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4342040&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=P2lelJoaNr3VNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP4342040",
                                    "KIND": "A1",
                                    "XPN": "EP4342040",
                                    "V_PNID": "EP-4342040A1-8",
                                    "DATE": "2024-03-27",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x6pv1XozaCxdPEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4342040&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=P2lelJoaNr3VNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ],
                            "V_APL": [
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "PENDING",
                                    "ACT_EED": "2043-04-05",
                                    "XAP": "2024EP-0151595",
                                    "APD": "2023-04-05",
                                    "APID": "169323878",
                                    "REG_LINK": "https://register.epo.org/application?number=EP24151595",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=y9HOJaRJANPVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "EP4346030",
                                            "KIND": "A3",
                                            "XPN": "EP4346030",
                                            "V_PNID": "EP-4346030A3-8",
                                            "DATE": "2024-04-10",
                                            "STG": "Published search report",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x5JhoKUMSIlOo4J+Hxg+Ja9PJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4346030&kind=A3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=y9HOJaRJANPVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        },
                                        {
                                            "PN": "EP4346030",
                                            "KIND": "A2",
                                            "XPN": "EP4346030",
                                            "V_PNID": "EP-4346030A2-8",
                                            "DATE": "2024-04-03",
                                            "STG": "Application published without search report",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8TP/cX+h8x5JhoKUMSIlOhWceYjKUptoPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4346030&kind=A2",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=y9HOJaRJANPVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2043-04-05",
                            "XAP": "2023IL-0309629",
                            "APD": "2023-04-05",
                            "APID": "168330517",
                            "REG_LINK": "http://www.ilpatsearch.justice.gov.il/UI/MainPage.aspx",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ZPNLNxAg4Yc1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "IL309629",
                                    "KIND": "A",
                                    "XPN": "IL-309629",
                                    "V_PNID": "IL-309629A-54",
                                    "DATE": "2024-02-01",
                                    "STG": "Application of patent for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8NxgSjkqRCsxa+HyFFqScF0zzUpwOsUC6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IL-309629&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ZPNLNxAg4Yc1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2043-04-05",
                            "XAP": "2023AU-0250253",
                            "APD": "2023-04-05",
                            "APID": "167963516",
                            "REG_LINK": "http://pericles.ipaustralia.gov.au/ols/auspat/quickSearch.do?queryString=2023250253",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=S7Gp4TUcZhtMg09RTehAXbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "AU2023250253",
                                    "KIND": "A1",
                                    "XPN": "AU2023250253",
                                    "V_PNID": "AU-2023250253A1-55",
                                    "DATE": "2024-01-18",
                                    "STG": "Open to public inspection",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=OseQCaeVQ7zvxdh723PQSN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=AU2023250253&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=S7Gp4TUcZhtMg09RTehAXbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2043-04-05",
                            "XAP": "2023CA-3223916",
                            "APD": "2023-04-05",
                            "APID": "167840558",
                            "REG_LINK": "https://www.ic.gc.ca/opic-cipo/cpd/eng/patent/3223916/summary.html?type=number_search",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252BrpUW9NTGlzWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CA3223916",
                                    "KIND": "A1",
                                    "XPN": "CA3223916",
                                    "V_PNID": "CA-3223916A1-14",
                                    "DATE": "2023-10-12",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aDst65A0bjkH9Uhf0eA7p/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=CA3223916&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252BrpUW9NTGlzWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                }
            ],
            "REP": "EP4342040_B1",
            "EPRD": "2022-04-05",
            "PN": "EP4342040           B1 2024-08-14 [EP4342040]<br/>EP4342040           A1 2024-03-27 [EP4342040]<br/>EP4346030           A3 2024-04-10 [EP4346030]<br/>EP4346030           A2 2024-04-03 [EP4346030]<br/>WO2023/194921       A1 2023-10-12 [WO2023194921]<br/>IL309629            A  2024-02-01 [IL-309629]<br/>AU2023250253        A1 2024-01-18 [AU2023250253]<br/>CA3223916           A1 2023-10-12 [CA3223916]",
            "ADB": "(EP4342040)<br/><p>In fact, the possibility to obtain a high-power laser beam from the amplification of a single laser source is limited by non-linear optical effects and thermal effects.</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=2<br/>PNAAGE=0<br/>NBPA=1; <br/>ALLCT=7; SCT=2; NSCT=5; <br/>ALLCTG=0; SCTG=0; NSCTG=0; <br/>AFS=3; ACC=3; AMCC=2; <br/>IGEN=0.0; IORG=0.94; IRAD=0.97; <br/>IMPI=0.0; MACI=1.11; PASI=1.37; PAVI=1.1; ",
            "PTCC": "(US20230274647)<br/>CC=US EED=2043-02-17 STATUS=PENDING APID=165545501 APD=2023-02-17 XPN=US20230274647 PD=2023-08-31 EPD=2023-08-31 LPD=2023-08-31 <br/><br/>(WO2023163900)<br/>CC=WO EED=2025-08-25 STATUS=PENDING APID=165567462 APD=2023-02-17 XPN=WO2023163900 PD=2023-08-31 EPD=2023-08-31 LPD=2023-08-31 <br/>CC=EP EED=2043-02-17 STATUS=PENDING APID=165567462 XPN=WO2023163900 <br/>",
            "EPN": "US20230274647",
            "CTGN": "",
            "LAPD": "2023-02-17",
            "STDN": "",
            "NPN": "2",
            "DESC": "<p><h1>CROSS-REFERENCE</h1></p><p><span class=\"paragraph-number\">[0001]   </span>The present patent application claims benefit of U.S. Provisional Patent Application No. 63/313,859, filed Feb. 25, 2022, titled “SYSTEMS AND METHODS FOR ELECTRONIC SURVEILLANCE”.</p><br/><p><h1>INCORPORATION BY REFERENCE</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The disclosure and figures of U.S. Provisional Patent Application No. 63/313,859, filed Feb. 25, 2022, are specifically incorporated by reference herein as if set forth in its entirety.</p><p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0003]   </span>In one aspect, the present disclosure is directed to surveillance systems and methods, and more specifically, to surveillance systems and methods that facilitate collection and correlation of electronic signatures and/or visual identifiers for targets or convoys captured by a mobile collection system. Other aspects also are described.</p><p><h1>BACKGROUND</h1></p><p><span class=\"paragraph-number\">[0004]   </span>A large number of homes and businesses and other private and public spaces now include many devices that utilize Wi-Fi signals, Bluetooth signals, RFID signals, and/or other suitable wireless signals. Further, use of home security cameras and/or doorbell cameras has become more common among large portions of the population. While cameras in public and private spaces can capture images and/or video, the cameras cannot identify people who are obscured, masked, or otherwise attempt to hide their identity. Notably, most people carry at least one electronic device regularly, e.g., a smartphone.</p><p><span class=\"paragraph-number\">[0005]   </span>It can be seen that a need exists for surveillance systems and methods that can be used to provide a correlation between devices, images, and/or locations over a wide area or region, thus enabling tracking of objects, unidentified persons, etc. in a selected area.</p><p><span class=\"paragraph-number\">[0006]   </span>The present disclosure is directed to the foregoing and other related, and unrelated, problems in the relevant art.</p><p><h1>SUMMARY</h1></p><p><span class=\"paragraph-number\">[0007]   </span>Briefly described, the present disclosure is directed to surveillance systems and methods for collecting electronic signatures and/or images, for identification of targets, such as unidentified persons or vehicles within a prescribed or selected location or area and/or for tracking of packages (e.g., high value packages). Further, electronic signatures and/or images may be correlated thus enabling monitoring and potential identification of unidentified persons or vehicles and/or facilitating detection of package delivery exceptions.</p><p><span class=\"paragraph-number\">[0008]   </span>According to aspects of the present disclosure, the surveillance system is configured to utilize existing movement of vehicles (e.g., delivery vehicles, patrol vehicles, etc.) by placing collection devices, including a plurality of sensors, detectors or other, similar devices, on such vehicles. Each of the collection devices will be configured to collect electronic signals as the respective vehicles move along streets and approach homes, businesses, and other locations within a selected area (e.g., for deliveries, etc.) for the purpose of correlating those signals with other collected electronic signals or signature information and developed signal/signature patterns to identify a target or targets that may have been present and/or for tracking objects, such as packages. In addition, the collected electronic signals can be compared with, e.g. developed or stored signal patterns and/or previously identified or vetted electronic device signals to look for anomalies such as unknown electronic devices present at a location where a criminal or other event has occurred.</p><p><span class=\"paragraph-number\">[0009]   </span>In embodiments, the collection devices each may be an independent device, or can be linked to other collection devices in a network or an array, and further may be integrated into existing systems, such as a logistics system for a delivery service or other suitable systems. The surveillance system can be configured to cooperate with other collection systems, such as stationary collection systems installed in homes, businesses, and other locations and configured to utilize existing Wi-Fi connectivity of those locations. Such systems can include home automation, convenience or other electronic devices. Examples include integration with video doorbell systems; video surveillance systems; alarm components; mailbox sensors; exterior lighting and/or motion detection systems; garage, door and gate activation pads or openers, neighborhood watch systems, etc. . . .</p><p><span class=\"paragraph-number\">[0010]   </span>In some embodiments, collected electronic signal data obtained by the collection devices may be stored and/or filtered on the vehicle and uploaded to a central system when the vehicle returns to its base and/or may be sent wirelessly (e.g., via cellular and/or satellite data networks) to a central database system for storage and correlation processing. In embodiments, the database and/or resulting correlation information could be made available to law enforcement for processing. The collected data generally will be individually anonymous, e.g. unlike a video or photograph of a person, etc., the collected data is directed to features of the captured electronic signals from electronic devices with ‘rolling’ identifiers that are intended to be variable. The surveillance system will include programming, including models configured for cluster and pattern analysis, which, in embodiments of the present disclosure, provide a central capability to identify certain electronic devices and targets (e.g. vehicles, individual electronic devices, etc.). Signals and signal characteristics can be used individually or in combination with adjacent signals and/or other collected data to uniquely identify a source for correlation with and identification of targets. For example, the collected electronic signal information could be provided to law enforcement for comparison with automated license plate data collected at or near a location such as to aid in criminal investigations.</p><p><span class=\"paragraph-number\">[0011]   </span>Such surveillance systems and methods may include one or more collection devices mounted on one or more vehicles and/or installed at one or more selected locations. Each of the one or more collection devices may include one or more antennas configured to detect and receive electronic signals from electronic devices using a corresponding frequency. In embodiments, each of the one or more collection devices also may include communications circuitry for transmitting collected electronic signals to an intelligence device that may include communications circuitry to receive any detected electronic signals and/or other data (e.g., images, a series of images, video, location data, license plate numbers, and/or other data related to potential targets). The intelligence device will be configured and/or will include programming configured to analyze the received data. For example, the data from the collection devices can be analyzed to compare data for respective locations recorded at different times and segmented into likely fixed and mobile sources to facilitate identification of vehicles and individuals regularly in the area. In some embodiments, the collected data can be filtered such that regular or known sources are not stored to increase privacy, while new sources or investigation targets are stored, such as to facilitate a variety of implementations from general data collection to precisely focused investigative storage in order to maximize investigative value and/or maximize residential privacy, respectively.</p><p><span class=\"paragraph-number\">[0012]   </span>The electronic signals included within the received data may include tags identifying a type of electronic device that the signal originated from, as well as a number of times and a length of time that the signal is located within a particular area or within multiple areas. The tags may also indicate whether signal is not typically located in that particular area. The intelligence device can correlate unidentified and/or atypical electronic signals and/or other data with electronic signals typically found in respective areas. The intelligence device may then determine whether the unidentified and/or atypical electronic signals and/or other data is correlated with a particular target, convoy, or person based on data from other locations or areas. In addition, or alternatively, the unidentified and/or atypical electronic signals can be stored for potential future correlation (e.g., to a crime that is reported later and that occurred in the vicinity of the unidentified and/or atypical electronic signals). Thus, a target, convoy, and/or person(s)/electronic devices can be tracked and/or associated with events in selected areas or locations.</p><p><span class=\"paragraph-number\">[0013]   </span>According to aspects of the present disclosure, an at least partially mobile surveillance system is provided, which includes collection systems, devices, and/or assemblies, and an intelligence system having classification and search capabilities. In embodiments, the surveillance system will use the characteristics of the collected identifying characteristics to prioritize or otherwise indicate to an investigator that a particular characteristic is material to the identification of the target of an investigation in a particular area or location (e.g., a home, a neighborhood, and/or a business).</p><p><span class=\"paragraph-number\">[0014]   </span>In embodiments, a method is provided that can record electronic signal telemetry while moving through a selected region or area and that can use correlation statistics and analysis to develop relationships between identifiers and non-unique characteristics over a single encounter (e.g., an atypical electronic device located in a selected area during a particular event) or multiple encounters in one or more locations. No single factor may be an absolute or unique identifier. One or more combinations of non-unique characteristics and broadcast or visible variables, methods and transmitted values can be used to identify a set that are collectively statistically significant in their unique association with the source area or location. In embodiments, this method may use artificial intelligence and “Big Data” techniques to identify correlations and to rank those results based on statistical methods created in expert noise reduction and confidence analysis.</p><p><span class=\"paragraph-number\">[0015]   </span>In embodiments, the at least partially mobile surveillance system can include a plurality of collection systems, devices, and/or assemblies that are mounted on vehicles that move through one or more selected geographic and/or strategic areas. By placing a collection of antennae and computer equipment in a delivery vehicle, the package could filter, collect, and stage significant amounts of electronic signal data, integrated with a GPS located on the vehicle. For example, the collection system can be configured to gather signal location, strength, source type, frequency, and data payload information. Since the vehicle is frequently moving through the selected region, the collection system can facilitate triangulation of source location for further refining a signal source location as well. The information could be stored in a raw form and not processed for correlation or refined on location to protect privacy until an authorized, auditable inquiry triggered offload and/or based on a periodic or other triggering event to cause the data to be sent to a central processing location or other system for processing of the data independently or along with other collected source data. By collecting the data centrally, law enforcement personnel can analyze data from multiple crime scenes, known target locations, vehicle accident scenes, emergency incidents, sensitive locations etc.</p><p><span class=\"paragraph-number\">[0016]   </span>In embodiments, the collection systems generally are configured to capture or facilitate collection of information related to visual identifiers and/or electronic signatures associated with and/or atypical to the selected areas/locations as the collection systems are moved through the selected area or areas. For example, the collection devices can include purpose-built collection hardware, additional antennae, and radio hardware that can be integrated into vehicles that often travel through portions of the selected areas to allow collection of electronic signal data that can be time and location correlated across the collection as the vehicle moves through selected areas. In some embodiments, the surveillance system also can include stationary collection systems, devices, and/or assemblies that are located at selected geographic areas or strategic locations. Placing sensors in locations where people are already aware of and/or are comfortable with cameras and surveillance would allow sensing and recording of approach and location access.</p><p><span class=\"paragraph-number\">[0017]   </span>In embodiments, the collection systems can include at least one sensor configured to collect or otherwise capture electronic signal information related electronic signatures of targets and/or electronic devices. This information further can include visual identifiers such as license plate information or other visual or imaged information associated with vehicles (e.g., stickers, patterns, position(s) of component parts, after-market added parts, damage, and/or various other markings, etc. . . . ) that can be used to distinguish or otherwise identify, detect or discern a target vehicle; and/or images or a series of images, such as photographs or video captured by security cameras and/or doorbell cameras. The electronic signatures can include an electronic signal or combination(s) of electronic signals emanating from transmitting electronic devices, and which are associated with and/or can uniquely identify the targets in or moving about the selected areas/locations, such as cell phones, laptops, computing devices, garage door openers, home automation devices, security panels, security cameras, doorbell cameras, key fobs for a vehicle, and/or other electronic devices emitting a wireless signal. The data collected from any of the devices may be tagged. The tags may include the type of device and whether the device is typical or atypical to the selected locations.</p><p><span class=\"paragraph-number\">[0018]   </span>In addition, in some aspects, the surveillance system can include an intelligence device or system that is in communication with the plurality of collection systems, and will be configured to receive the information collected or captured by the collection systems or devices (e.g., data points or packets of location, time, and date stamped information in real time for targets and/or devices within proximity of the collection point systems), and will further be configured (e.g. including programming, etc.) to identify and/or track the atypical targets and/or electronic devices based on this received information. In embodiments, the intelligence system can include classification and search capabilities, for example, including one or more classification and search engines and an intelligence database in communication therewith. The one or more classification and search engines can be configured to identify or extract the electronic signatures associated with the targets using the information collected by the collection systems and catalogue them in the intelligence database with a number of occurrences or discoveries and/or certain identifying characteristics (e.g., geographical coordinates, time stamps, source manufacturer, source type and unique ID, etc.) allowing these identified electronic signatures to become unique, identifiable, individually searchable, and/or searchable in combination with other electronic signatures or targets (e.g., such as in a convoy search).</p><p><span class=\"paragraph-number\">[0019]   </span>The surveillance system thus is configurable to track, map, catalogue, etc., movements of atypical targets (e.g., atypical to a selected area or location) in real time or historically as electronic signals are collected by one or more mobile and/or stationary collection systems or devices in one or more selected areas or locations. The tracking information generated can be used create a map of typical and/or expected electronic signals at multiple locations in one or more selected areas, to help confirm and/or authenticate potential target identification, and further can be configured to generate alerts or notifications when certain targets or atypical targets are recorded by one or more of the mobile and/or stationary collection systems in proximity to one or more locations during an event or during a selected time period including the event.</p><p><span class=\"paragraph-number\">[0020]   </span>The one or more classification and search engines can develop inferences of relationships between electronic devices and targets typical to an area or location and electronic devices and targets atypical to an area based on consistency and/or frequency of detected correlations between identified/extracted electronic signatures and/or targets. Further, the one or more classification and search engines can base such relationships on a reported event or alert, such as a crime or other events.</p><p><span class=\"paragraph-number\">[0021]   </span>For example, the one or more classification and search engines can use frequency and consistency of electronic signals to determine the relative certainty of association of the transmitted electronic devices and targets to develop electronic signatures of the targets. That is, if the relative certainty or probability that a certain electronic signal or combination of electronic signals are associated with a target meets a prescribed threshold, the one or more classification and search engines can identify an electronic signal or combinations of electronic signals as a specific electronic signature associated with that target. Further, the one or more classification and search engines can use frequency and consistency of captured images of different targets traveling together to develop a correlation between different targets. That is, if the relative certainty or probability that a certain first target travels with a second target meets a prescribed threshold, the one or more classification and search engines can identify one or more targets, e.g. first and second targets and/or others, as associated with a convoy. The term “convoy” generally refers to a group of or two or more targets that travel together one or more times on one or more days (e.g., two vehicles that travel together at a specific time on various days). In such embodiments, a convoy may be generated based on electronic signals and/or targets usually found in a selected area. Different or atypical electronic signals and/or targets may be distinguished based on exclusion in existing convoys.</p><p><span class=\"paragraph-number\">[0022]   </span>In an embodiment, the one or more classification and search engines will be configured to correlate one or more identifying characteristics and/or non-unique characteristics over a single encounter or multiple encounters. The one or more identifying characteristics may include license plates, electronic signals, images, a series of images, and/or visual idiosyncrasies, among other factors. Non-unique characteristics may include vehicle make, vehicle model, vehicle color, vehicle year, articles of clothing, among other non-unique characteristics and/or personal characteristics. Such correlations may be determined via machine learning models or classifiers and/or statistical modeling or analysis. The one or more classification and search engines may utilize such correlations to determine various aspects of a target, such as a potential association or correlation between a target and an event in a selected location, among other aspects. Further, the one or more classification and search engines may be utilized to determine statistically significant correlations or associations between atypical targets or atypical electronic signals and/or electronic signals.</p><p><span class=\"paragraph-number\">[0023]   </span>In an embodiment, the one or more classification and search engines will be configured to analyze correlation results using frequency of occurrence, relative representation, signal type, signal receipt location diversity, and signal strength profiling to generate and present confidence levels and/or rankings for correlations between signal-receipt events. The one or more classification and search engines may be configured to filter and sort results such that the user is directed to signals to be associated with a particular event or alarm.</p><p><span class=\"paragraph-number\">[0024]   </span>In an embodiment, the systems and methods may include filtering in-coming electronic signals to maximize the receipt and storage of moving, stable, identifiable signals by analyzing the signal value, strength, spectrum, and embedded identification data. The systems and method may also simultaneously reduce and filter signals and identifiers that are ‘noise’ from likely-unrelated sources and not relevant to the future correlation.</p><p><span class=\"paragraph-number\">[0025]   </span>In addition, or in the alternative, the one or more classification and search engines will be configured to associate or correlate identifying atypical electronic signatures with visual identifiers and frequent electronic signatures at a selected location, such as a visual vehicle identifier, to allow independent identification, tracking, and location identification of targets based on the associated identifying electronic signatures. That is, once the system has records correlating electronic signatures associated with a specific visual vehicle identifier, e.g., a specific license plate number, the intelligence system will be able to detect the likely presence of a vehicle and its associated license plate without visual information, e.g., without the use of a camera. Further, correlation between two or more targets may allow dependent tracking and location identification of targets based on association or correlation with one or more targets. That is, once the system has records correlating a first target with a second target (or more targets), the intelligence system will be able to determine likely presence of the first target based on visual information and/or electronic signals of the second or more targets.</p><p><span class=\"paragraph-number\">[0026]   </span>Furthermore, the collection systems can be mounted on vehicles that move through areas that include homes, neighborhoods, businesses, and/or other locations, such that the intelligence system will be able to identify, and catalogue known electronic signatures and targets in selected areas, e.g., for tracking, mapping, etc. of persons or electronic devices atypical or different than that of persons or electronic devices usually found in the selected areas.</p><p><span class=\"paragraph-number\">[0027]   </span>In embodiments, the at least one sensor of each collection system can include a plurality of sensor assemblies. The sensor assemblies can include one or more cameras or camera systems configured to capture or facilitate collection of information related to vehicle identifiers, such as visual information related to a license plate of a vehicle or other visual vehicle identifiers.</p><p><span class=\"paragraph-number\">[0028]   </span>In addition, the sensor assemblies can include one or more antennas or other signal receivers configured to capture information related to the electronic signatures. The one or more antennas can include a plurality of antennas, such as a Bluetooth® antenna, a Wi-Fi antenna, a RFID antenna, or other RF antennas or combinations thereof, configured to capture information related to electronic signals associated with the targets.</p><p><span class=\"paragraph-number\">[0029]   </span>In some embodiments, the collection systems can be used in conjunction with or include Automated License Plate Readers (“ALPR”) in certain areas, allowing the intelligence system to develop a subset of electronic signals, i.e., an electronic signature, associated with a license plate read at a moment in time and location. Electronic data points from less expensive collectors can then be used to provide more precise tracking than ALPR alone.</p><p><span class=\"paragraph-number\">[0030]   </span>In some embodiments, the surveillance system can be configured to capture sample electronic signature information from a target and/or visual identifiers of other targets, associate that information with the target's identification, and then search for or alert on receipts of similar electronic signature information at one of the collection point systems.</p><p><span class=\"paragraph-number\">[0031]   </span>In additional embodiments, the surveillance system can be configured to allow for search inquiries or scans of suspect's electronic signatures to search selected locations in the database history, placing the suspect at those locations and at a particular time or times. In such examples, the surveillance system can include a user interface. A user can access the user interface and provide various inputs into the user interface. The inputs may include one or more of time, location, license plate numbers, partial license plate numbers, convoys, and/or data related to an event (e.g., package delivery, crime, new visitor, etc.). In such examples, the surveillance system may include text recognition algorithms to parse through text corresponding to the event and separate out important or key words, such as identifying characteristics. Upon providing the various inputs, the surveillance system may provide, as an output, information correlated to the various inputs. For example, an input may include a time, a location, and a portion of a license plate. The output may include how often a vehicle with the portion of the license plate is at that location. Such an output may be determined, at least in part, based on the correlation between that vehicle and other vehicles, electronic data signals, and/or people.</p><p><span class=\"paragraph-number\">[0032]   </span>In still other embodiments, the surveillance system can be configured to allow for labeling of specific electronic signatures with a target and then alert or search for history of those specific electronic signatures in the database, placing the target at various locations.</p><p><span class=\"paragraph-number\">[0033]   </span>In further embodiments, the surveillance system further can indicate or determine changes in association or travel of suspects or other individuals of interest based on variations in electronic signatures and/or correlated targets associated with a target or targets.</p><p><span class=\"paragraph-number\">[0034]   </span>In further embodiments, the surveillance system further can be utilized to generate mail and package delivery notifications (e.g., including package theft), transient signal schedule tracking, regular transient signal reporting to improve bus or transport arrival or departure predictability and alerts, intrusion detection, tagged pet tracking, integrated known-visitor security and lock status-change activation, occupancy trend tracking and reporting for integrated utility and energy management, customization of entertainment and lighting systems by occupancy, simplified guest arrival and security management for commercial space rentals, hotel and campus security systems, and/or integrated video surveillance retrieval and queueing systems, etc.</p><p><span class=\"paragraph-number\">[0035]   </span>In further embodiments, the system can cooperate with a delivery services systems to track packages, such as high-value packages, and alert personnel to potential thefts and/or deliveries to incorrect locations. For example, if a target package is recorded in the courier's system as being on a delivery vehicle or is otherwise expected to be on the vehicle (e.g., before it is scheduled to be delivered) and the surveillance system does not detect the package on the vehicle and/or detects the package at a location that is sufficiently far from the vehicle (e.g., the package is out of range of an RFID reader on the delivery vehicle and/or an RFID signal associated with the package is detected by a collection system on another vehicle at another location), the system can generate an alert that the package may have been misdelivered or stolen off the vehicle and provide surveillance data (e.g., electronic signatures, images, etc. near the vehicle) over a relevant time period (e.g., a time period including when the package was last detected on the vehicle and the time of the alert). This data may be used to track the target package and/or those who may be with the target package (e.g., if the system detects signals associated with one or more devices, such as mobile phones, along with the target package in one or more locations). In another example, a target package may be detected at an unexpected location or area after it has been recorded as properly delivered, in which case, the system can record the unexpected location with associated time and surveillance data in case the package is reported stolen or misdelivered and/or generate an appropriate alert.</p><p><span class=\"paragraph-number\">[0036]   </span>Accordingly, embodiments of at least partially mobile surveillance systems and methods, including systems and methods for facilitating collection and correlation of electronic signatures and/or visual identifiers for targets or convoys that are directed to the above discussed and other needs are disclosed. The foregoing and other advantages and aspects of the embodiments of the present disclosure will become apparent and more readily appreciated from the following detailed description, taken in conjunction with the accompanying drawings. Moreover, it is to be understood that both the foregoing summary of the disclosure and the following detailed description are exemplary and intended to provide further explanation without limiting the scope of the present disclosure.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0037]   </span>It will be appreciated that for simplicity and clarity of illustration, elements illustrated in the Figures are not necessarily drawn to scale. For example, the dimensions of some elements may be exaggerated relative to other elements. Embodiments incorporating teachings of the present disclosure are shown and described with respect to the drawings herein, in which:</p><p><span class=\"paragraph-number\">[0038]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b></a> is a schematic diagram of a surveillance system according to the present disclosure.</p><p><span class=\"paragraph-number\">[0039]   </span><a href=\"#DRAWINGS\">FIG. <b>2</b></a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, and <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a> are schematic diagrams of a surveillance system according to the present disclosure.</p><p><span class=\"paragraph-number\">[0040]   </span><a href=\"#DRAWINGS\">FIGS. <b>4</b>A through <b>4</b>G</a> show exemplary screen shots of an interface associated with the surveillance system according to <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, <a href=\"#DRAWINGS\">FIG. <b>2</b></a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, and/or <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>.</p><p><span class=\"paragraph-number\">[0041]   </span><a href=\"#DRAWINGS\">FIG. <b>5</b></a> is a schematic view of an area with various locations, streets, and vehicles, wherein some of the vehicles include mobile components of the surveillance system of <a href=\"#DRAWINGS\">FIG. <b>1</b></a>.</p><br/><p><h1>DETAILED DESCRIPTION</h1></p><p><span class=\"paragraph-number\">[0042]   </span>The use of the same reference symbols in different drawings indicates similar or identical items.</p><p><h1>DETAILED DESCRIPTION</h1></p><p><span class=\"paragraph-number\">[0043]   </span>The following description in combination with the Figures is provided to assist in understanding the teachings disclosed herein. No attempt is made to show structural details of this disclosure in more detail than may be necessary for a fundamental understanding of the exemplary embodiments discussed herein and various embodiments in which they may be practiced. While the description is focused on specific implementations and embodiments of the teachings, and is provided to assist in describing the teachings, this focus should not be interpreted as a limitation on the scope or applicability of the teachings disclosed herein.</p><p><span class=\"paragraph-number\">[0044]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>, <b>2</b>, and <b>3</b></a> provides a schematic diagram of example embodiments of a surveillance system <b>10</b> for collecting and correlating electronic signal signatures and/or visual identifier information with targets, such as vehicles, individuals, devices or the like, to build intelligence databases that facilitate electronic surveillance, identification and associating indications of common location and movement of targets throughout selected geographic areas or locations at specified times.</p><p><span class=\"paragraph-number\">[0045]   </span>“Electronic surveillance,” as used herein, refers to the collection and correlation of electronic signal information that can be used to identify movements of electronic devices, and potentially individuals and vehicles associated therewith. Some electronic devices transmit information that uniquely identifies them. Others transmit data that can be received repeatedly over time such that the content, format, frequency, or pattern of transmission that can provide enough identification data/a signature to be able to resolve identity to a reasonable specificity across time or on subsequent receipt. The combination of electronic device signal patterns can also be consolidated to identify collections of electronic devices travelling frequently together with an individual or vehicle such that the collection pattern itself can identify the source and/or an individual or vehicle associated or correlated with the electronic device(s) with statistically significant specificity. The electronic devices' transmissions can be classified into groups of technology and frequency ranges. Cellular, Navigation, Bluetooth, Wi-Fi, RFID, Keyless entry, medical device, and tracking tags all typically transmit data that can be collected and correlated as needed. In embodiments, the system would not need to interpret, decrypt, or access the actual data payload of the communications. Rather, the broadcast data and identity structures of the communicating devices may be sufficient to resolve an identity.</p><p><span class=\"paragraph-number\">[0046]   </span>In accordance with embodiments of the present disclosure, the surveillance system <b>10</b> will be adapted to utilize the travel of delivery vehicles <b>11</b> and/or other vehicles through a selected region, such as in residential areas around homes, as well as at or around businesses and other locations. The vehicles <b>11</b> can have regular or irregular routes through the region, traveling on streets and making stops while recording information about the electronic signals encountered along the route, such as signals from home automation systems, wireless security systems, and other integrated electronic devices for managing home electronics and systems. Such collection of electronic signal data can be used to enhance security applications in residential/home environments and/or other locations. For example, devices like Ring® video doorbells and integrated garage door openers as well as home portal systems provide a platform for monitoring and collecting internal and video events. Some of these devices apply video analytics, but still may generally rely on lighting and visibility of faces and objects.</p><p><span class=\"paragraph-number\">[0047]   </span>The addition of electronic surveillance aspects provided by the surveillance system of the present disclosure is less intrusive than off-site video processing for facial or other recognition and can enable collection of data for analysis that could identify individuals even masked or in the dark. The electronic signals can be used to match with other locations, some of which might include better video or identity markers that would allow coordinated mapping of the targets (e.g., suspected intruders, witnesses, etc.) to one or more specific individuals. At rest, however, the data is anonymous and low risk with respect to unwanted privacy intrusion. When mapped at the broader data collection levels by authorized or law enforcement staff, useful correlations of data points emerge. The concept of a neighborhood watch thus could be extended to electronic collection, and the timing and identity of deliveries, visitors, or intruders could be tracked, monitored and reported, without the need for complex or expensive facial, image or license plate recognition. For example, during the holidays, more frequent and later deliveries can be made to homes, while at the same time, more thefts of packages can occur; and the surveillance system of the present disclosure thus can provide for monitoring and identification of delivery persons versus thieves and can provide law enforcement with a means for identifying and tracking such perpetrators.</p><p><span class=\"paragraph-number\">[0048]   </span>In embodiments, the surveillance system is configured to enable advanced correlation searching, including correlation analysis that can incorporate/utilize a series of methods, models and processes for the correlation of identifying-characteristics and/or identifiers including license plate, electronic signals, and visual idiosyncrasies, such that an operator can use known factors to identify previously unknown factors or can use patterns of activity, identifying information, electronic signals or visual idiosyncrasies to draw conclusions about a target's location, association to persons, association to locations and/or travel patterns. The surveillance system thus enables an operator to use known factors to identify previously unknown factors or use patterns of activity, identifying information, electronic signals, or visual idiosyncrasies to draw conclusions about the target's location, association to persons, association to locations and/or travel patterns. Using these known patterns and/or associations, the system may form a convoy for different sets of targets and/or electronic signatures. In such embodiments, the introduction of a new or atypical target and/or electronic signature may indicate an event or may enable the system to cross-check such an introduction against reported events.</p><p><span class=\"paragraph-number\">[0049]   </span>In embodiments, the surveillance system can leverage existing fleet vehicles typically traveling through a region by utilizing a plurality of collection systems or devices mounted to the vehicles as they move through a selected region, traveling on streets and onto various sites (e.g., driveways, parking lots, etc.). The plurality of collection systems or devices may be included in the surveillance system for collecting electronic surveillance data from fixed locations and/or transient electronic surveillance data as the vehicles move on their routes. The collection systems or devices will include a plurality of sensors or detectors, for example, including Bluetooth and Wi-Fi collection source devices (e.g., to gather data relating to such signals), a cell phone collection application or device, a LPR or ALPR, a video or image capture device, RFID reading devices, and/or another device or set of sensors to capture different types of signals or identifiers. Such collection systems or devices can be carried by the vehicles such that the collected electronic signature data could show the transition of vehicles and people encountered as respective vehicles travel their routes. The plurality of collection systems may gather or receive signals from a number of sources, such as garage door openers, video doorbells, security cameras, motion detectors, home automation devices, smart devices, key fobs, computing devices, home/business Wi-Fi, gaming systems, cellular devices, and/or other devices at a home, at a business, at other locations, and/or on vehicles, or that are otherwise transient/non-permanent, that generate an electronic signal. Accordingly, the mobile collection devices can collect a range of signals for central communication and storage over a wide area. In exemplary embodiments, the surveillance system can produce, over time, a map of the known/expected fixed and transient signals collected over an area, which map can be used for comparison when atypical signals are recorded.</p><p><span class=\"paragraph-number\">[0050]   </span>Based on the received electronic signals and/or targets, the surveillance system may generate a convoy or group of targets or electronic signatures for a selected location. In such embodiments, the surveillance system may determine the convoy. In such examples, the convoy may include data relevant to each part of the convoy. Further, additional signals for the convoy may not be recorded, thus reducing the amount of data stored in the surveillance system. Further, using the convoy, the surveillance system may determine whether a new target or electronic signal is a part of the convoy or atypical or different than normal. The identification or discovery of the new target and/or electronic signal may indicate an event is occurring or has occurred. Based on such an occurrence, an alarm may be generated.</p><p><span class=\"paragraph-number\">[0051]   </span>In embodiments, the surveillance system can filter and sort results such that the user is directed to signals most likely to have originated from the same set of devices travelling together. “Signals” here can mean electronic signals, visual identifiers, or license plate identification. In addition, the use of the transmitted methods and features of an electronic source with respect to signal strength, advertised methods, order of advertised elements, public and private attributes, and/or signal spectrum utilization by the surveillance system, as described further herein, can be used to collectively identify that source relatively distinctly.</p><p><span class=\"paragraph-number\">[0052]   </span>In embodiments of the methods disclosed herein, the method(s) can incorporate correlation confidence assignment whereby correlated results between electronic signatures and targets are analyzed using factors such as a frequency of occurrence, relative representation, signal type, signal receipt location diversity and signal strength profiling to generate and present confidence levels for correlations between signal-receipt events. The methods further will use correlation statistics and analysis to develop relationships between identifiers and non-unique characteristics, such as frequency of identifications, and other factors, captures/associated over multiple encounters.</p><p><span class=\"paragraph-number\">[0053]   </span>No single factor may be an absolute or unique identifier. In some embodiments, for example, captured signals or factors can be related to locations that could also be correlated or associated with other factors such as a set of captured license plates, witness statements, etc. The cross-correlations also can be broken into subsets for filtering and generating confidence in the results of such advance correlation searching. The combination of non-unique characteristics and broadcast or visible variables, methods and transmitted values are used to identify a set that are collectively statistically significant in their unique association with the source entity.</p><p><span class=\"paragraph-number\">[0054]   </span>In other embodiments, the method can include correlation data noise-reduction at a collection point for filtering in-coming electronic signals to maximize the receipt and storage of moving, stable, identifiable signals by analyzing the signal value, strength, spectrum and embedded identification data. The method also can substantially simultaneously reduce and filter signals and identifiers that are ‘noise’ from likely-unrelated sources and not relevant to the future correlation.</p><p><span class=\"paragraph-number\">[0055]   </span>As indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, the surveillance system <b>10</b> includes a plurality of collection systems, devices, or assemblies <b>12</b> that are mounted on vehicles <b>11</b> (e.g., delivery or patrol vehicles) that move through one or more selected regions (e.g., one or more towns, counties, cities, metropolitan areas, etc.), such as for making deliveries. A portion of a selected region is schematically shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>. For example, the collection systems <b>12</b> can be mounted on selected vehicles <b>11</b> in a fleet of vehicles such as fleet delivery deployments including consumer package delivery agent vehicles, postal vehicles, government vehicles, utility vehicles, transportation vehicles, and/or other suitable public or private fleet vehicles. In some embodiments, the surveillance system <b>10</b> can include fixed collection systems <b>12</b> installed in stationary settings located at selected geographic areas or strategic/targeted locations about one or more properties such as residential or commercial properties <b>5</b>, e.g. on a mailbox, post, gutter, adjacent a camera etc. (as indicated at <b>13</b> in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>).</p><p><span class=\"paragraph-number\">[0056]   </span>The collection systems <b>12</b> generally can be configured to capture or facilitate collection of information related to visual identifiers and/or electronic signal signature information from nearby or proximal transmitting electronic devices <b>14</b> associated with targets. The targets generally will include persons, vehicles, or a combination of both in and/or moving about the selected areas or locations. Targets also can include transmitted electronic devices or other objects, without departing from the scope of the present disclosure.</p><p><span class=\"paragraph-number\">[0057]   </span>The mobile collection systems <b>12</b> can be placed with vehicles <b>11</b> that typically move through portions of the selected region for other purposes, such as deliveries, utility inspection, or patrols, or can be otherwise mobile. For example, the mobile collection systems can be carried by law enforcement personnel, postal workers, delivery vehicles and personnel, or couriers on walking or driving along predetermined or varying routes, or could be mounted on drones (e.g., for package delivery, utility inspection, etc.), which can offer greater freedom of movement than vehicles limited to streets and driveways and/or can collect data from the upper floors of high rise buildings. In embodiments, stationary collection systems <b>12</b> can be positioned at various locations or collection points about a specific geographic area, e.g., a nearby or proximal to a home, a business, and/or neighborhood, or combinations thereof. Such stationary/fixed collection systems can be limited by their lack of movement, but can provide continuous data collection at strategic locations.</p><p><span class=\"paragraph-number\">[0058]   </span>As schematically shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>, the vehicles <b>11</b> carrying the mobile collection systems <b>12</b> can move through a region, traveling on streets near homes, businesses, and/or other buildings in the region and encountering other vehicles on the streets and on nearby properties. As the vehicles <b>11</b> move through the region and make stops (e.g., to deliver packages, inspect utility equipment, etc.), the mobile collection systems can collect signals from nearby locations, passing vehicles, and parked vehicles. While the routes taken by the vehicles <b>11</b> may vary as needed for different delivery destinations, for example, the vehicles can cooperate to cover a wide area over time as they travel through the region; and in embodiments, such vehicles can travel assigned or pre-determined routes, such as for patrolling or delivery of mail, etc. . . .</p><p><span class=\"paragraph-number\">[0059]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>-<b>3</b></a> further show an embodiment wherein each collection system includes a sensor or sensor assembly <b>16</b> configured to collect or otherwise capture the information related to visual identifiers and/or electronic signatures of targets. The sensor or sensor assembly accordingly can include one or more antennae <b>18</b> for capture of various electronic signals “ES” (<a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b></a>); and/or one or more cameras or camera systems configured to capture or facilitate collection of information related to vehicle identifiers “V”, such as visual or imaged information (e.g. video or photographic or digital images) related to a license plate of a vehicle and/or other visual vehicle or personal identifiers that can be used to discern, detect and/or otherwise identify or confirm the identity of a target vehicle or person.</p><p><span class=\"paragraph-number\">[0060]   </span>For example, in some aspects, such as shown in <a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b></a>, such vehicle markings can include, but are not limited to, signage, stickers, bumper stickers, non-license plate tags, patterns, position or configuration of component parts, damage to the vehicle, such as scratches, dents, repair marks, etc. and the location thereof on the vehicle, small markings or symbols or other indicia on vehicle components, as well as various other identifiable visual markings, or combinations thereof. In some embodiments, the camera system also can include an Automated License Plate Reader (“ALPR”) <b>20</b> integrated or otherwise associated with a collection system, or the surveillance system can include ALRPs in addition to, or in place of, one or more collection systems. An ALPR that is integrated into a mobile collection system can record license plate images and/or numbers in transit and/or at stops and can associate the data with time, date, and location of collection.</p><p><span class=\"paragraph-number\">[0061]   </span>In addition, or in the alternative, the at least one sensor or sensor assembly also can include an antenna, antenna array, or plurality of antennas <b>18</b> configured to capture or otherwise receive electronic signals from transmitting electronic devices associated with the targets for identification/extraction of electronic signatures. The at least one sensor or sensor assembly can include additional sensors, such as IR sensors or other light sensors, without departing from the present disclosure.</p><p><span class=\"paragraph-number\">[0062]   </span>As further illustrated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a> in some non-limiting example embodiments, the transmitting electronic devices <b>14</b> can include, but are not limited to, transmitting electronic devices associated with a vehicle, such as vehicle components including, but not limited to, tire pressure sensors or other manufacturer installed or after-market vehicle sensors, vehicle stereo or entertainments systems, vehicle navigation systems, vehicle infotainment systems, self-driving or driver assist vehicle guidance systems, vehicle Wi-Fi hotspots, other components of internal or external vehicle systems, etc . . . ; and additionally can include transmitting electronic devices associated with persons, packages, utility hardware and/or other types of targets, including, but not limited to, cellular phones and/or other communication devices, tablets, laptops, smart watches, fitness trackers, wireless headphones, RFID tags (e.g., key cards, library books, assets tags, pallet transmitters, pet collars), Wi-Fi hot spots, home automation devices, smart home devices, a garage door opener, a security camera, a doorbell camera, and/or other electronic devices.</p><p><span class=\"paragraph-number\">[0063]   </span>Each sensor or sensor assembly is configured to capture or collect signals transmitted by or otherwise emanating from the transmitting electronic devices when the targets get within proximity of the collection systems and/or when the mobile collection systems get within proximity of the targets. For example, transmitting electronic devices can generate data through inter-device communication across networks and for electronic ‘advertising’ (e.g., for adding devices to networks, rejoining devices to networks, connecting Bluetooth devices, forming ad hoc networks, etc.). Many devices are constantly or frequently polling for partnered devices over ‘advertising’ frequencies. These transmissions can be captured and provide a profile of the transmitting device. In embodiments, certain devices (e.g., often fixed devices) transmit identity, pairing, and/or connection information for wireless networks and actually transmit a rich set of history related to prior connections, which can also be collected for analysis. For example, devices such as Ring doorbells and integrated garage door openers as well as home portal systems provide a platform for collection and communication of data, and Wi-Fi and Bluetooth devices communicate on common frequencies including 2.4 GHz and/or other suitable frequencies.</p><p><span class=\"paragraph-number\">[0064]   </span>In embodiments, the mobile collection systems can include a GPS receiver or other features for tracking location of the mobile collection systems as they are carried on the vehicles during transit. In addition, or alternatively, the mobile collection systems can receive location data from the respective vehicles' tracking system (e.g., GPS). Accordingly, the electronic signal data can be combined with location data identifying the respective locations in which it was recorded along with time and date data to form telemetry data. Stationary collection systems can be installed at a known location and the telemetry can be formed using the known location.</p><p><span class=\"paragraph-number\">[0065]   </span>The collection systems also can be configured to receive signals within a collection range, for example, and not limitation, within a prescribed or selected proximity in relation thereto. For example, in some embodiments, the collection systems could be configured to look for and receive signals transmitted within about 200 feet of the collection systems; while in other embodiments, such as to reduce or limit extraneous noise or to help filter such noise, shorter ranges of signals also can be used, i.e. in some locations, the collections systems can be configured to receive signals transmitted within about 100 feet of the collection systems, and in still other embodiments or locations, signals transmitted within about 50 feet of the collection systems. Other, varying ranges also can be used.</p><p><span class=\"paragraph-number\">[0066]   </span>In embodiments, the data from the collection devices can be analyzed to compare data for respective locations recorded at different times (e.g., when one or more vehicles with collection systems travel near the respective locations at different times) and segmented into likely fixed and mobile/transient sources to facilitate identification of vehicles and individuals regularly in respective areas. In some embodiments, the collected data can be filtered such that regular or known sources are not stored to increase privacy, while new sources or investigation targets are stored, such as to facilitate a variety of implementations from general data collection to precisely focused investigative storage in order to maximize investigative value and/or maximize residential privacy, respectively.</p><p><span class=\"paragraph-number\">[0067]   </span>In addition, as indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, the surveillance system includes an intelligence system that is in communication with the plurality of collection systems. The intelligence system <b>25</b> is configured to receive information collected or captured by the collection systems and to identify and/or track targets or correlate a target with other targets or electronic devices based on this received information. The intelligence system can be in wireless communication with the collection systems, e.g., through a public or private network using Wi-Fi, cellular, etc. . . . . In addition, or in the alternative, the intelligence system and one or more of the collection systems can be connected through one or more wired connections. In this regard, when targets come within proximity of the collection systems, the collection systems will collect visual information and/or electronic signal information associated with the targets and transmit data points or packets of information, e.g., time and location stamped information, related to collected visual and/or electronic signal information to the intelligence system.</p><p><span class=\"paragraph-number\">[0068]   </span>The collection systems can include communications circuitry (e.g. one or more transmitters, receivers, etc.) <b>22</b> configured to transmit data points or packets substantially simultaneously or generally in real time when targets come within proximity to the collection systems. For example, the collection systems can send one or more data points including information corresponding to each electronic signal or visual identifier as it is captured or can send a data packet including information corresponding to multiple electronic signals or visual identifiers received. In addition, or in the alternative, the collection systems can transmit the data points or packets at specific time intervals, such as every few seconds, minutes, hours, etc. or at other times or intervals after the electronic signals or visual identifiers are captured, without departing from the scope of the present disclosure. For example, in some embodiments, a mobile collection system can transmit data when the respective vehicle returns to its base and the mobile collection system can be connected to a locally-managed wired or wireless network.</p><p><span class=\"paragraph-number\">[0069]   </span>In addition, in embodiments such as indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, such electronic signal data can be collected by a cellular device <b>23</b>, such as a cell phone, tablet, etc. running an application configured for collection of such electronic signal data. Alternatively, one or more of the collection devices or systems can include a wireless module or cellular connectivity for transmission of the captured electronic signal data. For example, a series of collection devices can be linked or networked together to a master collection device that receives, compiles and transmits the data received from the other localized collection devices connected thereto to an intelligences system <b>25</b> that can be accessed by law enforcement, for example. As a further alternative, the collection device(s) can be linked to home or business Wi-Fi network(s) for transmission of the collected electronic signal data.</p><p><span class=\"paragraph-number\">[0070]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>-<b>3</b></a> further show that the intelligence system <b>25</b> will include correlation and search capabilities or one or more correlation and search engines <b>28</b> (<a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>) and an intelligence database <b>26</b>. The correlation and search engine is configured to identify or extract electronic signatures and/or other targets associated with a target using collected visual and/or electronic signal information at the collection systems. In particular, the correlation and search engine(s) is configured to ingest or process the data points/data packets to associate or correlate the visual identifiers with the received electronic device signals and/or other visual identifiers of other targets to facilitate the identification or extraction of electronic signatures and/or other targets identifying the targets. In such embodiments, such an association or correlation can be utilized by the correlation and search engine to create a convoy or, in other words, a group of targets which may travel together at varying times on varying dates.</p><p><span class=\"paragraph-number\">[0071]   </span>In embodiments, the electronic signatures can include information related to the collected electronic signals of the transmitting electronic devices or combinations of collected electronic signals of the transmitting electronic devices that uniquely identify the targets. For example, and without limitation, a combination of one or more signals from a plurality of transmitting electronic devices (e.g., a watch, cell phone/communication device, headphones, etc.) can include an electronic signature that uniquely identifies a person; a combination of one or more signals from a plurality of transmitting vehicle components (e.g., a vehicle sensor, infotainment system, etc.) can include an electronic signature that uniquely identifies a vehicle; a combination of one or more signals from a plurality of transmitting home or business components (e.g., a garage door openers, computing devices, video doorbells, etc.) can include one or more electronic signatures that uniquely identifies a home or business, which may or may not include vehicles; or one or more signals from a transmitting electronic device can include an electronic signature that uniquely identifies that electronic device.</p><p><span class=\"paragraph-number\">[0072]   </span>The correlation and search engine further can be configured to filter or otherwise alter the received electronic signatures (or information related thereto) to reduce or diminish signal noise and facilitate identification or extraction of unique, identifying electronic signatures. For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p><p><span class=\"paragraph-number\">[0073]   </span>During the course of an investigation, investigators can use the filtered and/or raw data to track atypical and/or suspect devices to search and/or track potential witnesses and/or suspects. The system also can indicate if wireless security cameras or other relevant devices were in the area of an event so that investigators can look into whether those cameras may have recorded aspects of the event and attempt to obtain those recordings, such as by request and/or via appropriate databases.</p><p><span class=\"paragraph-number\">[0074]   </span>In an embodiment, the intelligence system <b>25</b> or intelligence device and/or the correlation and search engine <b>28</b> or circuitry further may include a memory and a processor or one or more processors. For example, as illustrated in <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, the surveillance system <b>100</b> may include an intelligence device <b>102</b> and the intelligence device <b>102</b> may include a memory <b>104</b> and a processor <b>105</b>, as well as a correlation engine <b>106</b>. The memory <b>104</b> may store instructions executable by the processor <b>105</b> or one or more processors. In an example, the memory <b>104</b> may be a non-transitory machine-readable storage medium.</p><p><span class=\"paragraph-number\">[0075]   </span>As used herein, a “non-transitory machine-readable storage medium” may be any electronic, magnetic, optical, or other physical storage apparatus to contain or store information such as executable instructions, data, and the like. For example, any machine-readable storage medium described herein may be any of random access memory (RAM), volatile memory, non-volatile memory, flash memory, a storage drive (e.g., hard drive), a solid state drive, any type of storage disc, and the like, or a combination thereof. As noted, the memory <b>104</b> may store or include instructions executable by the processor <b>105</b>.</p><p><span class=\"paragraph-number\">[0076]   </span>As used herein, a “processor” may include, for example one processor or multiple processors included in a single device or distributed across multiple computing devices. The processor may comprise at least one of a central processing unit (CPU), a semiconductor-based microprocessor, a graphics processing unit (GPU), a field-programmable gate array (FPGA) to retrieve and execute instructions, a real time processor (RTP), other electronic circuitry suitable for the retrieval and execution instructions stored on a machine-readable storage medium, or a combination thereof.</p><p><span class=\"paragraph-number\">[0077]   </span>In embodiments, the instructions executable by the processor may include instructions to retrieve data or signals continuously, substantially continuously, or at specified intervals from one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N. Each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may include at least one sensor <b>110</b>A, <b>110</b>B, and <b>110</b>N and a communications circuitry <b>112</b>A, <b>112</b>B, and <b>112</b>N, respectively. Each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may further include at least one antenna. The intelligence device <b>102</b> may send a request for data or signals and/or scan for data or signals. For example, if a collection device is detected, the intelligence device <b>102</b> may connect to or scan the communications circuitry of that collection device and collect the data or signals associated with the collection device. The instructions also may include instructions to correlate captured signals to one or more of packages, utility assets, other vehicles, targets, convoys, and/or locations, as described herein. In embodiments, the instructions may further include instructions to generate an interface or graphical user interface (GUI) enabling a user to search and filter received and correlated data or signals. Other instructions may be included in the memory to perform the functions described herein. In an embodiment, the instructions described above may be included in or may be a correlation engine <b>106</b> of the intelligence device <b>102</b>.</p><p><span class=\"paragraph-number\">[0078]   </span>In an embodiment, each one of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may be positioned on a respective vehicle. Each collection device may be mounted to the vehicle, for example, mechanically (for example, via welds, fasteners, and/or connectors, among other types of mechanical connections as will be understood by one skilled in the art) and/or adhesively. Further, each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may include a power source and/or power supply to provide power to the components within the each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N. In another embodiment, in addition to or rather than including an independent power source and/or power supply, a collection device may connect to a respective vehicles power supply (for example, a battery).</p><p><span class=\"paragraph-number\">[0079]   </span>In yet another embodiment, each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may be a kit or included in a kit. The kit may include the components (the collection device, mounts, wires, and/or other components or devices) described herein, allowing a user or operator to mount the collection device to the vehicle and utilize the collection device.</p><p><span class=\"paragraph-number\">[0080]   </span>As used herein, “signal communication” refers to electric communications with/from electronic devices, such as by hard wiring two components together or wireless communication, as understood by those skilled in the art. For example, wireless communication may be Wi-Fi®, Bluetooth®, ZigBee, RFID, and/or forms of near and/or far field communications. In addition, signal communication may include one or more intermediate controllers or relays disposed between elements that are in signal communication with one another.</p><p><span class=\"paragraph-number\">[0081]   </span>In embodiments, the correlation engine <b>106</b> may generate electronic signatures based on collected electronic signals. Electronic signatures can include information related to the collected electronic signals of the transmitting electronic devices or combinations of collected electronic signals of the transmitting electronic devices that uniquely identify the targets. For example, and without limitation, a combination of one or more signals from a plurality of transmitting electronic devices (e.g., a package (such as a package including a RFID tag), a utility asset, a watch, cell phone/communication device, headphones, or another vehicle, among other potential targets) can include an electronic signature that uniquely identifies a person, animal, or item (such as the package or utility asset); a combination of one or more signals from a plurality of transmitting vehicle components (e.g., a vehicle sensor, infotainment system, etc.) can include an electronic signature that uniquely identifies a vehicle; a combination of one or more signals from a plurality of transmitting home or business components (e.g., a garage door openers, computing devices, video doorbells, etc.) can include one or more electronic signatures that uniquely identifies a home or business, which may or may not include vehicles; and/or one or more signals from a transmitting electronic device can include an electronic signature that uniquely identifies that electronic device. In an embodiment, the correlation engine <b>106</b> may generate a prediction of where an animal being tracked via collected electronic signals may appear next.</p><p><span class=\"paragraph-number\">[0082]   </span>In embodiments, such signals may include data unique to a device, as well as anonymous. While such signals may, in some embodiments, not specify a user, person, animal or pet, or item (e.g., anonymous), the correlation and search engine may be configured to associate such signals with a target based on known previously captured signals and/or may be configured to generate a target based on those signals. For example, the collected signals can be identified as relating to a certain type of signal and/or a certain type of device, and can be correlated with other identifying signal information to develop an electronic signature for the electronic device, which electronic device can be associated with a target and later identified by comparing additional collected electronic signals to those of a machining electronic signature for a device or devices associated with a target.</p><p><span class=\"paragraph-number\">[0083]   </span>The correlation and search engine further can be configured to filter or otherwise alter the received electronic signatures (or information related thereto) to reduce or diminish signal noise (e.g., from a noisy signal) and facilitate identification or extraction of unique, identifying electronic signatures. For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected noisy electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p><p><span class=\"paragraph-number\">[0084]   </span>As further shown in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>, in an embodiment, the surveillance system <b>101</b> or apparatus may include processing circuitry <b>114</b>, memory <b>112</b>, communications circuitry <b>118</b>, and correlation circuitry <b>116</b>, each of which will be described in greater detail below. While the various components are illustrated in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a> as being connected with processing circuitry <b>114</b>, it will be understood that the system <b>101</b> or apparatus may further comprise a bus (not expressly shown in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>) for passing information amongst any combination of the various components of the surveillance system <b>101</b> or apparatus. The surveillance system <b>101</b> or apparatus further may include programming or instructions configured to execute various operations described herein, such as those described above in connection with <a href=\"#DRAWINGS\">FIGS. <b>1</b> through <b>3</b>B</a> and below in connection with <a href=\"#DRAWINGS\">FIGS. <b>4</b>A through <b>4</b>G</a>.</p><p><span class=\"paragraph-number\">[0085]   </span>The processing circuitry <b>114</b> (and/or co-processor or any other processor assisting or otherwise associated therewith) may be in communication with the memory <b>112</b> via a bus for passing information amongst components of the surveillance system <b>101</b> or apparatus. The processing circuitry <b>114</b> may be embodied in a number of different ways and may, for example, include one or more processing devices configured to perform independently. Furthermore, the processing circuitry <b>114</b> may include one or more processors configured in tandem via a bus to enable independent execution of software instructions, pipelining, and/or multithreading. The use of the term “processor” may be understood to include a single core processor, a multi-core processor, multiple processors of the surveillance system <b>101</b> or apparatus, remote or “cloud” processors, or any combination thereof.</p><p><span class=\"paragraph-number\">[0086]   </span>The processing circuitry <b>114</b> may be configured to execute software instructions stored in the memory <b>112</b> or otherwise accessible to the processing circuitry <b>114</b>. In some cases, the processing circuitry <b>114</b> may be configured to execute hard-coded functionality. As such, whether configured by hardware or software methods, or by a combination of hardware with software, the processing circuitry <b>114</b> represents an entity or device (e.g., an element that can be physically embodied in circuitry) capable of performing operations according to various embodiments of the present disclosure while configured accordingly. Alternatively, as another example, when the processing circuitry <b>114</b> is embodied as an executor of software instructions, the software instructions may specifically configure the processing circuitry <b>114</b> to perform the algorithms and/or operations described herein when the software instructions are executed.</p><p><span class=\"paragraph-number\">[0087]   </span>The memory <b>112</b> may be a non-transitory machine readable storage medium and may include, for example, one or more volatile and/or non-volatile memories. In other words, for example, the memory <b>112</b> may be an electronic storage device (e.g., a computer readable storage medium). The memory <b>112</b> may be configured to store information, data, content, applications, software instructions, or the like, for enabling the apparatus to carry out various functions in accordance with example embodiments contemplated herein.</p><p><span class=\"paragraph-number\">[0088]   </span>The communications circuitry <b>118</b> may include at least one device or circuitry embodied in either hardware or a combination of hardware and software that is configured to receive and/or transmit data from/to a network and/or any other device, circuitry, or module in communication with the surveillance system <b>200</b> or apparatus (e.g., one or more collection devices). In this regard, the communications circuitry <b>118</b> may include, for example, a network interface for enabling communications with a wired or wireless communication network. For example, the communications circuitry <b>118</b> may include one or more network interface cards, antennas, buses, switches, routers, modems, and supporting hardware and/or software, or any other device suitable for enabling communications via a network. Furthermore, the communications circuitry <b>118</b> may include the processing circuitry for causing transmission of such signals to a network or for handling receipt of signals received from a network.</p><p><span class=\"paragraph-number\">[0089]   </span>The surveillance system <b>101</b> or apparatus generally will include a correlation circuitry <b>226</b> configured to obtain and/or receive data and/or signals from one or more collection devices (such as collection devices associated with respective vehicles), identify and/or develop electronic signatures based on the data and/or signals, and/or correlate the data and/or signals or the electronic signature to a target, convoy, location, event, and/or other aspect. For example, the surveillance system <b>101</b> or apparatus may scan for various signals (e.g., via Wi-Fi, Bluetooth, etc.). Once a signal is detected, the correlation circuitry <b>116</b> may request or obtain data and/or signals from the collection device emanating the signal. Once the correlation circuitry <b>116</b> obtains or receives the data and/or signals, the correlation circuitry <b>116</b> may identify and/or develop an electronic signature or identifying electronic signature based on the data and/or signals.</p><p><span class=\"paragraph-number\">[0090]   </span>The electronic signature or identifying electronic signature may be based on various aspects of data and/or signals, such as the type of data and/or signal, a device associated with the data and/or signal, number of times or frequency that the data and/or signal has been detected, location associated with the data and/or signal, among other aspects. The correlation circuitry <b>116</b> may correlate the electronic signature or identifying electronic signature with one or more of a target, convoy, location, event, package, route, emergency capacity, and/or other aspect. In an example, the correlation circuitry <b>116</b> may determine whether the data and/or signal or the electronic signature or identifying electronic signature is associated with a known or unknown target or convoy and/or whether a target or convoy is in a typical or atypical location and/or may track or enable tracking of a target (such as a package). For example, a package may be tracked to determine whether the package is removed from a delivery vehicle prior to reaching the package's destination. In a further embodiment, the correlation circuitry <b>116</b> may generate an alarm, to be transmitted to one or more users, when an unknown target is detected or when a target is in an atypical location. In yet another embodiment, the correlation circuitry <b>116</b> may determine emergency capacity for a building and/or vehicles and/or may determine available and/or accessible emergency routes. The correlation circuitry <b>116</b> may store the results of the correlation, as well as other information related to the data and/or signal, in a database. The correlation circuitry <b>116</b> may generate a user interface enabling a user to search through and/or filter the results.</p><p><span class=\"paragraph-number\">[0091]   </span>In addition, and as depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>A-<b>4</b>G</a>, the correlation and search engine is configured to catalogue the electronic signatures and/or visual identifiers in the intelligence database with specific identifying characteristics allowing these identified electronic signatures and/or visual identifiers to become unique, identifiable, and searchable. The identifying characteristics can include, but are not limited to, geographical coordinates, time stamps, source manufacturer, source type and unique ID, etc. . . . . The correlation and search engine also can be configured to build catalogs or groupings of independent data points/data packets in the intelligence database that allow correlation analysis to show what otherwise anonymous or non-unique electronic signals and/or other visual identifiers (e.g., other license plates) consistently appear with the targets.</p><p><span class=\"paragraph-number\">[0092]   </span>“Cluster Analysis” can be utilized to associate signal occurrences that follow a pattern, and the system may dynamically generate associations between the signals in a sample. Cluster analysis can allow new signal patterns to generate new cluster identities and for additional signals to be associated with that cluster when the system identifies the cluster-defining pattern. Further, the cluster analysis then allows otherwise anonymous signals to be categorized to a level of uniqueness that the surveillance system modeling/algorithms can use to identify the source with a confidence of uniqueness based on the presence of signals matching one or more cluster. The cluster-defining pattern criteria may include, but are not limited to, identifying information, content structure, transmission pattern, transmission size, encrypted content structure or content variation.</p><p><span class=\"paragraph-number\">[0093]   </span>The surveillance system thus can identify, track, map, catalogue, etc., the presence and/or movements of the targets, in real time for a particular convoy, as electronic signals emanating therefrom occur in proximity to the collection systems or based on image captures of visual identifiers. The surveillance system further can generate alerts or notifications when certain targets (e.g., atypical or unknown) are in proximity to the collection systems. Still further, the surveillance system further allows for the searches or queries of the intelligence database, e.g., for investigating locations or movements of suspects or other persons of interest. The surveillance system, as noted, can generate alerts or notifications when selected known targets are in proximity to the collection systems.</p><p><span class=\"paragraph-number\">[0094]   </span>In embodiments, the correlation and search engine can use algorithms, models, statistical models, machine learning algorithms/models, Big Data analysis or statistics, cluster analysis, etc., to infer relationships between transmitting electronic devices and/or targets based on consistency or likelihood of correlation of the visual identifiers and/or electronic signals of the transmitting electronic devices. For example, the correlation and search engine can be configured to evaluate and combine singular collection events at the collection systems with other catalogued events in the intelligence database to develop correlated information related to the intersection of multiple collected/captured electronic signals and/or visual identifiers that occurred at a specific time and geographical area or location. And, the correlation and search engine can use the frequency and/or consistency of electronic signals and/or visual identifiers received at collection systems to determine the relative certainty of association of the transmitting electronic devices and/or targets to develop electronic signatures (correlated electronic devices) or correlated targets (e.g., correlated license plates) for the targets.</p><p><span class=\"paragraph-number\">[0095]   </span>By way of example and not limitation, the system can identify high confidence correlations in which a set of signals received in a given location as the vehicle moves through an area and makes stops along its route may indicate vehicles and/or devices expected in respective locations (e.g., vehicles, Wi-Fi networks, security devices, etc. typically found at the respective location). As an additional example, the system might consistently see a set of signals associated with a particular home and the typical occupants and may classify these as having a high confidence of being correlated with the home. If an additional signal begins to consistently appear with that pattern, the system may be configured to retain the new signal as ‘known’ within the correlation, or if configured for higher security, may generate or create a notification indicating that a change has occurred, thus allowing the owner to assess if a new device was acquired or if some suspicious new source has appeared. The presence of an additional new signal (e.g., a new signal which is not part of a known pattern of identification as it appears over time) may be added to a category of known devices such that its presence over time with known devices may make the new signal less likely to be considered a concern when that device appears without the other known devices.</p><p><span class=\"paragraph-number\">[0096]   </span>The correlation and search engine can be programmed to determine a likelihood or probability that a specific electronic signal, a combination or set of electronic signals, and/or other target or targets are associated with a target or location (e.g., a home or neighborhood), and if the determined likelihood or probability meets a prescribed/selected likelihood or probability threshold, the engine will identify or extract an electronic signal or combinations of electronic signals as an electronic signature or electronic signatures to be associated with that target. In one embodiment, the likelihood or probability threshold can be about 70% or more (e.g., above 75%, above 80%, above 85%, above 90%, above 95%, above 98%, etc.) that an electronic signal, combination/set of electronic signals, and/or other targets are associated with a particular target, convoy, or location.</p><p><span class=\"paragraph-number\">[0097]   </span>For example, the correlation and search engine may correlate two or more license plates and one or more electronic devices based on multiple events. Based on such a correlation, a prediction of whether a particular vehicle may be present at a specific location may be determined by the correlation and search engine. Further, the two or more license plates may be from or may define a convoy (e.g., group of targets or target vehicles). In such an example, the electronic devices may be associated with the convoy.</p><p><span class=\"paragraph-number\">[0098]   </span>In some embodiments, the correlation and search engine can be configured to determine or identify a location at which a visual identifier and correlated electronic signature and/or other visual identifier are matched to enable tracking and/or verification of targets at such a location. In addition, or in the alternative, the correlation and search engine can be configured to associate identifying electronic signatures and/or other visual identifiers with a location, such as a home or neighborhood, to allow for comparison between a convoy and new, atypical electronic signals. For example, once the engine has records correlating electronic signatures and/or other visual identifiers for a selected location, e.g., a license plate likely to be located at or near a specific visual vehicle identifier, associated with the specific visual vehicle identifier, e.g., a specific license plate number, the correlation and search engine will be able to detect the likely presence of a vehicle and its associated license plate without visual information of that specific vehicle, e.g., a camera may or may not be used.</p><p><span class=\"paragraph-number\">[0099]   </span>In addition, or in the alternative, an existing ALPR can be modified or retrofitted to include components of the collection point systems to enable collection of electronic signals jointly with license plate reads. Further, in some embodiments, collection systems with or near cameras or ALPRs can be used in connection with collection systems without cameras or ALPRs, as indicated at <b>20</b> in <a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b></a>.</p><p><span class=\"paragraph-number\">[0100]   </span>As a result, electronic data points from less expensive collection systems can be used to provide more precise tracking than ALPR alone. That is, the lower cost collection systems can increase collection density beyond the collection of ALPR or camera records, enabling data from both collection system types to be combined to provide more detailed intelligence and increased accuracy of verification or authentication of possible targets, including providing monitoring personnel (e.g. law enforcement, security, or other personnel) with an increased level of confidence of locations of potential criminals, stolen or other vehicles of interest.</p><p><span class=\"paragraph-number\">[0101]   </span>Additionally, or alternatively, collection systems without cameras (or with cameras) can be positioned in areas or locations that cannot be accessed by a vehicle, such as on trains, near railways, around public buildings, etc., to enable collection of electronic signals from persons away from their vehicle, e.g., for cataloguing, tracking, mapping, etc. . . . positions or movements thereof.</p><p><span class=\"paragraph-number\">[0102]   </span>The intelligence system generally includes one or more processors, controller's, CPUs, etc., and one or more memories, such as RAM, ROM, etc., in communication with the one or more processors. And, the engine can include computer programming instructions stored in the one or more memories that can be accessed and executed by the one or more processors to facilitate execution of the processes thereof, e.g., correlation of information, identification and tracking of the targets, searching of the intelligence database, etc. . . .</p><p><span class=\"paragraph-number\">[0103]   </span>The correlation and search engine can process the information from the received data points or data packages to correlate the received signal information with the visual information to develop electronic signatures uniquely identifying each vehicle or person at a selected location based on the received electronic signals or combinations thereof, and also can populate the intelligence database with the signature information identifying each vehicle and/or person. As multiple license plates may be read at a time and multiple signals detected, correlation may occur when or if multiple data points exist for a particular vehicle. Operators then can search or query the intelligence database, e.g., using a user interface or GUI as shown in <a href=\"#DRAWINGS\">FIGS. <b>4</b>A-<b>4</b>D</a>, for identification, mapping, tracking, etc., of vehicles, people, and/or locations at specific times.</p><p><span class=\"paragraph-number\">[0104]   </span>For example, in <a href=\"#DRAWINGS\">FIG. <b>4</b>A</a>, a user may search for a particular vehicle based on a license plate number or other identifier or signature. In <a href=\"#DRAWINGS\">FIG. <b>4</b>B</a>, a user may perform a cross-search. A cross-search can include searching for a particular parameter (e.g., a license plate number, a convoy, an electronics signature, and/or some other identifier) in a first step and then perform additional searches in additional steps (e.g., step <b>2</b>, step <b>3</b>, etc.). In yet another example, as depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>C-<b>4</b>D</a>, a user may search for a particular convoy or search based on selected characteristics of a convoy.</p><p><span class=\"paragraph-number\">[0105]   </span>Summary use cases utilizing embodiments of the surveillance system of the present disclosure can include fully automated, scan-free real time vehicle and package location service, electronic signal correlation processing, mail and package delivery notifications, transient signal schedule tracking, regular transient signal reporting to improve bus or transport arrival or departure predictability and alerts, anomaly/intrusion detection, lost tagged-pet tracking, lost package tracking, integrated known-visitor security and reporting for integrated utility and energy management, security management for commercial space rentals, hotel and campus security systems, integrated video surveillance retrieval and queueing systems, general asset management improvement, law enforcement signal source correlation and tracking, and/or other applications/uses.</p><p><span class=\"paragraph-number\">[0106]   </span>By way of example only, and not limitation, in cases such as for automated, scan-free real time vehicle and package location services, e.g., to notify a recipient and record where and when a package was delivered and to confirm delivery instructions therefor. In embodiments, such as when RFID or other tags are used for packages, the surveillance systems can be used to track lost or stolen packages, such as when packages are delivered to a wrong location, are delivered and subsequently taken from the delivery location, or are reported as delivered, but either remained on the delivery vehicle or were otherwise disposed of without being delivered.</p><p><span class=\"paragraph-number\">[0107]   </span>In other examples, transient signal schedule tracking can include determining the schedule of vehicles in an area, such as school buses, transit vehicles, mail delivery vehicles, etc. Lost pet tracking can include, for example, a mobile or fixed collection system happens to read a tag associated with a lost pet (e.g., where a pet has been “chipped” with an identification tag or marker), which id tags/markers can be included on a hot list and can generate an alert with the location of the lost pet to help focus a search. In exemplary embodiments, integrated known-visitor security and reporting for integrated utility and energy management can include informing security personnel that visitors and/or atypical devices/vehicles are in an area, such as in gated communities, restricted access facilities, etc. Also, integrated utility and energy management can relate to signals received from cable company assets, wireless company assets, electric/gas company assets, etc., which can include communication modules for relaying operation information to utility personnel (e.g., without having to climb utility poles). Such signals from utilities equipment may be identified by the surveillance system and can be associated with relatively precise locations, and the system can generate alerts if such devices were found to be non-functioning. For example, the system may determine that a Wi-Fi hotspot is not working and alert the associated cable company.</p><p><span class=\"paragraph-number\">[0108]   </span>In exemplary embodiments, integrated video surveillance retrieval and queueing systems can relate to integration with video databases, such as Neighbors by Ring, etc., in which users upload security camera videos, and investigators can review videos based on location, time, and date data associated with a particular event when the surveillance system detects relevant camera devices in the area of the event. In embodiments, general asset management improvement can include reporting data related to signals received from tagged assets for a partner agency or business, which data can be used to determine if assets are being properly used, such as determining if vehicles or equipment are making routes or are in appropriate locations and/or are functional.</p><p><span class=\"paragraph-number\">[0109]   </span>Another exemplary summary use case utilizing embodiments of the surveillance system of the present disclosure can include occupancy scanning and device location mapping. For example, circumnavigating a building or area could triangulate, count, and map signal sources in the interior providing occupancy information, which can help law enforcement and/or personnel locate potential threats in a building (e.g., during a robbery or hostage situation, for locating an enemy, etc.) and/or can help identify potential locations of persons needing rescue, such as in the case of a fire or building collapse. Additionally, anomaly and/or intrusion detection can be correlated with the capture of electronic signal information by the surveillance systems to help law enforcement in investigations; and for integrated known-visitor security and reporting for integrated utility and energy management, and for management of commercial and residential spaces. In another example, a mobile system traveling through an area regularly could capture and map the status of utility assets or other sources and provide mapping information. In a further example, emergency services could map device occupancy by device class to assure evacuation and efficiently manage rescue operations.</p><p><span class=\"paragraph-number\">[0110]   </span>By way of example only, in some embodiments, the surveillance system can be configured to capture an electronic signature and associated information from a target, and can associate such electronic signature, as well as associate other targets, and associated information with the target's identification, e.g., license plate number or other visual identifier, with the correlation and search engine, and then allow searches for or provide alerts or notifications on receipts of similar electronic signature information and/or visual identifier at one or more of the collection systems. In an embodiment, the association or correlation of two or more different license plates, which may include correlated one or more different electronic devices, may form a convoy. Convoys may be selectable, as illustrated in <a href=\"#DRAWINGS\">FIG. <b>4</b>D-<b>4</b>F</a>, and/or locations for searching targets or convoys can be selectable.</p><p><span class=\"paragraph-number\">[0111]   </span>The surveillance system further can be configured to allow for search inquiries or scans of one or more specific electronic signatures associated with a target or convoy or may search for a specific convoy or target associated with one or more convoys, and to provide search results including known location data points, in the intelligence database. As depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>E-<b>4</b>G</a>, the search results can include maps or other images showing the locations of the collection systems that captured electronic signals associated with the one or more electronic signatures searched at the time of capture, e.g., indicating the selected target's or convoy's presence or movements about a prescribed location or area.</p><p><span class=\"paragraph-number\">[0112]   </span>In addition, or in the alternative, the search results can include groupings or listings of search results associating the target, electronic signals, and/or convoy searched with information related to the collection systems which captured target, electronic signals, and/or convoy associated with the two or more targets and/or one or more electronic signatures searched. The grouping or listing can include images captured (e.g., images of the person, vehicle, vehicle license plate, etc.), temporal information (e.g., the date and time the visual or signal information was collected), the visual identifier (e.g., license plate number), location information (e.g., GPS coordinates, state, city, etc.), information identifying the collection point system, states of the collection (e.g., normal read, error, etc.), etc. . . .</p><p><span class=\"paragraph-number\">[0113]   </span>The surveillance system can generate an alarm or alert when the specific electronic signature(s) and/or visual identifier distinct or atypical from a convoy is captured at a selected location. The alarm may alert a user of the presence of an atypical or distinct target(s) at or near the selected location. The alarm or alert can be provided to the operator of the surveillance system and/or local authorities, e.g., law enforcement or other third parties. In some embodiments, the target can be selected based on a specific criteria associated with the target of the convoy, e.g., arrest warrant, Amber or Silver Alert, expired registration, immigration violation, etc. . . . , and when the labeled electronic signatures and/or visual identifiers are collected at one or more of the collection systems, the proper authorities can be notified.</p><p><span class=\"paragraph-number\">[0114]   </span>In still further embodiments, the surveillance system further can indicate or determine changes in association or travel of suspects based on variations in electronic signatures associated with a location. For example, based on unique electronic signatures, the surveillance system can indicate whether particular individuals are or were traveling with a vehicle through or in the selected location, which can allow investigators to determine whether suspects were actually at the selected location during an event.</p><p><span class=\"paragraph-number\">[0115]   </span>By way of example and not limitation, in an embodiment for analysis of electronic signature data, an initial goal is to find associations of electronic signatures and/or targets to known ALPR targets. For this, multiple locations can be used. The repeated linking of a target (e.g., a license plate) to electronic signatures and/or other targets can be the value. For example, a particular license plate can be associated with a convoy, the convoy can be associated with a list of electronic signatures, and the convoy and/or electronic signatures associated with non-LPR sites.</p><p><span class=\"paragraph-number\">[0116]   </span>In some aspects, the surveillance system and the operation thereof can include the harvest or collection of values in convoy searches when a target value is unknown. Such a search can be based on a date/time, tight correlations, and/or other factors. Reading a signal simply at one site or by one mobile collection system may not be valuable, but a read at two or more sites (e.g., by one or more mobile and/or stationary collection systems) may indicate that a target is moving and may be valuable or more valuable than a single read of a potentially stationary target. Using such systems and methods described herein, a search can be quickly refined to values that are read at multiple sites and have convoy hits/correlation or association, with and/or without a plate match. A convoy can be limited by site and by multiple electronic signature reads at a series of sites, e.g. two or more successive sites.</p><p><span class=\"paragraph-number\">[0117]   </span>In embodiments, incorporation of mobile collection systems into delivery vehicles can facilitate and/or enhance package tracking. For example, by including RFID reading technology inside and outside of the vehicle, package tracking detail can be increased, providing the locations of packages in real time along with a location at which a package moves out of range of the RFID reader on the respective vehicle (e.g., if the package is moved away from the vehicle and/or the vehicle moves away from the package). In embodiments, RFID source tags could be introduced to all, or to high-value packages for increased accuracy in tracking. The RFID technology and on-vehicle reading can provide positive asset tracking, actively and regularly confirming one or more items are onboard a vehicle during its travels, which can facilitate accuracy assurance and last-known-location tracking for accidental off-loads. In exemplary embodiments, driver key-fobs could also improve auditability of shift and activity information. In embodiments, the addition of internal-facing and external-facing RFID reading could all be included at minimal incremental cost above a single read-point in order to help control the expense of incorporating an RFID system into a fleet of delivery vehicles. In embodiments, the surveillance system with the integrated package tracking system can generate alerts to the driver and/or other suitable personnel, such as if items left the vehicle during the driver's absence (e.g., the system determines that devices associated with the driver, such as a key fob, mobile phone, barcode scanner, RFID tag, etc., moved away from the vehicle around the time of an event) and/or if an item additional to the intended delivery load was inadvertently taken off at an incorrect location.</p><p><span class=\"paragraph-number\">[0118]   </span>In exemplary embodiments, the integration of package tracking with other electronic surveillance can facilitate the response to a loss of a package with information about what devices, and thereby people and vehicles, may have been in range at the time of the incident (e.g., for identifying potential witnesses and/or suspects of a crime). In another example, the integrated package tracking can help deter and/or investigate package dumping by delivery personnel. The system also can help detect the theft of a package after it has been delivered and can help track the stolen package, such as when a package is recorded as being properly delivered but is later detected along with atypical devices associated with unexpected persons and/or vehicles. In embodiments, the electronic collection by the mobile collection systems of the present disclosure can also help increase the accuracy of the location information (e.g., from GPS) using the location of known, fixed signal sources, such as Wi-Fi routers and utility sources, when signals from such fixed sources are recorded by the mobile collection system at the time of a loss.</p><p><span class=\"paragraph-number\">[0119]   </span>In embodiments, surveillance systems as described herein that utilize mobile collection systems can provide several benefits over surveillance systems that use data gathered from fixed sites alone. When the mobile collection systems are mounted on delivery vehicles and/or other private or public fleet vehicles, which may have irregular routes and/or visit locations at irregular times, nevertheless can result in collecting a rich data set for analysis of device location and anomalies over a wide area. For example, data can be collected at least occasionally at many sites without fixed collection systems over the region. In embodiments, a database resulting from a coordinated and consolidated feed of the data generated by the surveillance systems of the present disclosure could be an investigative, intelligence, and research foundation for everything from law enforcement to traffic analysis to route audit and efficiency management.</p><p><span class=\"paragraph-number\">[0120]   </span>In addition, the surveillance system of the present disclosure can have significant benefits over video technology since it would be less invasive, more omni-directional, improving coverage, and would not require complex video redaction to remove sensitive image areas or concerns about unintended video capture. At rest, the data is anonymous and low risk with respect to unwanted privacy intrusion. When mapped at the broader data collection by authorized or law enforcement staff, useful correlation of data points emerge. That said, the system could be deployed with or without integrated video capture technology. If video collection so collocated, integrated event recording and queuing would be possible.</p><p><span class=\"paragraph-number\">[0121]   </span>The foregoing description generally illustrates and describes various embodiments of the present disclosure. It will, however, be understood by those skilled in the art that various changes and modifications can be made to the above-discussed construction of the present disclosure without departing from the spirit and scope of the disclosure as disclosed herein, and that it is intended that all matter contained in the above description or shown in the accompanying drawings shall be interpreted as being illustrative, and not to be taken in a limiting sense. Furthermore, the scope of the present disclosure shall be construed to cover various modifications, combinations, additions, alterations, etc., above and to the above-described embodiments, which shall be considered to be within the scope of the present disclosure. Accordingly, various features and characteristics of the present disclosure as discussed herein may be selectively interchanged and applied to other illustrated and non-illustrated embodiments of the disclosure, and numerous variations, modifications, and additions further can be made thereto without departing from the spirit and scope of the present disclosure as set forth in the appended claims.</p>",
            "CLMS": "(US20230274647)<br/><p><b>1</b>. A surveillance system comprising:<br/> a plurality of collection systems, one or more of the collection system of the plurality of collection systems positioned on an associated vehicle of a plurality of vehicles;<br/> wherein each of the collection systems comprises:<br/>  at least one sensor configured to collect electronic signals from proximal electronic devices, and<br/>  communication circuitry to transmit collected electronic signals; and<br/> an intelligence device configured to receive the collected electronic signals transmitted from the collection systems;<br/> wherein the intelligence device comprises:<br/>  a database, and<br/>  correlation circuitry configured to determine a correlation between one or more different electronic signals of the collected electronic signals and produce an identifying electronic signature.</p><p><b>2</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein each of the collection systems further includes a positioning device associated with the associated vehicle for generating location data associated with the collected electronic signals, and wherein the communication circuitry is configured to transmit the location data along with the collected electronic signals.</p><p><b>3</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein one or more of the collection systems further includes an automated license plate reader (ALPR) configured to capture license plate numbers and/or other identifying vehicle characteristics, and wherein the intelligence device correlates at least one captured license plate number transmitted from the one or more collection systems with one or more of the collected electronic signals.</p><p><b>4</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the associated vehicle comprises a delivery vehicle, and the one or more of the collection systems includes one or more RFID readers positioned on the delivery vehicle, and wherein the one or more RFID readers is configured to collect RFID tag numbers associated with packages in the delivery vehicle and generate a record indicating when the packages are removed from the delivery vehicle.</p><p><b>5</b>. The surveillance system of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref>, wherein the intelligence device is configured to detect differences between an expected delivery location of a package and a location of the delivery vehicle when the one or more RFID readers indicates that the package is removed from the delivery vehicle.</p><p><b>6</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the at least one sensor of each of the plurality of collection systems includes one or more readers configured to read RFID signals, Wi-Fi signals, cellular signals, or other wireless signals, a license plate reader, a camera, or combinations thereof.</p><p><b>7</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the at least one sensor comprises a Bluetooth® antenna, Wi-Fi antenna, RFID antenna, RF antennas, or combinations thereof, each configured to collect the electronic signals associated with a target.</p><p><b>8</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the one or more electronic signals include one or more identifying signals, location data, a time stamp, images, video, source type, or combinations thereof.</p><p><b>9</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the correlation circuitry is further configured associate each electronic signature with a known or unknown target; wherein each known or unknown target comprises at least one transmitting electronic device, a package including a RFID tag, a person, a vehicle, a convoy, one or more utility assets, or combinations thereof.</p><p><b>10</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein each of the collection systems is configured to collect electronic signals from proximal electronic devices associated with a vehicle during operation of the associated vehicle.</p><p><b>11</b>. A surveillance system comprising:<br/> a plurality of mobile collection systems each comprising:<br/>  at least one sensor configured to collect electronic signals from proximal electronic devices as the mobile collection systems are moved about an area,<br/>  wherein the electronic signals comprise RFID signals, Wi-Fi signals, cellular signals, Bluetooth® or other wireless signals, a license plate reader, a camera, or combinations thereof, and<br/>  a communication circuitry to transmit collected electronic signals; and<br/> an intelligence device positioned separate from the mobile collection systems and comprising:<br/>  a database, and<br/>  a correlation circuitry to:<br/>   develop an electronic signature for each of the proximal devices from which the electronic signals are collected by one or more of the mobile collection systems, and<br/>   determine a correlation between one or more electronic signals of each electronic signature and a target.</p><p><b>12</b>. The surveillance system of <claim-ref idref=\"CLM-00011\">claim 11</claim-ref>, wherein the at least one sensor of each of the plurality of mobile collection systems includes at least one Bluetooth® antenna, Wi-Fi antenna, RFID antenna, RF antennas, or combinations thereof, each configured to collect the electronic signals.</p><p><b>13</b>. The surveillance system of <claim-ref idref=\"CLM-00011\">claim 11</claim-ref>, wherein the target comprises at least one package, vehicle, a convoy, a person, a vehicle, a utility asset, a transmitting electronic device, or combinations thereof.</p><p><b>14</b>. The surveillance system of <claim-ref idref=\"CLM-00011\">claim 11</claim-ref>, wherein the one of one or more mobile collection systems are configured to be carried by a delivery vehicle, and wherein the correlation circuitry is configured to alert an operator if at least one package having an RFID tag or other transmitting electronic device associated therewith is removed from the delivery vehicle prior to reaching a selected location or destination.</p><p><b>15</b>. The surveillance system of <claim-ref idref=\"CLM-00011\">claim 11</claim-ref>, wherein each mobile collection system includes a GPS location device configured to generate real-time location data for an identified target detected by the mobile collection system; and wherein the correlation circuitry is configured to transmit real-time location data of the identified target to an operator upon request or upon determination of the correlation.</p><p><b>16</b>. A method comprising:<br/> collecting, via a plurality of collection systems each positioned on a respective one of a plurality of vehicles, electronic signals from proximal electronic devices while the any of the plurality of vehicles operate;<br/> transmitting collected electronic signals to an intelligence device; and<br/> determining a correlation between one or more different electronic signals of the collected electronic signals.</p><p><b>17</b>. The method of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, wherein collecting the electronic signals by each of the plurality of collection systems includes detecting and capturing RFID signals, Wi-Fi signals, cellular signals, or other wireless signals, license plate or other vehicle identifying information, images, video, or combinations thereof.</p><p><b>18</b>. The method of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, further comprising:<br/> tracking, based on the correlation, a real-time location of a subject, wherein the subject includes one or more of a package, an animal, at least one other vehicle, or a target; and<br/> determining, based on data generated via tracking, one or more a status of package delivery, a predicted next location of the animal, occupancy of the at least one other vehicle.</p><p><b>19</b>. The method of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, wherein one or more of the proximal electronic devices correspond to one or more of a building, utility assets, or a second plurality of vehicles, and further comprising:<br/> determining, based on the correlation, one or more of an interior occupancy for each of the one or more buildings, one or more of availability or status of the utility assets, a known-visitor report for the utility assets, or a route for an evacuation and rescue operation.</p><p><b>20</b>. The method of <claim-ref idref=\"CLM-00016\">claim 16</claim-ref>, wherein the one of one or more collection systems are carried by a delivery vehicle, and wherein the electronic signals are generated from RFID tags or other transmitting device carried by one or more packages, and further comprising generating an alert if a collected electronic signal indicates a package is removed from the delivery vehicle prior to reaching a selected location or destination.</p>",
            "NPR": "2",
            "APID": "165545501",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G06Q-010/0833<br/>G06V-010/80<br/>G06V-020/52<br/>G06V-020/62<br/>G08G-001/00<br/>G08G-001/017",
            "ID": "106243695",
            "AB": "(US20230274647)<br/>A system and method for monitoring, via collection systems mounted on vehicles, for one or more electronic signals associated with one or more selected locations. In an embodiment, the system may include a plurality of collection systems. Each collection system of the plurality of collection systems may be positioned on a respective vehicle of a plurality of vehicles. Each of the collection systems may include at least one sensor configured to collect electronic signals from proximal electronic devices and a communication circuitry to transmit collected electronic signals. The system may include an intelligence device receiving the transmitted collected electronic signals. The intelligence device may include a database and correlation circuitry to determine a correlation between one or more different electronic signals of the collected electronic signals.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HauAR0G9YNwgBstjf3AJlMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=",
            "EAPD": "2023-02-17",
            "PA": "LEONARDO US CYBER & SECURITY SOLUTIONS<br/>SELEX",
            "PAAD": "(US20230274647)<br/>(PUB:US-20230274647A1-2)NAME=Selex ES Inc.  , CITY=Greensboro , STATE=NC , COUNTRY=US<br/><br/><br/>(WO2023163900)<br/>(PUB:WO-2023/163900A1-3)NAME=SELEX ES INC. 4221 Tudor Lane Greensboro, NC 27410 , POSTCODE=27410 , COUNTRY=US<br/>",
            "FAN": "106243695",
            "TI": "Systems and methods for electronic surveillance",
            "TECD": "Computer technology<br/>Control<br/>IT methods for management",
            "EPD": "2023-08-31",
            "ICLM": "(US20230274647)<br/><p>1 . A surveillance system comprising: a plurality of collection systems, one or more of the collection system of the plurality of collection systems positioned on an associated vehicle of a plurality of vehicles; wherein each of the collection systems comprises: at least one sensor configured to collect electronic signals from proximal electronic devices, and communication circuitry to transmit collected electronic signals; and an intelligence device configured to receive the collected electronic signals transmitted from the collection systems; wherein the intelligence device comprises: a database, and correlation circuitry configured to determine a correlation between one or more different electronic signals of the collected electronic signals and produce an identifying electronic signature.</p><p>11 . A surveillance system comprising: a plurality of mobile collection systems each comprising: at least one sensor configured to collect electronic signals from proximal electronic devices as the mobile collection systems are moved about an area, wherein the electronic signals comprise RFID signals, Wi-Fi signals, cellular signals, Bluetooth® or other wireless signals, a license plate reader, a camera, or combinations thereof, and a communication circuitry to transmit collected electronic signals; and an intelligence device positioned separate from the mobile collection systems and comprising: a database, and a correlation circuitry to: develop an electronic signature for each of the proximal devices from which the electronic signals are collected by one or more of the mobile collection systems, and determine a correlation between one or more electronic signals of each electronic signature and a target.</p><p>16 . A method comprising: collecting, via a plurality of collection systems each positioned on a respective one of a plurality of vehicles, electronic signals from proximal electronic devices while the any of the plurality of vehicles operate; transmitting collected electronic signals to an intelligence device; and determining a correlation between one or more different electronic signals of the collected electronic signals.</p>",
            "CTN": "(WO2023163900)<br/>US20140225719 45557140 WHO=EXAMINER SELF=N CAT=A<br/>US20050065711 62076400 WHO=EXAMINER SELF=N CAT=A<br/>US20070291118 44142743 WHO=EXAMINER SELF=N CAT=A<br/>US20230070108 103937091 WHO=EXAMINER SELF=Y CAT=E<br/>US20230073717 103938676 WHO=EXAMINER SELF=Y CAT=E<br/>US20160021344 72027267 WHO=EXAMINER SELF=N CAT=A<br/>US20150381948 71056781 WHO=EXAMINER SELF=N CAT=A<br/>XP093087463 none WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2025-08-25",
                    "XAP": "2023WO-US13274",
                    "APD": "2023-02-17",
                    "APID": "165567462",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2023163900&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=lAOACGUbGOuN6DCcepW9B7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2023/163900",
                            "KIND": "A1",
                            "XPN": "WO2023163900",
                            "V_PNID": "WO-2023/163900A1-3",
                            "DATE": "2023-08-31",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDFAnk32D5Ind0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2023163900&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=lAOACGUbGOuN6DCcepW9B7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2043-02-17",
                    "XAP": "2023US-18110923",
                    "APD": "2023-02-17",
                    "APID": "165545501",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/18110923",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HauAR0G9YNwgBstjf3AJlMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US20230274647",
                            "KIND": "A1",
                            "XPN": "US20230274647",
                            "V_PNID": "US-20230274647A1-2",
                            "DATE": "2023-08-31",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcNGVaVlLSXOsM/J3aSBKS3mbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20230274647&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HauAR0G9YNwgBstjf3AJlMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "US20230274647_A1",
            "EPRD": "2022-02-25",
            "PN": "US20230274647       A1 2023-08-31 [US20230274647]<br/>WO2023/163900       A1 2023-08-31 [WO2023163900]",
            "ADB": "(US20230274647)<br/><p>It can be seen that a need exists for surveillance systems and methods that can be used to provide a correlation between devices, images, and/or locations over a wide area or region, thus enabling tracking of objects, unidentified persons, etc. in a selected area.</p><p>It will be appreciated that for simplicity and clarity of illustration, elements illustrated in the Figures are not necessarily drawn to scale.</p><p>The foregoing and other advantages and aspects of the embodiments of the present disclosure will become apparent and more readily appreciated from the following detailed description, taken in conjunction with the accompanying drawings.</p><p>For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p><p>For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected noisy electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p><p>Such stationary/fixed collection systems can be limited by their lack of movement, but can provide continuous data collection at strategic locations.</p>"
        },
        {
            "FNUM": "APAGE=11<br/>NBPC=4<br/>PNAAGE=16<br/>NBPA=1; <br/>ALLCT=4; SCT=1; NSCT=3; <br/>ALLCTG=1; SCTG=0; NSCTG=1; <br/>AFS=23; ACC=22; AMCC=4; <br/>IGEN=0.0; IORG=0.88; IRAD=0.93; <br/>IMPI=2.4; MACI=1.66; PASI=3.09; PAVI=3.36; ",
            "PTCC": "(EP4198842)<br/>CC=EP EED=2041-12-17 STATUS=GRANTED APID=164376127 APD=2021-12-17 XPN=EP4198842 PD=2023-06-21 PD=2024-05-22 EPD=2023-06-21 LPD=2024-05-22 PDG=2024-05-22 <br/>CC=CH EED=2041-12-17 STATUS=GRANTED APID=164376127 XPN=EP4198842 PDG=2024-05-22 <br/>CC=DE EED=2041-12-17 STATUS=GRANTED APID=164376127 XPN=EP4198842 PDG=2024-05-22 <br/>CC=GB EED=2041-12-17 STATUS=GRANTED APID=164376127 XPN=EP4198842 PDG=2024-05-22 <br/>CC=IE EED=2041-12-17 STATUS=GRANTED APID=164376127 XPN=EP4198842 PDG=2024-05-22 <br/><br/>(WO2023111716)<br/>CC=WO EED=2025-06-17 STATUS=PENDING APID=164383734 APD=2022-11-16 XPN=WO2023111716 PD=2023-06-22 EPD=2023-06-22 LPD=2023-06-22 <br/>CC=CN EED=2042-11-16 STATUS=PENDING APID=171504312 APD=2022-11-16 XPN=CN118414623 PD=2024-07-30 EPD=2024-07-30 LPD=2024-07-30 <br/>CC=EP EED=2042-11-16 STATUS=PENDING APID=164383734 XPN=WO2023111716 <br/>CC=KR EED=2042-11-16 STATUS=PENDING APID=172691461 APD=2022-11-16 XPN=KR20240147662 PD=2024-10-08 EPD=2024-10-08 LPD=2024-10-08 <br/>CC=US EED=2042-11-16 STATUS=PENDING APID=164383734 XPN=WO2023111716 <br/><br/>(KR20240147662)<br/>CC=KR EED=2042-11-16 STATUS=PENDING APID=172691461 APD=2022-11-16 XPN=KR20240147662 PD=2024-10-08 EPD=2024-10-08 LPD=2024-10-08 <br/><br/>(CN118414623)<br/>CC=CN EED=2042-11-16 STATUS=PENDING APID=171504312 APD=2022-11-16 XPN=CN118414623 PD=2024-07-30 EPD=2024-07-30 LPD=2024-07-30 <br/>",
            "EPN": "EP4198842",
            "CTGN": "(WO2023111716)<br/>CN117806345 109150956 WHO=EXAMINER SELF=N CAT=A",
            "LAPD": "2022-11-16",
            "STDN": "",
            "NPN": "4",
            "DESC": "<p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method for classifying the manoeuvres performed by an aircraft, by segmentation of time series of measurements acquired during a flight of the aircraft.</p><p><span class=\"paragraph-number\">[0002]   </span>As is known, in aeronautics the need to monitor the state of fatigue, and more generally the state of health, of the components of an aircraft is particularly felt, for example in order to be able to accurately estimate the residual life time of each component, and therefore to optimise maintenance activities, without compromising flight safety.</p><p><span class=\"paragraph-number\">[0003]   </span>In particular, it is known that the state of fatigue to which the components of an aircraft are subjected depends on the manoeuvres to which, during usage, the aircraft has been subjected, since the loads to which each component is subjected depend on the manoeuvres performed by the aircraft. Consequently, the need is felt to correctly identify the manoeuvres performed by an aircraft, so that the so-called \"real usage spectrum\" can then be determined. To this end, it is known to equip aircraft with monitoring systems adapted to measure flight-related quantities, i.e. adapted to acquire values (samples) of these quantities; this allows a large number of measurements of these quantities to be acquired, which can then be analysed to study the history of the manoeuvres performed by the aircraft.</p><p><span class=\"paragraph-number\">[0004]   </span>For example, <figref>Figure 1A</figref> shows a helicopter 1, which is equipped with a monitoring system 2, which includes sensors adapted to measure corresponding quantities, which are referred to in the following as the primary quantities. Generally, the samples of the primary quantities are acquired with a certain sampling frequency, typically in the order of about ten Hertz. Purely by way of example, the primary quantities may include: variables related to the aircraft kinematics (such as, for example, pitch angle, roll angle, yaw angle, track angle, vertical acceleration, vertical speed, longitudinal acceleration, lateral acceleration, roll rate, pitch rate, yaw rate, northbound speed, eastbound speed, main rotor speed); variables related to the aircraft controls (such as, for example, collective control position, lateral position cyclic control, longitudinal position cyclic control, pedal position); environmental variables (such as, for example, air speed, radar altitude, barometric altitude, wind speed, wind direction, total air temperature, take-off weight); variables related to the energy systems (such as, for example, the torque of the motors, the rotation speed of the engine turbines, the rotation speed of the engine generators).</p><p><span class=\"paragraph-number\">[0005]   </span>For example, <figref>Figure 1B</figref> shows the trends over time of five primary quantities (denoted as quantities 1-5, respectively), which are monitored by corresponding sensors of the monitoring system 2 during a test flight. The sensors in the monitoring system 2 periodically provide the corresponding samples and operate, for example, synchronously and without phase shift, with the same sampling frequency f<sub>c</sub> (e.g. equal to 12.5 Hz).</p><p><span class=\"paragraph-number\">[0006]   </span>However, the Applicant has observed that, even having such measurements, the correct detection of the executed manoeuvres requires the execution of advanced data processing techniques and is also hampered by the fact that different manoeuvres typically have different durations, which complicates the analysis of the aforementioned time trends.</p><p><span class=\"paragraph-number\">[0007]   </span>In order to overcome the problem of the different manoeuvre durations, <patcit dnum=\"EP20425059\" dnum-type=\"L\">European patent application No. 20425059.1, filed on 18 December 2020</patcit> on behalf of the Applicant, describes a computer-implemented method for detecting the execution, by an aircraft, of a manoeuvre belonging to a macrocategory among a plurality of predetermined macrocategories. In particular, as shown in <figref>Figure 2</figref>, the set (denoted with 5) of the manoeuvres that can be carried out by an aircraft can be subdivided into a plurality of subsets, to which in the continuation reference is made precisely as to macrocategories (denoted with MC). Each macrocategory MC groups together subclasses of manoeuvres with similar features. For example, <figref>Figure 2</figref> shows macrocategories MC relating to level flight, bank turn, vertical take-off, climbing, etc., respectively. In turn, the macrocategory relating to level flight may include a plurality of manoeuvres (only four shown in <figref>Figure 2</figref>, denoted with \"level flight at forty knots\", \"level flight at sixty knots\", \"level flight at ninety knots\" and \"level flight at one hundred and fifty knots\"). In other words, each macrocategory MC represents a corresponding class of manoeuvres, i.e. a corresponding flight regime.</p><p><span class=\"paragraph-number\">[0008]   </span>That being said, the method described in <patcit dnum=\"EP20425059\" dnum-type=\"L\">European Patent Application No. 20425059.1</patcit> contemplates acquiring a data structure including a plurality of time series of values of quantities relating to a flight of the aircraft, and then performing, for each instant of time of a succession of instants of time, the steps of: for each time duration among a plurality of predetermined time durations, selecting a corresponding subset of the data structure having a time extent equal to the time duration and centred as a function of the instant of time; from each selected subset of the data structure, extracting a corresponding feature vector; based on the feature vectors, generating a corresponding input macrovector, alternatively by aggregation of the feature vectors or by performing classifications of the feature vectors, in order to generate input prediction vectors (each of which is indicative, for each macrocategory, of a corresponding probability that, in said instant of time of the succession of instants of time, the aircraft was performing a manoeuvre belonging to said macrocategory) and subsequent aggregation of the input prediction vectors. The method also contemplates performing, for each instant of time of the succession of instants of time, the steps of: applying to the input macrovector an output classifier, which is configured to generate a corresponding output vector including, for each macrocategory, a corresponding estimate of the probability that, in the aforementioned instant of time of the succession of instants of time, the aircraft was performing a manoeuvre belonging to this macrocategory; based on the output vector, detecting the macrocategory to which the manoeuvre performed by the aircraft in the aforementioned instant of time of the succession of instants of time belongs.</p><p><span class=\"paragraph-number\">[0009]   </span>In more detail, the method described in the above-mentioned <patcit dnum=\"EP20425059\" dnum-type=\"L\">European patent application No. 20425059.1</patcit> requires the training of a plurality of classifiers in a supervised manner. Such training requires the provision of a training data structure that stores the time series (understood as successions of samples associated with corresponding instants of time) formed by the values of the primary quantities detected by helicopter monitoring systems during the test flights; in addition, it is necessary for pilots to label the test manoeuvres performed during the test flights, so that the training data structure stores, for each test manoeuvre, the macrocategory to which the test manoeuvre belongs. In this way, the training data structure is formed by a plurality of portions, referred to as data groups, each of which is associated with a corresponding macrocategory; furthermore, these portions may possibly be interspersed with portions referring to unlabelled periods of time, i.e. periods of time in which pilots have not reported performing manoeuvres. For example, <figref>Figure 1B</figref> show a first and a second interval of time T1, T2, in which respectively a first and a second test manoeuvre M1, M2 of a test flight of the helicopter 1 are verified, which are reported by the pilot, belong to corresponding macrocategories (possibly, to a same macrocategory) and correspond to the data groups denoted respectively with DG1 and DG2; furthermore, in <figref>Figure 1B</figref> three periods of time are denoted respectively with NMP1, NMP2, NMP3, which are interspersed with respect to the first and second interval of time T1, T2, in which no manoeuvres are reported by the pilot; in other words, the periods of time NMP1, NMP2, NMP3 are unlabelled periods.</p><p><span class=\"paragraph-number\">[0010]   </span>The training of the classifiers is then carried out in a supervised manner based on the training data structure and is a function of the macrocategories reported by the pilots during the test flights (also known as load survey flights).</p><p><span class=\"paragraph-number\">[0011]   </span>The method described in the above-mentioned <patcit dnum=\"EP204250591A\">European patent application No 204250591</patcit> thus makes it possible to detect the macrocategories to which the manoeuvres performed by an aircraft belong with high precision, but it is based on the above-mentioned extraction of features, which must be carefully chosen in order to optimise the precision with which the macrocategories are detected. Moreover, the above-mentioned method is characterised by a rather high computational burden. In addition, the above-mentioned method requires defining the number and dimension of the above-mentioned time durations (also known as time windows).</p><p><span class=\"paragraph-number\">[0012]   </span><patcit dnum=\"US10935938B1\">US 10935938 B1</patcit> discloses a system for learning practical autonomy including a module comprising a machine learning module configured to perform the steps of: receiving inputs, which include operator response data, and generating an output that tracks or trains against the one or more inputs, the output including one or more control system commands; and classifying a state based on a representation that correlates the operator response data to the state; and evaluating one or more manoeuvres responsive to the state to generate an evaluation gradient.</p><p><span class=\"paragraph-number\">[0013]   </span><patcit dnum=\"EP2270618A2\">EP 2270618 A2</patcit> discloses a method for fault determination for an aircraft, which includes the steps of generating a predicted manoeuvre of the aircraft using an aircraft operating input and a model of aircraft performance, determining an actual manoeuvre of the aircraft using information obtained from an inertial measurement system, comparing the predicted manoeuvre and the actual manoeuvre, and determining a fault of the aircraft based on the comparison of the predicted manoeuvre and the actual manoeuvre.</p><p><span class=\"paragraph-number\">[0014]   </span><patcit dnum=\"EP2725337A1\">EP 2725337 A1</patcit> discloses a fatigue management system, wherein load classification flight parameters are correlated by means of a collection of heuristic models to associate said load classification flight parameters via the respective causative operational conditions collected during classification flights to the corresponding load data from at least one precedent load classification flight.</p><p><span class=\"paragraph-number\">[0015]   </span>Aim of the present invention is thus to provide a method for classifying the manoeuvres performed by an aircraft, which at least partially overcomes the drawbacks of the prior art.</p><p><span class=\"paragraph-number\">[0016]   </span>According to the present invention, a method and a system for classifying manoeuvres are realized, as defined in the appended claims.</p><p><span class=\"paragraph-number\">[0017]   </span>To better understand the present invention preferred embodiments thereof will be now described, for merely exemplary and non-limiting purposes, with reference to the appended drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1A</figref> schematically shows a view of an aircraft equipped with a monitoring system;</li><br/><li> <figref>Figure 1B</figref> shows examples of trends over time of values of quantities acquired by means of the monitoring system shown in <figref>Figure 1A</figref>;</li><br/><li> <figref>Figure 2</figref> shows a block diagram which exemplifies a possible subdivision into macrocategories of a set of manoeuvres that can be performed by an aircraft;</li><br/><li> <figref>Figures 3 and 18</figref> show flow diagrams of operations according to the present method;</li><br/><li> <figref>Figures 4</figref>, <figref>20</figref> and <figref>21</figref> schematically show data structures according to the present method;</li><br/><li> <figref>Figure 5</figref> shows a block diagram of a portion of the data structure shown in <figref>Figure 4</figref>;</li><br/><li> <figref>Figure 6</figref> shows a block diagram of a neural network;</li><br/><li> <figref>Figures 7</figref>, <figref>11</figref>, <figref>12A-12B</figref> and <figref>15</figref> show block diagrams of portions of the neural network shown in <figref>Figure 6</figref></li><br/><li> <figref>Figures 8</figref>, <figref>9</figref>, <figref>17</figref> and <figref>22</figref> schematically show further data structures according to the present method;</li><br/><li> <figref>Figures 10, 13</figref>, <figref>14 and 16</figref> schematically show data structures subject to operations according to the present method; and</li><br/><li> <figref>Figure 19</figref> schematically shows the trends of curves according to this method.</li></ul></p><p><span class=\"paragraph-number\">[0018]   </span>Purely by way of example, the present method is now described on the assumption that the monitoring system 2 is adapted to acquire the samples relating to a number N of primary quantities. Furthermore, it is assumed that the macrocategories, which are referred to as classes in the following, are equal to NUM_C in number.</p><p><span class=\"paragraph-number\">[0019]   </span>In consideration of the foregoing, the present method provides, as shown in <figref>Figure 3</figref>, acquiring (block 100) a training data structure 10, an example of which is qualitatively shown in <figref>Figure 4</figref>, where it has been assumed for simplicity's sake that the number N of quantities primary is equal to five. As shown again in <figref>Figure 4</figref>, the training data structure 10 can be stored in a computer 12.</p><p><span class=\"paragraph-number\">[0020]   </span>In detail, the training data structure 10 stores the time series (understood as successions of samples associated with corresponding instants of time) formed by the samples of the primary quantities detected by the monitoring system 2 of the helicopter 1 during test flights, i.e. flights for which the manoeuvres performed are known. Furthermore, the training data structure 10 may also store time series formed by samples of the primary quantities acquired by monitoring systems (not shown) of several aircraft (not shown and for example identical to each other) during respective test flights. However, in the following it is assumed for simplicity's sake that the training data structure 10 includes only samples of the primary quantities detected by the monitoring system 2 of the helicopter 1 during the execution of manoeuvres, carried out during the test flights.</p><p><span class=\"paragraph-number\">[0021]   </span>In more detail, and without any loss of generality, the training data structure 10 stores samples relating to instants of time when manoeuvres are performed; in other words, the training data structure 10 stores samples of the primary quantities relating to labelled periods.</p><p><span class=\"paragraph-number\">[0022]   </span>In practice, the training data structure 10 stores, for each manoeuvre performed during a test flight (referred to briefly in the following as the test manoeuvre), a corresponding data group (denoted with DG), which is formed by the samples of the primary quantities acquired by the monitoring system 2 during the interval of time in which the test manoeuvre was performed by the helicopter 1. In addition, for each test manoeuvre, the detection data structure 10 stores the class to which the test manoeuvre belongs.</p><p><span class=\"paragraph-number\">[0023]   </span>For example, in <figref>Figure 4</figref> it is assumed that the training data structure 10 refers to a number L of test manoeuvres; in particular, with regard to the l-th test manoeuvre (with 1 = 1,..., L), the training data structure 10 stores a corresponding l-th data group DGl, as well as the association with the corresponding class. For example, in <figref>Figure 4</figref> it was assumed that the first three test manoeuvres, which took place in the intervals of time T1, T2 and T3, belong to the classes C<sub>3</sub>, C<sub>1</sub> and C<sub>2</sub>, respectively; furthermore, it was assumed that the L-th test manoeuvre, which took place in the interval of time TL, belongs to class C<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0024]   </span>Even in greater detail, the time series of samples of the primary quantities stored in the training data structure 10 refer to a succession of instants of time, which in <figref>Figure 4</figref> extends between a first instant of time t<sub>0</sub> and a last instant of time t<sub>nmax</sub>. Furthermore, considering each data group of the training data structure 10, and thus considering each test manoeuvre, the corresponding portions of the time series of samples of the primary quantities refer to a corresponding succession of instants of time, which are temporally spaced by a time step denoted with Δ<sub>c</sub> and equal to the inverse of the sampling frequency f<sub>c</sub>. Furthermore, considering, for example, the first and second data groups DG1, DG2 of the training data structure 10, the last instant of time of the first data group DG1 (denoted with t<sub>M1</sub>) and the first instant of time of the second data group DG2 (denoted with t<sub>M2</sub>) may have a time distance different from Δ<sub>c</sub>, since, as explained above, the first and the second test manoeuvres M1, M2 may have been performed after some time, rather than immediately one after the other. Similar considerations apply to each pair of adjacent data groups in the training data structure 10. From another point of view, the axis of the time shown in <figref>Figure 4</figref> is formed by a succession of instants of time, not necessarily equally spaced between them.</p><p><span class=\"paragraph-number\">[0025]   </span>In practice, for each instant of time, the training data structure 10 stores a corresponding training vector including, for each of the primary quantities, the corresponding sample. In this regard, <figref>Figure 4</figref> shows, by way of example, the training vector (denoted with Vx) relative to the instant of time t<sub>x</sub>, which falls within the interval of time T1 and stores the corresponding samples of the primary quantities 1-5, denoted respectively with Q1<sub>tx</sub> - Q5<sub>tx</sub> (visible in <figref>Figure 5</figref>). The training data structure 10 is therefore a two-dimensional matrix of dimensions N*(nmax+1), in which each column consists of a corresponding training vector.</p><p><span class=\"paragraph-number\">[0026]   </span>Then, as shown again in <figref>Figure 3</figref>, the computer 12 trains (block 106) a neural network 29, the structure of which is shown in <figref>Figure 6</figref>. Before describing in detail the training modalities of the neural network 29, the functioning of the neural network 29 is described hereunder, on the assumption that the training is ended and with reference to the case in which, as input to the neural network 29, a generic input matrix M is provided, which includes a number of rows equal to the number N of primary quantities and a number of columns (or vectors) equal to a number W. For example, and without any loss of generality, in the following W=3840 is assumed; moreover, each column refers to a corresponding instant of time.</p><p><span class=\"paragraph-number\">[0027]   </span>In detail, the neural network 29 comprises an encoding stage 30 and a decoding stage 40, a bottom layer 50 and an output stage 60.</p><p><span class=\"paragraph-number\">[0028]   </span>The encoding stage 30 comprises a first, a second, a third and a fourth encoding layer 31, 32, 33 and 34, arranged in cascade, as described in greater detail below.</p><p><span class=\"paragraph-number\">[0029]   </span>The decoding stage 40 comprises a first, a second, a third and a fourth decoding layer 41, 42, 43 and 44, arranged in a cascade, as described in greater detail below.</p><p><span class=\"paragraph-number\">[0030]   </span>The bottom layer 50 is interposed between the fourth encoding layer 34 and the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0031]   </span>The output stage 60 is arranged downstream of the fourth decoding layer 44.</p><p><span class=\"paragraph-number\">[0032]   </span>In greater detail, as shown in <figref>Figure 7</figref>, each of the first, second, third and fourth encoding layer 31, 32, 33 and 34 comprises a respective first processing stage (denoted with 131, 132, 133 and 134, respectively) and a respective second processing stage (denoted with 231, 232, 233 and 234, respectively), as well as a respective reduction stage (denoted with 331, 332, 333 and 334, respectively).</p><p><span class=\"paragraph-number\">[0033]   </span>In detail, the first processing stage 131 of the first encoding layer 31 receives the input matrix M and generates a matrix M<sub>e1</sub>' (N, W, 16), by performing filtering, activation and normalisation operations.</p><p><span class=\"paragraph-number\">[0034]   </span>In greater detail, the first processing layer 131 stores a number F1 of respective filters (for example, in the present description F1 = 16 is assumed) of 1x3 type; in practice, referring to an f-th filter (with f = 1, 2,..., F1), it is defined by four parameters: a corresponding bias w<sub>0</sub><sup>f</sup> and a corresponding triad of coefficients w<sub>1</sub><sup>f</sup>, w<sub>2</sub><sup>f</sup> and w<sub>3</sub><sup>f</sup>. Consequently, the first processing stage 131 stores a number of respective parameters equal to 4*F1, i.e. a number of parameters equal to 64. Moreover, the first processing stage 131 performs a convolution between each of the respective filters and the input matrix M. This causes, as shown qualitatively in <figref>Figure 8</figref>, where the rows and the columns of the input matrix M are indexed by the indices i and j respectively, the first processing stage 131 to generate a three-dimensional matrix O(i,j,f) having dimensions N*W*F1, i.e. formed by a number equal to F1 of two-dimensional matrices O(i,j)<sup>f</sup>, which have dimensions equal to N*W. Furthermore, if again the indices i and j are used to index the rows and the columns of the f-th matrix O(i,j)<sup>f</sup>, it is verified: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 66mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0001.tif&width=66mm&height=15mm\"/></maths></p><p><span class=\"paragraph-number\">[0035]   </span>In a per se known manner, the convolution may provide for the execution of techniques for managing the elements arranged at the edges of the input matrix M, such as for example the last column of the input matrix; for example, it is possible to apply the filters to a modified matrix that is identical to the input matrix M, but including in addition a W+1-th and a W+2-th column, which are identical to the last (that is, the W-th) column of the input matrix M. It is however possible to adopt a different technique to allow applying the filters to the edges of the input matrix M.</p><p><span class=\"paragraph-number\">[0036]   </span>Next, the first processing stage 131 performs a so-called activation of the matrix O(i,j,f), i.e., it applies to each element of the matrix O(i,j,f) a non-linear function, also known as an activation function (e.g., a so-called rectifier or sigmoid or hyperbolic and linear tangent) so as to obtain an activated matrix O(i,j,f), the elements of which are constituted by the results of the activation functions; subsequently, the first processing stage 131 carries out a normalisation (also known as batch-normalisation) of the activated matrix O(i,j,f), e.g. so that the elements assume values ranging between zero and one. The matrix M<sub>e1</sub>' (N,W,16) is therefore equal to the activated and normalised matrix O(i,j,f). In general, it is assumed in the following, by way of example, that all the activation functions mentioned in this description provide for the use of the same rectifier known as ELu with angular coefficient of 45°.</p><p><span class=\"paragraph-number\">[0037]   </span>The second processing stage 231 of the first encoding layer 31 receives the matrix M<sub>e1</sub>' (N,W, 16) generated by the first processing stage 131 and generates a matrix M<sub>e1</sub>\" (N,W,16), by performing corresponding filtering, activation and normalisation operations, which are the same as the operations described with reference to the first processing stage 131, except for the following differences.</p><p><span class=\"paragraph-number\">[0038]   </span>In detail, the second processing stage 231 stores a number of respective filters still equal to F1, such filters being still of 1x3 type, but being adapted to process an input of the multichannel type rather than a single channel, i.e. being adapted to process a three-dimensional matrix which is precisely the matrix M<sub>e1</sub>' (N,W,16).</p><p><span class=\"paragraph-number\">[0039]   </span>In more detail, referring to an f-th filter (with f = 1, 2, ..., F1), it is defined by a corresponding bias (denoted as w<sub>00</sub><sup>f</sup>) and by a number of triads (or kernels) of coefficients (w<sub>m1</sub><sup>f</sup>, w<sub>m2</sub><sup>f</sup>' w<sub>m3</sub><sup>f</sup>) equal to the value of the third dimension of the matrix M<sub>e1</sub>' (N,W, 16), i.e. by sixteen triads of coefficients; therefore, one has m = 1, ..., 16. Each filter is therefore defined by a number of parameters equal to 49; consequently, the second processing stage 231 stores a number of respective parameters equal to 784.</p><p><span class=\"paragraph-number\">[0040]   </span>In addition, the second processing stage 231 performs a convolution between each of the respective filters and the matrix M<sub>e1</sub>' (N, W, 16) . In particular, considering the f-th (with f = 1, 2, ..., F1) filter, the relative convolution with the matrix M<sub>e1</sub>' (N,W,16) generates a corresponding matrix O' (i,j)<sup>f</sup> having dimensions N*W and wherein: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 97mm; height: 16mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0002.tif&width=97mm&height=16mm\"/></maths></p><p> wherein Minput represents the third dimension of the matrix M<sub>e1</sub>' (N,W,16), and so in the present case one has Minput=F1=16. Also in this case, known per se techniques may be implemented for applying the filters to the edges of the matrix M<sub>e1</sub>' (N,W,16).</p><p><span class=\"paragraph-number\">[0041]   </span>As shown qualitatively in <figref>Figure 9</figref>, the set of matrices O'(i,j)<sup>f</sup> forms a three-dimensional matrix O'(i,j,f) having dimensions N*W*F1, i.e. having a third dimension equal to the number of filters implemented by the second processing stage 231.</p><p><span class=\"paragraph-number\">[0042]   </span>Subsequently, the second processing stage 231 performs an activation of the matrix O'(i,j,f), e.g. using the same activation function employed by the first processing stage 131. In this regard, for the sake of simplicity and without any loss of generality, it is assumed in the following that all the activations mentioned in this document are performed based on the same activation function. In addition, the second processing stage 231 performs a normalisation of the activated matrix O'(i,j,f), so that the elements assume values ranging between zero and one. The matrix M<sub>e1</sub>' (N,W,16) is therefore equal to the activated and normalised matrix O'(i,j,f).</p><p><span class=\"paragraph-number\">[0043]   </span>The reduction stage 331 of the first encoding layer 31 receives the matrix M<sub>e1</sub>\" (N,W, 16), on which it performs a so-called second dimension reduction operation, e.g. with a reduction factor P1=10, so as to generate a matrix M<sub>r1</sub>(N,W/10,16).</p><p><span class=\"paragraph-number\">[0044]   </span>In particular, as shown schematically in <figref>Figure 10</figref>, the reduction stage 331 performs, for each two-dimensional matrix M<sub>e1</sub>\"(N,W,f) (with f = 1, ..., 16) forming the matrix M<sub>e1</sub>\" (N,W,16), a so-called \"max pooling\" operation, which involves generating a corresponding two-dimensional matrix M<sub>e1</sub>\"(N,W/P1,f). For example, for each row of the two-dimensional matrix M<sub>e1</sub>\" ' (N,W,f), in each group formed by a number P1 of adjacent elements, the element of maximum value is selected. In practice, it is verified, with f fixed and for i=1:N and j=1:(W/P1): </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 80mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0003.tif&width=80mm&height=8mm\"/></maths></p><p><span class=\"paragraph-number\">[0045]   </span>The second encoding layer 32 receives as input the matrix M<sub>r1</sub>(N,W/10,16) and works in the same way as the first encoding layer 31, therefore it performs the same filtering, activation and normalisation operations, as well as the same dimension reduction operations, subject to the following differences.</p><p><span class=\"paragraph-number\">[0046]   </span>In detail, the first processing stage 132 receives the matrix M<sub>r1</sub>(N,W/10,16) and stores a number of respective filters equal to F2 (in the present example, F2=32 is assumed), each of which is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>r1</sub>(N,W/10,16), i.e. by sixteen triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 49; consequently, the first processing stage 132 stores a number of respective parameters equal to 1568. For each filter, the convolution takes place in the same manner as described with reference to the second processing stage 231 of the first encoding layer 31.</p><p><span class=\"paragraph-number\">[0047]   </span>Since the filters are equal to thirty-two in number, the first processing stage 132 provides, at the end of the normalisation operations, a matrix M<sub>e2</sub>' (N,W/10,32), which has precisely a third dimension equal to thirty-two.</p><p><span class=\"paragraph-number\">[0048]   </span>The second processing stage 232 receives the matrix M<sub>e2</sub>'(N,W/10, 32) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F2=32; each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>e2</sub>' (N,W/10,32), i.e. by thirty-two triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 97; consequently, the second processing stage 232 stores a number of respective parameters equal to 3104. The second processing stage 232 generates a matrix M<sub>e2</sub>\"(N,W/10,32), which has a third dimension precisely equal to thirty-two.</p><p><span class=\"paragraph-number\">[0049]   </span>The reduction stage 332 of the second encoding layer 32 receives the matrix M<sub>e2</sub>\" (N,W/10,32), on which it performs a reduction operation of the second dimension, with a reduction factor P2=8, so as to generate a matrix M<sub>r2</sub>(N,W/80,32). The reduction takes place in the same way as described with reference to the reduction stage 331 of the first encoding layer 31.</p><p><span class=\"paragraph-number\">[0050]   </span>The third encoding layer 33 receives as input the matrix M<sub>r2</sub> (N,W/80,32) and works in the same way as the first and second encoding layer 31, 32, therefore it performs the same filtering, activation and normalisation operations, as well as the same dimension reduction operations, subject to the following differences.</p><p><span class=\"paragraph-number\">[0051]   </span>In detail, the first processing stage 133 receives the matrix M<sub>r2</sub>(N,W/80,32) and stores a number of respective filters equal to F3 (in the present example, F3=64 is assumed), each of which is of 1x3 type and is defined, as well as by a corresponding bias, and by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>r2</sub>(N,W/80,32), i.e. by thirty-two triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 97; consequently, the first processing stage 133 stores a number of respective parameters equal to 6208. Moreover, since the filters are equal to sixty-four in number, the first processing stage 133 provides, at the end of the normalisation operations, a matrix M<sub>e3</sub>' (N,W/80, 64), which has precisely a third dimension equal to sixty-four.</p><p><span class=\"paragraph-number\">[0052]   </span>The second processing stage 233 receives the matrix M<sub>e3</sub>' (N,W/80, 64) and performs respective filtering, activation and normalisation operation, based on a number of respective filters still equal to F3=64; each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>e3</sub>'(N,W/80,64), i.e. by sixty-four triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 193; consequently, the second processing stage 233 stores a number of respective parameters equal to 12352. The second processing stage 233 generates a matrix M<sub>e3</sub>\"(N,W/80,64), which has a third dimension precisely equal to sixty-four.</p><p><span class=\"paragraph-number\">[0053]   </span>The reduction stage 333 of the third encoding layer 33 receives the matrix M<sub>e3</sub>\" (N,W/80,64), on which it performs a reduction operation of the second dimension, with a reduction factor P3=6, so as to generate a matrix M<sub>r3</sub> (N,W/480, 64) .</p><p><span class=\"paragraph-number\">[0054]   </span>The fourth encoding layer 34 receives as input the matrix M<sub>r3</sub> (N,W/480, 64) and works in the same way as the first, second and third encoding layer 31, 32, 33, therefore it performs the same filtering, activation and normalisation operations, as well as the same dimension reduction operations, subject to the following differences.</p><p><span class=\"paragraph-number\">[0055]   </span>In detail, the first processing stage 134 receives the matrix M<sub>r3</sub>(N,W/480,64) and stores a number of respective filters equal to F4 (in the present example, F4=128 is assumed), each of which is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>r3</sub>(N,W/480,64), i.e. by sixty-four triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 193; consequently, the first processing stage 134 stores a number of respective parameters equal to 24704. Moreover, since the filters are equal to one hundred and twenty-eight in number, the first processing stage 134 provides, at the end of the normalisation operations, a matrix M<sub>e4</sub>'(N,W/480,128), which has a third dimension equal to one hundred and twenty-eight.</p><p><span class=\"paragraph-number\">[0056]   </span>The second processing stage 234 receives the matrix M<sub>e4</sub>' (N,W/480,128) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F4=128; each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>e4</sub>' (N,W/480,128), i.e. by one hundred and twenty-eight triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 385; consequently, the second processing stage 234 stores a number of respective parameters equal to 49280. The second processing stage 234 generates a matrix M<sub>e4</sub>\"(N,W/480,128), which has a third dimension precisely equal to one hundred and twenty-eight.</p><p><span class=\"paragraph-number\">[0057]   </span>The reduction stage 334 of the fourth encoding layer 34 receives the matrix M<sub>e4</sub>\" (N,W/480,128), on which it performs a reduction operation of the second dimension, with a reduction factor P4=4, so as to generate a matrix M<sub>r4</sub>(N,W/1920,128).</p><p><span class=\"paragraph-number\">[0058]   </span>As shown in <figref>Figure 11</figref>, the bottom layer 50 receives the matrix M<sub>r4</sub>(N,W/1920,128). Furthermore, the bottom layer 50 comprises a respective first processing stage 151 and a respective second processing stage 152, which operate in the same manner as described with reference to the first and second processing stages of the encoding step 30, subject to the following differences.</p><p><span class=\"paragraph-number\">[0059]   </span>In detail, the first processing stage 151 receives the matrix M<sub>r4</sub>(N,W/1920,128) and stores a number of respective filters equal to F5 (in the present example, F5=256 is assumed), each of which is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>r4</sub>(N,W/1920,128), i.e. by one hundred and twenty-eight triads of respective coefficients. Each filter is therefore defined by a number of parameters equal to 385; consequently, the first processing stage 151 stores a number of respective parameters equal to 98560. Furthermore, the first processing stage 151 provides, at the end of the normalisation operations, a matrix M<sub>b</sub>'(N,W/1920,256).</p><p><span class=\"paragraph-number\">[0060]   </span>The second processing stage 152 receives the matrix M<sub>b</sub>' (N,W/1920,256) and performs the respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F5; each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to 256. Each filter is therefore defined by 769 parameters; consequently, the second processing stage 152 stores a number of respective parameters equal to 196864. The second processing stage 152 generates a matrix M<sub>b</sub>\" (N,W/1920,256), which is provided to the decoding stage 40.</p><p><span class=\"paragraph-number\">[0061]   </span>As shown in <figref>Figures 12A</figref> and <figref>12B</figref>, each of the first, second, third and fourth decoding layer 41, 42, 43 and 44 comprises a respective upsampling stage (denoted with 141, 142, 143 and 144, respectively), a respective first processing stage (denoted with 241, 242, 243 and 244 respectively), a respective concatenation stage (denoted with 341, 342, 343 and 344 respectively), a respective second processing stage (denoted with 441, 442, 443 and 444 respectively) and a respective third processing stage (denoted with 541, 542, 543 and 544 respectively).</p><p><span class=\"paragraph-number\">[0062]   </span>In detail, the upsampling stage 141 of the first decoding layer 41 performs an upsampling operation of the matrix M<sub>b</sub>\"(N,W/1920,256), with upsampling factor U1=P4=4, so as to generate a matrix M<sub>d1</sub>' (N,W/480,256). In particular, the matrix M<sub>d1</sub>'(N,W/480,256) is obtained by stacking along the second dimension a number U1 of three-dimensional matrices equal to the matrix M<sub>b</sub>\" (N, W/1920, 256), as shown qualitatively in <figref>Figure 13</figref>.</p><p><span class=\"paragraph-number\">[0063]   </span>The first processing stage 241 of the first decoding layer 41 receives the matrix M<sub>d1</sub>' (N,W/480,256) and generates a matrix M<sub>d1</sub>\"(N,W/480,128), by performing filtering, activation and normalisation operations.</p><p><span class=\"paragraph-number\">[0064]   </span>In detail, the first processing stage 241 receives the matrix M<sub>d1</sub>' (N,W/480,256) and stores a number of respective filters equal to F4, i.e. 128. Each filter is of 1x4 type and is defined, as well as by a corresponding bias, by a number of quaternals of coefficients equal to the value of the third dimension of the matrix M<sub>d1</sub>'(N,W/480,256), i.e. by two hundred and fifty-six quaternals of respective coefficients. Each filter is therefore defined by a number of parameters equal to 1025; consequently, the first processing stage 241 stores a number of respective parameters equal to 131200. For each filter, the convolution takes place in the same way as described with reference to the convolutions performed by the encoding stage 30. Since the filters are equal to 128 in number, the first processing stage 241 provides, at the end of the normalisation operations, the matrix M<sub>d1</sub>\"(N,W/480,128), which has precisely a third dimension equal to 128.</p><p><span class=\"paragraph-number\">[0065]   </span>The concatenation stage 341 of the first decoding layer 41 concatenates the matrix M<sub>d1</sub>\"(N,W/480,128) with the matrix M<sub>e4</sub>\" (N,W/480,128) generated by the fourth encoding layer 34, so as to obtain a matrix M<sub>d1</sub>‴(N,W/480,256). In particular, as shown in <figref>Figure 14</figref>, the concatenation is performed by stacking the matrix M<sub>d1</sub>\" (N,W/480,128) and the matrix M<sub>e4</sub>\" (N,W/480,128) along the third dimension.</p><p><span class=\"paragraph-number\">[0066]   </span>The second processing stage 441 receives the matrix M<sub>d1</sub>‴(N,W/480,256) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F4=128. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d1</sub>‴(N,W/480,256), i.e. equal to 256. Each filter is therefore defined by a number of parameters equal to 769; consequently, the second processing stage 441 stores a number of respective parameters equal to 98432. The second processing stage 441 generates a matrix M<sub>d1</sub>ʺʺ(N,W/480,128), which has a third dimension precisely equal to thirty-two.</p><p><span class=\"paragraph-number\">[0067]   </span>The third processing stage 541 receives the matrix M<sub>d1</sub>ʺʺ(N,W/480,128) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F4=128. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d1</sub>ʺʺ(N,W/480,128), i.e. equal to 128. Each filter is therefore defined by a number of parameters equal to 385; consequently, the third processing stage 541 stores a number of respective parameters equal to 49280. The third processing stage 541 generates a matrix M<sub>d1</sub>‴ʺ(N,W/480,128), which has a third dimension precisely equal to 128.</p><p><span class=\"paragraph-number\">[0068]   </span>The second decoding layer 42 receives the matrix M<sub>d1</sub>‴ʺ(N,W/480,128) and works in the same way as the first decoding layer 41, thus performing upsampling, filtering, activation and normalisation operations, as well as concatenation operations.</p><p><span class=\"paragraph-number\">[0069]   </span>In detail, the upsampling stage 142 of the second decoding layer 42 performs an upsampling operation of the matrix M<sub>d1</sub>‴ʺ(N,W/480,128), with upsampling factor U2=P3=6, so as to generate a matrix M<sub>d2</sub>' (N,W/80,128). Upsampling takes place in the same way as described with reference to upsampling performed by the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0070]   </span>The first processing stage 242 of the second decoding layer 42 receives the matrix M<sub>d2</sub>'(N,W/80,128) and generates a matrix M<sub>d2</sub>\" (N,W/80,64), by performing filtering, activation and normalisation operations.</p><p><span class=\"paragraph-number\">[0071]   </span>In detail, the first processing stage 242 stores a number of respective filters equal to F3, i.e. 64. Each filter is of 1x6 type and is defined, as well as by a corresponding bias, by a number of sets of six coefficients equal to the value of the third dimension of the matrix M<sub>d2</sub>' (N,W/80,128), i.e. by one hundred and twenty-eight sets of six coefficients. Each filter is therefore defined by a number of parameters equal to 769; consequently, the first processing stage 242 stores a number of respective parameters equal to 49216. For each filter, the convolution takes place in the same way as described with reference to the convolutions performed by the encoding stage 30. Since the filters are equal to 64 in number, the first processing stage 242 provides, at the end of the normalisation operations, the matrix M<sub>d2</sub>\" (N,W/80,64), which has precisely the third dimension equal to 64.</p><p><span class=\"paragraph-number\">[0072]   </span>The concatenation stage 342 of the second decoding layer 42 concatenates the matrix M<sub>d2</sub>' (N,W/80, 64) with the matrix M<sub>e3</sub>\" (N,W/80,64) generated by the third encoding layer 33, so as to obtain a matrix M<sub>d2</sub>‴(N,W/80,128). The concatenation is performed in the same manner as described with reference to the concatenation stage 341 of the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0073]   </span>The second processing stage 442 receives the matrix M<sub>d2</sub>‴(N,W/80,128) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F3=64. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d2</sub>‴(N,W/80,128), i.e. equal to 128. Each filter is therefore defined by a number of parameters equal to 385; consequently, the second processing stage 442 stores a number of respective parameters equal to 24640. The second processing stage 442 generates a matrix M<sub>d2</sub>ʺʺ(N,W/80,64), which has a third dimension precisely equal to 64.</p><p><span class=\"paragraph-number\">[0074]   </span>The third processing stage 542 receives the matrix M<sub>d2</sub>ʺʺ(N,W/80, 64) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F3=64. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d2</sub>ʺʺ(N,W/80,64), i.e. equal to 64. Each filter is therefore defined by a number of parameters equal to 193; consequently, the third processing stage 542 stores a number of respective parameters equal to 12352. The third processing stage 542 generates a matrix M<sub>d2</sub>‴ʺ(N,W/80, 64), which has a third dimension precisely equal to 64.</p><p><span class=\"paragraph-number\">[0075]   </span>The third decoding layer 43 receives the matrix M<sub>d2</sub>‴ʺ(N,W/80, 64) and works in the same way as the first and second decoding layer 41, 42.</p><p><span class=\"paragraph-number\">[0076]   </span>In detail, the upsampling stage 143 of the third decoding layer 43 performs an upsampling operation of the matrix M<sub>d2</sub>‴ʺ(N,W/80, 64), with upsampling factor U3=P2=8, so as to generate a matrix M<sub>d3</sub>' (N,W/10,64). Upsampling takes place in the same way as described with reference to upsampling performed by the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0077]   </span>The first processing stage 243 of the third decoding layer 43 receives the matrix M<sub>d3</sub>' (N,W/10,64) and generates a matrix M<sub>d3</sub>\"(N,W/10, 32), by performing filtering, activation and normalisation operations.</p><p><span class=\"paragraph-number\">[0078]   </span>In detail, the first processing stage 243 stores a number of respective filters equal to F2, i.e. 32. Each filter is of 1x8 type and is defined, as well as by a corresponding bias, by a number of sets of eight coefficients equal to the value of the third dimension of the matrix M<sub>d3</sub>' (N,W/10, 64), i.e. by sixty-four sets of eight coefficients. Each filter is therefore defined by a number of parameters equal to 513; consequently, the first processing stage 243 stores a number of respective parameters equal to 16416. For each filter, the convolution takes place in the same way as described with reference to the convolutions performed by the encoding stage 30. Since the filters are equal to 32 in number, the first processing stage 243 provides, at the end of the normalisation operations, the matrix M<sub>d3</sub>\"(N,W/10,32), which has precisely the third dimension equal to 32.</p><p><span class=\"paragraph-number\">[0079]   </span>The concatenation stage 343 of the third decoding layer 43 concatenates the matrix M<sub>d3</sub>\"(N,W/10,32) with the matrix M<sub>e2</sub>\" (N,W/10,32) generated by the second encoding layer 32, so as to obtain a matrix M<sub>d3</sub>‴(N,W/10, 64). The concatenation is performed in the same manner as described with reference to the concatenation stage 341 of the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0080]   </span>The second processing stage 443 receives the matrix M<sub>d3</sub>‴(N,W/10,64) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F2=32. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d3</sub>‴(N,W/10,64), i.e. equal to 64. Each filter is therefore defined by a number of parameters equal to 193; consequently, the second processing stage 443 stores a number of respective parameters equal to 6176. The second processing stage 443 generates a matrix M<sub>d3</sub>ʺʺ(N,W/10,32), which has a third dimension precisely equal to 32.</p><p><span class=\"paragraph-number\">[0081]   </span>The third processing stage 543 receives the matrix M<sub>d3</sub>ʺʺ(N,W/10, 32) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F2=32. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d3</sub>ʺʺ(N,W/10,32), i.e. equal to 32. Each filter is therefore defined by a number of parameters equal to 97; consequently, the third processing stage 543 stores a number of respective parameters equal to 3104. The third processing stage 543 generates a matrix M<sub>d3</sub>‴ʺ(N,W/10,32), which has a third dimension precisely equal to 32.</p><p><span class=\"paragraph-number\">[0082]   </span>The fourth decoding layer 44 receives the matrix M<sub>d3</sub>‴ʺ(N,W/10,32) and works in the same way as the first, second and third decoding layer 41, 42, 43.</p><p><span class=\"paragraph-number\">[0083]   </span>In detail, the upsampling stage 144 of the fourth decoding layer 44 performs an upsampling operation of the matrix M<sub>d3</sub>‴ʺ(N,W/10,32), with upsampling factor U4=P1=10, so as to generate a matrix M<sub>d4</sub>'(N,W,32). Upsampling takes place in the same way as described with reference to upsampling performed by the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0084]   </span>The first processing stage 244 of the fourth decoding layer 44 receives the matrix M<sub>d4</sub>' (N,W,32) and generates a matrix M<sub>d4</sub>\"(N,W,16), by performing filtering, activation and normalisation operations.</p><p><span class=\"paragraph-number\">[0085]   </span>In detail, the first processing stage 244 stores a number of respective filters equal to F1, i.e. 16. Each filter is of 1x10 type and is defined, as well as by a corresponding bias, by a number of sets of ten coefficients equal to the value of the third dimension of the matrix M<sub>d4</sub>' (N,W,32), i.e. by thirty-two sets of ten coefficients. Each filter is therefore defined by a number of parameters equal to 321; consequently, the first processing stage 244 stores a number of respective parameters equal to 5136. For each filter, the convolution takes place in the same way as described with reference to the convolutions performed by the encoding stage 30. Since the filters are equal to 16 in number, the first processing stage 244 provides, at the end of the normalisation operations, the matrix M<sub>d4</sub>\"(N,W,16), which has precisely the third dimension equal to 16.</p><p><span class=\"paragraph-number\">[0086]   </span>The concatenation stage 344 of the fourth decoding layer 44 concatenates the matrix M<sub>d4</sub>\"(N,W,16) with the matrix M<sub>e1</sub>ʺ(N,W,16) generated by the first encoding layer 31, so as to obtain a matrix M<sub>d4</sub>‴(N,W,32). The concatenation is performed in the same manner as described with reference to the concatenation stage 341 of the first decoding layer 41.</p><p><span class=\"paragraph-number\">[0087]   </span>The second processing stage 444 receives the matrix M<sub>d4</sub>‴(N,W,32) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F1=16. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d4</sub>‴(N,W,32), i.e. equal to 32. Each filter is therefore defined by a number of parameters equal to 97; consequently, the second processing stage 444 stores a number of respective parameters equal to 1552. The second processing stage 444 generates a matrix M<sub>d4</sub>ʺʺ(N,W,16), which has a third dimension precisely equal to 16.</p><p><span class=\"paragraph-number\">[0088]   </span>The third processing stage 544 receives the matrix M<sub>d4</sub>ʺʺ(N,W, 16) and performs respective filtering, activation and normalisation operations, based on a number of respective filters still equal to F1=16. Each filter is of 1x3 type and is defined, as well as by a corresponding bias, by a number of triads of coefficients equal to the value of the third dimension of the matrix M<sub>d4</sub>ʺʺ(N,W,16), i.e. equal to 16. Each filter is therefore defined by a number of parameters equal to 49; consequently, the third processing stage 544 stores a number of respective parameters equal to 784. The third processing stage 544 generates a matrix M<sub>d4</sub>‴ʺ(N,W, 16), which has a third dimension precisely equal to 16 and is provided to output stage 60.</p><p><span class=\"paragraph-number\">[0089]   </span>As shown in <figref>Figure 15</figref>, the output stage 60 comprises a reshaping stage 61 and a respective filtering and activation stage 62.</p><p><span class=\"paragraph-number\">[0090]   </span>The reshaping stage 61 receives the matrix M<sub>d4</sub>ʺ‴(N,W,16) and changes its dimensions in the manner shown in <figref>Figure 16</figref>.</p><p><span class=\"paragraph-number\">[0091]   </span>In particular, the reshaping stage 61 generates a two-dimensional matrix M<sub>out</sub>(N*16,W), which is obtained by stacking along the first dimension the sixteen two-dimensional matrices M<sub>d4</sub>‴ʺ(N,W, f) (with f=1, ..., 16) that form the matrix M<sub>d4</sub>‴ʺ(N,W,16).</p><p><span class=\"paragraph-number\">[0092]   </span>The filtering and activation stage 62 receives the matrix M<sub>out</sub>(N*16, W) and performs respective filtering operations and subsequent activation, based on a number of respective filters equal to the above-mentioned number NUM_C, i.e. equal to the number of classes, so to generate a matrix M<sub>prob</sub>(49,W). In the example shown in <figref>Figure 15</figref>, NUM_C=49 was assumed.</p><p><span class=\"paragraph-number\">[0093]   </span>Each filter of the filtering and activation stage 62 is of type (N*16)x1, i.e., it is therefore defined, as well as by a corresponding bias wp<sub>0</sub><sup>k</sup>, by a set of coefficients wp<sub>1</sub><sup>k</sup>,...wp<sub>N*16</sub><sup>k</sup>, with k=1, ..., NUM_C; in other words, each filter is defined by a number of parameters equal to N*16+1. Furthermore, the filtering and activation stage 62 performs a convolution between each of the respective filters and the matrix M<sub>out</sub>(N*16, W), so as to calculate the elements of the corresponding row of the matrix M<sub>prob</sub>(49, W) .</p><p><span class=\"paragraph-number\">[0094]   </span>In particular, as shown qualitatively in <figref>Figure 17</figref>, considering the k-th (with k = 1, 2, ..., NUM_C) filter, it is applied to each column of the matrix M<sub>out</sub>(N*16, W), so as to generate the values of the k-th row of the matrix M<sub>prob</sub> (N*16,W), which are equal to: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 83mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0004.tif&width=83mm&height=15mm\"/></maths></p><p> with j = 1, ...,W.</p><p><span class=\"paragraph-number\">[0095]   </span>Consequently, the matrix M<sub>prob</sub>(49, W) includes a column for each of the instants of time to which the input matrix M referred; each column is formed by a vector that includes a number of elements equal to NUM_C, each element being equal to an estimate of the probability that, in the instant of time to which the column refers, a manoeuvre belonging to the class corresponding to the element was performed.</p><p><span class=\"paragraph-number\">[0096]   </span>In other words, each column of the matrix M<sub>prob</sub>(49,W) refers to a corresponding instant of time and is formed by a vector that includes, for each class, the corresponding estimate of the probability that, at that instant of time, a manoeuvre belonging to that class was performed. In other words, the matrix M<sub>prob</sub>(49, W) was generated starting from the input matrix M and provides a segmentation relative to the classes of the manoeuvres, to which they belong, performed during the instants of time referred to by the input matrix M. Moreover, considering a generic w-th column of the matrix M<sub>prob</sub>(49,W), the elements of this column are a (non-linear) function of the values of the parameters of the neural network 29 and of the values of the elements of the input matrix M.</p><p><span class=\"paragraph-number\">[0097]   </span>Again with reference to <figref>Figure 3</figref>, the training (block 106) of the neural network 29 is performed as shown in <figref>Figure 18</figref>.</p><p><span class=\"paragraph-number\">[0098]   </span>In detail, initially, the computer 12 initialises (block 108) the previously described parameters of the neural network 29, in a per se known way, so that they assume a first set of values. For example, each value of such a first set of values may be extracted randomly from a standard normal distribution.</p><p><span class=\"paragraph-number\">[0099]   </span>Subsequently, the computer 12 selects (block 109) portions of the training data structure 10, which are referred to in the following as the training matrices.</p><p><span class=\"paragraph-number\">[0100]   </span>In detail, the training matrices (two shown in <figref>Figure 4</figref>, denoted with TM1 and TM2, respectively, by way of example only) have dimensions equal to N*W (with N equal to the number of rows and W equal to the number of columns), i.e., they have the same dimensions as the aforementioned input matrix M. Moreover, without any loss of generality, the training matrices are formed by adjacent and non-overlapping portions of the training data structure 10, i.e., they do not have any training vector in common. In this regard, <figref>Figure 4</figref> shows segments having a length equal to a number of samples equal to W, which indicate the arrangements of corresponding training matrices. Furthermore, although not apparent from <figref>Figure 4</figref>, W may be much greater than the number of samples that are typically acquired by the monitoring system 2 during the execution of a generic test manoeuvre, so that each training matrix includes numerous data groups of the training data structure 10, i.e. it includes samples of the primary quantities relative to a plurality of test manoeuvres.</p><p><span class=\"paragraph-number\">[0101]   </span>Subsequently, assuming that a number NUM_W of training matrices has been selected, the computer 12 generates (block 110) a number (hereafter referred to as NUM_L) of batches of training matrices. For this purpose, the computer 12 may for example select the first NUM_ML (with NUM_ML representing an integer) training matrices, so that they form the first batch, and subsequently it may select the second NUM_ML training matrices, so that they form the second batch, and so on, until the training matrices are exhausted; thus, all batches include a number of training matrices equal to NUM_ML (with NUM_ML &lt;NUM_W), except the last batch, which may include a smaller number of training matrices. Thus, the number NUM_L of batches generated is equal to ceil (NUM_W/NUM_ML) . In other words, the computer 12 groups the training matrices into batches.</p><p><span class=\"paragraph-number\">[0102]   </span>Then, for each batch, the operations described below are performed; these operations are then iterated for a number of times equal to the number NUM_L of batches.</p><p><span class=\"paragraph-number\">[0103]   </span>In detail, the neural network 29 is applied to each training matrix of the batch (block 111), the parameters of which are equal to a set of current values; at the first iteration this set of current values is equal to the aforementioned first set of values. In this way, a corresponding matrix M<sub>prob</sub>(NUM_C,W) is obtained for each training matrix.</p><p><span class=\"paragraph-number\">[0104]   </span>In practice, as shown in <figref>Figure 19</figref>, where for simplicity's sake it has been assumed that only a class '0' and a class '1' are present, for each training matrix a corresponding predicted probability mask is obtained for each class, i.e. a discrete curve whose points are formed by the elements (equal to W in number) of the relative row of the corresponding matrix M<sub>prob</sub>(NUM_C,W). In particular, <figref>Figure 19</figref> shows the predicted probability mask relative to class '1'.</p><p><span class=\"paragraph-number\">[0105]   </span>In addition, for each training matrix, the computer 12 stores a so-called \"ground truth\" curve, i.e. a curve which is formed by a number of samples equal to W and which indicates, sample by sample, to which class the test manoeuvre performed at the corresponding instant of time belongs. An example of a \"ground truth\" curve, relative to the simplified scenario with only the classes '0' and '1', is shown again in <figref>Figure 19</figref>.</p><p><span class=\"paragraph-number\">[0106]   </span>In greater detail, the \"ground truth\" curve can assume a number of levels equal to the number NUM_C of classes, each level being associated precisely with a corresponding class.</p><p><span class=\"paragraph-number\">[0107]   </span>On the basis of the matrices M<sub>prob</sub>(NUM_C,W) relating to the training matrices of the batch and of the corresponding ground truth curves, the computer 12 updates (block 113) the value of the parameters of the neural network 29, which thus assume a set of updated values. In particular, the computer 12 determines the set of updated values so as to approach the minimum of a loss function, which is indicative of the difference between each predicted probability mask and the corresponding \"ground truth\" curve.</p><p><span class=\"paragraph-number\">[0108]   </span>For example, in the following it is assumed that the loss function is of the so-called \"sparse categorical cross-entropy\" type, i.e. it is assumes that, considering a generic w-th column M<sub>prob</sub>(NUM_C,w) (with w fixed and ranging between 1 and W) of a matrix M<sub>prob</sub> (NUM_C,W) relative to any training matrix, the corresponding contribution to the loss function is equal to: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 62mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0005.tif&width=62mm&height=15mm\"/></maths></p><p> wherein tr (w) represents the w-th value of the \"ground truth\" curve, i.e. the value of the \"ground truth\" curve that corresponds to the aforementioned w-th column M<sub>prob</sub>(NUM_C,w) . In addition, the loss function requires that the contributions relative to the columns of the matrix M<sub>prob</sub> (NUM_C,W) are averaged between them in order to obtain a corresponding average value. Furthermore, it is assumed that the loss function, when calculated based on the matrices M<sub>prob</sub>(NUM_C,W) relative to the training matrices (equal to NUM_ML in number) of the batch, provides for averaging the corresponding average values.</p><p><span class=\"paragraph-number\">[0109]   </span>In more detail, in order to update the values of the parameters of the neural network 29, and thus to determine the aforementioned set of updated values, the computer 12 may apply methods which are per se such as, for example, the so-called gradient technique, which envisages identifying the set of updated values so that the loss function calculated based on the set of updated values assumes a smaller value than the value assumed by the loss function when calculated based on the set of current values. In particular, the set of updated values derives in a per se known way from the set of current values, based on the following updating equation: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 60mm; height: 13mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010593630&ekey=1959&cc=EP&producerName=imgb0006.tif&width=60mm&height=13mm\"/></maths></p><p> wherein: E<sub>k</sub> represents the set of current values of the parameters of the neural network 29; E<sub>k+1</sub> represents the set of updated values of the parameters of the neural network 29; f represents the loss function, which depends on a non-linear function θ implemented by the neural network 29, which in turn depends on the parameters of the neural network 29 and on the data provided as input to the neural network 29 (in this case, the training matrices), the loss function f also depending on the \"ground truth\" curves.</p><p><span class=\"paragraph-number\">[0110]   </span>In practice, at each iteration of the operations referred to in blocks 111-113, the set of current values of the parameters of the neural network 29 during the operations referred to in block 111 is equal to the set of updated values generated by the operations referred to in block 113 of the previous iteration. Furthermore, at the end of the iterations, the neural network 29 was applied to all the training matrices NUM_W.</p><p><span class=\"paragraph-number\">[0111]   </span>Once the iterations of the operations referred to in blocks 111-113 have been ended, i.e. once the batches have been ended, the computer 12 reshuffles in a pseudo-random manner (block 119) the sequence of the data groups (in a number always equal to L) of the training data structure 10, as shown, for example, in <figref>Figure 20</figref>, in which it can be noted that this sequence now begins with the manoeuvres performed in the intervals of time T2, T3 and T5, which belong to the classes C<sub>1</sub>, C<sub>2</sub> and C<sub>4</sub>, respectively, and ends with the manoeuvre performed during the interval of time T1, which, as mentioned, belongs to class C<sub>3</sub>.</p><p><span class=\"paragraph-number\">[0112]   </span>The operations relative to block 109, block 110, to the iterations of blocks 111-113 and to block 119 define a so-called era; moreover, the computer 12 iterates these operations for a predefined number of eras, at the end of which the training of the neural network 29 is considered as completed.</p><p><span class=\"paragraph-number\">[0113]   </span>In particular, thanks to the reshuffling, the composition of the training matrices (still in a number equal to NUM_W and having dimensions still equal to N*W) that are generated during the new execution of the operations referred to in block 109 differs from the previous era. For example, in <figref>Figure 20</figref> it can be noted how the training matrix TM1 now includes the data group DG1 and part of the data group DG3, while the training matrix TM2 now includes part of the data group DG3 and the data group DG5. Consequently, at each era, the computer 12 generates a number NUM_L of corresponding batches of training matrices, by performing the operations referred to in block 110. Thus, the training of the neural network 29 is less dependent on the initial sequence of the data groups within the training data structure 10.</p><p><span class=\"paragraph-number\">[0114]   </span>In addition, reshuffling operations involve corresponding modifications of the \"ground truth\" curves; however, each training matrix remains associated with a corresponding \"ground truth\" curve.</p><p><span class=\"paragraph-number\">[0115]   </span>In greater detail, in each era, the corresponding operations relative to block 109, to block 110, to the iterations of blocks 111-113 and to block 119 are performed in the same manner as described above except that, for each era following the first era, when the neural network 29 is applied to the training matrices of the corresponding first batch, the set of current values of the parameters of the neural network 29 is equal to the set of updated values calculated based on the last batch of training matrices of the previous era. Furthermore, with regard to the last era, the reshuffling referred to in block 119 is not performed.</p><p><span class=\"paragraph-number\">[0116]   </span>Once the training is completed, the computer 12 uses the neural network 29 to classify unknown manoeuvres, as explained below, again with reference to <figref>Figure 3</figref>.</p><p><span class=\"paragraph-number\">[0117]   </span>In detail, the computer 12 acquires (block 120, <figref>Figure 3</figref>) an unknown data structure 910, an example of which is shown in <figref>Figure 21</figref>, again assuming N=5.</p><p><span class=\"paragraph-number\">[0118]   </span>The unknown data structure 910 stores time series of samples of the primary quantities detected by the monitoring system 2 of the helicopter 1 during unknown flights, i.e. flights for which the manoeuvres performed are not known. These time series of samples refer to a succession of instants of time, which are temporally spaced by Δ<sub>c</sub>; for each instant of time, the unknown data structure 910 stores a corresponding unknown vector (one shown in <figref>Figure 21</figref>, denoted with IV), which has the same form as the training vectors, therefore it includes the samples of the primary quantities relative to the corresponding instant of time. The unknown data structure 910 therefore has a number of rows equal to the number N of primary quantities.</p><p><span class=\"paragraph-number\">[0119]   </span>Subsequently, the computer 12 selects (block 121) portions of the unknown data structure 910, which are referred to in the following as the unknown matrices (three shown in <figref>Figure 21</figref>, where they are denoted with TMX).</p><p><span class=\"paragraph-number\">[0120]   </span>The unknown matrices TMX have the same dimensions as the training matrices (i.e., N*W). Furthermore, without any loss of generality, the unknown matrices TMX are formed by adjacent, non-overlapping portions of the unknown data structure 910.</p><p><span class=\"paragraph-number\">[0121]   </span>Subsequently, the computer 12 applies (block 122) the neural network 29 to each unknown matrix 910, so as to obtain a corresponding matrix MX<sub>prob</sub>(NUM_C,W), which comprises, for each unknown vector IV of the unknown matrix TMX, a corresponding vector, as shown for example in <figref>Figure 22</figref>, in which a vector denoted with CX is shown.</p><p><span class=\"paragraph-number\">[0122]   </span>Each vector of the matrix MX<sub>prob</sub>(NUM_C,W) is relative to a corresponding unknown vector of the unknown matrix TMX and includes a number of elements equal to NUM_C, each element being equal to an estimate of the probability that, at the instant of time to which the corresponding unknown vector refers, the helicopter 1 performed a manoeuvre belonging to the corresponding class.</p><p><span class=\"paragraph-number\">[0123]   </span>Then, on the basis of each matrix MX<sub>prob</sub>(NUM_C,W), the computer 12 detects (block 123), for each of the unknown vectors, the class to which the manoeuvre performed in the corresponding instant of time belongs, by selecting the class to which the element with the highest probability estimate refers, among the elements of the corresponding vector of the matrix MX<sub>prob</sub>(NUM_C,W) . In this way, the computer 12 generates, for each unknown matrix TMX, a corresponding segmentation vector SEGx (one shown in <figref>Figure 22</figref>), which is formed by a number of elements equal to W, each element being referred to a corresponding unknown vector of the unknown matrix TMX and being indicative of the class detected with respect to such corresponding unknown vector.</p><p><span class=\"paragraph-number\">[0124]   </span>In practice, each segmentation vector SEGx represents, for each instant of time of an unknown matrix TMX, the class of the manoeuvre performed by the helicopter 1 at that instant of time. A segmentation by classes of each unknown TMX is thus obtained, this segmentation benefiting from the features explained below, with reference to the above-mentioned generic input matrix M.</p><p><span class=\"paragraph-number\">[0125]   </span>In detail, the neural network 29 is characterised by the ability to detect so-called \"features\" of the input matrix M even when these \"features\" extend over samples of the input matrix M that are very distant from each other, thanks to the presence of \"max pooling\" operations.</p><p><span class=\"paragraph-number\">[0126]   </span>Furthermore, the neural network 29 has an encoder-decoder type structure, in which the encoding stage 30 allows the detection of the presence of features within the input matrix M, while the decoding stage 40 allows the localisation of the detected features, i.e. to determine the position thereof within the input matrix M, in order to allow a correct segmentation.</p><p><span class=\"paragraph-number\">[0127]   </span>In addition, the concatenation operations between the encoding stage 30 and the decoding stage 40 make it possible to use the detections made by the encoding stage 30 also in the decoding phase, with a consequent increase in the ability to correctly detect the classes of the manoeuvres.</p><p><span class=\"paragraph-number\">[0128]   </span>The advantages that the present method allows to obtain therefore emerge clearly from the previous description.</p><p><span class=\"paragraph-number\">[0129]   </span>In particular, the present method allows to accurately detect the classes of the manoeuvres performed at each instant of time corresponding to any unknown vector of the unknown data structure 910, by employing a neural network that does not require the selection of particular features, nor to dimension time windows. These detections can therefore be used reliably, for example to estimate the state of fatigue and therefore the residual fatigue life of the components of an aircraft.</p><p><span class=\"paragraph-number\">[0130]   </span>Clearly, changes may be made to the method and system described and shown herein without, however, departing from the scope of the present invention, as defined in the accompanying claims.</p>",
            "CLMS": "(EP4198842)<br/><p>1. Method implemented by computer (12) for classifying manoeuvres performed by a first aircraft (1) equipped with a monitoring system (2) configured to acquire samples of a number of quantities relative to the flight of the first aircraft, comprising the steps of:<br/> - acquiring (120) a data structure (910) including at least one unknown data matrix (TMX) including a plurality of time series of samples of said quantities, said samples being relative to a succession of instants of time;<br/> - applying to the unknown data matrix (TMX) a neural network (29) configured to generate a corresponding probability matrix (MX<sub>prob</sub>(NUM_C,W)), said neural network (29) having been trained based on a plurality of classes of manoeuvres and based on a plurality of first training matrices equal to corresponding portions of a training data structure (10) including a sequence of data groups (DG1,DG2,DG3,DGL), each data group including corresponding time series of samples of said quantities, the time series of samples of each data group (DG1,DG2,DG3,DGL) being relative to a corresponding time period (T1, T2, T3, TL) in which said first aircraft (1) or one or more second aircraft that are identical to said first aircraft and equipped with respective monitoring systems have performed a corresponding manoeuvre belonging to a corresponding class among said plurality of classes of manoeuvres, said neural network (29) having also been trained on the basis of curves that are indicative, for each first training matrix (TM1, TM2), of the classes of the manoeuvres performed by said first aircraft (1) or by said second aircraft during the acquisition of the data groups (DG1,DG2,DG3,DGL) of the first training matrix (TM1, TM2), so that said probability matrix (MX<sub>prob</sub>(NUM_C,W)) comprises, for each instant of time of said succession of instants of time, a corresponding probability vector (CX) including, for each class of said plurality of classes of manoeuvres, a corresponding estimate of the probability that, at said instant of time, the first aircraft (1) performed a manoeuvre belonging to said class; and<br/> - selecting (123), for each instant of time of said succession of instants of time, a corresponding class of manoeuvres, based on the probability estimates of the corresponding probability vector (CX).</p><p>2. Method according to claim 1, wherein the neural network (29) comprises:<br/> - an encoding stage (30) configured to receive the unknown data matrix (TMX) and including a number of encoding layers (31,32,33,34) arranged in cascade;<br/> - a decoding stage (40) comprising a number of decoding layers (41,42,43,34) arranged in cascade;<br/> - a bottom layer (50), interposed between the encoding stage (30) and the decoding stage (40); and<br/> - an output stage (60), arranged downstream of the decoding stage (40);<br/>and wherein each encoding layer (31,32,33,34) comprises:<br/> - one or more respective processing stages (131-134, 231-324) arranged in cascade, each of which is configured to store a number of respective filters and to perform convolution operations, based on the respective filters, and subsequent activation and normalisation operations;<br/> - a respective reduction stage (331-334) configured to perform an aggregation operation and arranged downstream of said respective processing stages;<br/>and wherein the bottom layer (50) comprises:<br/> - one or more respective processing stages (51,52) arranged in cascade, each of which is configured to store a number of respective filters and to perform convolution operations, based on the respective filters, and subsequent activation and normalisation operations;<br/>and wherein each decoding layer (41,42,43,44) comprises:<br/> - a respective upsampling stage (141-144) configured to perform upsampling operations;<br/> - one or more respective processing stages (241-244, 441-444, 541-544) arranged downstream of said respective upsampling stage, each of which is configured to store a number of respective filters and to perform convolution operations, based on the respective filters, and subsequent activation and normalisation operations.</p><p>3. Method according to claim 2, wherein the reduction stages (331-334) of the encoding layers (31,32,33,34) are configured to perform max pooling operations.</p><p>4. Method according to claim 2 or 3, wherein the output stage (60) comprises a respective processing stage (62) configured to store a number of respective filters equal to the number of said classes of manoeuvres and to generate said probability matrix (MX<sub>preb</sub>(NUM_C,W)) by performing convolution operations, based on the respective filters, and subsequent activation operations.</p><p>5. Method according to any one of claims 2-4, wherein the unknown data matrix (TMX) and the first training matrices (TM1,TM2) have a first dimension equal to the number (N) of quantities, a second dimension equal to a predefined number (W) and a unitary third dimension; and wherein each encoding layer (31,32,33,34) is configured to implement a reduction of the second dimension and an increase of the third dimension; and wherein said one or more processing stages (51,52) of the bottom layer (50) are configured to perform convolution operations which leave the first and second dimension unchanged and increase the third dimension; and wherein each decoding layer (41,42,43,44) is configured to implement an increase of the second dimension and a reduction of the third dimension.</p><p>6. Method according to claim 5, wherein each encoding layer (31,32,33,34) comprises:<br/> - a respective first processing stage (131-134) configured to generate a corresponding first three-dimensional encoding matrix (M<sub>e1</sub>'(N,W,16), M<sub>e2</sub>'(N,W/10,32), M<sub>e3</sub>'(N,W/80,64), M<sub>e4</sub>'(N,W/460,128));<br/> - a respective second processing stage (231-234) configured to generate a corresponding second three-dimensional encoding matrix (M<sub>e1</sub>\"(N,W,16), M<sub>e2</sub>\"(N,W/10,32), M<sub>e3</sub>\"(N,W/80,64), M<sub>e4</sub>\"(N,W/460,128)) having the same dimensions as the corresponding first three-dimensional encoding matrix;<br/>and wherein the reduction stage (331-334) of each encoding layer (31,32,33,34) is configured to receive the second three-dimensional encoding matrix generated by the corresponding second processing stage (231-234).</p><p>7. Method according to claim 6, wherein the decoding layers (41,42,43,44) are in a number equal to the encoding layers (31,32,33,34); and wherein each upsampling stage (141-144) is configured to increase the second dimension and is configured to generate a respective first three-dimensional decoding matrix (M<sub>d1</sub>'(N,W/480,256), M<sub>d2</sub>'(N,W/80,128), M<sub>d3</sub>'(N,W/10, 64), M<sub>d4</sub>'(N,W,32)); and wherein each decoding layer (41,42,43,44) comprises:<br/> - a respective first processing stage (241,242,243,244) arranged downstream of the corresponding upsampling stage (141-144) and configured to generate a respective second three-dimensional decoding matrix (M<sub>d1</sub>\"(N,W/480,128), M<sub>d2</sub>\"(N,W/80,64), M<sub>d3</sub>\"(N,W/10,32), M<sub>d4</sub>'(N,W,16)) having a third dimension lower than the third dimension of the corresponding first three-dimensional decoding matrix;<br/> - a respective concatenation stage (341, 342, 343, 344) configured to generate a corresponding third three-dimensional decoding matrix (M<sub>d1</sub>‴(N,W/480,256), M<sub>d2</sub>‴(N,W/80,128), Md<sub>3</sub>‴(N,W/10,64), M<sub>d4</sub>‴(N,W,32)) by concatenation of the corresponding second three-dimensional decoding matrix with the corresponding second three-dimensional encoding matrix (M<sub>e1</sub>\"(N,W,16), M<sub>e2</sub>\"(N,W/10, 32), M<sub>e3</sub>\"(N,W/80, 64), M<sub>e4</sub>\"(N,W/460,128)), said corresponding third three-dimensional decoding matrix having the same third dimension as the corresponding first three-dimensional decoding matrix;<br/> - a respective second processing stage (441,442,443,444) arranged downstream of the corresponding concatenation stage and configured to generate a respective fourth three-dimensional decoding matrix (M<sub>d1</sub>ʺʺ (N,W/480,128), M<sub>d2</sub>ʺʺ(N,W/80,64), M<sub>d3</sub>ʺʺ (N,W/10,32), M<sub>d4</sub>ʺʺ(N,W,16)) having a reduced third dimension with respect to the third dimension of the corresponding third three-dimensional decoding matrix; and<br/> - a respective third processing stage (541,542,543,544) arranged downstream of the corresponding second processing stage and configured to generate a respective fifth three-dimensional decoding matrix (M<sub>d1</sub>‴ʺ(N,W/480,128), M<sub>d2</sub>‴ʺ(N,W/80,64), M<sub>d3</sub>‴ʺ(N,W/10,32), M<sub>d4</sub>‴ʺ(N,W,16)) having the same dimensions as the corresponding fourth three-dimensional decoding matrix.</p><p>8. Method according to claim 7, wherein the output stage (60) further comprises a reshaping stage (61) configured to receive the fifth three-dimensional decoding matrix (M<sub>d4</sub>‴ʺ(N,W,16)) generated by the last decoding layer (44), which is formed by a plurality of respective two-dimensional matrices M<sub>d4</sub>‴ʺ(N,W,f), and to generate a two-dimensional output matrix (M<sub>out</sub>(N*16,W)) by stacking said two-dimensional matrices along the first dimension; and wherein the processing stage (62) of the output stage (60) is configured to operate on the two-dimensional output matrix (M<sub>out</sub>(N*16,W)).</p><p>9. Method according to any one of the preceding claims, wherein the neural network (29) is defined by a plurality of parameters, which have been determined by training on the basis of said first training matrices (TM1, TM2), of said curves indicative of the classes of the manoeuvres performed and of a loss function.</p><p>10. Method according to claim 9, wherein said parameters have been determined by performing the steps of:<br/> - assigning (109) a first set of values to the parameters of the neural network (29); and then<br/> - generating (110) a number of first training batches, each first training batch including a number of respective first training matrices (TM1, TM2);<br/>said method also comprising, for each batch among the first training batches, performing the steps of:<br/> - applying (111) the neural network (29) to each first training matrix of the batch, so as to generate a corresponding training probability matrix (M<sub>prob</sub>(NUM_C,W)); and then<br/> - updating (113) the values of the parameters of the neural network (29) on the basis of said loss function, of the training probability matrices (M<sub>prob</sub>(NUM_C,W)) relative to the first training matrices of the batch and of said curves that are indicative, for each first training matrix of the batch, of the classes of the manoeuvres performed by said first aircraft (1) or by said second aircraft during the acquisition of the data groups (DG1,DG2,DG3,DGL) of the first training matrix.</p><p>11. Method according to claim 10, further comprising performing at least once the steps of:<br/> - modifying (119) the sequence of the data groups (DG1,DG2,DG3,DGL) of the training data structure (10) and then selecting a plurality of second training matrices (TM1,TM2) starting from the training data structure with modified sequence of the data groups;<br/> - generating (110) a number of second training batches, each second training batch including a number of respective second training matrices (TM1, TM2); and<br/> - for each batch among the second training batches, applying (111) the neural network (29) to each second training matrix of the batch, so as to generate a corresponding training probability matrix (M<sub>prob</sub>(NUM_C,W)), and then updating (113) the values of the parameters of the neural network (29) on the basis of said loss function, of the training probability matrices (M<sub>prob</sub>(NUM_C,W)) relative to the second training matrices of the batch and of curves that are indicative, for each second training matrix of the batch, of the classes of the manoeuvres performed by said first aircraft (1) or by said second aircraft during the acquisition of the data groups (DG1,DG2,DG3,DGL) of the second training matrix.</p><p>12. Processing system comprising means (12) configured to carry out the method according to any one of the preceding claims.</p><p>13. Computer program comprising instructions which, when the program is executed by a computer (12), cause the execution of the method according to any one of claims 1 to 11.</p><p>14. Computer medium readable by a computer (12), on which the computer program according to claim 13 is stored.</p>",
            "NPR": "2",
            "APID": "164376127",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G05B-023/02<br/>G06N-003/0455<br/>G06N-003/0464<br/>G06N-003/047<br/>G06N-003/048<br/>G06N-003/09<br/>G06N-020/00<br/>G08G-005/00",
            "ID": "105386908",
            "AB": "(EP4198842)<br/>A computer-implemented method (12) for classifying manoeuvres performed by an aircraft (1), including: acquiring (120) a data structure (910) including at least one unknown data matrix (TMX) including a plurality of time series of samples of quantities related to the flight of the aircraft (1), the samples being relative to a succession of instants of time; applying to the unknown data matrix (TMX) a neural network (29) generating a corresponding probability matrix (MXprob(NUM_C,W)) including, for each instant of time of the succession of instants of time, a corresponding probability vector (CX) including, for each class of a plurality of classes of manoeuvres, a corresponding estimate of the probability that, in the instant of time, the aircraft (1) has performed a manoeuvre belonging to the class; and selecting (123), for each instant of time of the succession of instants of time, a corresponding class of manoeuvres, based on the probability estimates of the corresponding probability vector (CX).",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Ln1g6tRdKf6seLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2021-12-17",
            "PA": "LEONARDO<br/>POLITECNICO DI MILANO",
            "PAAD": "(EP4198842)<br/>(PUB:EP-4198842B1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/>(PUB:EP-4198842A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/>NAME=Politecnico di Milano Piazza Leonardo da Vinci 32 , CITY=20133 Milano , COUNTRY=IT , REG=101672175<br/><br/><br/>(WO2023111716)<br/>(PUB:WO-2023/111716A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 ROMA , POSTCODE=00195 , COUNTRY=IT<br/>NAME=POLITECNICO DI MILANO Piazza Leonardo Da Vinci, 32 20133 MILANO , POSTCODE=20133 , COUNTRY=IT<br/><br/><br/>(KR20240147662)<br/>(PUB:KR-10-2024-0147662A-113)NAME=LEONARDO SPA  , COUNTRY=IT<br/><br/><br/>(CN118414623)<br/>(PUB:CN-118414623A-168)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "105386908",
            "TI": "Method for classifying manouevres performed by an aircraft using a neural network",
            "TECD": "Computer technology<br/>Control",
            "EPD": "2023-06-21",
            "ICLM": "(EP4198842)<br/><p>1. Method implemented by computer (12) for classifying manoeuvres performed by a first aircraft (1) equipped with a monitoring system (2) configured to acquire samples of a number of quantities relative to the flight of the first aircraft, comprising the steps of: - acquiring (120) a data structure (910) including at least one unknown data matrix (TMX) including a plurality of time series of samples of said quantities, said samples being relative to a succession of instants of time; - applying to the unknown data matrix (TMX) a neural network (29) configured to generate a corresponding probability matrix (MXprob(NUM_C,W)), said neural network (29) having been trained based on a plurality of classes of manoeuvres and based on a plurality of first training matrices equal to corresponding portions of a training data structure (10) including a sequence of data groups (DG1,DG2,DG3,DGL), each data group including corresponding time series of samples of said quantities, the time series of samples of each data group (DG1,DG2,DG3,DGL) being relative to a corresponding time period (T1, T2, T3, TL) in which said first aircraft (1) or one or more second aircraft that are identical to said first aircraft and equipped with respective monitoring systems have performed a corresponding manoeuvre belonging to a corresponding class among said plurality of classes of manoeuvres, said neural network (29) having also been trained on the basis of curves that are indicative, for each first training matrix (TM1, TM2), of the classes of the manoeuvres performed by said first aircraft (1) or by said second aircraft during the acquisition of the data groups (DG1,DG2,DG3,DGL) of the first training matrix (TM1, TM2), so that said probability matrix (MXprob(NUM_C,W)) comprises, for each instant of time of said succession of instants of time, a corresponding probability vector (CX) including, for each class of said plurality of classes of manoeuvres, a corresponding estimate of the probability that, at said instant of time, the first aircraft (1) performed a manoeuvre belonging to said class; and - selecting (123), for each instant of time of said succession of instants of time, a corresponding class of manoeuvres, based on the probability estimates of the corresponding probability vector (CX).</p>",
            "CTN": "(EP4198842)<br/>US10935938 92874915 WHO=EXAMINER SELF=N CAT=X<br/>EP2270618 15002680 WHO=EXAMINER SELF=N CAT=X<br/>EP2725337 65313881 WHO=EXAMINER SELF=N CAT=X<br/>EP204250591 none WHO=APPLICANT SELF=N<br/>EP2270618 15002680 WHO=APPLICANT SELF=N<br/>EP2725337 65313881 WHO=APPLICANT SELF=N<br/>EP4016221 100568507 WHO=APPLICANT SELF=Y<br/><br/>(WO2023111716)<br/>US10935938 92874915 WHO=EXAMINER SELF=N CAT=A<br/>EP2270618 15002680 WHO=EXAMINER SELF=N CAT=A<br/>EP2725337 65313881 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2025-06-17",
                    "XAP": "2022WO-IB61023",
                    "APD": "2022-11-16",
                    "APID": "164383734",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2023111716&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Aqpb0AFryMaizzCP0AdYw7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2023/111716",
                            "KIND": "A1",
                            "XPN": "WO2023111716",
                            "V_PNID": "WO-2023/111716A1-3",
                            "DATE": "2023-06-22",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCAeqZI9XPqHY90P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2023111716&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Aqpb0AFryMaizzCP0AdYw7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-11-16",
                            "XAP": "2024KR-7024135",
                            "APD": "2022-11-16",
                            "APID": "172691461",
                            "REG_LINK": "http://link.kipris.or.kr/link/main/KPAXML.jsp?APPLNO=1020247024135",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HwgOklpqgjWZA2qn3TW2cMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "KR10-2024-0147662",
                                    "KIND": "A",
                                    "XPN": "KR20240147662",
                                    "V_PNID": "KR-10-2024-0147662A-113",
                                    "DATE": "2024-10-08",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aJxR8iNWnoo4ksh2s8z9z4DOQ6NLC580ETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=KR20240147662&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HwgOklpqgjWZA2qn3TW2cMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-11-16",
                            "XAP": "2022CN-80083396",
                            "APD": "2022-11-16",
                            "APID": "171504312",
                            "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ufgYF5AL%252FvB6oFNE9k4Ax5NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CN118414623",
                                    "KIND": "A",
                                    "XPN": "CN118414623",
                                    "V_PNID": "CN-118414623A-168",
                                    "DATE": "2024-07-30",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=hXP7Q1+dwoTyu3TbFd0iNck/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN118414623&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ufgYF5AL%252FvB6oFNE9k4Ax5NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2041-12-17",
                    "XAP": "2021EP-0215745",
                    "APD": "2021-12-17",
                    "APID": "164376127",
                    "REG_LINK": "https://register.epo.org/application?number=EP21215745",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Ln1g6tRdKf6seLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4198842",
                            "KIND": "B1",
                            "XPN": "EP4198842",
                            "V_PNID": "EP-4198842B1-8",
                            "DATE": "2024-05-22",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=VCVyqWEeIcBqls9OhmuRv6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4198842&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Ln1g6tRdKf6seLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP4198842",
                            "KIND": "A1",
                            "XPN": "EP4198842",
                            "V_PNID": "EP-4198842A1-8",
                            "DATE": "2023-06-21",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=VCVyqWEeIcBqls9OhmuRv/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4198842&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Ln1g6tRdKf6seLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4198842_B1",
            "EPRD": "2021-12-17",
            "PN": "EP4198842           B1 2024-05-22 [EP4198842]<br/>EP4198842           A1 2023-06-21 [EP4198842]<br/>WO2023/111716       A1 2023-06-22 [WO2023111716]<br/>KR10-2024-0147662   A  2024-10-08 [KR20240147662]<br/>CN118414623         A  2024-07-30 [CN118414623]",
            "ADB": "(EP4198842)<br/><p>In addition, the concatenation operations between the encoding stage 30 and the decoding stage 40 make it possible to use the detections made by the encoding stage 30 also in the decoding phase, with a consequent increase in the ability to correctly detect the classes of the manoeuvres.</p><p>The method described in the above-mentioned European patent application No 204250591 thus makes it possible to detect the macrocategories to which the manoeuvres performed by an aircraft belong with high precision, but it is based on the above-mentioned extraction of features, which must be carefully chosen in order to optimise the precision with which the macrocategories are detected.</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=3<br/>PNAAGE=13<br/>NBPA=1; <br/>ALLCT=3; SCT=0; NSCT=3; <br/>ALLCTG=0; SCTG=0; NSCTG=0; <br/>AFS=4; ACC=4; AMCC=2; <br/>IGEN=0.0; IORG=0.88; IRAD=0.95; <br/>IMPI=0.0; MACI=1.14; PASI=1.41; PAVI=1.14; ",
            "PTCC": "(US20230196780)<br/>CC=US EED=2042-12-01 STATUS=PENDING APID=164364111 APD=2022-12-01 XPN=US20230196780 PD=2023-06-22 EPD=2023-06-22 LPD=2023-06-22 <br/><br/>(WO2023121841)<br/>CC=WO EED=2025-06-21 STATUS=PENDING APID=164553008 APD=2022-12-01 XPN=WO2023121841 PD=2023-06-29 EPD=2023-06-29 LPD=2023-06-29 <br/>CC=EP EED=2042-12-01 STATUS=PENDING APID=164553008 XPN=WO2023121841 <br/>CC=MX EED=2042-12-01 STATUS=PENDING APID=172589267 APD=2022-12-01 XPN=MX2024007729 PD=2024-07-01 EPD=2024-07-01 LPD=2024-07-01 <br/><br/>(MX2024007729)<br/>CC=MX EED=2042-12-01 STATUS=PENDING APID=172589267 APD=2022-12-01 XPN=MX2024007729 PD=2024-07-01 EPD=2024-07-01 LPD=2024-07-01 <br/>",
            "EPN": "US20230196780",
            "CTGN": "",
            "LAPD": "2022-12-01",
            "STDN": "",
            "NPN": "3",
            "DESC": "<p><h1>CROSS REFERENCE TO RELATED APPLICATION</h1></p><p><span class=\"paragraph-number\">[0001]   </span>The present Patent application claims the benefit of U.S. Provisional Application No. 63/292,111, filed Dec. 21, 2021, titled “SYSTEMS AND METHODS FOR ELECTRONIC SURVEILLANCE”.</p><br/><p><h1>INCORPORATION BY REFERENCE</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The disclosures made in U.S. Provisional Application No. 63/292,111, filed Dec. 21, 2021, are specifically incorporated by reference herein as if set forth in its entirety.</p><p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0003]   </span>In one aspect, the present disclosure is directed to surveillance systems and methods, and more specifically, to surveillance systems and methods that facilitate collection and correlation of electronic signatures and/or visual identifiers for targets or convoys captured proximate to a home, a business, and/or a neighborhood or specified area. Other aspects also are described.</p><p><h1>BACKGROUND</h1></p><p><span class=\"paragraph-number\">[0004]   </span>A large number of homes and businesses now include many devices that utilize Wi-Fi and/or Bluetooth signals. Further, use of home security cameras and/or doorbell cameras has become more common among large portions of the population. While, the cameras can capture images and/or video, the cameras cannot identify people who are obscured, masked, or otherwise attempt to hide their identity. Finally, most people carry at least one electronic device regularly, e.g., a smartphone.</p><p><span class=\"paragraph-number\">[0005]   </span>It can be seen that a need exists for surveillance systems and methods that can be used to provide a correlation between devices, images, and/or locations, thus enabling tracking of unidentified persons at or near a home, a business, or a neighborhood.</p><p><span class=\"paragraph-number\">[0006]   </span>The present disclosure is directed to the foregoing and other related, and unrelated, problems in the relevant art.</p><p><h1>SUMMARY</h1></p><p><span class=\"paragraph-number\">[0007]   </span>Briefly described, the present disclosure is directed to surveillance systems and methods for collecting electronic signatures and/or images, for identification of targets, such as unidentified persons or vehicles within a prescribed or selected location or area. Further, electronic signatures and/or images may be correlated thus enabling monitoring and potential identification of unidentified persons or vehicles.</p><p><span class=\"paragraph-number\">[0008]   </span>According to aspects of the present disclosure, the surveillance system is configured to utilize existing Wi-Fi connectivity of homes, businesses, and other locations by placing collection devices, including a plurality of sensors, detectors or other, similar devices, positioned at tactical locations on a property. Each of the collection devices will be configured to collect electronic signals within a collection range of the premises for the purpose of correlating those signals with other collected signals and patterns to identify a target or targets that may have been present. The collection devices each may be an independent device, or can be linked to other collection devices in a network or an array, and further may be integrated into other home automation, convenience, or other electronic devices. Examples include integration with video doorbell systems; video surveillance systems; alarm components; mailbox sensors; exterior lighting and/or motion detection systems; garage, door and gate activation pads or openers, neighborhood watch systems, etc. . . .</p><p><span class=\"paragraph-number\">[0009]   </span>In embodiments, collected electronic signal data obtained by the collection devices may be filtered locally and sent to a central database system for storage and correlation processing. In embodiments, the database and/or resulting correlation information could be made available to law enforcement for processing. The collected data generally will be individually anonymous, e.g., unlike a video or photograph of a person, etc., the collected data is directed to features of the captured electronic signals with ‘rolling’ identifiers that are intended to be variable. The surveillance system will include programming, including models configured for cluster and pattern analysis, which, in embodiments of the present disclosure, provide a central capability to identify certain electronic devices and targets (e.g., vehicles, individuals, etc.). Signals and signal characteristics can be used individually or in combination with adjacent signals to uniquely identify a source for correlation with and identification of targets.</p><p><span class=\"paragraph-number\">[0010]   </span>Such surveillance systems and methods may include one or more collection devices positioned at one or more selected locations. Each of the one or more collection devices may include one or more antennas configured to detect and receive electronic signals from electronic devices using a corresponding frequency. In embodiments, each of the one or more collection devices also may include communications circuitry for transmitting collected electronic signals to an intelligence device that may include communications circuitry to receive any detected electronic signals and/or other data (e.g., images, a series of images, video, location data, license plate numbers, and/or other data related to potential targets). The intelligence device will be configured and/or will include programming configured to analyze the received data.</p><p><span class=\"paragraph-number\">[0011]   </span>The electronic signals included within the received data may include tags identifying a type of electronic device that the signal originated from, as well as a number of times and a length of time that the signal is located within a particular area. The tags may also indicate whether signal is not typically located in that particular area. The intelligence device can correlate unidentified and/or atypical electronic signals and/or other data with electronic signals typically found in the area. The intelligence device may then determine whether the unidentified and/or atypical electronic signals and/or other data is correlated with a particular target, convoy, or person based on data from other locations or areas. Thus, a target, convoy, or person can be tracked and/or associated with events in selected areas or locations.</p><p><span class=\"paragraph-number\">[0012]   </span>According to aspects of the present disclosure, a surveillance system is provided, which includes collection systems, devices, or assemblies, and an intelligence system having classification and search capabilities. In embodiments, the surveillance system will use the characteristics of the collected identifying characteristics to prioritize or otherwise indicate to an investigator that a particular characteristic is material to the identification of the target of an investigation in a particular area or location (e.g., a home, a neighborhood, and/or a business).</p><p><span class=\"paragraph-number\">[0013]   </span>In embodiments, a method is provided that can use correlation statistics and analysis to develop relationships between identifiers and non-unique characteristics over a single encounter (e.g., an atypical electronic device located in a selected area during a particular event) or multiple encounters. No single factor is required to be an absolute or unique identifier. One or more combinations of non-unique characteristics and broadcast or visible variables, methods and transmitted values can be used to identify a set that are collectively statistically significant in their unique association with the source area or location. In embodiments, this method may use artificial intelligence and “Big Data” techniques to identify correlations and to rank those results based on statistical methods created in expert noise reduction and confidence analysis.</p><p><span class=\"paragraph-number\">[0014]   </span>In embodiments, the surveillance system can include a plurality of collection systems, devices, or assemblies that are located at selected geographic areas or strategic locations. The collection systems generally are configured to capture or facilitate collection of information related to visual identifiers and/or electronic signatures associated with and/or atypical to the selected areas/locations. For example, the collection devices can include purpose-built collection hardware, additional antennae and radio hardware that can be integrated into existing Wi-Fi platforms at a home or business to allow collection of passing, approaching and/or entering individuals that can be time and location correlated across the collection. Placing sensors in locations where people are already aware of and/or are comfortable with cameras and surveillance would allow sensing and recording of approach and home access.</p><p><span class=\"paragraph-number\">[0015]   </span>In embodiments, the collection systems can include at least one sensor configured to collect or otherwise capture electronic signal information related electronic signatures of targets and/or electronic devices. This information further can include visual identifiers such as license plate information or other visual or imaged information associated with vehicles (e.g., stickers, patterns, position(s) of component parts, after-market added parts, damage, and/or various other markings, etc. . . . ) that can be used to distinguish or otherwise identify, detect or discern a target vehicle; and/or images or a series of images, such as photographs or video captured by security cameras and/or doorbell cameras. The electronic signatures can include an electronic signal or combination(s) of electronic signals emanating from transmitting electronic devices, and which are associated with and/or can uniquely identify the targets in or moving about the selected areas/locations, such as cell phones, laptops, computing devices, garage door openers, home automation devices, security panels, security cameras, doorbell cameras, key fobs for a vehicle, and/or other electronic devices emitting a wireless signal. The data collected from any of the devices may be tagged. The tags may include the type of device and whether the device is typical or atypical to the selected location.</p><p><span class=\"paragraph-number\">[0016]   </span>In addition, in some aspects, the surveillance system can include an intelligence device or system that is in communication with the plurality of collection systems, and will be configured to receive the information collected or captured by the collection systems or devices (e.g., data points or packets of time and date stamped information in real time for targets within proximity of the collection point systems), and will further be configured (e.g. including programming, etc.) to identify and/or track the atypical targets and/or electronic devices based on this received information. In embodiments, the intelligence system can include classification and search capabilities, for example, including one or more classification and search engines and an intelligence database in communication therewith. The one or more classification and search engines can be configured to identify or extract the electronic signatures associated with the targets using the information collected by the collection systems and catalogue them in the intelligence database with a number of occurrences or discoveries and/or certain identifying characteristics (e.g., geographical coordinates, time stamps, source manufacturer, source type and unique ID, etc.) allowing these identified electronic signatures to become unique, identifiable, individually searchable, and/or searchable in combination with other electronic signatures or targets (e.g., such as in a convoy search).</p><p><span class=\"paragraph-number\">[0017]   </span>The surveillance system thus is configurable to track, map, catalogue, etc., movements of atypical targets (e.g., atypical to a selected area or location) in real time or historically as electronic signals emanating in proximity to the collection systems or devices at one or more selected areas or locations. The tracking information generated can be used to help confirm and/or authenticate potential target identification, and further can be configured to generate alerts or notifications when certain targets or atypical targets are in proximity to the collection systems during an event.</p><p><span class=\"paragraph-number\">[0018]   </span>The one or more classification and search engines can develop inferences of relationships between electronic devices and targets typical to an area or location and electronic devices and targets atypical to an area based on consistency and/or frequency of detected correlations between identified/extracted electronic signatures and/or targets. Further, the one or more classification and search engines can base such relationships on a reported event or alert, such as a crime or other events.</p><p><span class=\"paragraph-number\">[0019]   </span>For example, the one or more classification and search engines can use frequency and consistency of electronic signals to determine the relative certainty of association of the transmitted electronic devices and targets to develop electronic signatures of the targets. That is, if the relative certainty or probability that a certain electronic signal or combination of electronic signals are associated with a target meets a prescribed threshold, the one or more classification and search engines can identify an electronic signal or combinations of electronic signals as a specific electronic signature associated with that target. Further, the one or more classification and search engines can use frequency and consistency of captured images of different targets traveling together to develop a correlation between different targets. That is, if the relative certainty or probability that a certain first target travels with a second target meets a prescribed threshold, the one or more classification and search engines can identify one or more targets, e.g., first and second targets and/or others, as associated with a convoy. The term “convoy” generally refers to a group of or two or more targets that travel together one or more times on one or more days (e.g., two vehicles that travel together at a specific time on various days). In such embodiments, a convoy may be generated based on electronic signals and/or targets usually found in a selected area. Different or atypical electronic signals and/or targets may be distinguished based on exclusion in existing convoys.</p><p><span class=\"paragraph-number\">[0020]   </span>In an embodiment, the one or more classification and search engines will be configured to correlate one or more identifying characteristics and/or non-unique characteristics over single encounter or multiple encounters. The one or more identifying characteristics may include license plates, electronic signals, images, a series of images, and/or visual idiosyncrasies, among other factors. Non-unique characteristics may include vehicle make, vehicle model, vehicle color, vehicle year, articles of clothing, among other non-unique characteristics and/or personal characteristics. Such correlations may be determined via machine learning models or classifiers and/or statistical modeling or analysis. The one or more classification and search engines may utilize such correlations to determine various aspects of a target, such as a potential association or correlation between a target and an event in a selected location, among other aspects. Further, the one or more classification and search engines may be utilized to determine statistically significant correlations or associations between atypical targets or atypical electronic signals and/or electronic signals.</p><p><span class=\"paragraph-number\">[0021]   </span>In an embodiment, the one or more classification and search engines will be configured to analyze correlation results using frequency of occurrence, relative representation, signal type, signal receipt location diversity, and signal strength profiling to generate and present confidence levels and/or rankings for correlations between signal-receipt events. The one or more classification and search engines may be configured to filter and sort results such that the user is directed to signals to be associated with a particular event or alarm.</p><p><span class=\"paragraph-number\">[0022]   </span>In an embodiment, the systems and methods may include filtering in-coming electronic signals to maximize the receipt and storage of moving, stable, identifiable signals by analyzing the signal value, strength, spectrum, and embedded identification data. The systems and method may also simultaneously reduce and filter signals and identifiers that are ‘noise’ from likely-unrelated sources and not relevant to the future correlation.</p><p><span class=\"paragraph-number\">[0023]   </span>In addition, or in the alternative, the one or more classification and search engines will be configured to associate or correlate identifying atypical electronic signatures with visual identifiers and frequent electronic signatures at a selected location, such as a visual vehicle identifier, to allow independent identification, tracking, and location identification of targets based on the associated identifying electronic signatures. That is, once the system has records correlating electronic signatures associated with a specific visual vehicle identifier, e.g., a specific license plate number, the intelligence system will be able to detect the likely presence of a vehicle and its associated license plate without visual information, e.g., without the use of a camera. Further, correlation between two or more targets may allow dependent tracking and location identification of targets based on associated or correlated one or more targets. That is, once the system has records correlating a first target with a second target (or more targets), the intelligence system will be able to determine likely presence of the first target based on visual information and/or electronic signals of the second or more targets.</p><p><span class=\"paragraph-number\">[0024]   </span>Furthermore, the collection systems can be placed in locations or areas nearby homes, neighborhoods, and/or businesses, such that the intelligence system will be able to identify, and catalogue known electronic signatures and targets in selected areas, e.g., for tracking, mapping, etc. of persons or electronic devices atypical or different than that of persons or electronic devices usually found in the selected areas.</p><p><span class=\"paragraph-number\">[0025]   </span>In embodiments, the at least one sensor of each collection system can include a plurality of sensor assemblies. The sensor assemblies can include one or more cameras or camera systems configured to capture or facilitate collection of information related to vehicle identifiers, such as visual information related to a license plate of a vehicle or other visual vehicle identifiers.</p><p><span class=\"paragraph-number\">[0026]   </span>In addition, the sensor assemblies can include one or more antennas or other signal receivers configured to capture information related to the electronic signatures. The one or more antennas can include a plurality of antennas, such as a Bluetooth® antenna, a Wi-Fi antenna, a RFID antenna, or other RF antennas or combinations thereof, configured to capture information related to electronic signals associated with the targets.</p><p><span class=\"paragraph-number\">[0027]   </span>In some embodiments, the collection systems can be used in conjunction with or include Automated License Plate Readers (“ALPR”) in certain areas, allowing the intelligence system to develop a subset of electronic signals, i.e., an electronic signature, associated with a license plate read at a moment in time and location. Electronic data points from less expensive collectors can then be used to provide more precise tracking than ALPR alone.</p><p><span class=\"paragraph-number\">[0028]   </span>In some embodiments, the surveillance system can be configured to capture sample electronic signature information from a target and/or visual identifiers of other targets, associate that information with the target's identification, and then search for or alert on receipts of similar electronic signature information at one of the collection point systems.</p><p><span class=\"paragraph-number\">[0029]   </span>In additional embodiments, the surveillance system can be configured to allow for search inquiries or scans of suspect's electronic signatures to search selected locations in the database history, placing the suspect at those locations and at a particular time or times. In such examples, the surveillance system can include a user interface. A user can access the user interface and provide various inputs into the user interface. The inputs may include one or more of time, location, license plate numbers, partial license plate numbers, convoys, and/or data related to an event (e.g., package delivery, crime, new visitor, etc.). In such examples, the surveillance system may include text recognition algorithms to parse through text corresponding to the event and separate out important or key words, such as identifying characteristics. Upon providing the various inputs, the surveillance system may provide, as an output, information correlated to the various inputs. For example, an input may include a time, a location, and a portion of a license plate. The output may include how often a vehicle with the portion of the license plate is at that location. Such an output may be determined, at least in part, based on the correlation between that vehicle and other vehicles, electronic data signals, and/or people.</p><p><span class=\"paragraph-number\">[0030]   </span>In still other embodiments, the surveillance system can be configured to allow for labeling of specific electronic signatures with a target and then alert or search for history of those specific electronic signatures in the database, placing the target at various locations.</p><p><span class=\"paragraph-number\">[0031]   </span>In further embodiments, the surveillance system further can indicate or determine changes in association or travel of suspects or other individuals of interest based on variations in electronic signatures and/or correlated targets associated with a target or targets.</p><p><span class=\"paragraph-number\">[0032]   </span>In further embodiments, the surveillance system further can be utilized to generate mail and package delivery notifications (e.g., including package theft), transient signal schedule tracking, regular transient signal reporting to improve bus or transport arrival or departure predictability and alerts, intrusion detection, tagged pet tracking, integrated known-visitor security and lock status-change activation, occupancy trend tracking and reporting for integrated utility and energy management, customization of entertainment and lighting systems by occupancy, simplified guest arrival and security management for commercial space rentals, hotel and campus security systems, and/or integrated video surveillance retrieval and queueing systems, etc.</p><p><span class=\"paragraph-number\">[0033]   </span>According to another aspect of the present disclosure, a surveillance system may include one or more collection devices positioned proximate one or more of a home, neighborhood, or business. Each of the one or more collection devices may comprise at least one sensor, at least one antenna, or a combination thereof, each configured to collect, such as by monitoring or being configured to detect a selected or a corresponding frequency, electronic signals from proximal electronic devices. The one or more collection devices may comprise a communication circuitry to transmit collected electronic signals. The surveillance system may comprise an intelligence device positioned separate from the one or more collection devices. The intelligence device may comprise a database, and a correlation circuitry to develop an electronic signature for each of the proximal devices from which the electronic signals are collected and determine a correlation of each electronic signature and one or more locations of the one or more of the home, neighborhood, or business.</p><p><span class=\"paragraph-number\">[0034]   </span>In an embodiment, the one or more collection devices may be configured to tag an electronic signal based on a type of electronic device emitting the electronic signal. The one or more collection devices may be configured to associate and include a timestamp and location data with each electronic signal.</p><p><span class=\"paragraph-number\">[0035]   </span>In embodiments, the correlation circuitry may be configured to further determine a correlation between the one or more different electronic signals of the collected electronic signals and one or more identified targets. The one or more identified targets may include one or more of a convoy or a person.</p><p><span class=\"paragraph-number\">[0036]   </span>In embodiments, the correlation circuitry may include one or more classification and search engines configured to identify the collected electronic signals and may compare identified collected electronic signals with one or more targets to thereby further determine the correlation of one or more different electronic signals of the collected electronic signals and one or more identified targets. The one or more classification and search engines may determine inferences of targets typical to the one or more locations and targets atypical to the one or more locations. In some embodiments, such a correlation may be based on the inferences of targets typical to the one or more locations and targets atypical to the one or more locations.</p><p><span class=\"paragraph-number\">[0037]   </span>In embodiments, the determination of the inferences may be based on one or more of reported events or reported alerts. The one or more of reported events or reported alerts may include crimes and other events. In embodiments, the determination of the inferences may further be based on detection of one of one or more electronic signals more than a preselected threshold. The at least one sensor may include one or more cameras configured to capture electronic signals related to vehicle identifiers.</p><p><span class=\"paragraph-number\">[0038]   </span>According to another aspect of the present disclosure, a method may include collecting, via one or more collection devices positioned proximate a home, electronic signals from proximal electronic devices positioned at one or more of within the home or proximate the home. The method may include reviewing the electronic signals for detection of noisy signals collected within the electronic signals. The method may include, in response to detection of noisy signals, removing the noisy signals of the electronic signals to thereby form filtered electronic signals. The method may include transmitting the filtered electronic signals to a database. The method may include developing an electronic signature for each of the proximal devices from which the filtered electronic signals are collected. The method may include determining a correlation between each electronic signature and one or more targets based upon a comparison of each electronic signature and one or more stored electronic signals associated with the one or more targets.</p><p><span class=\"paragraph-number\">[0039]   </span>In an embodiment, the method may include, upon reception of the electronic signals, tagging each of the electronics signals based on a type of electronic device from which a corresponding electronic signal is collected.</p><p><span class=\"paragraph-number\">[0040]   </span>In embodiments, the one or more targets may include one or more convoys or people. In some embodiments, the one or more different electronic signals may comprise one or more of unidentified signals or atypical signals. The method further may include tracking one or more targets based on the correlation.</p><p><span class=\"paragraph-number\">[0041]   </span>Accordingly, embodiments of a surveillance system and methods, including systems and methods for facilitating collection and correlation of electronic signatures and/or visual identifiers for targets or convoys that are directed to the above discussed and other needs are disclosed. The foregoing and other advantages and aspects of the embodiments of the present disclosure will become apparent and more readily appreciated from the following detailed description, taken in conjunction with the accompanying drawings. Moreover, it is to be understood that both the foregoing summary of the disclosure and the following detailed description are exemplary and intended to provide further explanation without limiting the scope of the present disclosure.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0042]   </span>It will be appreciated that for simplicity and clarity of illustration, elements illustrated in the Figures are not necessarily drawn to scale. For example, the dimensions of some elements may be exaggerated relative to other elements. Embodiments incorporating teachings of the present disclosure are shown and described with respect to the drawings herein, in which:</p><p><span class=\"paragraph-number\">[0043]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b></a> is a schematic diagram of a surveillance system according to the present disclosure.</p><p><span class=\"paragraph-number\">[0044]   </span><a href=\"#DRAWINGS\">FIG. <b>2</b></a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, and <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a> are schematic diagrams of a surveillance system according to the present disclosure.</p><p><span class=\"paragraph-number\">[0045]   </span><a href=\"#DRAWINGS\">FIGS. <b>4</b>A through <b>4</b>G</a> show exemplary screen shots of an interface associated with the surveillance system according to <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, <a href=\"#DRAWINGS\">FIG. <b>2</b></a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>, <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, and <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>.</p><br/><p><h1>DETAILED DESCRIPTION</h1></p><p><span class=\"paragraph-number\">[0046]   </span>The use of the same reference symbols in different drawings indicates similar or identical items.</p><p><h1>DETAILED DESCRIPTION</h1></p><p><span class=\"paragraph-number\">[0047]   </span>The following description in combination with the Figures is provided to assist in understanding the teachings disclosed herein. No attempt is made to show structural details of this disclosure in more detail than may be necessary for a fundamental understanding of the exemplary embodiments discussed herein and various embodiments in which they may be practiced. While the description is focused on specific implementations and embodiments of the teachings, and is provided to assist in describing the teachings, this focus should not be interpreted as a limitation on the scope or applicability of the teachings disclosed herein.</p><p><span class=\"paragraph-number\">[0048]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>, <b>2</b>, and <b>3</b>A</a> provides a schematic diagram of example embodiments of a surveillance system <b>10</b> for collecting and correlating electronic signal signatures and/or visual identifier information with targets, such as vehicles, individuals, devices or the like, to build intelligence databases that facilitate electronic surveillance, identification and associating indications of common location and movement of targets throughout selected geographic areas or locations at specified times.</p><p><span class=\"paragraph-number\">[0049]   </span>“Electronic surveillance,” as used herein, refers to the collection and correlation of electronic signal information that can be used to identify movements of electronic devices, and potentially individuals and vehicles associated therewith. Some electronic devices transmit information that uniquely identifies them. Others transmit data that can be received repeatedly over time such that the content, format or pattern of transmission can provide enough identification data/a signature to be able to resolve identity to a reasonable specificity. The combination of electronic device signal patterns also can be consolidated to identify collections of electronic devices travelling with an individual or vehicle such that the collection pattern itself can identify the source and/or an individual or vehicle associated or correlated with the electronic device(s) with statistically significant specificity. The electronic devices' transmissions can be classified into groups of technology and frequency ranges. Cellular, Navigation, Bluetooth, Wi-Fi, RFID, Keyless entry, medical device, and tracking tags all typically transmit data that can be collected and correlated as needed.</p><p><span class=\"paragraph-number\">[0050]   </span>In accordance with embodiments of the present disclosure, the surveillance system <b>10</b> will be adapted to utilize existing Wi-Fi network connectivity at a remote or selected location, such as in residential areas around homes or in neighborhoods, as well as at or around businesses and other locations or selected locations. The introduction of home automation systems, wireless security systems, and other integrated electronic devices for managing home electronics and systems, provides an opportunity to integrate collection of electronic signal data for enhancement of security applications in residential/home environments. For example, devices like Ring® video doorbells and integrated garage door openers as well as home portal systems provide a platform for monitoring and collecting internal and video events. Some of these devices apply video analytics, but still must generally rely on lighting and visibility of faces and objects.</p><p><span class=\"paragraph-number\">[0051]   </span>The addition of electronic surveillance aspects provided by the surveillance system of the present disclosure is less intrusive than off-site video processing for facial or other recognition and can enable collection of data for analysis that could identify individuals even masked or in the dark. The electronic signals can be used to match with other locations, some of which might include better video or identity markers that would allow coordinated mapping of the intruder to a specific individual. At rest, however, the data is anonymous and low risk with respect to unwanted privacy intrusion. When mapped at the broader data collection levels by authorized or law enforcement staff, useful correlations of data points emerge. The concept of a neighborhood watch thus could be extended to electronic collection, and the timing and identity of deliveries, visitors or intruders could be tracked, monitored and reported, without the need for complex or expensive facial, image or license plate recognition. For example, during the holidays, more frequent and later deliveries can be made to homes, while at the same time, more thefts of packages can occur; and the surveillance system of the present disclosure thus can provide for monitoring and identification of delivery persons versus thieves and can provide law enforcement with a means for identifying and tracking such perpetrators.</p><p><span class=\"paragraph-number\">[0052]   </span>In embodiments, the surveillance system is configured to enable advanced correlation searching, including correlation analysis that can incorporate/utilize a series of methods, models and processes for the correlation of identifying-characteristics and/or identifiers including license plate, electronic signals, and visual idiosyncrasies, such that an operator can use known factors to identify previously unknown factors or can use patterns of activity, identifying information, electronic signals or visual idiosyncrasies to draw conclusions about the vehicles location, association to persons, association to locations and/or travel patterns. The surveillance system thus enables an operator to use known factors to identify previously unknown factors or use patterns of activity, identifying information, electronic signals, or visual idiosyncrasies to draw conclusions about the vehicle's location, association to persons, association to locations and/or travel patterns. Using these known patterns and/or associations, the system may form a convoy for different sets of targets and/or electronic signatures. In such embodiments, the introduction of a new or atypical target and/or electronic signature may indicate an event or may enable the system to cross-check such an introduction against reported events.</p><p><span class=\"paragraph-number\">[0053]   </span>In embodiments, the surveillance system can leverage existing Wi-Fi network connectivity by utilizing a plurality of collection systems or devices. The plurality of collection systems or devices may be included in the surveillance system. The collection systems or devices will include a plurality of sensors or detectors, for example, including Bluetooth and Wi-Fi collection source devices (e.g., to gather data relating to such signals), a cell phone collection application or device, a LPR or ALPR, a video or image capture device, and/or another device or set of sensors to capture different types of signals or identifiers. Such collection systems or devices can be located on mailboxes, home entrances, driveways, and signage such that the collected electronic signature data could show the transition of vehicles and people through neighborhoods and properties. The plurality of collection systems may gather or receive signals from a number of sources, such as a garage door opener, video doorbell, security cameras, motion detectors, home automation devices, smart devices, key fobs, computing devices, home/business Wi-Fi, gaming systems, cellular devices, and/or other devices at a home that generate an electronic signal. In addition, by placing devices at tactical locations on a property, the devices could collect a range of signals for central communication and storage.</p><p><span class=\"paragraph-number\">[0054]   </span>In a further embodiment, the plurality of collection systems may be, in addition to or rather than being separate systems or devices, included in or be a part of the number of sources. For example, at least one of the plurality of collection systems or device can include or can be integrated with (e.g., may be included in or a part of) a garage door opener, video doorbell, security cameras, motion detectors, home automation devices, smart devices, key fobs, computing devices, home/business Wi-Fi, gaming systems, cellular devices, and/or other devices at a home that generate an electronic signal.</p><p><span class=\"paragraph-number\">[0055]   </span>Based on the received electronic signals and/or targets, the surveillance system may generate a convoy or group of targets or signals for a selected location. In such embodiments, the surveillance system may determine the convoy. In such examples, the convoy may include data relevant to each part of the convoy. Further, additional signals for the convoy may not be recorded, thus reducing the amount of data stored in the surveillance system. Further, using the convoy, the surveillance system may determine whether a new target or electronic signal is a part of the convoy or atypical or different than normal. The identification or discovery of the new target and/or electronic signal may indicate an event is occurring or has occurred. Based on such an occurrence, an alarm may be generated.</p><p><span class=\"paragraph-number\">[0056]   </span>In embodiments, the surveillance system can filter and sort results such that the user is directed to signals most likely to have originated from the same set of devices travelling together. “Signals” here can mean electronic signals, visual identifiers, or license plate identification. In addition, the use of the transmitted methods and features of an electronic source with respect to signal strength, advertised methods, order of advertised elements, public and private attributes, and/or signal spectrum utilization by the surveillance system, as described further herein, can be used to collectively identify that source relatively distinctly.</p><p><span class=\"paragraph-number\">[0057]   </span>In embodiments of the methods disclosed herein, the method(s) can incorporate correlation confidence assignment whereby correlated results between electronic signatures and targets are analyzed using factors such as a frequency of occurrence, relative representation, signal type, signal receipt location diversity and signal strength profiling to generate and present confidence levels for correlations between signal-receipt events. The methods further will use correlation statistics and analysis to develop relationships between identifiers and non-unique characteristics, such as frequency of identifications, and other factors, captures/associated over multiple encounters.</p><p><span class=\"paragraph-number\">[0058]   </span>No single factor is required to be an absolute or unique identifier. In some embodiments, for example, captured signals or factors can be related to locations that could also be correlated or associated with other factors such a set of captured license plates, witness statements, etc. The cross-correlations also can be broken into subsets for filtering and generating confidence in the results of such advance correlation searching. The combination of non-unique characteristics and broadcast or visible variables, methods and transmitted values are used to identify a set that are collectively statistically significant in their unique association with the source entity.</p><p><span class=\"paragraph-number\">[0059]   </span>In other embodiments, the method can include correlation data noise-reduction at a collection point for filtering in-coming electronic signals to maximize the receipt and storage of moving, stable, identifiable signals by analyzing the signal value, strength, spectrum and embedded identification data. The method also can substantially simultaneously reduce and filter signals and identifiers that are ‘noise’ from likely-unrelated sources and not relevant to the future correlation.</p><p><span class=\"paragraph-number\">[0060]   </span>As indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, the surveillance system <b>10</b> includes a plurality of collection systems, devices or assemblies <b>12</b> that are located at selected geographic areas or strategic/targeted locations about a property such as a residential or commercial property <b>5</b>, e.g., on a mailbox, post, gutter, adjacent a camera, other locations on a house or building, etc. (as indicated at <b>13</b> in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>). The collection systems generally will be configured to capture or facilitate collection of information related to visual identifiers and/or electronic signal signature information from nearby transmitting electronic devices <b>14</b> associated with targets. The targets generally will include persons, vehicles, or a combination of both in and/or moving about the selected areas or locations. Targets also can include transmitted electronic devices or other objects and/or electronic devices associated with a specified person, without departing from the scope of the present disclosure. The collection systems can be positioned at various locations or collection points about a specific geographic area, e.g., a nearby or proximate to a home, a business, and/or neighborhood, or combinations thereof.</p><p><span class=\"paragraph-number\">[0061]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>-<b>3</b>A</a> further show an embodiment wherein each collection system includes a sensor or sensor assembly <b>16</b> configured to collect or otherwise capture the information related to visual identifiers and/or electronic signatures of targets. The sensor or sensor assembly accordingly can include one or more antennae <b>18</b> for capture of various electronic signals “ES” (<a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b>A</a>); and/or one or more cameras or camera systems configured to capture or facilitate collection of information related to vehicle identifiers “V”, such as visual or image information (e.g. video or photographic or digital images) related to a license plate of a vehicle and/or other visual vehicle or personal identifiers that can be used to discern, detect and/or otherwise identify or confirm the identity of a target vehicle or person.</p><p><span class=\"paragraph-number\">[0062]   </span>For example, in some aspects, such as shown in <a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b>A</a>, such vehicle markings can include, but are not limited to, signage, stickers, bumper stickers, non-license plate tags, patterns, position or configuration of component parts, damage to the vehicle, such as scratches, dents, repair marks, etc. and the location thereof on the vehicle, small markings or symbols or other indicia on vehicle components, as well as various other identifiable visual markings, or combinations thereof. In some embodiments, the camera system also can include an Automated License Plate Reader (“ALPR”) <b>20</b> integrated or otherwise associated with a collection system, or the surveillance system can include ALRPs in addition to, or in place of, one or more collection systems.</p><p><span class=\"paragraph-number\">[0063]   </span>In addition, or in the alternative, the at least one sensor or sensor assembly also can include an antenna, antenna array, or plurality of antennas <b>18</b> configured to capture or otherwise receive electronic signals from transmitting electronic devices associated with the targets for identification/extraction of electronic signatures. The at least one sensor or sensor assembly can include additional sensors, such as IR sensors or other light sensors, without departing from the present disclosure.</p><p><span class=\"paragraph-number\">[0064]   </span>As further illustrated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a> in some non-limiting example embodiments, the transmitting electronic devices <b>14</b> can include, but are not limited to, transmitting electronic devices associated with a vehicle, such as vehicle components including, but not limited to, tire pressure sensors or other manufacturer installed or after-market vehicle sensors, vehicle stereo or entertainments systems, vehicle navigation systems, vehicle infotainment systems, self-driving or driver assist vehicle guidance systems, vehicle Wi-Fi hotspots, other components of internal or external vehicle systems, etc. . . . ; and additionally can include transmitting electronic devices associated with persons or other types of targets, including, but not limited to, cellular phones and/or other communication devices, tablets, laptops, smart watches, fitness trackers, wireless headphones, RFID tags (e.g., key cards, library books, assets tags, pallet transmitters, pet collars), Wi-Fi hot spots, home automation devices, smart home devices, a garage door opener, a security camera, a doorbell camera, and/or other personal electronic devices. Each sensor or sensor assembly is configured to capture or collect signals transmitted by or otherwise emanating from the transmitting electronic devices when the targets get within proximity of the collection systems.</p><p><span class=\"paragraph-number\">[0065]   </span>The collection systems also can be configured to receive signals within a collection range, for example, and not limiting, within a prescribed or selected proximity in relation thereto. For example, in some embodiments, the collection systems could be configured to look for and receive signals transmitted within about 200 feet of the collection systems; while in other embodiments, such as to reduce or limit extraneous noise or to help filter such noise, shorter ranges of signals also can be used, i.e. in some locations, the collections systems can be configured to receive signals transmitted within about 100 feet of the collection systems, and in still other embodiments or locations, signals transmitted within about 50 feet of the collection systems. Other, varying ranges also can be used.</p><p><span class=\"paragraph-number\">[0066]   </span>In addition, as indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, the surveillance system includes an intelligence system that is in communication with the plurality of collection systems. The intelligence system <b>25</b> is configured to receive information collected or captured by the collection systems and to identify and/or track targets or correlate a target with other targets or electronic devices and/or locations based on this received information. The intelligence system can be in wireless communication with the collection systems, e.g., through a public or private network using Wi-Fi, cellular, etc. . . . . In addition, or in the alternative, the intelligence system and one or more of the collection systems can be connected through one or more wired connections. In this regard, when targets come within proximity of the collection systems, the collection systems will collect visual information and/or electronic signal information associated with the targets and transmit data points or packets of information, e.g., time and location stamped information, related to collected visual and/or electronic signal information to the intelligence system.</p><p><span class=\"paragraph-number\">[0067]   </span>The collection systems can include communications circuitry (e.g., one or more transmitters, receivers, etc.) <b>22</b> configured to transmit data points or packets substantially simultaneously or generally in real time when targets come within proximity to the collection systems. For example, the collection systems can send one or more data points including information corresponding to each electronic signal or visual identifier as it is captured or can send a data packet including information corresponding to multiple electronic signals or visual identifiers received. In addition, or in the alternative, the collection systems can transmit the data points or packets at specific time intervals, such as every few seconds, minutes, hours, etc. or at other times or intervals after the electronic signals or visual identifiers are captured, without departing from the scope of the present disclosure.</p><p><span class=\"paragraph-number\">[0068]   </span>In addition, in embodiments such as indicated in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, such electronic signal data can be collected by a cellular device <b>23</b>, such as a cell phone, tablet, etc. running an application configured for collection of such electronic signal data. Alternatively, one or more of the collection devices or systems can include a wireless model or cellular connectivity for transmission of the captured electronic signal data. For example, a series of collection devices can be linked or networked together to a master collection device that receives, compiles and transmits the data received from the other localized collection devices connected thereto to an intelligence system <b>25</b> that can be accessed by law enforcement. As a further alternative, the collection device(s) can be linked to the home or business Wi-Fi network for transmission of the collected electronic signal data.</p><p><span class=\"paragraph-number\">[0069]   </span><a href=\"#DRAWINGS\">FIGS. <b>1</b>-<b>3</b>C</a> further show that the intelligence system <b>25</b> will include correlation and search capabilities or one or more correlation and search engines <b>28</b> or circuitry (<a href=\"#DRAWINGS\">FIG. <b>3</b>A</a>) and an intelligence database <b>26</b>. The correlation and search engine <b>28</b> or circuitry is configured to identify or extract electronic signatures and/or other targets associated with a target using collected visual and/or electronic signal information at the collection systems. In particular, the correlation and search engine(s) <b>28</b> or circuitry is configured to ingest or process the data points/data packets to associate or correlate the visual identifiers with the received electronic device signals and/or other visual identifiers of other targets to facilitate the identification or extraction of electronic signatures and/or other targets identifying the targets. In such embodiments, such an association or correlation can be utilized by the correlation and search engine <b>28</b> or circuitry to create a convoy or, in other words, a group of targets which may travel together at varying times on varying dates and/or at varying locations (e.g., typical or atypical locations that a target or convoy may be traveling in proximation thereto).</p><p><span class=\"paragraph-number\">[0070]   </span>In an embodiment, the intelligence system <b>25</b> or intelligence device and/or the correlation and search engine <b>28</b> or circuitry further may include a memory and a processor or one or more processors. For example, as illustrated in <a href=\"#DRAWINGS\">FIG. <b>3</b>B</a>, the surveillance system <b>100</b> may include an intelligence device <b>102</b> and the intelligence device <b>102</b> may include a memory <b>104</b> and a processor <b>105</b>, as well as a correlation engine <b>106</b>. The memory <b>104</b> may store instructions executable by the processor <b>105</b> or one or more processors. In an example, the memory <b>104</b> may be a non-transitory machine-readable storage medium.</p><p><span class=\"paragraph-number\">[0071]   </span>As used herein, a “non-transitory machine-readable storage medium” may be any electronic, magnetic, optical, or other physical storage apparatus to contain or store information such as executable instructions, data, and the like. For example, any machine-readable storage medium described herein may be any of random access memory (RAM), volatile memory, non-volatile memory, flash memory, a storage drive (e.g., hard drive), a solid state drive, any type of storage disc, and the like, or a combination thereof. As noted, the memory <b>104</b> may store or include instructions executable by the processor <b>105</b>.</p><p><span class=\"paragraph-number\">[0072]   </span>As used herein, a “processor” may include, for example one processor or multiple processors included in a single device or distributed across multiple computing devices. The processor may comprise at least one of a central processing unit (CPU), a semiconductor-based microprocessor, a graphics processing unit (GPU), a field-programmable gate array (FPGA) to retrieve and execute instructions, a real time processor (RTP), other electronic circuitry suitable for the retrieval and execution instructions stored on a machine-readable storage medium, or a combination thereof.</p><p><span class=\"paragraph-number\">[0073]   </span>In embodiments, the instructions executable by the processor may include instructions to retrieve data or signals continuously, substantially continuously, or at specified intervals from one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N. Each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may include at least one sensor <b>110</b>A, <b>110</b>B, and <b>110</b>N and a communications circuitry <b>112</b>A, <b>112</b>B, and <b>112</b>N, respectively. Each of the one or more collection devices <b>108</b>A, <b>108</b>B, and up to <b>108</b>N may further include at least one antenna. The intelligence device <b>102</b> may send a request for data or signals and/or scan for data or signals. For example, if a collection device is detected, the intelligence device <b>102</b> may connect to or scan the communications circuitry of that collection device and collect the data or signals associated with the collection device. The instructions also may include instructions to correlate captured signals to one or more of targets, convoys, and/or locations, as described herein. In embodiments, the instructions may further include instructions to generate an interface or graphical user interface (GUI) enabling a user to search and filter received and correlated data or signals. Other instructions may be included in the memory to perform the functions described herein. In an embodiment, the instructions described above may be included in or may be a correlation engine <b>106</b> of the intelligence device <b>102</b>.</p><p><span class=\"paragraph-number\">[0074]   </span>As used herein, “signal communication” refers to electric communications with/from electronic devices, such as by hard wiring two components together or wireless communication, as understood by those skilled in the art. For example, wireless communication may be Wi-Fi®, Bluetooth®, ZigBee, and/or forms of near and/or far field communications. In addition, signal communication may include one or more intermediate controllers or relays disposed between elements that are in signal communication with one another.</p><p><span class=\"paragraph-number\">[0075]   </span>In embodiments, the electronic signatures can include information related to the collected electronic signals of the transmitting electronic devices or combinations of collected electronic signals of the transmitting electronic devices that uniquely identify the targets. For example, and without limitation, a combination of one or more signals from a plurality of transmitting electronic devices (e.g., a watch, cell phone/communication device, headphones, etc.) can include an electronic signature that uniquely identifies a person; a combination of one or more signals from a plurality of transmitting vehicle components (e.g., a vehicle sensor, infotainment system, etc.) can include an electronic signature that uniquely identifies a vehicle; a combination of one or more signals from a plurality of transmitting home or business components (e.g., a garage door openers, computing devices, video doorbells, etc.) can include one or more electronic signatures that uniquely identifies a home or business, which may or may not include vehicles; or one or more signals from a transmitting electronic device can include an electronic signature that uniquely identifies that electronic device.</p><p><span class=\"paragraph-number\">[0076]   </span>In embodiments, such signals may include data unique to a device, as well as anonymous. While such signals may, in some embodiments, not specify a user or person (e.g., anonymous), the correlation and search engine may be configured to associate such signals with a target based on known previously captured signals and/or may be configured to generate a target based on those signals. For example, the collected signals can be identified as relating to a certain type of signal and/or a certain type of device, and can be correlated with other identifying signal information to develop an electronic signature for the electronic device, which electronic device can be associated with a target and later identified by comparing additional collected electronic signals to those of a machining electronic signature for a device or devices associated with a target.</p><p><span class=\"paragraph-number\">[0077]   </span>The correlation and search engine further can be configured to filter or otherwise alter the received electronic signatures (or information related thereto) to reduce or diminish signal noise (e.g., from a noisy signal) and facilitate identification or extraction of unique, identifying electronic signatures. For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected noisy electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p><p><span class=\"paragraph-number\">[0078]   </span>As further shown in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>, in an embodiment, the surveillance system <b>101</b> or apparatus may include processing circuitry <b>114</b>, memory <b>112</b>, communications circuitry <b>118</b>, and correlation circuitry <b>116</b>, each of which will be described in greater detail below. While the various components are illustrated in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a> as being connected with processing circuitry <b>114</b>, it will be understood that the system <b>101</b> or apparatus may further comprise a bus (not expressly shown in <a href=\"#DRAWINGS\">FIG. <b>3</b>C</a>) for passing information amongst any combination of the various components of the surveillance system <b>101</b> or apparatus. The surveillance system <b>101</b> or apparatus further may include programming or instructions configured to execute various operations described herein, such as those described above in connection with <a href=\"#DRAWINGS\">FIGS. <b>1</b> through <b>3</b>B</a> and below in connection with <a href=\"#DRAWINGS\">FIGS. <b>4</b>A through <b>4</b>G</a>.</p><p><span class=\"paragraph-number\">[0079]   </span>The processing circuitry <b>114</b> (and/or co-processor or any other processor assisting or otherwise associated therewith) may be in communication with the memory <b>112</b> via a bus for passing information amongst components of the surveillance system <b>101</b> or apparatus. The processing circuitry <b>114</b> may be embodied in a number of different ways and may, for example, include one or more processing devices configured to perform independently. Furthermore, the processing circuitry <b>114</b> may include one or more processors configured in tandem via a bus to enable independent execution of software instructions, pipelining, and/or multithreading. The use of the term “processor” may be understood to include a single core processor, a multi-core processor, multiple processors of the surveillance system <b>101</b> or apparatus, remote or “cloud” processors, or any combination thereof.</p><p><span class=\"paragraph-number\">[0080]   </span>The processing circuitry <b>114</b> may be configured to execute software instructions stored in the memory <b>112</b> or otherwise accessible to the processing circuitry <b>114</b>. In some cases, the processing circuitry <b>114</b> may be configured to execute hard-coded functionality. As such, whether configured by hardware or software methods, or by a combination of hardware with software, the processing circuitry <b>114</b> represents an entity or device (e.g., an element that can be physically embodied in circuitry) capable of performing operations according to various embodiments of the present invention while configured accordingly. Alternatively, as another example, when the processing circuitry <b>114</b> is embodied as an executor of software instructions, the software instructions may specifically configure the processing circuitry <b>114</b> to perform the algorithms and/or operations described herein when the software instructions are executed.</p><p><span class=\"paragraph-number\">[0081]   </span>The memory <b>112</b> may be a non-transitory machine readable storage medium and may include, for example, one or more volatile and/or non-volatile memories. In other words, for example, the memory <b>112</b> may be an electronic storage device (e.g., a computer readable storage medium). The memory <b>112</b> may be configured to store information, data, content, applications, software instructions, or the like, for enabling the apparatus to carry out various functions in accordance with example embodiments contemplated herein.</p><p><span class=\"paragraph-number\">[0082]   </span>The communications circuitry <b>118</b> may include at least one device or circuitry embodied in either hardware or a combination of hardware and software that is configured to receive and/or transmit data from/to a network and/or any other device, circuitry, or module in communication with the surveillance system <b>200</b> or apparatus (e.g., one or more collection devices). In this regard, the communications circuitry <b>118</b> may include, for example, a network interface for enabling communications with a wired or wireless communication network. For example, the communications circuitry <b>118</b> may include one or more network interface cards, antennas, buses, switches, routers, modems, and supporting hardware and/or software, or any other device suitable for enabling communications via a network. Furthermore, the communications circuitry <b>118</b> may include the processing circuitry for causing transmission of such signals to a network or for handling receipt of signals received from a network.</p><p><span class=\"paragraph-number\">[0083]   </span>The surveillance system <b>101</b> or apparatus generally will include a correlation circuitry <b>226</b> configured to obtain and/or receive data and/or signals from one or more collection devices, identify and/or develop electronic signatures based on the data and/or signals, and/or correlate the data and/or signals or the electronic signature to a target, convoy, location, event, and/or other aspect. For example, the surveillance system <b>101</b> or apparatus may scan for various signals (e.g., via Wi-Fi, Bluetooth, etc.). Once a signal is detected, the correlation circuitry <b>116</b> may request or obtain data and/or signals from the collection device emanating the signal. Once the correlation circuitry <b>116</b> obtains or receives the data and/or signals, the correlation circuitry <b>116</b> may identify and/or develop an electronic signature or identifying electronic signature based on the data and/or signals.</p><p><span class=\"paragraph-number\">[0084]   </span>The electronic signature or identifying electronic signature may be based on various aspects of data and/or signals, such as the type of data and/or signal, a device associated with the data and/or signal, number of times or frequency that the data and/or signal has been detected, location associated with the data and/or signal, among other aspects. The correlation circuitry <b>116</b> may correlate the electronic signature or identifying electronic signature with one or more of a target, convoy, location, event, and/or other aspect. In an example, the correlation circuitry <b>116</b> may determine whether the data and/or signal or the electronic signature or identifying electronic signature is associated with a known or unknown target or convoy and/or whether a target or convoy is in a typical or atypical location. In a further embodiment, the correlation circuitry <b>116</b> may generate an alarm, to be transmitted to one or more users, when an unknown target is detected or when a target is in an atypical location. The correlation circuitry <b>116</b> may store the results of the correlation, as well as other information related to the data and/or signal, in a database. The correlation circuitry <b>116</b> may generate a user interface enabling a user to search through and/or filter the results.</p><p><span class=\"paragraph-number\">[0085]   </span>In addition, and as depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>A-<b>4</b>G</a>, the correlation and search engine is configured to catalogue the electronic signatures and/or visual identifiers in the intelligence database with specific identifying characteristics allowing these identified electronic signatures and/or visual identifiers to become unique, identifiable, and searchable. The identifying characteristics can include, but are not limited to, geographical coordinates, time stamps, source manufacturer, source type and unique ID, etc. . . . . The correlation and search engine also can be configured to build catalogs or groupings of independent data points/data packets in the intelligence database that allow correlation analysis to show what otherwise anonymous or non-unique electronic signals and/or other visual identifiers (e.g., other license plates) consistently appear with the targets.</p><p><span class=\"paragraph-number\">[0086]   </span>“Cluster Analysis” can be utilized to associate signal occurrences that follow a pattern, and the system may dynamically generate associations between the signals in a sample. Cluster analysis can allow new signal patterns to generate new cluster identities and for additional signals to be associated with that cluster when the system identifies the cluster-defining pattern. Further, the cluster analysis then allows otherwise anonymous signals to be categorized to a level of uniqueness that the surveillance system modeling/algorithms can use to identify the source with a confidence of uniqueness based on the presence of signals matching one or more cluster. The cluster-defining pattern criteria may include, but are not limited to, identifying information, content structure, transmission pattern, transmission size, encrypted content structure or content variation.</p><p><span class=\"paragraph-number\">[0087]   </span>The surveillance system thus can identify, track, map, catalogue, etc., the presence and/or movements of the targets, in real time for a particular convoy, as electronic signals emanating therefrom occur in proximity to the collection systems or based on image captures of visual identifiers. The surveillance system further can generate alerts or notifications when certain targets (e.g., atypical or unknown) are in proximity to the collection systems. Still further, the surveillance system further allows for the searches or queries of the intelligence database, e.g., for investigating locations or movements of suspects or other persons of interest. The surveillance system, as noted, can generate alerts or notifications when selected known targets are in proximity to the collection systems and, further, initiate home automation systems based on such an alert or notification.</p><p><span class=\"paragraph-number\">[0088]   </span>In embodiments, the correlation and search engine can use algorithms, models, statistical models, machine learning algorithms/models, Big Data analysis or statistics, cluster analysis, etc., to infer relationships between transmitting electronic devices and/or targets based on consistency or likelihood of correlation of the visual identifiers and/or electronic signals of the transmitting electronic devices. For example, the correlation and search engine can be configured to evaluate and combine singular collection events at the collection systems with other catalogued events in the intelligence database to develop correlated information related to the intersection of multiple collected/captured electronic signals and/or visual identifiers that occurred at a specific time and geographical area or location. And, the correlation and search engine can use the frequency and/or consistency of electronic signals and/or visual identifiers received at collection systems to determine the relative certainty of association of the transmitting electronic devices and/or targets to develop electronic signatures (correlated electronic devices) or correlated targets (e.g., correlated license plates) for the targets.</p><p><span class=\"paragraph-number\">[0089]   </span>By way of example and not limitation, the system can identify high confidence correlations in which a set of signals entering the receiving range of a residence to indicate the arrival of the owner and/or a known vehicle. This might be used to trigger home automation (e.g., open a garage door, turn on specified lights, etc.) or to reduce the level of threat assessment being monitored at the previously vacant residence (e.g., a target is known and, for example, signals associated with the target may not be monitored for a specified time period, such as while the owner is home, after initial identification). As an additional example, the system might consistently see a set of signals associated with a home-owner's vehicle and the typical occupants and may classify these as having a high confidence of being correlated with the vehicle. If an additional signal begins to consistently appear with that pattern, the system may be configured to retain the new signal as ‘known’ within the correlation, or if configured for higher security, may generate or create a notification indicating that a change has occurred, thus allowing the owner to assess if a new device was acquired or if some suspicious new source has appeared. The presence of an additional new signal (e.g., a new signal which is not part of a known pattern of identification as it appears over time) may be added to a category of known devices such that its presence over time with known devices may make the new signal less likely to be considered a concern when that device appears without the other known devices.</p><p><span class=\"paragraph-number\">[0090]   </span>The correlation and search engine can be programmed to determine a likelihood or probability that a specific electronic signal, a combination or set of electronic signals, and/or other target or targets are associated with a target or location (e.g., a home or neighborhood), and if the determined likelihood or probability meets a prescribed/selected likelihood or probability threshold, the engine will identify or extract an electronic signal or combinations of electronic signals as an electronic signature or electronic signatures to be associated with that target at the location. In one embodiment, the likelihood or probability threshold can be about 70% or more (e.g., above 75%, above 80%, above 85%, above 90%, above 95%, above 98%, etc.) that an electronic signal, combination/set of electronic signals, and/or other targets are associated with a particular target, convoy, and/or location.</p><p><span class=\"paragraph-number\">[0091]   </span>For example, the correlation and search engine may correlate two or more license plates and one or more electronic devices based on multiple events. Based on such a correlation, a prediction of whether a particular vehicle may be present at a specific location may be determined by the correlation and search engine. Further, the two or more license plates may be from or may define a convoy (e.g., group of targets or target vehicles). In such an example, the electronic devices may be associated with the convoy.</p><p><span class=\"paragraph-number\">[0092]   </span>In some embodiments, the correlation and search engine can be configured to determine or identify a location at which a visual identifier and correlated electronic signature and/or other visual identifier are matched to enable tracking and/or verification of targets at such a location. In addition, or in the alternative, the correlation and search engine can be configured to associate identifying electronic signatures and/or other visual identifiers with a location, such as a home or neighborhood, to allow for comparison between a convoy and new, atypical electronic signals. For example, once the engine has records correlating electronic signatures and/or other visual identifiers for a selected location, e.g., a license plate likely to be located at or near a specific visual vehicle identifier, associated with the specific visual vehicle identifier, e.g., a specific license plate number, the correlation and search engine will be able to detect the likely presence of a vehicle and its associated license plate without visual information of that specific vehicle, e.g., a camera may or may not be used.</p><p><span class=\"paragraph-number\">[0093]   </span>In addition, or in the alternative, an existing ALPR can be modified or retrofitted to include components of the collection point systems to enable collection of electronic signals jointly with license plate reads. Further, in some embodiments, collection systems with or near cameras or ALPRs can be used in connection with collection systems without cameras or ALPRs, as indicated at <b>20</b> in <a href=\"#DRAWINGS\">FIGS. <b>1</b> and <b>3</b>A</a>.</p><p><span class=\"paragraph-number\">[0094]   </span>As a result, electronic data points from less expensive collection systems can be used to provide more precise tracking than ALPR alone. That is, the lower cost collection systems can increase collection density beyond the collection of ALPR or camera records, enabling data from both collection system types to be combined to provide more detailed intelligence and increased accuracy of verification or authentication of possible targets, including providing monitoring personnel (e.g. law enforcement, security or other personnel) with an increased level of confidence of locations of potential criminals, stolen or other vehicles of interest.</p><p><span class=\"paragraph-number\">[0095]   </span>Additionally, or alternatively, collection systems without cameras (or with cameras) can be positioned in areas or locations that cannot be accessed by a vehicle, such as on trains, near railways, around public buildings, etc., to enable collection of electronic signals from persons away from their vehicle, e.g., for cataloguing, tracking, mapping, etc. . . . positions or movements thereof.</p><p><span class=\"paragraph-number\">[0096]   </span>The intelligence system generally includes one or more processors, controller's, CPUs, etc., and one or more memories, such as RAM, ROM, etc., in communication with the one or more processors. And, the engine can include computer programming instructions stored in the one or more memories that can be accessed and executed by the one or more processors to facilitate execution of the processes thereof, e.g., correlation of information, identification and tracking of the targets, searching of the intelligence database, etc. . . .</p><p><span class=\"paragraph-number\">[0097]   </span>The correlation and search engine can process the information from the received data points or data packages to correlate the received signal information with the visual information to develop electronic signatures uniquely identifying each vehicle or person at a selected location based on the received electronic signals or combinations thereof, and also can populate the intelligence database with the signature information identifying each vehicle and/or person. As multiple license plates may be read at a time and multiple signals detected, correlation may occur when or if multiple data points exist for a particular vehicle. Operators then can search or query the intelligence database, e.g., using a user interface or GUI as shown in <a href=\"#DRAWINGS\">FIGS. <b>4</b>A-<b>4</b>D</a>, for identification, mapping, tracking, etc., of vehicles, people, and/or locations at specific times.</p><p><span class=\"paragraph-number\">[0098]   </span>For example, in <a href=\"#DRAWINGS\">FIG. <b>4</b>A</a>, a user may search for a particular vehicle based on a license plate number or other identifier or signature in an interface or GUI. After searching for a particular license plate number or other identifier or signature, the GUI may display a type of signal <b>402</b>, an image <b>404</b> (if available), a date/time stamp <b>406</b> (e.g., when the particular license plate number or other identifier or signature was last detected), a license plate number <b>408</b> (if available), a GPS based location, and/or the reader <b>412</b> or device discovering or gathering signals associated with the particular license plate number or other identifier or signature.</p><p><span class=\"paragraph-number\">[0099]   </span>In <a href=\"#DRAWINGS\">FIG. <b>4</b>B</a>, a user may perform a cross-search via an interface or GUI <b>414</b>. A cross-search can include searching for a particular parameter (e.g., a license plate number, a convoy, an electronics signature, and/or some other identifier) in a first step and then perform additional searches in additional steps (e.g., step 2, step 3, etc.).</p><p><span class=\"paragraph-number\">[0100]   </span>In yet another example, as depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>C-<b>4</b>D</a>, a user may search for a particular convoy or search based on selected characteristics of a convoy. Upon searching for a convoy, the interface or GUI may display a convoy identifier <b>416</b>, the make <b>418</b> of the convoy (e.g., vehicle manufacturer, if available), the model <b>420</b> of the convoy (e.g., type of vehicle from the manufacturer, if available), the color <b>420</b> of the convoy (e.g., the color of the vehicle, if available), a license plate number <b>424</b> (if available), a primary identifier <b>426</b> or primary identifiers (e.g., an identifier for a target primarily associated with the convoy, and/or the number of occurrences <b>428</b> or detections of the convoy at one or more specified locations, among other data.</p><p><span class=\"paragraph-number\">[0101]   </span>For example, as illustrated in <a href=\"#DRAWINGS\">FIG. <b>4</b>D</a>, a user may search for a primary identifier (e.g., see <b>430</b>). Upon execution of the search data relating to that primary identifier may be displayed in the GUI (e.g., see <b>432</b> or <b>434</b> of <a href=\"#DRAWINGS\">FIG. <b>4</b>E</a>). Further, as illustrated in <a href=\"#DRAWINGS\">FIG. <b>4</b>F</a>, a user my select a particular convoy or instance of a detection of a convoy and view related and/or associated details with the convoy or that instance of detection of that convoy (e.g., see <b>436</b>). In yet another embodiment, and as noted herein, the interface or GUI may display a map view and/or geographical view of an area. The interface or GUI may be configured such that portions of the map view and/or geographical view are selectable. For example, a user may select a point and drag a cursor in another direction to form a box (e.g., see <b>442</b>). In another example, a user may draw a shape to select such a portion or utilize other actions to perform such a selection.</p><p><span class=\"paragraph-number\">[0102]   </span>Summary use cases utilizing embodiments of the surveillance system of the present disclosure can include mail and package delivery notifications, transient signal schedule tracking, regular transient signal reporting to improve bus or transport arrival or departure predictability and alerts, intrusion detection, tagged pet tracking, integrated known-visitor security and lock status-change activation, occupancy trend tracking and reporting for integrated utility and energy management, customization of entertainment and lighting systems by occupancy, simplified guest arrival and security management for commercial space rentals, hotel and campus security systems, integrated video surveillance retrieval and queueing systems and other applications/uses.</p><p><span class=\"paragraph-number\">[0103]   </span>By way of example only, in some embodiments, the surveillance system can be configured to capture an electronic signature and associated information from a target, and can associate such electronic signature, as well as associate other targets, and associated information with the target's identification, e.g., license plate number or other visual identifier, with the correlation and search engine, and then allow searches for or provide alerts or notifications on receipts of similar electronic signature information and/or visual identifier at one or more of the collection systems. In an embodiment, the association or correlation of two or more different license plates, which may include correlated one or more different electronic devices, may form a convoy. Convoys may be selectable, as illustrated in <a href=\"#DRAWINGS\">FIGS. <b>4</b>D-<b>4</b>F</a>, and/or locations for searching targets or convoys can be selectable.</p><p><span class=\"paragraph-number\">[0104]   </span>The surveillance system further can be configured to allow for search inquiries or scans of one or more specific electronic signatures associated with a target or convoy or may search for a specific convoy or target associated with one or more convoys, and to provide search results including known location data points, in the intelligence database. As depicted in <a href=\"#DRAWINGS\">FIGS. <b>4</b>E-<b>4</b>G</a>, the search results can include maps or other images showing the collection systems that captured electronic signals associated with the one or more electronic signatures searched, e.g., indicating the selected target's or convoy's presence or movements about a prescribed location or area.</p><p><span class=\"paragraph-number\">[0105]   </span>In addition, or in the alternative, the search results can include groupings or listings of search results associating the target, electronic signals, and/or convoy searched with information related to the collection systems which captured target, electronic signals, and/or convoy associated with the two or more targets and/or one or more electronic signatures searched. The grouping or listing can include images captured (e.g., images of the person, vehicle, vehicle license plate, etc.), temporal information (e.g., the date and time the visual or signal information was collected), the visual identifier (e.g., license plate number), location information (e.g., GPS coordinates, state, city, etc.), information identifying the collection point system, statues of the collection (e.g., normal read, error, etc.), etc. . . .</p><p><span class=\"paragraph-number\">[0106]   </span>The surveillance system can generate an alarm or alert when the specific electronic signature(s) and/or visual identifier distinct or atypical from a convoy is captured at a selected location. The alarm may alert a user of the presence of an atypical or distinct target(s) at or near the selected location. The alarm or alert can be provided to the operator of the surveillance system and/or local authorities, e.g., law enforcement or other third parties. In some embodiments, the target can be selected based on a specific criteria associated with the target of the convoy, e.g., arrest warrant, Amber or Silver Alert, expired registration, immigration violation, etc. . . . , and when the labeled electronic signatures and/or visual identifiers are collected at one or more of the collection systems, the proper authorities can be notified.</p><p><span class=\"paragraph-number\">[0107]   </span>In still further embodiments, the surveillance system further can indicate or determine changes in association or travel of suspects based on variations in electronic signatures associated with a location. For example, based on unique electronic signatures, the surveillance system can indicate whether particular individuals are or were traveling with a vehicle through or in the selected location, which can allow investigators to determine whether suspects were actually at the selected location during an event.</p><p><span class=\"paragraph-number\">[0108]   </span>By way of example and not limitation, in an embodiment for analysis of electronic signature data, an initial goal is to find associations of electronic signatures and/or targets to known ALPR targets. For this, multiple locations can be used. The repeated linking of a target (e.g., a license plate) to electronic signatures and/or other targets can be the value. For example, a particular license plate can be associated with a convoy, the convoy can be associated with a list of electronic signatures, and the convoy and/or electronic signatures associated with non-LPR sites.</p><p><span class=\"paragraph-number\">[0109]   </span>In some aspects, the surveillance system and the operation thereof can include the harvest or collection of values in convoy searches when a target value is unknown. Such a search can be based on a date/time, tight correlations, and/or other factors. Reading a signal simply at one site may not be valuable, but a read at two or more sites may indicate that a target is moving and may be valuable or more valuable than a single read of a potentially stationary target. Using such systems and methods described herein, a search can be quickly refined to values that are read at multiple sites and have convoy hits/correlation or association, with and/or without a plate match. A convoy can be limited by site and by multiple electronic signature reads at a series of sites, e.g., two or more successive sites.</p><p><span class=\"paragraph-number\">[0110]   </span>The foregoing description generally illustrates and describes various embodiments of the present disclosure. It will, however, be understood by those skilled in the art that various changes and modifications can be made to the above-discussed construction of the present disclosure without departing from the spirit and scope of the disclosure as disclosed herein, and that it is intended that all matter contained in the above description or shown in the accompanying drawings shall be interpreted as being illustrative, and not to be taken in a limiting sense. Furthermore, the scope of the present disclosure shall be construed to cover various modifications, combinations, additions, alterations, etc., above and to the above-described embodiments, which shall be considered to be within the scope of the present disclosure. Accordingly, various features and characteristics of the present disclosure as discussed herein may be selectively interchanged and applied to other illustrated and non-illustrated embodiments of the disclosure, and numerous variations, modifications, and additions further can be made thereto without departing from the spirit and scope of the present invention as set forth in the appended claims.</p>",
            "CLMS": "(US20230196780)<br/><p><h1>What is claimed is:</h1></p><p><b>1</b>. A surveillance system comprising:<br/> one or more collection devices positioned proximate one or more of a home business, or neighborhood, each of the one or more collection devices comprising:<br/>  at least one sensor configured to collect electronic signals from proximal electronic devices,<br/>  a communication circuitry to transmit collected electronic signals; and<br/> an intelligence device configured to receive the collected electronic signals and comprising:<br/>  a database, and<br/>  a correlation circuitry configured to:<br/>   generate an identifying electronic signature for the proximate electronic devices from which the electronic signals are collected, and<br/>   determine a correlation between identifying electronic signatures and one of a known target or unknown target.</p><p><b>2</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein one or more of the one or more collection devices further comprises one or more of a sensor or camera configured to capture one or more of an image, a series of images, or video, and wherein the intelligence device utilizes the collected electronic signals and one or more of the one or more of an image, a series of images, or video to correlate one or more of the one or more of an image, a series of images, or video with one or more of the collected electronic signals.</p><p><b>3</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein one or more of the one or more collection devices is located at a known location, and wherein the intelligence device correlates the known location of the one or more collection devices with one or more of the collected electronic signals received by the one or more collection devices.</p><p><b>4</b>. The surveillance system of <claim-ref idref=\"CLM-00003\">claim 3</claim-ref>, wherein correlation between the known location and the one or more collected electronic signals indicates a target at an atypical location.</p><p><b>5</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein at least some of the one or more collection devices include a global positioning system (GPS) device for determining a location thereof</p><p><b>6</b>. The surveillance system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein one or more of the one or more collection devices includes an automated license plate reader (ALPR) to capture license plate numbers and/or other vehicle characteristics, and wherein the intelligence device correlates a capture license plate number with one or more of the collected electronic signals</p><p><b>7</b>. A surveillance system comprising:<br/> one or more collection devices positioned proximate one or more of a home, neighborhood, or business, each of the one or more collection devices comprising:<br/>  at least one sensor, at least one antenna; or a combination thereof, configured to collect, via a corresponding frequency, electronic signals from proximal electronic devices, and<br/>  a communication circuitry to transmit collected electronic signals an intelligence device positioned separate from the one or more collection devices and comprising:<br/>  a database, and<br/>  a correlation circuitry to:<br/>   develop an electronic signature for each of the proximal devices from which the electronic signals are collected, and<br/>   determine a correlation of each electronic signature and one or more locations of the one or more of the home, neighborhood, or business.</p><p><b>8</b>. The surveillance system of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the one or more collection devices are configured to tag an electronic signal based on a type of electronic device emitting the electronic signal.</p><p><b>9</b>. The surveillance system of <claim-ref idref=\"CLM-00008\">claim 8</claim-ref>, wherein the one or more collection devices are configured to associate a timestamp and location data with each electronic signal.</p><p><b>10</b>. The surveillance system of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the correlation circuitry is configured to determine a correlation between the one or more different electronic signals of the collected electronic signals and one or more identified targets.</p><p><b>11</b>. The surveillance system of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref>, wherein the one or more identified targets include one or more of a convoy or a person, or a combination thereof.</p><p><b>12</b>. The surveillance system of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref>, wherein the correlation circuitry includes one or more classification and search engines configured to identify the collected electronic signals and compare identified collected electronic signals with one or more targets to determine the correlation of the one or more different electronic signals of the collected electronic signals and the one or more identified targets.</p><p><b>13</b>. The surveillance system of <claim-ref idref=\"CLM-00012\">claim 12</claim-ref>, wherein the one or more classification and search engines are configured to determine inferences of targets typical to the one or more locations and targets atypical to the one or more locations, and wherein the correlation is based on the inferences of targets typical to the one or more locations and targets atypical to the one or more locations.</p><p><b>14</b>. The surveillance system of <claim-ref idref=\"CLM-00013\">claim 13</claim-ref>, wherein determination of the inferences is based on one or more of reported events or reported alerts.</p><p><b>15</b>. The surveillance system of <claim-ref idref=\"CLM-00014\">claim 14</claim-ref>, wherein the one or more of reported events or reported alerts include crimes and other events.</p><p><b>16</b>. The surveillance system of <claim-ref idref=\"CLM-00014\">claim 14</claim-ref>, wherein the determination of the inferences is further based on detection of one of one or more electronic signals more than a preselected threshold.</p><p><b>17</b>. The surveillance system of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the at least one sensor comprises one or more cameras configured to capture electronic signals related to vehicle identifiers.</p><p><b>18</b>. A method comprising:<br/> collecting, via one or more collection devices positioned proximate a residential or commercial building, electronic signals from proximal electronic devices positioned at one or more of within the home or proximate the home;<br/> reviewing the electronic signals for detection of noisy signals collected within the electronic signals;<br/> in response to detection of noisy signals collected within the electronic signals, removing the noisy signals of the electronic signals to thereby form filtered electronic signals;<br/> transmitting the filtered electronic signals to a database;<br/> developing an electronic signature for each of the proximal devices from which the filtered electronic signals are collected; and<br/> determining a correlation between each electronic signature and one or more targets based upon a comparison of each electronic signature and one or more stored electronic signals associated with the one or more targets.</p><p><b>19</b>. The method of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, further comprising, upon reception of the electronic signals, tagging each of the electronics signals based on a type of electronic device from which a corresponding electronic signal is collected.</p><p><b>20</b>. The method of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, wherein the one or more targets comprise one or more convoys or people.</p><p><b>21</b>. The method of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, wherein the one or more different electronic signals comprise one or more of unidentified signals or atypical signals.</p><p><b>22</b>. The method of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, further comprising tracking one or more targets based on the correlation.</p>",
            "NPR": "3",
            "APID": "164364111",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G06V-020/52<br/>G06V-020/62<br/>G08B-013/196<br/>G08B-025/01<br/>G08G-001/017<br/>G08G-001/065",
            "ID": "105331626",
            "AB": "(US20230196780)<br/>A system and method for monitoring for one or more electronic signals associated with one or more selected locations. In an embodiment, the system may include collection devices positioned at selected locations. The collection devices may include (1) at least one sensor or (2) at least one antenna configured to collect, via a corresponding frequency, electronic signals from proximal electronic devices. The collection devices may include a communication circuitry to transmit collected electronic signals. The system may include an intelligence device positioned separate from the collection devices. The intelligence device may include a database and a correlation circuitry to determine a correlation of one or more different electronic signals of the collected electronic signals and one or more targets based upon a comparison of the collected electronic signals with one or more electronic signatures associated with one or more targets.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=XWWMYUwT5qwrT9h6rfcXEMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=",
            "EAPD": "2022-12-01",
            "PA": "LEONARDO US CYBER & SECURITY SOLUTIONS<br/>SELEX",
            "PAAD": "(US20230196780)<br/>(PUB:US-20230196780A1-2)NAME=Selex ES Inc.  , CITY=Greensboro , STATE=NC , COUNTRY=US<br/><br/><br/>(WO2023121841)<br/>(PUB:WO-2023/121841A1-3)NAME=SELEX ES INC. 4221 Tudor Lane Greensboro, NC 27410 , POSTCODE=27410 , COUNTRY=US<br/>",
            "FAN": "105331626",
            "TI": "Systems and methods for electronic surveillance",
            "TECD": "Computer technology<br/>Control",
            "EPD": "2023-06-22",
            "ICLM": "(US20230196780)<br/><p>1 . A surveillance system comprising: one or more collection devices positioned proximate one or more of a home business, or neighborhood, each of the one or more collection devices comprising: at least one sensor configured to collect electronic signals from proximal electronic devices, a communication circuitry to transmit collected electronic signals; and an intelligence device configured to receive the collected electronic signals and comprising: a database, and a correlation circuitry configured to: generate an identifying electronic signature for the proximate electronic devices from which the electronic signals are collected, and determine a correlation between identifying electronic signatures and one of a known target or unknown target.</p><p>18 . A method comprising: collecting, via one or more collection devices positioned proximate a residential or commercial building, electronic signals from proximal electronic devices positioned at one or more of within the home or proximate the home; reviewing the electronic signals for detection of noisy signals collected within the electronic signals; in response to detection of noisy signals collected within the electronic signals, removing the noisy signals of the electronic signals to thereby form filtered electronic signals; transmitting the filtered electronic signals to a database; developing an electronic signature for each of the proximal devices from which the filtered electronic signals are collected; and determining a correlation between each electronic signature and one or more targets based upon a comparison of each electronic signature and one or more stored electronic signals associated with the one or more targets.</p><p>7 . A surveillance system comprising: one or more collection devices positioned proximate one or more of a home, neighborhood, or business, each of the one or more collection devices comprising: at least one sensor, at least one antenna; or a combination thereof, configured to collect, via a corresponding frequency, electronic signals from proximal electronic devices, and a communication circuitry to transmit collected electronic signals an intelligence device positioned separate from the one or more collection devices and comprising: a database, and a correlation circuitry to: develop an electronic signature for each of the proximal devices from which the electronic signals are collected, and determine a correlation of each electronic signature and one or more locations of the one or more of the home, neighborhood, or business.</p>",
            "CTN": "(WO2023121841)<br/>US20180211115 80623904 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>US7173526 43503462 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>US20070069921 14939405 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2025-06-21",
                    "XAP": "2022WO-US51494",
                    "APD": "2022-12-01",
                    "APID": "164553008",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2023121841&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=zLpq0f00dDcaSfq1je27gbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2023/121841",
                            "KIND": "A1",
                            "XPN": "WO2023121841",
                            "V_PNID": "WO-2023/121841A1-3",
                            "DATE": "2023-06-29",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDvrXS0fJu13t0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2023121841&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=zLpq0f00dDcaSfq1je27gbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-12-01",
                            "XAP": "2024MX-0007729",
                            "APD": "2022-12-01",
                            "APID": "172589267",
                            "REG_LINK": "https://siga.impi.gob.mx/newSIGA/content/common/principal.jsf",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=xkPblRqfI4ppiLCrAvOnyrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "MX2024007729",
                                    "KIND": "A",
                                    "XPN": "MX2024007729",
                                    "V_PNID": "MX-2024007729A-0",
                                    "DATE": "2024-07-01",
                                    "STG": "Patent application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=jU6hsZbekahvEO9KiiSVQAMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=MX2024007729&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=xkPblRqfI4ppiLCrAvOnyrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2042-12-01",
                    "XAP": "2022US-18072924",
                    "APD": "2022-12-01",
                    "APID": "164364111",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/18072924",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=XWWMYUwT5qwrT9h6rfcXEMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US20230196780",
                            "KIND": "A1",
                            "XPN": "US20230196780",
                            "V_PNID": "US-20230196780A1-2",
                            "DATE": "2023-06-22",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcOEc/5ZZ9GDTEGd4JhdgzD3bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20230196780&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=XWWMYUwT5qwrT9h6rfcXEMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "US20230196780_A1",
            "EPRD": "2021-12-21",
            "PN": "US20230196780       A1 2023-06-22 [US20230196780]<br/>WO2023/121841       A1 2023-06-29 [WO2023121841]<br/>MX2024007729        A  2024-07-01 [MX2024007729]",
            "ADB": "(US20230196780)<br/><p>It can be seen that a need exists for surveillance systems and methods that can be used to provide a correlation between devices, images, and/or locations, thus enabling tracking of unidentified persons at or near a home, a business, or a neighborhood.</p><p>It will be appreciated that for simplicity and clarity of illustration, elements illustrated in the Figures are not necessarily drawn to scale.</p><p>The foregoing and other advantages and aspects of the embodiments of the present disclosure will become apparent and more readily appreciated from the following detailed description, taken in conjunction with the accompanying drawings.</p><p>A convoy can be limited by site and by multiple electronic signature reads at a series of sites, e.g., two or more successive sites.</p><p>For example, the correlation and search engine can apply filtering (e.g., linear or non-linear filters, dynamic noise reduction, etc.) to collected noisy electronic signals to diminish, reduce, or substantially eliminate stationary and variable noise and other values that cannot be usefully correlated with targets, allowing unique electronic signal values to be extracted or identified.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=4<br/>PNAAGE=16<br/>NBPA=1; <br/>ALLCT=3; SCT=1; NSCT=2; <br/>ALLCTG=0; SCTG=0; NSCTG=0; <br/>AFS=29; ACC=28; AMCC=3; <br/>IGEN=0.0; IORG=0.88; IRAD=0.92; <br/>IMPI=0.0; MACI=1.34; PASI=1.65; PAVI=1.47; ",
            "PTCC": "(EP4163750)<br/>CC=EP EED=2041-10-11 STATUS=GRANTED APID=163256496 APD=2021-10-11 XPN=EP4163750 PD=2023-04-12 PD=2024-01-31 EPD=2023-04-12 LPD=2024-01-31 PDG=2024-01-31 <br/>CC=CH EED=2041-10-11 STATUS=GRANTED APID=163256496 XPN=EP4163750 PDG=2024-01-31 <br/>CC=DE EED=2041-10-11 STATUS=GRANTED APID=163256496 XPN=EP4163750 PDG=2024-01-31 <br/>CC=GB EED=2041-10-11 STATUS=GRANTED APID=163256496 XPN=EP4163750 PDG=2024-01-31 <br/>CC=IE EED=2041-10-11 STATUS=GRANTED APID=163256496 XPN=EP4163750 PDG=2024-01-31 <br/><br/>(WO202362519)<br/>CC=WO EED=2025-04-11 STATUS=PENDING APID=163382619 APD=2022-10-11 XPN=WO202362519 PD=2023-04-20 EPD=2023-04-20 LPD=2023-04-20 <br/>CC=CN EED=2042-10-11 STATUS=PENDING APID=170375799 APD=2022-10-11 XPN=CN118119905 PD=2024-05-31 EPD=2024-05-31 LPD=2024-05-31 <br/>CC=KR EED=2042-10-11 STATUS=PENDING APID=171308720 APD=2022-10-11 XPN=KR20240113465 PD=2024-07-22 EPD=2024-07-22 LPD=2024-07-22 <br/><br/>(KR20240113465)<br/>CC=KR EED=2042-10-11 STATUS=PENDING APID=171308720 APD=2022-10-11 XPN=KR20240113465 PD=2024-07-22 EPD=2024-07-22 LPD=2024-07-22 <br/><br/>(CN118119905)<br/>CC=CN EED=2042-10-11 STATUS=PENDING APID=170375799 APD=2022-10-11 XPN=CN118119905 PD=2024-05-31 EPD=2024-05-31 LPD=2024-05-31 <br/>",
            "EPN": "EP4163750",
            "CTGN": "",
            "LAPD": "2022-10-11",
            "STDN": "",
            "NPN": "4",
            "DESC": "<p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and system for detecting flight regimes of an aircraft, on the basis of measurements acquired during an aircraft flight.</p><p><span class=\"paragraph-number\">[0002]   </span>As is known, in aeronautics the need to monitor the state of fatigue, and more generally the state of health, of the components of an aircraft, for example in order to estimate with precision the residual life time of each component, and therefore optimise maintenance activities, without compromising flight safety, is particularly felt.</p><p><span class=\"paragraph-number\">[0003]   </span>In particular, it is known that the state of fatigue to which the components of an aircraft are subjected depends on the manoeuvres to which, during usage, the aircraft has been subjected, since the loads to which each component is subjected depend on the manoeuvres carried out by the aircraft. Consequently, the need is felt to correctly detect the manoeuvres performed by an aircraft, in order to then be able to determine the so-called real usage spectrum. To this end, it is known to equip aircraft with monitoring systems adapted to detect the values of quantities relative to the flight; this makes it possible to acquire a large number of measurements of these quantities, which can be analysed to reconstruct the history of the manoeuvres carried out by the aircraft.</p><p><span class=\"paragraph-number\">[0004]   </span>For example, <figref>Figure 1A</figref> shows a helicopter 1, which is equipped with a monitoring system 2, which includes sensors adapted to measure corresponding quantities, which are referred to in the following as primary quantities. Generally, the samples of the primary quantities are generated with a certain sampling frequency, typically in the order of about ten Hertz. Purely by way of example, the primary quantities may include: variables related to the aircraft kinematics (e.g. pitch angle, roll angle, yaw angle, vertical acceleration, vertical speed, longitudinal acceleration, lateral acceleration, roll rate, pitch rate, yaw rate, northbound speed, eastbound speed, main rotor speed); variables related to the aircraft controls (such as, for example, collective control position, lateral position cyclic control, longitudinal position cyclic control, pedal position); environmental variables (such as, for example, air speed, radar altitude, barometric altitude, wind speed, wind direction, total air temperature); variables related to the energy systems (such as, for example, the torque of the motors, the rotation speed of the engine turbines, the rotation speed of the engine generators).</p><p><span class=\"paragraph-number\">[0005]   </span>For example, <figref>Figure 1B</figref> shows the trends over time of five primary quantities (denoted respectively as quantities 1-5), which are monitored by corresponding sensors of the monitoring system 2, which periodically provide the corresponding samples.</p><p><span class=\"paragraph-number\">[0006]   </span>That being said, the Applicant has observed that, even having such measurements, the correct detection of the executed manoeuvres requires an analysis by means of advanced data processing techniques and is further hampered by the fact that different manoeuvres typically have different durations, which complicates the analysis of the aforementioned temporal trends.</p><p><span class=\"paragraph-number\">[0007]   </span>In order to overcome the problem of the different manoeuvre durations, <patcit dnum=\"EP20425059\" dnum-type=\"L\">European patent application No. 20425059.1, filed on 18 December 2020</patcit> on behalf of the Applicant, describes a method implemented by computer for detecting the execution, by an aircraft, of a manoeuvre belonging to a macrocategory among a plurality of predetermined macrocategories. In particular, as shown in <figref>Figure 2</figref>, the set (denoted by 5) of the manoeuvres that may be carried out by an aircraft can be subdivided into a plurality of subsets, to which in the continuation reference is indeed made as to the macrocategories (denoted by MC) . Each macrocategory MC groups together subclasses of manoeuvres with similar features. For example, <figref>Figure 2</figref> shows macrocategories MC related to level flight, bank turn, vertical take-off, climb, etc., respectively. In turn, the macrocategory related to level flight may include a plurality of manoeuvres (only four shown in <figref>Figure 2</figref>, indicated by \"forty-node level flight\", \"sixty-node level flight\", \"ninety-node level flight\" and \"one hundred and fifty-node level flight\"). In other words, each macrocategory MC represents a corresponding class of manoeuvres, i.e. a corresponding flight regime.</p><p><span class=\"paragraph-number\">[0008]   </span>That being said, the method described in the <patcit dnum=\"EP20425059\" dnum-type=\"L\">European Patent Application No. 20425059.1</patcit> envisages acquiring a data structure including a plurality of temporal series of values of quantities relative to a flight of the aircraft, and subsequently performing, for each instant of time of a succession of instants of time, the steps of: for each temporal duration among a plurality of predetermined temporal durations, selecting a corresponding subset of the data structure having a temporal extent equal to the temporal duration and centred as a function of the instant of time; from each selected subset of the data structure, extracting a corresponding feature vector; on the basis of the feature vectors, generating a corresponding input macrovector, alternatively by aggregation of the feature vectors or by performing classifications of the feature vectors, in order to generate input prediction vectors (each of which is indicative, for each macrocategory, of a corresponding probability that, in said instant of time of the succession of instants of time, the aircraft was performing a manoeuvre belonging to said macrocategory) and subsequent aggregation of the input prediction vectors. The method further envisages to perform, for each instant of time of the succession of instants of time, the steps of: applying to the input macrovector an output classifier, which is configured to generate a corresponding output vector including, for each macrocategory, a corresponding estimate of the probability that, in the aforementioned instant of time of the succession of instants of time, the aircraft was performing a manoeuvre belonging to this macrocategory; on the basis of the output vector, detecting the macrocategory to which the manoeuvre performed by the aircraft in the aforementioned instant of time of the succession of instants of time belongs.</p><p><span class=\"paragraph-number\">[0009]   </span>In more detail, the method described in the aforementioned <patcit dnum=\"EP20425059\" dnum-type=\"L\">European patent application No. 20425059.1</patcit> requires a training a plurality of classifiers in a supervised manner. Such training requires having a training data structure that stores the temporal series (understood as successions of samples associated with corresponding temporal instants) formed by the values of the primary quantities detected by the helicopter monitoring systems during test flights; furthermore, it is necessary for pilots to label the test manoeuvres performed during test flights, so that the training data structure stores, for each test manoeuvre, the macrocategory to which the test manoeuvre belongs. In this way, the training data structure is formed by a plurality of portions, referred to as data groups, each of which is associated with a corresponding macrocategory; furthermore, these portions may possibly be interspersed with portions referring to unlabelled periods of time, i.e. periods of time in which the pilots did not report performing manoeuvres. For example, <figref>Figure 1B</figref> show a first and a second time interval T1, T2, wherein respectively a first and a second test manoeuvre M1, M2 of a test flight of the helicopter 1 are verified, which are reported by the pilot, belong to corresponding macrocategories (possibly, to a same macrocategory) and correspond to the data groups denoted respectively with DG1 and DG2; furthermore, in <figref>Figure 1B</figref> three periods of time are denoted by NMP1, NMP2, NMP3 respectively, which are spaced with respect to the first and second time interval T1, T2, wherein no manoeuvres are reported by the pilot; in other words, the periods of time NMP1, NMP2, NMP3 are unlabelled periods.</p><p><span class=\"paragraph-number\">[0010]   </span>The training of the classifiers is thus carried out, in a supervised manner, on the basis of the training data structure and is a function of the macrocategories reported by the pilots during test flights (also known as load survey flights).</p><p><span class=\"paragraph-number\">[0011]   </span>The method described in the aforementioned <patcit dnum=\"EP204250591A\">European Patent Application No. 204250591</patcit> therefore allows the macrocategories to which the manoeuvres performed by an aircraft belong to be detected with high precision, however it is based on the aforementioned feature extraction; consequently, the method is not very dependent on the actual waveforms of the primary quantities, which, in some situations, can lead to a reduction in the accuracy of the detection.</p><p><span class=\"paragraph-number\">[0012]   </span>The document \"<nplcit npl-type=\"s\">Airborne sensor data-based unsupervised recursive identification for UAV flight phases\", IEEE SENSORS JOURNAL, vol.20, no.18, September 15, 2020, of Benkuan Wang</nplcit> et al. discloses a Gaussian Mixture Model (GMM) clustering to identify flight phases. Furthermore, in order to reduce the identification errors caused by the fluctuations of the flight data, the flight data are preprocessed to achieve data smoothing.</p><p><span class=\"paragraph-number\">[0013]   </span>The document \"<nplcit npl-type=\"s\">Unsupervised flight phase recognition with flight data clustering based on GMM\", 2020 IEEE International Instrumentation and Measurement Technology Conference, 25 May 2020, pages 1-6, of Datong Liu</nplcit> et al. discloses a flight phase recognition method based on Gaussian Mixture Model (GMM). Furthermore, in order to solve the problem of different parameter lengths, the cubic spline interpolation is used.</p><p><span class=\"paragraph-number\">[0014]   </span><patcit dnum=\"CN112257152A\">CN 112 257 152A</patcit> discloses a method for identifying flight phases based on aircraft data, which leverages a threshold-based approach and provides for a density-based spatial clustering of applications with noise (DBSCAN) to fix misclassifications.</p><p><span class=\"paragraph-number\">[0015]   </span><patcit dnum=\"US20110288836A\">US 2011/0288836</patcit> discloses detecting anomalies in an aero-engine; the anomaly detection is achieved by comparing the estimated singularities (zeros and poles) of a transfer function (in the Laplace domain) of the considered regime instance and of a reference function.</p><p><span class=\"paragraph-number\">[0016]   </span>Aim of the present invention is to provide a method for detecting flight regimes, which overcomes at least in part the drawbacks of the prior art.</p><p><span class=\"paragraph-number\">[0017]   </span>According to the present invention, there are provided a method and a system for detecting flight regimes, as defined in the appended Claims.</p><p><span class=\"paragraph-number\">[0018]   </span>To better understand the present invention preferred embodiments thereof will be now described, for merely exemplary and non-limiting purposes, with reference to the appended drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1A</figref> schematically shows a view of an aircraft equipped with a monitoring system;</li><br/><li> <figref>Figure 1B</figref> shows examples of trends over time of values of quantities acquired through monitoring systems;</li><br/><li> <figref>Figure 2</figref> shows a block diagram which exemplifies a possible subdivision into macrocategories of a set of manoeuvres that can be executed by an aircraft;</li><br/><li> <figref>Figures 3</figref> and <figref>11</figref> show block diagrams relative to operations according to the present method;</li><br/><li> <figref>Figures 4</figref>, <figref>6</figref>, <figref>10</figref> and <figref>12</figref> show block diagrams of data structures acquired according to the present method;</li><br/><li> <figref>Figure 5</figref> shows a Cartesian graph on which a plurality of samples and an approximating function are arranged;</li><br/><li> <figref>Figure 7</figref> shows examples of temporal trends of a plurality of functions;</li><br/><li> <figref>Figure 8</figref> shows trends over time of signals, before and after the execution of registration operations; and</li><br/><li> <figref>Figure 9</figref> shows examples of temporal trends of a plurality of functions deriving from the execution of registration operations of the functions shown in <figref>Figure 7</figref>.</li></ul></p><p><span class=\"paragraph-number\">[0019]   </span>Purely by way of example, the present method is now described with reference to the helicopter 1; moreover, it is assumed that the monitoring system 2 allows to monitor a number NQ of primary quantities; purely by way of example, it is assumed NQ=5, unless otherwise specified. Furthermore, it is assumed that the number of possible flight regimes to be detected is equal to NUM_REG (for example, NUM_REG = 19).</p><p><span class=\"paragraph-number\">[0020]   </span>That being said, for each of the aforementioned flight regimes, the operations shown in <figref>Figure 3</figref> are performed, which refer, by way of example, to a generic m-th flight regime.</p><p><span class=\"paragraph-number\">[0021]   </span>In detail, the helicopter 1 performs (block 100) a number equal to Ninst (for example, Ninst = 39) of manoeuvres belonging to the m-th flight regime; during the execution of each of these manoeuvres, the monitoring system 2 acquires (block 102), for each primary quantity, a corresponding series of samples, which includes a number of samples Nsmax (for example, Nsmax=350). Without any loss of generality, for the sake of simplicity it is assumed that the temporal series of samples are acquired at the same sampling rate and aligned over time, i.e. in a manner that, at each sampling time, corresponding samples of all primary quantities are acquired.</p><p><span class=\"paragraph-number\">[0022]   </span>For example, referring to the i-th primary quantity (with i varying between 1 and NQ) and to the j-th manoeuvre (with j varying between 1 and Ninst), the monitoring system 2 acquires a corresponding series of samples s<sub>ij</sub>[n], with n integer ranging between 1 and Nsmax.</p><p><span class=\"paragraph-number\">[0023]   </span>In practice, each manoeuvre belonging to the m-th flight regime represents an instance of the m-th flight regime, which is associated to a corresponding training data matrix TFDM[j,m], whose columns are formed by the series of samples s<sub>1j</sub>[n] - s<sub>NQj</sub>[n] . Consequently, the execution of the Ninst manoeuvres belonging to the m-th flight regime allows to store (block 104, <figref>Figure 3</figref>) a corresponding training data structure TFDS[m], shown qualitatively in <figref>Figure 4</figref>, wherein for simplicity's sake of visualisation Ninst=3 has been assumed (in addition to, as previously mentioned, NQ=5). In the following it is assumed, for simplicity's sake, that the training data structures TFDS[m] are stored in a computer 19 (shown in <figref>Figure 1A</figref>), which can be coupled to the monitoring system 2.</p><p><span class=\"paragraph-number\">[0024]   </span>Subsequently, for each of the aforementioned flight regimes, for each series of samples s<sub>ij</sub>[n] of each training data matrix TFDM[j,m] of the corresponding training data structure TFDS[m], a so-called smoothing operation (block 106, <figref>Figure 3</figref>) is performed, as described below; purely by way of example, it is assumed that the smoothing operation is carried out by the computer 19.</p><p><span class=\"paragraph-number\">[0025]   </span>In detail, considering each series of samples s<sub>ij</sub>[n] of the training data structure TFDS[m] relative to the m-th flight regime, the computer 19 determines, in a per se known manner, a corresponding approximating function F<sub>ij</sub>(t) of time-continuous type.</p><p><span class=\"paragraph-number\">[0026]   </span>In more detail, the approximating function F<sub>ij</sub>(t) can be defined as a linear combination of a series of base functions (also known briefly as bases), which define a corresponding Hilbert space; the approximating function F<sub>ij</sub>(t) thus corresponds to a point in Hilbert space. Furthermore, the approximating function F<sub>ij</sub>(t) is not bound to pass through the samples of the respective series s<sub>ij</sub>[n] and has a smoother trend than the samples of the respective series s<sub>ij</sub>[n] .</p><p><span class=\"paragraph-number\">[0027]   </span>Even in more detail, assuming that a number K of base functions ϕ<sub>k</sub>(t) is adopted, the smoothing operation allows to determine a corresponding set of coefficients Ck<sub>k,ij</sub> so that it results in: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 47mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010492100&ekey=1810&cc=EP&producerName=imgb0001.tif&width=47mm&height=15mm\"/></maths></p><p><span class=\"paragraph-number\">[0028]   </span>Purely by way of example, the base functions ϕ<sub>k</sub>(t) may be formed by Fourier bases (i.e., sine or cosine functions) or by polynomials or splines; in such cases, a so-called basis smoother is implemented. Alternatively, the base functions ϕ<sub>k</sub>(t) may be formed by so-called kernels, i.e., by non-linear functions, in which case a so-called \"kernel smoother\" is implemented.</p><p><span class=\"paragraph-number\">[0029]   </span>Without any loss of generality, in the present description it is assumed that, for each series of samples s<sub>ij</sub>[n] of the training data structure TFDS[m], the computer 19 performs a so-called \"kernel nearest neighbour smoothing\", i.e., kernels are adopted that perform non-linear operations on corresponding subsets of adjacent samples of each series of samples s<sub>ij</sub>[n]. Consequently, in each point of the approximating function F<sub>ij</sub>(t), it occurs that the corresponding value of the approximating function F<sub>ij</sub>(t) depends on the samples of the series s<sub>ij</sub>[n] surrounding this point.</p><p><span class=\"paragraph-number\">[0030]   </span>An example of the relationship present between a generic series of samples s<sub>ij</sub>[n] and the corresponding approximating function F<sub>ij</sub>(t) is shown in <figref>Figure 5</figref>, wherein the samples of the series s<sub>ij</sub>[n] follow one another temporally at a rate equal to the aforementioned sampling rate (denoted by f<sub>c</sub>).</p><p><span class=\"paragraph-number\">[0031]   </span>In practice, since the computer 19 has determined, for each series of samples s<sub>ij</sub>[n] of the training data structure TFDS[m] relative to the m-th flight regime, the corresponding set of coefficients C<sub>k,ij</sub>, the computer 19 is able to determine the value assumed by the corresponding approximating function F<sub>ij</sub>(t) at any temporal instant. In other words, the computer 19 has performed a functional analysis, i.e. it has reconstructed, from the available samples, the mathematical function of the process underlying these samples.</p><p><span class=\"paragraph-number\">[0032]   </span>Furthermore, the smoothing operation includes calculating, for each sample of the series s<sub>ij</sub>[n], a corresponding sample of a series s'<sub>ij</sub>[n], which is referred to in the following as the smoothed series s'<sub>ij</sub>[n].</p><p><span class=\"paragraph-number\">[0033]   </span>In detail, for each sample of the series s<sub>ij</sub>[n], the corresponding sample of the smoothed series s'<sub>ij</sub>[n] is equal to the corresponding value of the corresponding approximating function F<sub>ij</sub>(t), as shown for example in <figref>Figure 5</figref>. In other words, referring to the case wherein n=n0, and thus referring to the sample s<sub>ij</sub>[n0] of the series of samples s<sub>ij</sub>[n], the corresponding sample s'<sub>ij</sub>[n0] of the smoothed series s'<sub>ij</sub>[n] is equal to the value of the approximating function F<sub>ij</sub>(t) relative to n0*1/f<sub>c</sub>.</p><p><span class=\"paragraph-number\">[0034]   </span>At the end of the operations referred to in block 106, the computer 19 has therefore, for each primary quantity (therefore, for each value of the index i), a corresponding plurality of smoothed series s'<sub>ij</sub>[n], as well as a corresponding plurality of sets of coefficients C<sub>k,ij</sub>, which define the approximating functions F<sub>ij</sub>(t) relative to the aforementioned smoothed series s'<sub>ij</sub>[n]. Consequently, the computer 19 stores, for each manoeuvre belonging to the m-th flight regime, a corresponding smoothed training data matrix TFDM' [j,m], whose columns are formed by the smoothed series s'<sub>1j</sub>[n] - s'<sub>NQj</sub>[n]; moreover, relative to the m-th flight regime, the computer 19 stores a corresponding smoothed training data structure TFDS' [m], which is formed by a number equal to Ninst of smoothed training data matrices TFDM' [j,m], as shown qualitatively in <figref>Figure 6</figref>, in which the associations present between each smoothed series s'<sub>ij</sub>[n] and the corresponding approximating function F<sub>ij</sub>(t) (and therefore the corresponding set of coefficients C<sub>k,ij</sub>) are also shown.</p><p><span class=\"paragraph-number\">[0035]   </span>For example, <figref>Figure 7</figref> shows examples (in number equal to Ninst) of trends of the approximating functions F<sub>ij</sub>(t) (with fixed i and with j=1, ..., Ninst) relating to the i-th primary quantity and to the execution of manoeuvres belonging to the m-th regime.</p><p><span class=\"paragraph-number\">[0036]   </span>Then, for each primary quantity, the computer 19 performs (block 108) a so-called shift-registration operation of the approximating functions F<sub>ij</sub>(t) relative to the primary quantity.</p><p><span class=\"paragraph-number\">[0037]   </span>In particular, considering a generic i-th primary quantity, the computer 19 processes in a per se known manner the corresponding approximating functions F<sub>ij</sub>(t) (with fixed i and j=1, ..., Ninst), so as to generate a corresponding set formed by a number equal to Ninst of shifted approximating functions F*<sub>ij</sub>(t), which have profiles that are more aligned with each other than the profiles of the approximating functions F<sub>ij</sub>(t) from which they derive.</p><p><span class=\"paragraph-number\">[0038]   </span>In more detail, for each primary quantity, it is verified that, starting from each approximating function F<sub>ij</sub>(t), a corresponding shifted approximating function F*<sub>ij</sub>(t) is generated, which is in fact shifted over time with respect to the corresponding approximating function F<sub>ij</sub>(t), so that the shifted approximating functions F*<sub>ij</sub>(t) have forms (trends over time) that are overall more superimposable between them than what happens in the case of the approximating functions F<sub>ij</sub>(t).</p><p><span class=\"paragraph-number\">[0039]   </span>In general, and in a per se known manner, the registration may be of the so-called landmark-based type, therefore based on the possibility of having a reference curve (known as a \"template\") of which the temporal instants at which so-called fiducial points occur are known a priori; in this case, the registration aims at aligning the fiducial points of the functions to the fiducial points of the curve of reference. Alternatively, and still by way of example, the registration may be of the so-called continuous (or simple) type, in which case no information on the form of the functions to be registered is known a priori; consequently, points common to the approximating functions F<sub>ij</sub>(t) are initially sought, on the basis of which the shifts are then performed. Purely by way of example, <figref>Figure 8</figref> shows examples of two signals, denoted by S1 and S2 respectively, which undergo a registration operation of the type based on points of reference, and in particular on the basis of a template denoted by T, with the consequent generation of corresponding shifted signals denoted by S1' and S2', which are respectively delayed with respect to the signal S1 by a time Δ1 and in advance with respect to the signal S2 by a time Δ2.</p><p><span class=\"paragraph-number\">[0040]   </span>By way of example, in the present case it is assumed that the registration, in addition to being of the shift type, is of the so-called continuous type, i.e. without resorting to templates.</p><p><span class=\"paragraph-number\">[0041]   </span><figref>Figure 9</figref> shows examples of shifted approximating functions F*<sub>ij</sub>(t) that can be obtained by performing shift registration operations of the approximating functions F<sub>ij</sub>(t) shown in <figref>Figure 7</figref>.</p><p><span class=\"paragraph-number\">[0042]   </span>The registration operations thus make it possible to thus determine, for each approximating function F<sub>ij</sub>(t), the phase shift (this is a time, hereafter denoted by Δ<sub>ij</sub>) between the approximating function F<sub>ij</sub>(t) and the corresponding shifted approximating function F*<sub>ij</sub>(t), which are defined by the same set of coefficients C<sub>k,ij</sub>, as well as by the same base functions, since they differ from each other only in a shift over time.</p><p><span class=\"paragraph-number\">[0043]   </span>Then, the computer 19 determines (block 110, <figref>Figure 3</figref>), for each smoothed series s'<sub>ij</sub>[n] of the smoothed training data structure TFDS' [m] relative to the m-th flight regime, a corresponding processed series of samples s\"<sub>ij</sub>[n], based on the corresponding phase shift Δ<sub>ij</sub>; in particular, the processed series of samples s\"<sub>ij</sub>[n] is obtained by shifting over time the smoothed series s\"<sub>ij</sub>[n] of the same phase shift Δ<sub>ij</sub> present between the corresponding approximating function F<sub>ij</sub>(t) and the corresponding shifted approximating function F*<sub>ij</sub>(t). The processed series of samples s\"<sub>ij</sub>[n] is in any case formed by a number of samples equal to Nsmax; moreover, the shift over time may imply that some of the samples of the smoothed series s'<sub>ij</sub>[n] are removed (because they are shifted outside the considered temporal interval) and may imply \"zero padding\" operations of the processed series of samples s\"<sub>ij</sub>[n], in order to guarantee that its number of samples is in any case equal to Nsmax.</p><p><span class=\"paragraph-number\">[0044]   </span>Each processed series of samples s\"<sub>ij</sub>[n] is associated with the same set of coefficients C<sub>k,ij</sub> to which the corresponding smoothed series s'<sub>ij</sub>[n] is associated, and thus also the corresponding series of sample s<sub>ij</sub>[n], these associations being stored by the computer 19.</p><p><span class=\"paragraph-number\">[0045]   </span>The operations referred to in blocks 106-110 allow to determine, for each series of samples s<sub>ij</sub>[n] of the training data structure TFDS[m] relative to the m-th flight regime, a corresponding processed series of samples s\"<sub>ij</sub>[n] . Consequently, the computer 19 stores, for each training data matrix TFDM[j,m], a corresponding processed training data matrix TFDM\"[j,m], which represents a so-called \"clean\" version of the corresponding training data matrix TFDM[j,m] and is associated with the aforementioned m-th flight regime, this association being stored by the computer 19. Furthermore, each processed training data matrix TFDM\"[j,m] is associated with a corresponding group of sets of coefficients C<sub>k,ij</sub>, which includes the sets of coefficients C<sub>k,ij</sub> to which the processed series of samples s\"<sub>ij</sub>[n] forming the processed training data matrix TFDM\"[j,m] are respectively associated, these associations being stored by the computer 19 and qualitatively represented in <figref>Figure 10</figref>.</p><p><span class=\"paragraph-number\">[0046]   </span>As shown qualitatively again in <figref>Figure 10</figref>, the processed training data matrices TFDM\"[j,m] form a processed training data structure TFDS\"[m], which is still associated with the m-th flight regime, this association being stored by the computer 19.</p><p><span class=\"paragraph-number\">[0047]   </span>Since the operations shown in <figref>Figure 3</figref> are repeated, as previously mentioned, for each of the flight regimes, the computer 19 has at its disposal a number equal to Ntot = Ninst * NUM_REG of processed training data matrices TFDM\"[j,m], each of which is associated with a corresponding flight regime.</p><p><span class=\"paragraph-number\">[0048]   </span>In general, the operation of registering the approximating functions F<sub>ij</sub>(t) and the subsequent generation of the processed series of samples s\"<sub>ij</sub>[n] are in any case optional; in other words, the operations which are described below with reference to the processed series of samples s\"<sub>ij</sub>[n] can be performed on the smoothed series s'<sub>ij</sub>[n]. However, the operation of registering the approximating functions F<sub>ij</sub>(t) and the subsequent generation of the processed series of samples s\"<sub>ij</sub>[n] allow to emphasise the differences between the forms of the approximating functions F<sub>ij</sub>(t), and thus between the smoothed series s'<sub>ij</sub>[n], due to real structural changes, reducing the impact, on the detection method, of the differences due to mere temporal shifts, for example attributable to different instants of start of sample acquisition. The registration therefore allows to improve the accuracy of the detection of flight regimes.</p><p><span class=\"paragraph-number\">[0049]   </span>That being said, as shown qualitatively in <figref>Figure 11</figref>, the computer 19 trains (block 200) a classifier, which in the following is assumed to be of the so-called \"fuzzy C-means\" type; the training is performed on the basis of the processed training data matrices TFDM\"[j,m], which as said are in a number equal to Ntot, as well as on the basis of the groups of sets of coefficients C<sub>k,ij</sub> associated with the processed training data matrices TFDM\"[j,m]. In practice, each processed training data matrix TFDM\"[j,m] represents, together with the corresponding group of sets of coefficients C<sub>k,ij</sub> (which are referred to the aforementioned base functions ϕ<sub>k</sub>(t)), a so-called observation.</p><p><span class=\"paragraph-number\">[0050]   </span>In more detail, the training of the classifier provides, in a per se known manner, for identifying a number of clusters equal to the number NUM_REG of flight regimes, by iteratively minimising a cost function that can be expressed as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 112mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010492100&ekey=1810&cc=EP&producerName=imgb0002.tif&width=112mm&height=6mm\"/></maths></p><p> wherein: x<sub>o</sub> represents the result of a so-called embedding of the o-th observation; U<sub>c</sub> represents the result of the embedding of the current estimate of the c-th centroid (with c=1, ..., NUM_REG); d represents the so-called \"degree of fuzzyness\"; µ<sub>co</sub> represents the current membership degree of the c-th cluster of the o-th observation; the operation denoted by ∥(·)∥* represents any norm (e.g., the so-called norm L<sup>2</sup>), which is calculated on the difference between the aforementioned embedding results.</p><p><span class=\"paragraph-number\">[0051]   </span>In addition, at each iteration, either the membership degrees and the centroids (equivalently, the relative embeddings) are updated in a per se known manner, respectively by means of the equations: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 68mm; height: 21mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010492100&ekey=1810&cc=EP&producerName=imgb0003.tif&width=68mm&height=21mm\"/></maths></p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 56mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000010492100&ekey=1810&cc=EP&producerName=imgb0004.tif&width=56mm&height=15mm\"/></maths></p><p><span class=\"paragraph-number\">[0052]   </span>In more detail, the embedding of any observation envisages calculating a quantity (e.g., a vector one) that has a dimensionality lower than the dimensionality of the corresponding processed training data matrix TFDM\"[j,m] and is a function of the corresponding processed series of samples s\"<sub>ij</sub>[n] and of the temporal trends of the corresponding approximating functions F<sub>ij</sub>(t). In other words, embedding is of the time-dependent type, since it depends not only on the values of the processed series of samples s\"<sub>ij</sub>[n], but also on the forms of the corresponding approximating functions F<sub>ij</sub>(t).</p><p><span class=\"paragraph-number\">[0053]   </span>For example, embedding an observation relative to any processed training data matrix TFDM\"[j,m] may involve calculating a vector having a number of elements equal to NQ, wherein the i-th element (with i = 1, ..., NQ) is a function of the processed series of samples s\"<sub>ij</sub>[n] (with fixed j) and of the corresponding set of coefficients C<sub>k,ij</sub> (with fixed j), so that this element depends on the form over time of the corresponding approximating function F<sub>ij</sub>(t).</p><p><span class=\"paragraph-number\">[0054]   </span>That being said, the embedding of the centroids is performed in the same way as the embedding of observations. In this regard, it is known that each centroid is equal, for example, to the average of the observations weighted by the respective membership degrees, therefore each centroid can be associated with a corresponding matrix, which is equal to a weighted average of the processed training data matrices TFDM\"[j,m] relative to the observations; on the basis of the matrix associated to the centroid, it is also possible to calculate a corresponding group of sets of coefficients, by performing \"kernel nearest neighbour smoothing\" operations, such coefficients being then also referred to the aforementioned base functions ϕ<sub>k</sub>(t), and thus to the aforementioned kernels.</p><p><span class=\"paragraph-number\">[0055]   </span>After training the classifier, the computer 19 stores (block 201, <figref>Figure 11</figref>) the associations present between the clusters (in a number equal to NUM_REG) and the corresponding flight regimes. In detail, each cluster is associated with the flight regime that is the most represented within the cluster, in the hypothesis that each observation is assigned to the cluster with respect to which it has the highest membership degree; in other words, referring to a generic cluster and assuming that, among the observations assigned to this cluster, most of them are related to a given flight regime among the possible flight regimes (the latter being in a number equal to NUM_REG), the computer 19 stores the association between this cluster and the given flight regime. In this regard, ideally each cluster includes observations related only to the corresponding flight regime.</p><p><span class=\"paragraph-number\">[0056]   </span>Subsequently, the computer 19 is able to detect unknown flight regimes, as described below.</p><p><span class=\"paragraph-number\">[0057]   </span>In detail, the helicopter 1 performs an unknown flight, i.e. a flight in which the performed manoeuvres are not known. The unknown flight is formed by a succession of unknown flight segments so that, for each unknown flight segment, the monitoring system 2 acquires (block 202, <figref>Figure 11</figref>), for each primary quantity, a corresponding series of samples formed by a number of samples still equal to Nsmax. For example, referring to the i-th primary quantity (with i varying between 1 and NQ), the monitoring system 2 acquires a corresponding series of samples sx<sub>i</sub>[n], which is referred to below as the series of unknown samples sx<sub>i</sub>[n].</p><p><span class=\"paragraph-number\">[0058]   </span>Consequently, for each unknown flight segment, the computer 19 acquires a corresponding matrix of unknown data TFDMx, whose columns are formed by the series of unknown samples sx<sub>1</sub>[n] - sx<sub>NQ</sub>[n], as shown qualitatively in <figref>Figure 12</figref>.</p><p><span class=\"paragraph-number\">[0059]   </span>Subsequently, for each of the aforementioned unknown flight segments, the computer 19 performs (block 204, <figref>Figure 11</figref>) a smoothing operation of each of the series of unknown samples sxi[n] of the corresponding matrix of unknown data TFDMx, in the same manner as described with reference to block 106.</p><p><span class=\"paragraph-number\">[0060]   </span>In more detail, it is assumed that the computer 19 still performs a \"kernel nearest neighbour smoothing\"; moreover, for each series of unknown samples sx<sub>i</sub>[n] a corresponding unknown smoothed series sx'<sub>i</sub>[n] and a corresponding unknown approximating function Fxi(t), which is defined by a corresponding set of coefficients Cx<sub>k,i</sub>, as well as by the kernels forming the base functions ϕ<sub>k</sub>(t), are determined. In the following reference is made to the set of coefficients Cx<sub>k,i</sub> as the set of unknown coefficients Cx<sub>k,i</sub>.</p><p><span class=\"paragraph-number\">[0061]   </span>At the end of the operations referred to in block 204, the computer 19 stores a corresponding matrix of smoothed unknown data TFDMx', whose columns are formed by the smoothed unknown series sx'<sub>1</sub>[n]-sx'<sub>NQ</sub>[n], as shown again in <figref>Figure 12</figref>, in which the associations present between each smoothed unknown series sx'<sub>i</sub>[n] and the corresponding set of unknown coefficients Cx<sub>k,i</sub> are also shown. In practice, the matrix of smoothed unknown data TFDMx' and the corresponding set of unknown coefficients Cx<sub>k,i</sub> represent an unknown observation.</p><p><span class=\"paragraph-number\">[0062]   </span>Then, for each unknown flight segment, the computer 19 applies (block 206, <figref>Figure 11</figref>) the classifier to the unknown observation, i.e., to the matrix of smoothed unknown data TFDMx' and to the corresponding group of sets of unknown coefficients with Cx<sub>k,i</sub>, so as to obtain a corresponding probability vector formed by a number of elements equal to the number of clusters, and thus equal to the number of flight regimes NUM_REG; each element of the probability vector is associated with a corresponding cluster, and thus also with the flight regime associated with the cluster, and is equal to the probability (as estimated by the classifier) that the unknown observation belongs to the cluster, and thus refers to the flight regime associated with that cluster. The application of the classifier to the unknown observation is also a function of the aforementioned base functions ϕ<sub>k</sub>(t), and thus of the aforementioned kernels. In practice, each element of the probability vector is equal to the distance of the unknown observation from the corresponding centroid, this distance being calculated on the basis of the results of the corresponding embeddings and of the aforementioned norm ∥(·)∥*.</p><p><span class=\"paragraph-number\">[0063]   </span>Subsequently, the computer 19 identifies (block 208) the flight regime in which the helicopter 1 operated relative to the unknown flight segment to which the unknown observation refers, by selecting the flight regime associated with the cluster corresponding to the element of the probability vector having the maximum value.</p><p><span class=\"paragraph-number\">[0064]   </span>The detections of the flight regimes can then be used reliably to estimate the state of fatigue and therefore the residual fatigue life of the components of an aircraft; consequently, such detections can be used, for example, to optimise the maintenance operations of a fleet of aircrafts, respecting the safety requirements.</p><p><span class=\"paragraph-number\">[0065]   </span>The advantages that the present method allows to obtain emerge clearly from the previous description.</p><p><span class=\"paragraph-number\">[0066]   </span>In particular, this method allows to detect with precision the flight regimes, without the need to resort to classifiers trained in a supervised manner and in a sensitive way to the temporal evolution of the primary quantities, overcoming the reduction in precision that can occur in the case of methods based on the extraction of features, as well as due to the discrepancy between the time-continuous nature of the temporal evolution of the primary quantities during the flights and the time-discrete nature of the corresponding series of samples.</p><p><span class=\"paragraph-number\">[0067]   </span>In addition, thanks to the use of a fuzzy classifier, the occurrence of any mixed flight regimes (i.e. flight regimes other than those used during training) does not affect the correctness of the detection.</p><p><span class=\"paragraph-number\">[0068]   </span>Clearly, changes may be made to the method and system described and shown herein without, however, departing from the scope of the present invention, as defined in the accompanying claims.</p><p><span class=\"paragraph-number\">[0069]   </span>For example, smoothing may be of a different type than described. Furthermore, as previously mentioned, the operations of registration and generation of the processed sample series can be omitted.</p><p><span class=\"paragraph-number\">[0070]   </span>The series of samples s<sub>ij</sub>[n] can be formed by different numbers of respective samples and/or by samples acquired with different sampling frequencies, in which case the series of samples can be further processed in order to standardise their lengths.</p><p><span class=\"paragraph-number\">[0071]   </span>In order to generate the data for training the classifier, flights of several aircrafts (preferably of the same type), equipped with respective monitoring systems adapted to acquire samples of the same quantities, may be used in addition to several flights of the same aircraft. Similarly, the unknown flight may be performed by an aircraft other than the aircraft(s) used to train the classifier.</p><p><span class=\"paragraph-number\">[0072]   </span>Finally, it is possible to use a non-fuzzy classifier, however this entails the loss of the benefits connected with this feature, and in particular a reduction in the detection capacity in the presence of intermediate flight regimes compared to those adopted in the training step. In addition, in the case of the fuzzy classifier, it may be different from a C-means classifier; for example, the classifier may be formed by a DBSCAN or hierarchical type clusteriser.</p>",
            "CLMS": "(EP4163750)<br/><p>1. Method implemented by computer (19) for detecting flight regimes of an aircraft (1) equipped with a monitoring system (2) configured to acquire samples of a number of quantities relating to a flight of the aircraft, comprising the steps of:<br/> - acquiring (202) at least one matrix (TFDMx) including, for each of the quantities, a corresponding series of samples (sx<sub>1</sub>[n] - sx<sub>NQ</sub>[n]) acquired by the monitoring system (2) during the flight of the aircraft;<br/> - performing (204) smoothing operations of each series of samples (sx<sub>1</sub>[n]-sx<sub>NQ</sub>[n]) of the matrix (TFDMx), sc as to generate a corresponding smoothed sample series (sx'<sub>1</sub>[n]-sx'<sub>NQ</sub>[n]) and so as to determine a corresponding time-continuous approximating function (Fxi(t)) defined by a respective set of coefficients (Cx<sub>k,i</sub>) and by a plurality of base functions (ϕ(t)), the smoothed sample series forming a smoothed matrix (TFDMx');<br/> - on the basis of the base functions (ϕ<sub>k</sub>(t)), applying (206) to the smoothed matrix (TFDMx') and to the corresponding sets of coefficients (Cx<sub>k,i</sub>) a classifier trained to generate, for each flight regime among a plurality of flight regimes, a corresponding estimate of the probability that the smoothed matrix (TFDMx') and the corresponding sets of coefficients (Cx<sub>k,i</sub>) belong to a cluster relative to said flight regime; and<br/> - identifying (208) a flight regime wherein the aircraft operated during said flight, based on the estimates generated by the classifier.</p><p>2. Method according to claim 1, wherein said classifier has been generated by performing the steps of, for each flight regime of said plurality of flight regimes:<br/> - for each time interval of a plurality of time intervals in which said aircraft (1) or one or more aircrafts other than said aircraft and equipped with respective monitoring systems have operated in the flight regime, acquiring (102) corresponding training matrices (TFDM[j,m]), each of which includes, for each of the quantities, a corresponding series of training samples (s<sub>ij</sub>[n]);<br/> - for each training matrix (TFDM[j,m]), performing (106) smoothing operations of each series of training samples (s<sub>ij</sub>[n]) of the training matrix (TFDM[j,m]) so as to generate a corresponding smoothed series of training samples (s'<sub>ij</sub>[n]) and so as to determine a corresponding time-continuous approximating function (F<sub>ij</sub>(t)) defined by a respective set of coefficients (C<sub>k,ij</sub>) and by said plurality of base functions ((ϕ<sub>k</sub>(t)), the smoothed series of training samples (s'<sub>ij</sub>[n]) forming a smoothed training matrix (TFDM' [j,m]);<br/> - for each smoothed training matrix (TFDM'[j,m]), determining (108,110), for each smoothed series of training samples (s'<sub>ij</sub>[n]) of the smoothed training matrix (TFDM' [j,m]), a corresponding processed series of training samples (s\"<sub>ij</sub>[n]), which is either equal to the smoothed series of training samples (s'<sub>ij</sub>[n]) or is equal to a temporal shift of the smoothed series of training samples (s'<sub>ij</sub>[n]), the processed series of training samples (s\"<sub>ij</sub>[n]) forming a corresponding processed training matrix (TFDM\"[j,m]);<br/>and wherein the classifier has further been generated by performing the step of:<br/> - training (200) the classifier on the basis of observations including, each, a corresponding processed training matrix (TFDM\"[j,m]) and the corresponding sets of coefficients (C<sub>k,ij</sub>), so as to identify, for each flight regime of said plurality of flight regimes, the centroid of the corresponding cluster.</p><p>3. Method according to claim 2, wherein the classifier has further been generated by performing the step of:<br/> for each of the quantities, performing (108) a shift registration procedure of the approximating functions (F<sub>ij</sub>(t)) relative to the smoothed series of training samples (s'<sub>ij</sub>[n]) relative to the quantity, so as to determine, for each of said approximating functions (F<sub>ij</sub>(t)), a corresponding shifted approximating function (F*<sub>ij</sub>(t)), which is temporally shifted with respect to the corresponding approximating function (F<sub>ij</sub>(t)) by a corresponding phase shift (Δ<sub>ij</sub>);<br/>and wherein, in each processed training matrix (TFDM\"[j,m]), each processed series of training samples (s\"<sub>ij</sub><br/>[n]) is obtained by shifting the corresponding smoothed series of training samples (s'<sub>ij</sub><br/>[n]) by a time equal to the phase shift (Δ<sub>ij</sub><br/>) present between the corresponding approximating function (F<sub>ij</sub><br/>(t)) and the corresponding shifted approximating function (F*<sub>ij</sub><br/>(t)).</p><p>4. Method according to claim 2 or 3, wherein said step of training (200) the classifier comprises determining, for each observation, respective degrees of membership to the clusters, said method comprising associating (201) to each cluster a corresponding flight regime among said plurality of flight regimes, as a function of the flight regimes to which the observations refer and of the degrees of membership to the clusters of the observations.</p><p>5. Method according to any one of the preceding claims, wherein said smoothing operations comprise performing a kernel nearest neighbour smoothing.</p><p>6. Method according to any one of the preceding claims, wherein the classifier is of the fuzzy type.</p><p>7. Method according to claim 6, wherein the classifier is a fuzzy C-means classifier.</p><p>8. Processing system comprising means configured to carry out the method according to any one of the preceding claims.</p><p>9. Computer program comprising instructions which, when the program is executed by a computer (19), cause the execution of the method according to any one of claims 1 to 7.</p><p>10. Computer medium readable by a computer (19), on which the computer program according to claim 9 is stored.</p>",
            "NPR": "2",
            "APID": "163256496",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64C-027/00<br/>B64D-045/00<br/>G05B-023/02",
            "ID": "104539134",
            "AB": "(EP4163750)<br/>Method implemented by computer for detecting flight regimes of an aircraft (1) equipped with a monitoring system (2) that acquires samples of quantities relative to the flight including: acquiring (202) an unknown matrix (TFDMx) including, for each quantity, a corresponding series of samples (sx1[n] - sxNQ[n]); performing (204) smoothing operations of each series of samples, so as to generate a corresponding series of smoothed samples (sx&apos;1[n]-sx&apos;NQ[n]) and determining a corresponding approximating function (Fxi(t)) defined by a respective series of coefficients (Cxk,i) and by a plurality of base functions (ϕk(t)), the smoothed series of samples forming a smoothed unknown matrix (TFDMx&apos;); on the basis of the base functions, applying (206) to the smoothed unknown matrix and to the corresponding sets of coefficients a classifier trained to generate, for each flight regime among a plurality of flight regimes, a corresponding estimate of the probability that the smoothed unknown matrix and the corresponding sets of coefficients belong to a cluster relative to the flight regime; identifying (208) a flight regime in which the aircraft operated, on the basis of the estimates generated by the classifier.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x7kp40rYkZzVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2021-10-11",
            "PA": "LEONARDO<br/>POLITECNICO DI MILANO",
            "PAAD": "(EP4163750)<br/>(PUB:EP-4163750B1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/>(PUB:EP-4163750A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/>NAME=Politecnico di Milano Piazza Leonardo da Vinci, 32 , CITY=20133 Milano (MI) , COUNTRY=IT , REG=101799951<br/><br/><br/>(WO202362519)<br/>(PUB:WO-2023/062519A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 ROMA , POSTCODE=00195 , COUNTRY=IT<br/>NAME=POLITECNICO DI MILANO Piazza Leonardo Da Vinci, 32 20133 MILANO (MI) , POSTCODE=20133 , COUNTRY=IT<br/><br/><br/>(KR20240113465)<br/>(PUB:KR-10-2024-0113465A-113)NAME=LEONARDO SPA  , COUNTRY=IT<br/><br/><br/>(CN118119905)<br/>(PUB:CN-118119905A-168)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "104539134",
            "TI": "Method and system for detecting flight regimes of an aircraft, on the basis of measurements acquired during an aircraft flight",
            "TECD": "Control<br/>Transport",
            "EPD": "2023-04-12",
            "ICLM": "(EP4163750)<br/><p>1. Method implemented by computer (19) for detecting flight regimes of an aircraft (1) equipped with a monitoring system (2) configured to acquire samples of a number of quantities relating to a flight of the aircraft, comprising the steps of: - acquiring (202) at least one matrix (TFDMx) including, for each of the quantities, a corresponding series of samples (sx1[n] - sxNQ[n]) acquired by the monitoring system (2) during the flight of the aircraft; - performing (204) smoothing operations of each series of samples (sx1[n]-sxNQ[n]) of the matrix (TFDMx), sc as to generate a corresponding smoothed sample series (sx'1[n]-sx'NQ[n]) and so as to determine a corresponding time-continuous approximating function (Fxi(t)) defined by a respective set of coefficients (Cxk,i) and by a plurality of base functions (ϕ(t)), the smoothed sample series forming a smoothed matrix (TFDMx'); - on the basis of the base functions (ϕk(t)), applying (206) to the smoothed matrix (TFDMx') and to the corresponding sets of coefficients (Cxk,i) a classifier trained to generate, for each flight regime among a plurality of flight regimes, a corresponding estimate of the probability that the smoothed matrix (TFDMx') and the corresponding sets of coefficients (Cxk,i) belong to a cluster relative to said flight regime; and - identifying (208) a flight regime wherein the aircraft operated during said flight, based on the estimates generated by the classifier.</p>",
            "CTN": "(EP4163750)<br/>XP011804923 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>XP033785704 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>CN112257152 92415818 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>US20110288836 6913551 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>EP204250591 none WHO=APPLICANT SELF=N<br/>US20110288836 6913551 WHO=APPLICANT SELF=N<br/>CN112257152 92415818 WHO=APPLICANT SELF=N<br/>EP4016221 100568507 WHO=APPLICANT SELF=Y<br/><br/>(WO202362519)<br/>XP011804923 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>XP033785704 none WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>CN112257152 92415818 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>US20110288836 6913551 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2025-04-11",
                    "XAP": "2022WO-IB59718",
                    "APD": "2022-10-11",
                    "APID": "163382619",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2023062519&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=IX7txtdG9hRV7mojNQd2ipNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2023/062519",
                            "KIND": "A1",
                            "XPN": "WO202362519",
                            "V_PNID": "WO-2023/062519A1-3",
                            "DATE": "2023-04-20",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCAndjIAwFIJbonVC+dywuLYLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=WO202362519&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=IX7txtdG9hRV7mojNQd2ipNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-10-11",
                            "XAP": "2024KR-7015634",
                            "APD": "2022-10-11",
                            "APID": "171308720",
                            "REG_LINK": "http://link.kipris.or.kr/link/main/KPAXML.jsp?APPLNO=1020247015634",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HwgOklpqgjUGOlnxAjy4xcRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "KR10-2024-0113465",
                                    "KIND": "A",
                                    "XPN": "KR20240113465",
                                    "V_PNID": "KR-10-2024-0113465A-113",
                                    "DATE": "2024-07-22",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aJxR8iNWnopysR92Rtkr7lq5LJ03xVJIETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=KR20240113465&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=HwgOklpqgjUGOlnxAjy4xcRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-10-11",
                            "XAP": "2022CN-80068326",
                            "APD": "2022-10-11",
                            "APID": "170375799",
                            "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=k7laxzQxzxLz%252F5fINSiEFJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CN118119905",
                                    "KIND": "A",
                                    "XPN": "CN118119905",
                                    "V_PNID": "CN-118119905A-168",
                                    "DATE": "2024-05-31",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=hXP7Q1+dwoRXIZbX7sUDv8k/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN118119905&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=k7laxzQxzxLz%252F5fINSiEFJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2041-10-11",
                    "XAP": "2021EP-0425046",
                    "APD": "2021-10-11",
                    "APID": "163256496",
                    "REG_LINK": "https://register.epo.org/application?number=EP21425046",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x7kp40rYkZzVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4163750",
                            "KIND": "B1",
                            "XPN": "EP4163750",
                            "V_PNID": "EP-4163750B1-8",
                            "DATE": "2024-01-31",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=VCVyqWEeIcDBvRShSaC0X6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4163750&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x7kp40rYkZzVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP4163750",
                            "KIND": "A1",
                            "XPN": "EP4163750",
                            "V_PNID": "EP-4163750A1-8",
                            "DATE": "2023-04-12",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=VCVyqWEeIcDBvRShSaC0X/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4163750&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x7kp40rYkZzVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4163750_B1",
            "EPRD": "2021-10-11",
            "PN": "EP4163750           B1 2024-01-31 [EP4163750]<br/>EP4163750           A1 2023-04-12 [EP4163750]<br/>WO2023/062519       A1 2023-04-20 [WO202362519]<br/>KR10-2024-0113465   A  2024-07-22 [KR20240113465]<br/>CN118119905         A  2024-05-31 [CN118119905]",
            "ADB": "(EP4163750)<br/><p>The registration operations thus make it possible to thus determine, for each approximating function Fij(t), the phase shift (this is a time, hereafter denoted by Δij) between the approximating function Fij(t) and the corresponding shifted approximating function F*ij(t), which are defined by the same set of coefficients Ck,ij, as well as by the same base functions, since they differ from each other only in a shift over time.</p><p>To this end, it is known to equip aircraft with monitoring systems adapted to detect the values of quantities relative to the flight; this makes it possible to acquire a large number of measurements of these quantities, which can be analysed to reconstruct the history of the manoeuvres carried out by the aircraft.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=5<br/>PNAAGE=20<br/>NBPA=1; <br/>ALLCT=6; SCT=0; NSCT=6; <br/>ALLCTG=1; SCTG=0; NSCTG=1; <br/>AFS=28; ACC=28; AMCC=5; <br/>IGEN=0.0; IORG=0.91; IRAD=0.95; <br/>IMPI=2.33; MACI=1.77; PASI=3.2; PAVI=3.81; ",
            "PTCC": "(EP4091945)<br/>CC=EP EED=2041-05-18 STATUS=GRANTED APID=160917772 APD=2021-05-18 XPN=EP4091945 PD=2022-11-23 PD=2023-09-06 EPD=2022-11-23 LPD=2023-09-06 PDG=2023-09-06 <br/>CC=CH EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/>CC=DE EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/>CC=FR EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/>CC=GB EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/>CC=IE EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/>CC=IT EED=2041-05-18 STATUS=GRANTED APID=160917772 XPN=EP4091945 PDG=2023-09-06 <br/><br/>(US20240228057)<br/>CC=US EED=2042-04-21 STATUS=PENDING APID=169636010 APD=2022-04-21 XPN=US20240228057 PD=2024-07-11 EPD=2024-07-11 LPD=2024-07-11 <br/><br/>(WO2022243764)<br/>CC=WO EED=2024-11-18 STATUS=PENDING APID=160921834 APD=2022-04-21 XPN=WO2022243764 PD=2022-11-24 EPD=2022-11-24 LPD=2022-11-24 <br/>CC=CN EED=2042-04-21 STATUS=PENDING APID=168980775 APD=2022-04-21 XPN=CN117730032 PD=2024-03-19 EPD=2024-03-19 LPD=2024-03-19 <br/>CC=KR EED=2042-04-21 STATUS=PENDING APID=168908137 APD=2022-04-21 XPN=KR20240032722 PD=2024-03-12 EPD=2024-03-12 LPD=2024-03-12 <br/>CC=US EED=2042-04-21 STATUS=PENDING APID=169636010 APD=2022-04-21 XPN=US20240228057 PD=2024-07-11 EPD=2024-07-11 LPD=2024-07-11 <br/><br/>(CN117730032)<br/>CC=CN EED=2042-04-21 STATUS=PENDING APID=168980775 APD=2022-04-21 XPN=CN117730032 PD=2024-03-19 EPD=2024-03-19 LPD=2024-03-19 <br/><br/>(KR20240032722)<br/>CC=KR EED=2042-04-21 STATUS=PENDING APID=168908137 APD=2022-04-21 XPN=KR20240032722 PD=2024-03-12 EPD=2024-03-12 LPD=2024-03-12 <br/>",
            "EPN": "EP4091945",
            "CTGN": "(WO2022243764)<br/>CN116049157B 104774508 WHO=EXAMINER SELF=N",
            "LAPD": "2022-04-21",
            "STDN": "",
            "NPN": "5",
            "DESC": "<p><h1>CROSS-REFERENCE TO RELATED APPLICATIONS</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This Patent application claims priority from European Patent Application No. 21425025.0 filed on May 18, 2021, the entire disclosure of which is incorporated herein by reference.</p><br/><p><h1>TECHNICAL FIELD OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates to a method and system for detecting anomalies relating to components of a transmission system of an aircraft, in particular a helicopter.</p><p><h1>STATE OF THE ART</h1></p><p><span class=\"paragraph-number\">[0003]   </span>As is well known, helicopters are extremely complex and vulnerable aircraft, since there is a transmission system between the engine(s) and the rotors, which includes critical components. Single malfunctions of any of these components may be extremely dangerous to the safety of the helicopter.</p><p><span class=\"paragraph-number\">[0004]   </span>In order to monitor the proper operation of a helicopter, so-called health and usage monitoring systems (HUMS) are known to be used. Typically, a HUMS system comprises a plurality of sensors (e.g. accelerometers), which are coupled to components of the transmission system and are adapted to monitor trends over time of corresponding physical quantities.</p><p><span class=\"paragraph-number\">[0005]   </span>Furthermore, monitoring methods are known which envisage extracting so-called synthetic indexes known as “health indexes” starting from the signals generated by the sensors, which can be analysed to detect, for example, the presence of cracks on gear teeth, wear on bearings, imbalances affecting drive shafts, etc.</p><p><span class=\"paragraph-number\">[0006]   </span>By way of example, <a href=\"#DRAWINGS\">FIG. <b>1</b></a> shows a transmission system <b>1</b>, which is mechanically interposed between one or more engines (not shown) and the rotors (main and tail, not shown) of a helicopter HC<sub>1 </sub>(not visible in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>; schematically shown in <a href=\"#DRAWINGS\">FIG. <b>4</b></a>) and includes a plurality of mechanical components, which comprise drive shafts, gears, bearings (not shown), etc. For the sake of simplicity, in <a href=\"#DRAWINGS\">FIG. <b>1</b></a> only a first and a second gear (indicated respectively with C<sub>1 </sub>and C<sub>2</sub>) are accompanied by reference marks, which are coupled to each other so as to form a gearbox arranged in proximity to the tail rotor and enclosed in a corresponding first external protective substructure <b>5</b> (shown only symbolically in <a href=\"#DRAWINGS\">FIG. <b>1</b></a> and also known as a box or casting); the rotation of the first and second gear C<sub>1</sub>, C<sub>2 </sub>with respect to the first external protective substructure <b>5</b>, and in particular the rotation of corresponding shafts integral with the first and second gear C<sub>1</sub>, C<sub>2 </sub>and extending through the first external protective substructure <b>5</b>, is permitted by the presence of a number (typically, four, i.e., two per gear) of bearings (not shown in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>) each mechanically interposed between the box and a corresponding shaft. In general, therefore, groups of mechanical components are arranged within corresponding external protective substructures, which allow, by means of appropriate bearings and openings, the coupling with mechanical components of other groups. For example, <a href=\"#DRAWINGS\">FIG. <b>1</b></a> shows (symbolically) a second external protective substructure <b>7</b>, which houses within it a corresponding portion of the transmission system <b>1</b>. Altogether, the external protective substructures form an external structure <b>9</b> of the transmission system <b>1</b>.</p><p><span class=\"paragraph-number\">[0007]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b></a> further shows (symbolically) a plurality of sensors A<sub>i </sub>(with i=1, . . . 13), which form a monitoring system MS, are accelerometers (e.g., of the uniaxial type) and are mechanically coupled to corresponding points of the transmission system <b>1</b>; in particular, each sensor A<sub>i </sub>is constrained to a corresponding point of the transmission system <b>1</b>, so as to generate a corresponding signal (referred to in the following as the primary signal) indicative of a corresponding quantity (for example, the acceleration along a respective axis), which in turn depends on the vibrations to which sensor A<sub>i </sub>is subjected. Primary signals are typically analogue signals.</p><p><span class=\"paragraph-number\">[0008]   </span>In more detail, each sensor A<sub>i </sub>is fixed to a corresponding point of the external structure <b>9</b> of the transmission system <b>1</b>. For example, the sensor A<sub>i </sub>is fixed to a point on the first external protective substructure <b>5</b>, so it is closer than all the other sensors to the aforementioned first and second gear C<sub>1</sub>, C<sub>2</sub>, as well as to the respective bearings. By way of example only, the sensors A<sub>2</sub>-A<sub>8</sub>, A<sub>12 </sub>and A<sub>13 </sub>are fixed to corresponding points of the second external protective substructure <b>7</b>, in proximity to corresponding mechanical components.</p><p><span class=\"paragraph-number\">[0009]   </span>The sensors may be arranged indifferently either on parts of the external structure <b>9</b> facing the mechanical components of the transmission system <b>1</b> or to the outside.</p><p><span class=\"paragraph-number\">[0010]   </span>That being said, each primary signal is indicative of the operation and integrity of one or more components of the transmission system <b>1</b>; in other words, the primary signal generated by each sensor A<sub>i </sub>is indicative of the operation of a corresponding subset of components of the transmission system <b>1</b>. Therefore, it is known to calculate, starting from the primary signal provided by each sensor A<sub>i</sub>, a plurality of health indexes relating to the components of the corresponding subset, by implementing a plurality of processing techniques. Furthermore, considering a single component, it can belong to several subsets associated with corresponding sensors A<sub>i</sub>, i.e. it is known to calculate health indexes relating to the same component on the basis of several primary signals, as explained below.</p><p><span class=\"paragraph-number\">[0011]   </span>In more detail, considering any primary signal (hereafter referred to as s<sub>i</sub>) generated by a sensor A<sub>i</sub>, it can be subjected to one or more processing techniques, which include digitising the primary signal s<sub>i</sub>, in order to generate corresponding health indexes.</p><p><span class=\"paragraph-number\">[0012]   </span>That said, as shown in <a href=\"#DRAWINGS\">FIG. <b>2</b></a>, the primary signal s<sub>i </sub>may be subjected to one or more preliminary processing steps, selected for example from:</p><p><ul type=\"none\"><ul type=\"none\"><li><span class=\"paragraph-number\">[0013]   </span> - a synchronous processing (block <b>100</b>), also known as time average processing, which is associated to a corresponding k-th component C<sub>k</sub>, is a function of the angular velocity of the component C<sub>k </sub>(detected by means of an appropriate dedicated sensor, not shown) and provides generating a respective pre-processed signal s′<sub>i,k</sub>, which is of digital type and is obtained by sampling the primary signal s<sub>i </sub>relating to a number Nrot of rotations of the component C<sub>k </sub>with a sampling frequency that is a multiple of the rotation frequency of the component C<sub>k</sub>, in order to acquire, for each rotation, a number NS of samples relating to corresponding angular positions of the component C<sub>k</sub>, and subsequently averaging, for each angular position, the corresponding samples (in number equal to Nrot), so that the pre-processed signal s′<sub>i,k </sub>includes a portion of the primary signal s<sub>i </sub>that is correlated with the angular velocity of the component C<sub>k</sub>;</li><br/><li><span class=\"paragraph-number\">[0014]   </span> - an envelope processing (block <b>200</b>), which is associated with a corresponding k-th component C<sub>k</sub>, is a function of the geometrical features of the k-th component C<sub>k </sub>and provides generating a high-frequency sampled version of the primary signal s<sub>i</sub>, a low-frequency sampled version of the primary signal s<sub>i </sub>(hereinafter indicated as pre-processed signal s″<sub>i,k,hf </sub>and s″<sub>i,k,lf</sub>) and a filtered sampled version (with high pass filtering) of the primary signal s<sub>i </sub>(hereinafter indicated as pre-processed signal s″<sub>i,k,filt </sub>and having the same sampling frequency as the pre-processed signal s″<sub>i,k,hf</sub>, thus also being sampled at high frequency), which are indicative of the peak envelope of the primary signal s<sub>i </sub>and of a filtered version (with high pass filtering) of the primary signal s<sub>i</sub>;</li><br/><li><span class=\"paragraph-number\">[0015]   </span> - a processing based on time histories (block <b>300</b>), which provides generating a version sampled at high-frequency (not necessarily equal to the high frequency used for envelope processing) of the primary signal s<sub>i</sub>, a version sampled at low-frequency (not necessarily equal to the low frequency used for envelope processing) of the primary signal s<sub>i </sub>(hereinafter indicated as pre-processed signals s′″<sub>i,hf </sub>and s′″<sub>i,lf</sub>) and a filtered sampled version (with high pass filtering) of the primary signal s<sub>i </sub>(referred to in the following as the pre-processed signal s′″<sub>i,filt </sub>and having the same sampling frequency as the pre-processed signal s′″<sub>i,hf</sub>, thus also being sampled at high frequency), which 25 are component-independent; and</li><br/><li><span class=\"paragraph-number\">[0016]   </span> - asynchronous processing (block <b>400</b>), which is component-independent and provides generating a respective pre-processed signal s′″<sub>i </sub>of digital type by calculating the averaged spectrum of the primary signal s<sub>i </sub>and, subsequently, the so-called “cepstrum” of the averaged spectrum.</li></ul></li></ul></p><p><span class=\"paragraph-number\">[0017]   </span>The health indexes are then calculated on the basis of the pre-processed signals obtained through the aforementioned preliminary processing, by implementing “feature extraction” algorithms that depend on the preliminary processing previously carried out.</p><p><span class=\"paragraph-number\">[0018]   </span>In particular, the synchronous processing <b>100</b>, the envelope processing <b>200</b>, the time history-based processing <b>300</b> and the asynchronous processing <b>400</b> are respectively followed by the execution of a first, a second, a third and a fourth set of feature extraction algorithms (indicated with <b>110</b>, <b>210</b>, <b>310</b> and <b>410</b>, respectively), starting from the pre-processed signal s′<sub>i,k</sub>, from the triad of pre-processed signals s″<sub>i,k,hf</sub>, s″<sub>i,k,lf </sub>and s″<sub>i,k,filt</sub>, from the triad of pre-processed signals s′″<sub>i,hf</sub>, S′″<sub>i,lf</sub>, S′″<sub>i,filt </sub>and from the pre-processed signal s″″<sub>i</sub>, respectively.</p><p><span class=\"paragraph-number\">[0019]   </span>The health indexes obtained by executing the sets of feature extraction algorithms <b>110</b>, <b>210</b> are characteristic of the behaviour of the component, i.e. they have a high specificity, while the health indexes obtained by executing the sets of feature extraction algorithms <b>310</b> and <b>410</b> are substantially independent from the features of the individual components and characterise, on the whole, the operation of the portion of the transmission system <b>1</b> (in the following, also referred to as zone) arranged in proximity to the sensor A<sub>i </sub>that generated the primary signal s<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0020]   </span>For example, the feature extraction algorithms of the first, the second, the third and the fourth set <b>110</b>, <b>210</b>, <b>310</b> and <b>410</b> may include algorithms for extracting statistical values (e.g., calculations of averages, variances, peak-to-peak values, etc.), as well as calculations of shape factors (e.g., kurtosis) and/or direct measurements of amplitudes of spectral components and indicators of spectral energy distribution. Furthermore, it is possible that the pre-processed signals undergo further pre-processing, such as signal enhancement, phase demodulation, etc., before feature extraction.</p><p><span class=\"paragraph-number\">[0021]   </span>For example, the set of feature extraction algorithms <b>110</b> may include so-called temporal analysis, spectral analysis, enhancement analysis and phase demodulation algorithms, which are executed on the pre-processed signal S′<sub>i,k</sub>, before extracting the corresponding features.</p><p><span class=\"paragraph-number\">[0022]   </span>The set of feature extraction algorithms <b>210</b> may include so-called algorithms for calculating the Hilbert transform of the pre-processed signals s″<sub>i,k,hf</sub>, S″<sub>i,k,lf </sub>and s″<sub>i,k,filt </sub>and the subsequent extraction of features indicative of the energy associated with a plurality of predetermined frequencies.</p><p><span class=\"paragraph-number\">[0023]   </span>The set of feature extraction algorithms <b>310</b> may include so-called residual analysis, temporal analysis and enhancement analysis algorithms, which are executed on the pre-processed signals s′″<sub>i,hf</sub>, s′″<sub>i,lf </sub>and s′″<sub>i,filt</sub>, prior to the aforementioned statistical value and/or form factor extraction algorithms.</p><p><span class=\"paragraph-number\">[0024]   </span>The set of feature extraction algorithms <b>410</b> may comprise the extraction of a plurality of features relative to the aforementioned cepstrum.</p><p><span class=\"paragraph-number\">[0025]   </span>In more detail, as shown schematically again in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>, the transmission system <b>1</b> is equipped with a processing system <b>10</b> and a storage system <b>11</b>, coupled to each other and to the monitoring system MS. During each flight of the helicopter HC<sub>1</sub>, for each time interval having a duration equal to ΔT (e.g., equal to fifteen minutes), the processing system <b>10</b> queries the sensors A<sub>i</sub>, e.g., sequentially, in order to acquire the corresponding primary signals s<sub>i </sub>generated by the sensors A<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0026]   </span>In other words, for each time interval of duration ΔT, the processing system <b>10</b> acquires, for each sensor A<sub>i</sub>, the corresponding primary signal s<sub>i</sub>, which has a respective duration lower than the duration ΔT. For each time interval having duration ΔT, the corresponding primary signals s<sub>i </sub>therefore extend over different time domains and have different durations; the primary signals s<sub>i </sub>are therefore indicative of the trends of the corresponding quantities in the respective time domains.</p><p><span class=\"paragraph-number\">[0027]   </span>Further, for each of said time intervals of duration ΔT, the processing system <b>10</b> calculates a corresponding set of health indexes, as a function of the corresponding primary signals s<sub>i</sub>, the calculated health indexes being thus indicative of the operation of the transmission system <b>1</b> during sub-portions of the time interval of duration ΔT; the health indexes are stored in the storage system <b>11</b>.</p><p><span class=\"paragraph-number\">[0028]   </span>Having said that, it is well known that, given any primary signal s<sub>i</sub>, the choice of processing that is performed, and therefore of the health indexes that are calculated, depends on the position of the sensor A<sub>i </sub>that generated it.</p><p><span class=\"paragraph-number\">[0029]   </span>For example, <a href=\"#DRAWINGS\">FIG. <b>3</b></a> shows how the sensor A<sub>i </sub>is associated with the first and second gear C<sub>1</sub>, C<sub>2 </sub>and, for ease of visualisation, to only one of the bearings (indicated with C<sub>3</sub>) of the aforementioned gearbox arranged near the tail rotor.</p><p><span class=\"paragraph-number\">[0030]   </span>Furthermore, <a href=\"#DRAWINGS\">FIG. <b>3</b></a> shows how, starting from the primary signal s<sub>i </sub>generated by the sensor A<sub>1</sub>, the aforementioned synchronous processing operations <b>100</b> are performed for each of the first and second gear C<sub>1</sub>, C<sub>2</sub>, so as to generate corresponding pre-processed signals s′<sub>1,1</sub>, s′<sub>1,2</sub>, which therefore depend on the angular velocities of the first and second gear C<sub>1</sub>, C<sub>2 </sub>and are strongly dependent on the operation of the first and, respectively, the second gear C<sub>1</sub>, C<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0031]   </span>In addition, starting from the primary signal s<sub>i</sub>, envelope processing operations <b>200</b> are performed as a function of the geometric features of the bearing C<sub>3</sub>, so as to generate the pre-processed signals s″<sub>1,3,hf</sub>, S″<sub>1,3,lf </sub>and s″<sub>1,3,filt</sub>, which are indicative of the operation of the bearing C<sub>3</sub>.</p><p><span class=\"paragraph-number\">[0032]   </span>Again starting from the primary signal s<sub>1</sub>, the operations of the processing that is based on the time histories <b>300</b> and the asynchronous processing operations <b>400</b> are also performed, so as to generate respectively the pre-processed signals s′″<sub>1,hf</sub>, S′″<sub>1,lf </sub>and s′″<sub>1,filt </sub>and the pre-processed signal s″″<sub>1</sub>, which are indicative of the overall operation of a zone Z<sub>1 </sub>of the transmission system <b>1</b> close to the sensor A<sub>1</sub>; this zone Z<sub>1 </sub>includes the first and the second gear C<sub>1</sub>, C<sub>2 </sub>and the bearing C<sub>3 </sub>(as well as the other three bearings mentioned above and not discussed in detail for the sake of brevity).</p><p><span class=\"paragraph-number\">[0033]   </span>In greater detail, referring for example again to <a href=\"#DRAWINGS\">FIG. <b>3</b></a>, typically the aforementioned synchronous processing <b>100</b>, envelope processing <b>200</b>, processing based on time histories <b>300</b> and asynchronous processing <b>400</b> are performed starting from respective portions of the primary signal s<sub>1 </sub>extending over respective sub-domains of the time domain associated with the sensor A<sub>1</sub>. Regardless of this implementation detail, <a href=\"#DRAWINGS\">FIG. <b>3</b></a> further shows how, by executing the set of feature extraction algorithms <b>110</b> on the pre-processed signals s′<sub>1,1 </sub>and s′<sub>1,2</sub>, a first and a second set of (for example) eighteen health indexes, indicated with HI<sub>1,1</sub>-HI<sub>1,18 </sub>and HI<sub>2,1</sub>-HI<sub>2,18 </sub>respectively, are generated. The health indexes HI<sub>1,1</sub>-HI<sub>1,18 </sub>are associated with a first acquisition index AcqID<sub>1</sub>, which is then associated with the triad (sensor A<sub>1</sub>, first gear C<sub>1</sub>, synchronous processing); the health indexes HI<sub>2,1</sub>-HI<sub>2,18 </sub>are associated with a second acquisition index AcqID<sub>2</sub>, which is then associated with the triad (sensor A<sub>i</sub>, second gear C<sub>2</sub>, synchronous processing).</p><p><span class=\"paragraph-number\">[0034]   </span><a href=\"#DRAWINGS\">FIG. <b>3</b></a> further shows how, by executing the set of feature extraction algorithms <b>210</b> on the pre-processed signals s″<sub>1,3,hf </sub>and s″<sub>1,3,filt</sub>, a third set of (for example) eighteen health indexes is generated, indicated with HI<sub>3,1</sub>-HI<sub>3,18 </sub>respectively, which are associated to a third acquisition index AcqID<sub>3</sub>, which is thus associated to the triad (sensor A<sub>i</sub>, bearing C<sub>3</sub>, envelope processing based on the aforementioned high-frequency sampled version of the primary signal s<sub>i </sub>and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0035]   </span>Furthermore, by executing the set of feature extraction algorithms <b>210</b> on the pre-processed signal s″<sub>1,3,1f</sub>, a fourth set of (for example) nine health indexes, indicated with HI<sub>4,1</sub>-HI<sub>4,9 </sub>respectively, is generated, which are associated with a fourth acquisition index AcqID<sub>4</sub>, which is then associated with the triad (sensor A<sub>1</sub>, bearing C<sub>3</sub>, envelope processing based on the aforementioned low-frequency sampled version of the primary signal s<sub>i</sub>). In the following, as well as in <a href=\"#DRAWINGS\">FIG. <b>3</b></a>, reference will be made for simplicity's sake in any case to a set of eighteen health indexes HI<sub>4,1</sub>-HI<sub>4,18</sub>, for example on the assumption that the health indexes HI<sub>4,10</sub>-HI<sub>4,18 </sub>are zero or otherwise indicative of a non-applicability condition.</p><p><span class=\"paragraph-number\">[0036]   </span>In addition, <a href=\"#DRAWINGS\">FIG. <b>3</b></a> shows how a fifth and a sixth set of (for example) eighteen health indexes are generated, which are indicated with HI<sub>5,1</sub>-HI<sub>5,18 </sub>and HI<sub>6,1</sub>-HI<sub>6,18 </sub>respectively and are associated with a fifth and a sixth health index AcqID<sub>5</sub>, AcqID<sub>6 </sub>respectively.</p><p><span class=\"paragraph-number\">[0037]   </span>In particular, the fifth set of health indexes HI<sub>5,1</sub>-HI<sub>5,18 </sub>is generated by executing the set of feature extraction algorithms <b>310</b> on the pre-processed signals s′″<sub>1,hf </sub>and s′″<sub>1,filt</sub>; the fifth acquisition index AcqID<sub>5 </sub>is thus associated to the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, processing based on the time histories based on the aforementioned high-frequency sampled version of the primary signal s<sub>i </sub>and the aforementioned filtered sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0038]   </span>The sixth set of health indexes HI<sub>6,1</sub>-HI<sub>6,18 </sub>is generated by executing the set of feature extraction algorithms <b>310</b> on the pre-processed signal s′″<sub>1,lf</sub>; the sixth acquisition index AcqID<sub>6 </sub>is thus associated to the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, time-history-based processing based on the aforementioned low-frequency sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0039]   </span><a href=\"#DRAWINGS\">FIG. <b>3</b></a> finally shows how a seventh set of (for example) eighteen health indexes, indicated with HI<sub>7,1</sub>-HI<sub>7,18</sub>, is generated by executing the set of feature extraction algorithms <b>410</b> on the pre-processed signal s″″<sub>1</sub>, respectively. The health indexes HI<sub>7,1</sub>-HI<sub>7,18 </sub>are associated with a seventh acquisition index AcqID<sub>7</sub>, which is associated with the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, asynchronous processing).</p><p><span class=\"paragraph-number\">[0040]   </span>Similarly, the processing of the primary signal s<sub>2 </sub>generated by the sensor A<sub>2 </sub>leads to the generation of further sets of health indexes, associated with corresponding acquisition indexes. Furthermore, as explained also below, the numbering of the acquisition indexes associated with a single sensor may not be consecutive.</p><p><span class=\"paragraph-number\">[0041]   </span>In practice, each acquisition index is relative to only one corresponding component or a corresponding zone, as well as to only one corresponding preliminary processing mode to be chosen from synchronous processing <b>100</b>, envelope processing <b>200</b> (alternatively, based on the aforementioned high-frequency sampled version of the primary signal s<sub>i </sub>and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>, or on the low-frequency sampled version of the primary signal s<sub>i</sub>), time history-based processing <b>300</b> (alternatively, based on the aforementioned high-frequency sampled version of the primary signal s<sub>i </sub>and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>, or on the low-frequency sampled version of the primary signal s<sub>i</sub>) and asynchronous processing <b>400</b>. Furthermore, each acquisition index is biunivocally associated with a corresponding set of health indexes. For example, in the following, it is assumed, unless otherwise specified, that the processing system <b>10</b> is configured to calculate health indexes relating to one hundred and eighty acquisition indexes, on the basis of the primary signals generated by the thirteen sensors A<sub>1</sub>-A<sub>13</sub>. However, it is possible that health indexes associated with one or more acquisition indexes are discarded, for example because they are irrelevant, unreliable or not applicable.</p><p><span class=\"paragraph-number\">[0042]   </span>As mentioned above, the processing system <b>10</b> stores in the storage system <b>11</b> all the health indexes that are calculated as they are calculated during the time intervals of duration ΔT that follow each other during the flights of the helicopter HC<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0043]   </span>Furthermore, as explained in more detail below, the processing system <b>10</b> stores flight parameter values in the storage system <b>11</b>, which are acquired by means of additional sensors (indicated with <b>8</b> in <a href=\"#DRAWINGS\">FIG. <b>1</b></a>), which are coupled to the helicopter HC<sub>1 </sub>and are able to detect, for example, the temperature and/or pressure of the lubricating oil, the torque transmitted by the main rotor, the flight speed, the attitude of the aircraft, etc.).</p><p><span class=\"paragraph-number\">[0044]   </span>In addition, for each time interval of duration ΔT, the processing system <b>10</b> stores in the storage system <b>11</b> the pre-processed signals on the basis of which the health indexes for that time interval have been calculated. In particular, considering a generic time interval of duration ΔT, the processing system <b>10</b> stores in the storage system <b>11</b> the pre-processed signals relating to this time interval, overwriting the pre-processed signals relating to the previous time interval of duration ΔT.</p><p><span class=\"paragraph-number\">[0045]   </span>Consequently, at the end of each flight, the storage system <b>11</b> of the helicopter HC<sub>1 </sub>stores the pre-processed signals relating to the last time interval of duration ΔT of the flight of the helicopter HC<sub>1</sub>; in the following reference is made to these pre-processed signals as the final time series TH<sub>1,p</sub>, with p=1, . . . , Pmax, wherein Pmax is for example equal to the total number of acquisition indexes AcqID. For example, referring for simplicity's sake only to the sensor A<sub>1</sub>, and more particularly to the acquisition AcqID<sub>1</sub>-AcqID<sub>7 </sub>shown in <a href=\"#DRAWINGS\">FIG. <b>3</b></a>, it occurs that the final time series TH<sub>1,1</sub>-TH<sub>1,7 </sub>are formed by the samples, respectively, of the pre-processed signals s′<sub>1,1</sub>, S′<sub>1,2</sub>, S″<sub>1,3,hf</sub>, S″<sub>1,3,1f</sub>, s′″<sub>1,hf</sub>, s′″<sub>1,lf </sub>and s″″<sub>1 </sub>generated by the processing system <b>10</b> during the last time interval of duration ΔT of the flight of the helicopter HC<sub>1</sub>, on the basis of which the health indexes relating to the aforementioned last time interval of duration ΔT of the flight were then calculated. In other words, a corresponding pre-processed signal is stored for each acquisition index; only the pre-processed signals S″<sub>1,3,filt </sub>and s′″<sub>i,filt </sub>are not stored. The final time series TH<sub>1,1</sub>-TH<sub>1,7 </sub>are therefore successions of acceleration samples generated starting from the primary signal s<sub>i </sub>generated by the sensor A<sub>i</sub>, by means of different processing.</p><p><span class=\"paragraph-number\">[0046]   </span>In the presence of several helicopters, equipped for example in the same way (same sensors), it is thus possible to obtain what is shown in <a href=\"#DRAWINGS\">FIG. <b>4</b></a>, in which for simplicity's sake reference is made, in addition to the helicopter HC<sub>1</sub>, only to a further helicopter HC<sub>2</sub>, identical to the helicopter HC<sub>1 </sub>and equipped with a monitoring system identical to the monitoring system MS of the helicopter HC<sub>1</sub>, as well as with a processing system, a storage system and additional sensors respectively identical to the processing system <b>10</b>, the storage system <b>11</b> and the additional sensors <b>8</b> of the first helicopter HC<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0047]   </span>In detail, for each flight of the helicopter HC<sub>1</sub>, the processing system <b>10</b> of the helicopter HC<sub>1 </sub>stores in the storage system <b>11</b> a corresponding set of final time series, collectively referred to as SET_TH<sub>1</sub>. Similarly, for each flight of the helicopter HC<sub>2</sub>, the processing system of the helicopter HC<sub>2 </sub>stores in the corresponding storage system a corresponding set of final time series, collectively referred to as SET_TH<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0048]   </span>In addition, for each flight of the helicopter HC<sub>1</sub>, the processing system <b>10</b> of the helicopter HC<sub>1 </sub>stores in the storage system <b>11</b> a respective flight data structure FDS<sub>1</sub>; similarly, for each flight of the helicopter HC<sub>2</sub>, the processing system of the helicopter HC<sub>2 </sub>stores in the corresponding storage system <b>11</b> a respective flight data structure FDS<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0049]   </span>The flight data structures FDS<sub>1</sub>, FDS<sub>2 </sub>have the same form, which is now described with reference to the flight data structure FDS<sub>1 </sub>as an example.</p><p><span class=\"paragraph-number\">[0050]   </span>As shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>, the flight data structure FDS<sub>1 </sub>comprises a plurality of portions, which are referred to as the elementary data structures (indicated with DS).</p><p><span class=\"paragraph-number\">[0051]   </span>Each elementary data structure DS is associated to a corresponding acquisition index; consequently, referring generically to the j-th elementary data structure DS<sub>j</sub>, it is associated to the j-th acquisition index AcqID<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0052]   </span>As shown in <a href=\"#DRAWINGS\">FIG. <b>6</b></a>, which refers to the elementary data structure DS<sub>1</sub>, and thus to the acquisition index AcqID<sub>1</sub>, each elementary data structure DS<sub>j </sub>stores, for each time interval of duration ΔT, a corresponding set of data, in the following indicated for brevity's sake as item U<sub>w</sub>, wherein w indexes the items of the elementary data structure and therefore also the time intervals of duration ΔT; for example, in <a href=\"#DRAWINGS\">FIG. <b>6</b></a> assumption is made that the elementary data structure DS<sub>1 </sub>comprises thirty items U<sub>w</sub>.</p><p><span class=\"paragraph-number\">[0053]   </span>The item U<sub>w </sub>comprises a time interval indication (indicated with T<sub>w</sub>), the acquisition index acqID<sub>j </sub>(for brevity's sake indicated in <a href=\"#DRAWINGS\">FIGS. <b>5</b> and <b>6</b></a> only by a number equal to index j), the set of health indexes associated with the acquisition index AcqID<sub>j </sub>and calculated on the basis of the corresponding primary signal acquired during said time interval, as well as the set of flight parameter values (indicated with SET_ΔT<sub>w</sub>) acquired by means of the additional sensors <b>8</b> during such time interval, and more precisely during the temporal sub-domain to which the portion of the primary signal used to calculate the aforementioned set of health indexes associated with the acquisition index AcqID<sub>j </sub>refers.</p><p><span class=\"paragraph-number\">[0054]   </span>In particular, the health indexes are columnarised in eighteen columns labelled as HI<sub>x,1</sub>-Hix, 18<sub>x,18 </sub>respectively, so that the elementary data structures DS of the flight data structure FDS<sub>1 </sub>can also be columnarised, as shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>. The identification of each health index is made by replacing the parameter “x” with the value of the parameter j indexing the acquisition index AcqID<sub>j </sub>and thus the elementary data structure DS<sub>j </sub>(in the case of <a href=\"#DRAWINGS\">FIG. <b>6</b></a>, we have x=j=1); moreover, within a generic u-th column (with u=1, . . . , 18) of the j-th elementary data structure DS<sub>j</sub>, the health indexes are indicated as HI<sub>j,u </sub>(w), wherein w indicates the time interval to which the health index refers, and therefore the item U<sub>w </sub>to which the health index belongs.</p><p><span class=\"paragraph-number\">[0055]   </span>Again with reference to <a href=\"#DRAWINGS\">FIG. <b>5</b></a>, as mentioned earlier, the columns in which the health indexes are stored are shared between the elementary data structures DS of the flight data structure FDS<sub>1</sub>. Consequently, considering the u-th column, the meaning of the health indexes stored there varies along the column, as a function of the elementary data structures DS to which these health indexes belong.</p><p><span class=\"paragraph-number\">[0056]   </span><a href=\"#DRAWINGS\">FIG. <b>5</b></a> also shows how the elementary data structures relating to some acquisition indexes (for example, the second acquisition index AcqID<sub>2</sub>) may not be included in the flight data structures FDS<sub>1</sub>, for example because they are judged to be irrelevant or unreliable, the latter occurring for example in the case of malfunctioning of the sensor associated to the corresponding acquisition index. In the following, however, is assumed for simplicity's sake that no elementary data structure is discarded.</p><p><span class=\"paragraph-number\">[0057]   </span>In addition, in the example shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>, it occurs that, net of any acquisition indexes not included in the flight data structure FDS<sub>1</sub>, the elementary data structures DS<sub>1</sub>-DS<sub>44</sub>, relative respectively to the acquisition indexes AcqID<sub>1</sub>-AcqID<sub>44</sub>, form a first portion P<sub>1 </sub>of the flight data structure FDS<sub>1 </sub>and are relative to the synchronous processing <b>100</b>, that is, they store acquisition indexes associated to sets of health indexes obtained by carrying out synchronous processing <b>100</b>; the elementary data structures DS<sub>45</sub>-DS<sub>60</sub>, respectively relative to the acquisition indexes AcqID<sub>45</sub>-AcqID<sub>60</sub>, form a second portion P<sub>2 </sub>of the flight data structure FDS<sub>1 </sub>and are relative to the asynchronous processing <b>400</b>, i.e. they store acquisition indexes associated to sets of health indexes obtained by carrying out asynchronous processing <b>400</b>; the elementary data structures DS<sub>61</sub>-DS<sub>100</sub>, respectively relative to the acquisition indexes AcqID<sub>61</sub>-AcqID<sub>100</sub>, form a third portion P<sub>3 </sub>of the flight data structure FDS<sub>1 </sub>and are relative to the processing based on the time histories <b>300</b>, that is they store acquisition indexes associated to sets of health indexes obtained by carrying out the processing based on the time histories <b>300</b>; and finally, the elementary data structures DS<sub>101</sub>-DS<sub>180</sub>, respectively relative to the acquisition indexes AcqID<sub>101</sub>-AcqID<sub>180</sub>, form a fourth portion P<sub>4 </sub>of the flight data structure FDS<sub>1 </sub>and are relative to the envelope processing <b>200</b>, i.e. they store acquisition indexes associated to sets of health indexes obtained by carrying out envelope processing <b>200</b>.</p><p><span class=\"paragraph-number\">[0058]   </span>Having said that, and as previously mentioned, having the aforementioned health indexes available, it is possible to detect possible malfunctions in the transmission system <b>1</b>. For example, it is known to analyse health indexes in a deterministic way, e.g. by comparing them with corresponding thresholds (the latter pre-set, for example, manually), or by checking whether each health index complies with a corresponding rule. This approach is characterised by an exact knowledge of the rules/thresholds that are applied, but it is not very flexible and tends to generate a high number of false positives; moreover, this approach is affected by the dispersion induced on the health indexes by the different operating conditions of the transmission system.</p><p><h1>Subject and Summary of the Invention</h1></p><p><span class=\"paragraph-number\">[0059]   </span>Aim of the present invention is therefore to provide a method for detecting anomalies which allows to overcome at least in part the drawbacks of the prior art.</p><p><span class=\"paragraph-number\">[0060]   </span>According to the present invention, there are provided a method and a system for detecting anomalies, as defined in the appended claims.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0061]   </span>For a better understanding of the present invention, embodiments thereof are now described, purely by way of non-limiting example, with reference to the accompanying drawings, in which:</p><p><span class=\"paragraph-number\">[0062]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b></a> shows schematically a perspective view of a transmission system;</p><p><span class=\"paragraph-number\">[0063]   </span><a href=\"#DRAWINGS\">FIG. <b>2</b></a> shows a block diagram relative to signal processing operations;</p><p><span class=\"paragraph-number\">[0064]   </span><a href=\"#DRAWINGS\">FIG. <b>3</b></a> shows a block diagram showing the relationships between a sensor, some components of the transmission system shown in <a href=\"#DRAWINGS\">FIG. <b>1</b></a> and corresponding health indexes;</p><p><span class=\"paragraph-number\">[0065]   </span><a href=\"#DRAWINGS\">FIG. <b>4</b></a> shows a block diagram showing the relationships between two helicopters and corresponding data structures;</p><p><span class=\"paragraph-number\">[0066]   </span><a href=\"#DRAWINGS\">FIG. <b>5</b></a> shows a flight data structure;</p><p><span class=\"paragraph-number\">[0067]   </span><a href=\"#DRAWINGS\">FIG. <b>6</b></a> shows in detail a portion of the flight data structure shown in <a href=\"#DRAWINGS\">FIG. <b>5</b></a>;</p><p><span class=\"paragraph-number\">[0068]   </span><a href=\"#DRAWINGS\">FIGS. <b>8</b> and <b>9</b></a> show diagrams of data structures relative to helicopter training flights;</p><p><span class=\"paragraph-number\">[0069]   </span><a href=\"#DRAWINGS\">FIGS. <b>10</b> and <b>11</b></a> show diagrams of data structures relative to unknown flights of the helicopter to which <a href=\"#DRAWINGS\">FIGS. <b>8</b> and <b>9</b></a> refer;</p><p><span class=\"paragraph-number\">[0070]   </span><a href=\"#DRAWINGS\">FIGS. <b>7</b>, <b>12</b>, <b>14</b>, <b>15</b> and <b>17</b></a> shows a block diagram relative to operations according to the present method;</p><p><span class=\"paragraph-number\">[0071]   </span><a href=\"#DRAWINGS\">FIGS. <b>13</b>A and <b>19</b></a> show block diagrams of classification operations;</p><p><span class=\"paragraph-number\">[0072]   </span><a href=\"#DRAWINGS\">FIG. <b>13</b>B</a> shows an example of an output matrix generated by a classifier;</p><p><span class=\"paragraph-number\">[0073]   </span><a href=\"#DRAWINGS\">FIGS. <b>16</b> and <b>20</b></a> show block diagrams relative to data vectors generated according to the present method;</p><p><span class=\"paragraph-number\">[0074]   </span><a href=\"#DRAWINGS\">FIG. <b>18</b></a> shows a Cartesian plane relative to a two-dimensional hyperspace, showing boundaries of confidence hyperspaces.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and system for detecting anomalies relating to components of a transmission system of an aircraft, in particular a helicopter.</p><p><span class=\"paragraph-number\">[0002]   </span>As is well known, helicopters are extremely complex and vulnerable aircraft, since there is a transmission system between the engine(s) and the rotors, which includes critical components. Single malfunctions of any of these components may be extremely dangerous to the safety of the helicopter.</p><p><span class=\"paragraph-number\">[0003]   </span>In order to monitor the proper operation of a helicopter, so-called health and usage monitoring systems (HUMS) are known to be used. Typically, a HUMS system comprises a plurality of sensors (e.g. accelerometers), which are coupled to components of the transmission system and are adapted to monitor trends over time of corresponding physical quantities.</p><p><span class=\"paragraph-number\">[0004]   </span>Furthermore, monitoring methods are known which envisage extracting so-called synthetic indexes known as \"health indexes\" starting from the signals generated by the sensors, which can be analysed to detect, for example, the presence of cracks on gear teeth, wear on bearings, imbalances affecting drive shafts, etc.</p><p><span class=\"paragraph-number\">[0005]   </span>By way of example, <figref>Figure 1</figref> shows a transmission system 1, which is mechanically interposed between one or more engines (not shown) and the rotors (main and tail, not shown) of a helicopter HC<sub>1</sub> (not visible in <figref>Figure 1</figref>; schematically shown in <figref>Figure 4</figref>) and includes a plurality of mechanical components, which comprise drive shafts, gears, bearings (not shown), etc. For the sake of simplicity, in <figref>Figure 1</figref> only a first and a second gear (indicated respectively with C<sub>1</sub> and C<sub>2</sub>) are accompanied by reference marks, which are coupled to each other so as to form a gearbox arranged in proximity to the tail rotor and enclosed in a corresponding first external protective substructure 5 (shown only symbolically in <figref>Figure 1</figref> and also known as a box or casting) ; the rotation of the first and second gear C<sub>1</sub>, C<sub>2</sub> with respect to the first external protective substructure 5, and in particular the rotation of corresponding shafts integral with the first and second gear C<sub>1</sub>, C<sub>2</sub> and extending through the first external protective substructure 5, is permitted by the presence of a number (typically, four, i.e., two per gear) of bearings (not shown in <figref>Figure 1</figref>) each mechanically interposed between the box and a corresponding shaft. In general, therefore, groups of mechanical components are arranged within corresponding external protective substructures, which allow, by means of appropriate bearings and openings, the coupling with mechanical components of other groups. For example, <figref>Figure 1</figref> shows (symbolically) a second external protective substructure 7, which houses within it a corresponding portion of the transmission system 1. Altogether, the external protective substructures form an external structure 9 of the transmission system 1.</p><p><span class=\"paragraph-number\">[0006]   </span><figref>Figure 1</figref> further shows (symbolically) a plurality of sensors A<sub>i</sub> (with i=1, ...13), which form a monitoring system MS, are accelerometers (e.g., of the uniaxial type) and are mechanically coupled to corresponding points of the transmission system 1; in particular, each sensor A<sub>i</sub> is constrained to a corresponding point of the transmission system 1, so as to generate a corresponding signal (referred to in the following as the primary signal) indicative of a corresponding quantity (for example, the acceleration along a respective axis), which in turn depends on the vibrations to which sensor A<sub>i</sub> is subjected. Primary signals are typically analogue signals.</p><p><span class=\"paragraph-number\">[0007]   </span>In more detail, each sensor A<sub>i</sub> is fixed to a corresponding point of the external structure 9 of the transmission system 1. For example, the sensor A<sub>i</sub> is fixed to a point on the first external protective substructure 5, so it is closer than all the other sensors to the aforementioned first and second gear C<sub>1</sub>, C<sub>2</sub>, as well as to the respective bearings. By way of example only, the sensors A<sub>2</sub>-A<sub>8</sub>, A<sub>12</sub> and A<sub>13</sub> are fixed to corresponding points of the second external protective substructure 7, in proximity to corresponding mechanical components.</p><p><span class=\"paragraph-number\">[0008]   </span>The sensors may be arranged indifferently either on parts of the external structure 9 facing the mechanical components of the transmission system 1 or to the outside.</p><p><span class=\"paragraph-number\">[0009]   </span>That being said, each primary signal is indicative of the operation and integrity of one or more components of the transmission system 1; in other words, the primary signal generated by each sensor A<sub>i</sub> is indicative of the operation of a corresponding subset of components of the transmission system 1. Therefore, it is known to calculate, starting from the primary signal provided by each sensor A<sub>i</sub>, a plurality of health indexes relating to the components of the corresponding subset, by implementing a plurality of processing techniques. Furthermore, considering a single component, it can belong to several subsets associated with corresponding sensors A<sub>i</sub>, i.e. it is known to calculate health indexes relating to the same component on the basis of several primary signals, as explained below.</p><p><span class=\"paragraph-number\">[0010]   </span>In more detail, considering any primary signal (hereafter referred to as s<sub>i</sub>) generated by a sensor A<sub>i</sub>, it can be subjected to one or more processing techniques, which include digitising the primary signal s<sub>i</sub>, in order to generate corresponding health indexes.</p><p><span class=\"paragraph-number\">[0011]   </span>That said, as shown in <figref>Figure 2</figref>, the primary signal s<sub>i</sub> may be subjected to one or more preliminary processing steps, selected for example from:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> a synchronous processing (block 100), also known as time average processing, which is associated to a corresponding k-th component C<sub>k</sub>, is a function of the angular velocity of the component C<sub>k</sub> (detected by means of an appropriate dedicated sensor, not shown) and provides generating a respective pre-processed signal s'<sub>i,k</sub>, which is of digital type and is obtained by sampling the primary signal s<sub>i</sub> relating to a number Nrot of rotations of the component C<sub>k</sub> with a sampling frequency that is a multiple of the rotation frequency of the component C<sub>k</sub>, in order to acquire, for each rotation, a number NS of samples relating to corresponding angular positions of the component C<sub>k</sub>, and subsequently averaging, for each angular position, the corresponding samples (in number equal to Nrot), so that the pre-processed signal s'<sub>i,k</sub> includes a portion of the primary signal s<sub>i</sub> that is correlated with the angular velocity of the component C<sub>k</sub>;</li><br/><li> an envelope processing (block 200), which is associated with a corresponding k-th component C<sub>k</sub>, is a function of the geometrical features of the k-th component C<sub>k</sub> and provides generating a high-frequency sampled version of the primary signal s<sub>i</sub>, a low-frequency sampled version of the primary signal s<sub>i</sub> (hereinafter indicated as pre-processed signal s\"<sub>i,k,hf</sub> and s\"<sub>i,k,lf</sub>) and a filtered sampled version (with high pass filtering) of the primary signal s<sub>i</sub> (hereinafter indicated as pre-processed signal s\"<sub>i,k,filt</sub> and having the same sampling frequency as the pre-processed signal s\"<sub>i,k,hf</sub>, thus also being sampled at high frequency), which are indicative of the peak envelope of the primary signal s<sub>i</sub> and of a filtered version (with high pass filtering) of the primary signal s<sub>i</sub>;</li></ul></p><p><ul compact=\"compact\" list-style=\"dash\"><li> a processing based on time histories (block 300), which provides generating a version sampled at high-frequency (not necessarily equal to the high frequency used for envelope processing) of the primary signal s<sub>i</sub>, a version sampled at low-frequency (not necessarily equal to the low frequency used for envelope processing) of the primary signal s<sub>i</sub> (hereinafter indicated as pre-processed signals s‴<sub>i,hf</sub> and s‴<sub>i,lf</sub>) and a filtered sampled version (with high pass filtering) of the primary signal s<sub>i</sub> (referred to in the following as the pre-processed signal s‴<sub>i,filt</sub> and having the same sampling frequency as the pre-processed signal s‴<sub>i,hf</sub>, thus also being sampled at high frequency), which are component-independent; and</li><br/><li> asynchronous processing (block 400), which is component-independent and provides generating a respective pre-processed signal sʺʺ<sub>i</sub> of digital type by calculating the averaged spectrum of the primary signal s<sub>i</sub> and, subsequently, the so-called \"cepstrum\" of the averaged spectrum.</li></ul></p><p><span class=\"paragraph-number\">[0012]   </span>The health indexes are then calculated on the basis of the pre-processed signals obtained through the aforementioned preliminary processing, by implementing \"feature extraction\" algorithms that depend on the preliminary processing previously carried out.</p><p><span class=\"paragraph-number\">[0013]   </span>In particular, the synchronous processing 100, the envelope processing 200, the time history-based processing 300 and the asynchronous processing 400 are respectively followed by the execution of a first, a second, a third and a fourth set of feature extraction algorithms (indicated with 110, 210, 310 and 410, respectively), starting from the pre-processed signal s'<sub>i,k</sub>, from the triad of pre-processed signals s\"<sub>i,k,hf</sub>, s\"<sub>i,k,lf</sub> and s\"<sub>i,k,filt</sub>, from the triad of pre-processed signals s‴<sub>i,hf</sub>, s‴<sub>i,if</sub>, s‴<sub>i,filt</sub> and from the pre-processed signal sʺʺ<sub>i</sub>, respectively.</p><p><span class=\"paragraph-number\">[0014]   </span>The health indexes obtained by executing the sets of feature extraction algorithms 110, 210 are characteristic of the behaviour of the component, i.e. they have a high specificity, while the health indexes obtained by executing the sets of feature extraction algorithms 310 and 410 are substantially independent from the features of the individual components and characterise, on the whole, the operation of the portion of the transmission system 1 (in the following, also referred to as zone) arranged in proximity to the sensor A<sub>i</sub> that generated the primary signal s<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0015]   </span>For example, the feature extraction algorithms of the first, the second, the third and the fourth set 110, 210, 310 and 410 may include algorithms for extracting statistical values (e.g., calculations of averages, variances, peak-to-peak values, etc.), as well as calculations of shape factors (e.g., kurtosis) and/or direct measurements of amplitudes of spectral components and indicators of spectral energy distribution. Furthermore, it is possible that the pre-processed signals undergo further pre-processing, such as signal enhancement, phase demodulation, etc., before feature extraction.</p><p><span class=\"paragraph-number\">[0016]   </span>For example, the set of feature extraction algorithms 110 may include so-called temporal analysis, spectral analysis, enhancement analysis and phase demodulation algorithms, which are executed on the pre-processed signal s'<sub>i,k</sub>, before extracting the corresponding features.</p><p><span class=\"paragraph-number\">[0017]   </span>The set of feature extraction algorithms 210 may include so-called algorithms for calculating the Hilbert transform of the pre-processed signals s\"<sub>i,k,hf</sub>, s\"<sub>i,k,if</sub> and s\"<sub>i,k,filt</sub> and the subsequent extraction of features indicative of the energy associated with a plurality of predetermined frequencies.</p><p><span class=\"paragraph-number\">[0018]   </span>The set of feature extraction algorithms 310 may include so-called residual analysis, temporal analysis and enhancement analysis algorithms, which are executed on the pre-processed signals s‴<sub>i,hf</sub>, s‴<sub>i,lf</sub> and s‴<sub>i,filt</sub>, prior to the aforementioned statistical value and/or form factor extraction algorithms.</p><p><span class=\"paragraph-number\">[0019]   </span>The set of feature extraction algorithms 410 may comprise the extraction of a plurality of features relative to the aforementioned cepstrum.</p><p><span class=\"paragraph-number\">[0020]   </span>In more detail, as shown schematically again in <figref>Figure 1</figref>, the transmission system 1 is equipped with a processing system 10 and a storage system 11, coupled to each other and to the monitoring system MS. During each flight of the helicopter HC<sub>1</sub>, for each time interval having a duration equal to ΔT (e.g., equal to fifteen minutes), the processing system 10 queries the sensors A<sub>i</sub>, e.g., sequentially, in order to acquire the corresponding primary signals s<sub>i</sub> generated by the sensors A<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0021]   </span>In other words, for each time interval of duration ΔT, the processing system 10 acquires, for each sensor A<sub>i</sub>, the corresponding primary signal s<sub>i</sub>, which has a respective duration lower than the duration ΔT. For each time interval having duration ΔT, the corresponding primary signals s<sub>i</sub> therefore extend over different time domains and have different durations; the primary signals s<sub>i</sub> are therefore indicative of the trends of the corresponding quantities in the respective time domains.</p><p><span class=\"paragraph-number\">[0022]   </span>Further, for each of said time intervals of duration ΔT, the processing system 10 calculates a corresponding set of health indexes, as a function of the corresponding primary signals s<sub>i</sub>, the calculated health indexes being thus indicative of the operation of the transmission system 1 during sub-portions of the time interval of duration ΔT; the health indexes are stored in the storage system 11.</p><p><span class=\"paragraph-number\">[0023]   </span>Having said that, it is well known that, given any primary signal s<sub>i</sub>, the choice of processing that is performed, and therefore of the health indexes that are calculated, depends on the position of the sensor A<sub>i</sub> that generated it.</p><p><span class=\"paragraph-number\">[0024]   </span>For example, <figref>Figure 3</figref> shows how the sensor A<sub>1</sub> is associated with the first and second gear C<sub>1</sub>, C<sub>2</sub> and, for ease of visualisation, to only one of the bearings (indicated with C<sub>3</sub>) of the aforementioned gearbox arranged near the tail rotor.</p><p><span class=\"paragraph-number\">[0025]   </span>Furthermore, <figref>Figure 3</figref> shows how, starting from the primary signal s<sub>1</sub> generated by the sensor A<sub>1</sub>, the aforementioned synchronous processing operations 100 are performed for each of the first and second gear C<sub>1</sub>, C<sub>2</sub>, so as to generate corresponding pre-processed signals s'<sub>1,1</sub>, s'<sub>1,2</sub>, which therefore depend on the angular velocities of the first and second gear C<sub>1</sub>, C<sub>2</sub> and are strongly dependent on the operation of the first and, respectively, the second gear C<sub>1</sub>, C<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0026]   </span>In addition, starting from the primary signal s<sub>1</sub>, envelope processing operations 200 are performed as a function of the geometric features of the bearing C<sub>3</sub>, so as to generate the pre-processed signals s\"<sub>1,3,hf</sub>, s\"<sub>1,3,if</sub> and s\"<sub>1,3,filt</sub>, which are indicative of the operation of the bearing C<sub>3</sub>.</p><p><span class=\"paragraph-number\">[0027]   </span>Again starting from the primary signal s<sub>1</sub>, the operations of the processing that is based on the time histories 300 and the asynchronous processing operations 400 are also performed, so as to generate respectively the pre-processed signals s‴<sub>i,hf</sub>, s‴<sub>1,lf</sub> and s‴<sub>1,filt</sub> and the pre-processed signal sʺʺ<sub>1</sub>, which are indicative of the overall operation of a zone Z<sub>1</sub> of the transmission system 1 close to the sensor A<sub>1</sub>; this zone Z<sub>1</sub> includes the first and the second gear C<sub>1</sub>, C<sub>2</sub> and the bearing C<sub>3</sub> (as well as the other three bearings mentioned above and not discussed in detail for the sake of brevity).</p><p><span class=\"paragraph-number\">[0028]   </span>In greater detail, referring for example again to <figref>Figure 3</figref>, typically the aforementioned synchronous processing 100, envelope processing 200, processing based on time histories 300 and asynchronous processing 400 are performed starting from respective portions of the primary signal s<sub>1</sub> extending over respective sub-domains of the time domain associated with the sensor A<sub>1</sub>. Regardless of this implementation detail, <figref>Figure 3</figref> further shows how, by executing the set of feature extraction algorithms 110 on the pre-processed signals s'<sub>1,1</sub> and s'<sub>1,2</sub>, a first and a second set of (for example) eighteen health indexes, indicated with HI<sub>1,1</sub> - HI<sub>1,18</sub> and HI<sub>2,1</sub> - HI<sub>2,18</sub> respectively, are generated. The health indexes HI<sub>1,1</sub> - HI<sub>1,18</sub> are associated with a first acquisition index AcqID<sub>1</sub>, which is then associated with the triad (sensor A<sub>1</sub>, first gear C<sub>1</sub>, synchronous processing) ; the health indexes HI<sub>2,1</sub> - HI<sub>2,18</sub> are associated with a second acquisition index AcqID<sub>2</sub>, which is then associated with the triad (sensor A<sub>1</sub>, second gear C<sub>2</sub>, synchronous processing).</p><p><span class=\"paragraph-number\">[0029]   </span><figref>Figure 3</figref> further shows how, by executing the set of feature extraction algorithms 210 on the pre-processed signals s\"<sub>1,3,hf</sub> and s\"<sub>1,3,filt</sub>, a third set of (for example) eighteen health indexes is generated, indicated with HI<sub>3,1</sub> - HI<sub>3,18</sub> respectively, which are associated to a third acquisition index AcqID<sub>3</sub>, which is thus associated to the triad (sensor A<sub>1</sub>, bearing C<sub>3</sub>, envelope processing based on the aforementioned high-frequency sampled version of the primary signal s<sub>i</sub> and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0030]   </span>Furthermore, by executing the set of feature extraction algorithms 210 on the pre-processed signal s\"<sub>1,3,lf</sub>, a fourth set of (for example) nine health indexes, indicated with HI<sub>4,1</sub> - HI<sub>4,9</sub> respectively, is generated, which are associated with a fourth acquisition index AcqID<sub>4</sub>, which is then associated with the triad (sensor A<sub>1</sub>, bearing C<sub>3</sub>, envelope processing based on the aforementioned low-frequency sampled version of the primary signal s<sub>i</sub>). In the following, as well as in <figref>Figure 3</figref>, reference will be made for simplicity's sake in any case to a set of eighteen health indexes HI<sub>4,1</sub> - HI<sub>4,18</sub>, for example on the assumption that the health indexes HI<sub>4,10</sub> - HI<sub>4,18</sub> are zero or otherwise indicative of a non-applicability condition.</p><p><span class=\"paragraph-number\">[0031]   </span>In addition, <figref>Figure 3</figref> shows how a fifth and a sixth set of (for example) eighteen health indexes are generated, which are indicated with HI<sub>5,1</sub> - HI<sub>5,18</sub> and HI<sub>6,1</sub> - HI<sub>6,18</sub> respectively and are associated with a fifth and a sixth health index AcqID<sub>5</sub>, AcqID<sub>6</sub> respectively.</p><p><span class=\"paragraph-number\">[0032]   </span>In particular, the fifth set of health indexes HI<sub>5,1</sub> - HI<sub>5,18</sub> is generated by executing the set of feature extraction algorithms 310 on the pre-processed signals s‴<sub>1,hf</sub> and s‴<sub>1,filt</sub>; the fifth acquisition index AcqID<sub>5</sub> is thus associated to the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, processing based on the time histories based on the aforementioned high-frequency sampled version of the primary signal s<sub>i</sub> and the aforementioned filtered sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0033]   </span>The sixth set of health indexes HI<sub>6,1</sub> - HI<sub>6,18</sub> is generated by executing the set of feature extraction algorithms 310 on the pre-processed signal s‴<sub>1,lf</sub>; the sixth acquisition index AcqID<sub>6</sub> is thus associated to the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, time-history-based processing based on the aforementioned low-frequency sampled version of the primary signal s<sub>i</sub>).</p><p><span class=\"paragraph-number\">[0034]   </span><figref>Figure 3</figref> finally shows how a seventh set of (for example) eighteen health indexes, indicated with HI<sub>7,1</sub> - HI<sub>7,18</sub>, is generated by executing the set of feature extraction algorithms 410 on the pre-processed signal sʺʺ<sub>1</sub>, respectively. The health indexes HI<sub>7,1</sub> - HI<sub>7,18</sub> are associated with a seventh acquisition index AcqID<sub>7</sub>, which is associated with the triad (sensor A<sub>1</sub>, zone Z<sub>1</sub>, asynchronous processing) .</p><p><span class=\"paragraph-number\">[0035]   </span>Similarly, the processing of the primary signal s<sub>2</sub> generated by the sensor A<sub>2</sub> leads to the generation of further sets of health indexes, associated with corresponding acquisition indexes. Furthermore, as explained also below, the numbering of the acquisition indexes associated with a single sensor may not be consecutive.</p><p><span class=\"paragraph-number\">[0036]   </span>In practice, each acquisition index is relative to only one corresponding component or a corresponding zone, as well as to only one corresponding preliminary processing mode to be chosen from synchronous processing 100, envelope processing 200 (alternatively, based on the aforementioned high-frequency sampled version of the primary signal s<sub>i</sub> and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>, or on the low-frequency sampled version of the primary signal s<sub>i</sub>), time history-based processing 300 (alternatively, based on the aforementioned high-frequency sampled version of the primary signal s<sub>i</sub> and on the aforementioned filtered sampled version of the primary signal s<sub>i</sub>, or on the low-frequency sampled version of the primary signal s<sub>i</sub>) and asynchronous processing 400. Furthermore, each acquisition index is biunivocally associated with a corresponding set of health indexes. For example, in the following, it is assumed, unless otherwise specified, that the processing system 10 is configured to calculate health indexes relating to one hundred and eighty acquisition indexes, on the basis of the primary signals generated by the thirteen sensors A<sub>1</sub> - A<sub>13</sub>. However, it is possible that health indexes associated with one or more acquisition indexes are discarded, for example because they are irrelevant, unreliable or not applicable.</p><p><span class=\"paragraph-number\">[0037]   </span>As mentioned above, the processing system 10 stores in the storage system 11 all the health indexes that are calculated as they are calculated during the time intervals of duration ΔT that follow each other during the flights of the helicopter HC<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0038]   </span>Furthermore, as explained in more detail below, the processing system 10 stores flight parameter values in the storage system 11, which are acquired by means of additional sensors (indicated with 8 in <figref>Figure 1</figref>), which are coupled to the helicopter HC<sub>1</sub> and are able to detect, for example, the temperature and/or pressure of the lubricating oil, the torque transmitted by the main rotor, the flight speed, the attitude of the aircraft, etc.).</p><p><span class=\"paragraph-number\">[0039]   </span>In addition, for each time interval of duration ΔT, the processing system 10 stores in the storage system 11 the pre-processed signals on the basis of which the health indexes for that time interval have been calculated. In particular, considering a generic time interval of duration ΔT, the processing system 10 stores in the storage system 11 the pre-processed signals relating to this time interval, overwriting the pre-processed signals relating to the previous time interval of duration ΔT.</p><p><span class=\"paragraph-number\">[0040]   </span>Consequently, at the end of each flight, the storage system 11 of the helicopter HC<sub>1</sub> stores the pre-processed signals relating to the last time interval of duration ΔT of the flight of the helicopter HC<sub>1</sub>; in the following reference is made to these pre-processed signals as the final time series TH<sub>1,p</sub>, with <i>p</i>=1, ..., Pmax, wherein Pmax is for example equal to the total number of acquisition indexes AcqID. For example, referring for simplicity's sake only to the sensor A<sub>1</sub>, and more particularly to the acquisition AcqID<sub>1</sub>-AcqID<sub>7</sub> shown in <figref>Figure 3</figref>, it occurs that the final time series TH<sub>1,1</sub>-TH<sub>1,7</sub> are formed by the samples, respectively, of the pre-processed signals s'<sub>1,1</sub>, s'<sub>1,2</sub>, s\"<sub>1,3,hf</sub>, s\"<sub>1,3,lf</sub>, s‴<sub>i,hf</sub>, s‴<sub>1,lf</sub> and sʺʺ<sub>1</sub> generated by the processing system 10 during the last time interval of duration ΔT of the flight of the helicopter HC<sub>1</sub>, on the basis of which the health indexes relating to the aforementioned last time interval of duration ΔT of the flight were then calculated. In other words, a corresponding pre-processed signal is stored for each acquisition index; only the pre-processed signals s\"<sub>1,3,filt</sub> and s‴<sub>1,filt</sub> are not stored. The final time series TH<sub>1,1</sub>-TH<sub>1,7</sub> are therefore successions of acceleration samples generated starting from the primary signal s<sub>1</sub> generated by the sensor A<sub>1</sub>, by means of different processing.</p><p><span class=\"paragraph-number\">[0041]   </span>In the presence of several helicopters, equipped for example in the same way (same sensors), it is thus possible to obtain what is shown in <figref>Figure 4</figref>, in which for simplicity's sake reference is made, in addition to the helicopter HC<sub>1</sub>, only to a further helicopter HC<sub>2</sub>, identical to the helicopter HC<sub>1</sub> and equipped with a monitoring system identical to the monitoring system MS of the helicopter HC<sub>1</sub>, as well as with a processing system, a storage system and additional sensors respectively identical to the processing system 10, the storage system 11 and the additional sensors 8 of the first helicopter HC<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0042]   </span>In detail, for each flight of the helicopter HC<sub>1</sub>, the processing system 10 of the helicopter HC<sub>1</sub> stores in the storage system 11 a corresponding set of final time series, collectively referred to as SET_TH<sub>1</sub>. Similarly, for each flight of the helicopter HC<sub>2</sub>, the processing system of the helicopter HC<sub>2</sub> stores in the corresponding storage system a corresponding set of final time series, collectively referred to as SET_TH<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0043]   </span>In addition, for each flight of the helicopter HC<sub>1</sub>, the processing system 10 of the helicopter HC<sub>1</sub> stores in the storage system 11 a respective flight data structure FDS<sub>1</sub>; similarly, for each flight of the helicopter HC<sub>2</sub>, the processing system of the helicopter HC<sub>2</sub> stores in the corresponding storage system 11 a respective flight data structure FDS<sub>2</sub>.</p><p><span class=\"paragraph-number\">[0044]   </span>The flight data structures FDS<sub>1</sub>, FDS<sub>2</sub> have the same form, which is now described with reference to the flight data structure FDS<sub>1</sub> as an example.</p><p><span class=\"paragraph-number\">[0045]   </span>As shown in <figref>Figure 5</figref>, the flight data structure FDS<sub>1</sub> comprises a plurality of portions, which are referred to as the elementary data structures (indicated with DS).</p><p><span class=\"paragraph-number\">[0046]   </span>Each elementary data structure DS is associated to a corresponding acquisition index; consequently, referring generically to the j-th elementary data structure DS<sub>j</sub>, it is associated to the j-th acquisition index AcqID<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0047]   </span>As shown in <figref>Figure 6</figref>, which refers to the elementary data structure DS<sub>1</sub>, and thus to the acquisition index AcqID<sub>1</sub>, each elementary data structure DS<sub>j</sub> stores, for each time interval of duration ΔT, a corresponding set of data, in the following indicated for brevity's sake as item U<sub>w</sub>, wherein w indexes the items of the elementary data structure and therefore also the time intervals of duration ΔT; for example, in <figref>Figure 6</figref> assumption is made that the elementary data structure DS<sub>1</sub> comprises thirty items U<sub>w</sub>.</p><p><span class=\"paragraph-number\">[0048]   </span>The item U<sub>w</sub> comprises a time interval indication (indicated with T<sub>w</sub>), the acquisition index acqID<sub>j</sub> (for brevity's sake indicated in <figref>Figures 5</figref> and <figref>6</figref> only by a number equal to index j), the set of health indexes associated with the acquisition index AcqID<sub>j</sub> and calculated on the basis of the corresponding primary signal acquired during said time interval, as well as the set of flight parameter values (indicated with SET_ΔT<sub>w</sub>) acquired by means of the additional sensors 8 during such time interval, and more precisely during the temporal sub-domain to which the portion of the primary signal used to calculate the aforementioned set of health indexes associated with the acquisition index AcqID<sub>j</sub> refers.</p><p><span class=\"paragraph-number\">[0049]   </span>In particular, the health indexes are columnarised in eighteen columns labelled as HI<sub>x,1</sub> - Hix,18<sub>x,18</sub> respectively, so that the elementary data structures DS of the flight data structure FDS<sub>1</sub> can also be columnarised, as shown in <figref>Figure 5</figref>. The identification of each health index is made by replacing the parameter \"x\" with the value of the parameter j indexing the acquisition index AcqID<sub>j</sub> and thus the elementary data structure DS<sub>j</sub> (in the case of <figref>Figure 6</figref>, we have x=j=1); moreover, within a generic u-th column (with u=1, ..., 18) of the j-th elementary data structure DS<sub>j</sub>, the health indexes are indicated as HI<sub>j,u</sub>(w), wherein w indicates the time interval to which the health index refers, and therefore the item U<sub>w</sub> to which the health index belongs.</p><p><span class=\"paragraph-number\">[0050]   </span>Again with reference to <figref>Figure 5</figref>, as mentioned earlier, the columns in which the health indexes are stored are shared between the elementary data structures DS of the flight data structure FDS<sub>1</sub>. Consequently, considering the u-th column, the meaning of the health indexes stored there varies along the column, as a function of the elementary data structures DS to which these health indexes belong.</p><p><span class=\"paragraph-number\">[0051]   </span><figref>Figure 5</figref> also shows how the elementary data structures relating to some acquisition indexes (for example, the second acquisition index AcqID<sub>2</sub>) may not be included in the flight data structures FDS<sub>1</sub>, for example because they are judged to be irrelevant or unreliable, the latter occurring for example in the case of malfunctioning of the sensor associated to the corresponding acquisition index. In the following, however, it is assumed for simplicity's sake that no elementary data structure is discarded.</p><p><span class=\"paragraph-number\">[0052]   </span>In addition, in the example shown in <figref>Figure 5</figref>, it occurs that, net of any acquisition indexes not included in the flight data structure FDS<sub>1</sub>, the elementary data structures DS<sub>1</sub>-DS<sub>44</sub>, relative respectively to the acquisition indexes AcqID<sub>1</sub>-AcqID<sub>44</sub>, form a first portion P<sub>1</sub> of the flight data structure FDS<sub>1</sub> and are relative to the synchronous processing 100, that is, they store acquisition indexes associated to sets of health indexes obtained by carrying out synchronous processing 100; the elementary data structures DS<sub>45</sub>-DS<sub>60</sub>, respectively relative to the acquisition indexes AcqID<sub>45</sub>-AcqID<sub>60</sub>, form a second portion P<sub>2</sub> of the flight data structure FDS<sub>1</sub> and are relative to the asynchronous processing 400, i.e. they store acquisition indexes associated to sets of health indexes obtained by carrying out asynchronous processing 400; the elementary data structures DS<sub>61</sub>-DS<sub>100</sub>, respectively relative to the acquisition indexes AcqID<sub>61</sub>-AcqID<sub>100</sub>, form a third portion P<sub>3</sub> of the flight data structure FDS<sub>1</sub> and are relative to the processing based on the time histories 300, that is they store acquisition indexes associated to sets of health indexes obtained by carrying out the processing based on the time histories 300; and finally, the elementary data structures DS<sub>101</sub>-DS<sub>180</sub>, respectively relative to the acquisition indexes AcqID<sub>101</sub>-AcqID<sub>180</sub>, form a fourth portion P<sub>4</sub> of the flight data structure FDS<sub>1</sub> and are relative to the envelope processing 200, i.e. they store acquisition indexes associated to sets of health indexes obtained by carrying out envelope processing 200.</p><p><span class=\"paragraph-number\">[0053]   </span>Having said that, and as previously mentioned, having the aforementioned health indexes available, it is possible to detect possible malfunctions in the transmission system 1. For example, it is known to analyse health indexes in a deterministic way, e.g. by comparing them with corresponding thresholds (the latter pre-set, for example, manually), or by checking whether each health index complies with a corresponding rule. This approach is characterised by an exact knowledge of the rules/thresholds that are applied, but it is not very flexible and tends to generate a high number of false positives; moreover, this approach is affected by the dispersion induced on the health indexes by the different operating conditions of the transmission system.</p><p><span class=\"paragraph-number\">[0054]   </span>Aim of the present invention is therefore to provide a method for detecting anomalies which allows to overcome at least in part the drawbacks of the prior art.</p><p><span class=\"paragraph-number\">[0055]   </span>According to the present invention, there are provided a method and a system for detecting anomalies, as defined in the appended claims.</p><p><span class=\"paragraph-number\">[0056]   </span>For a better understanding of the present invention, embodiments thereof are now described, purely by way of nonlimiting example, with reference to the accompanying drawings, in which:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1</figref> shows schematically a perspective view of a transmission system;</li><br/><li> <figref>Figure 2</figref> shows a block diagram relative to signal processing operations;</li><br/><li> <figref>Figure 3</figref> shows a block diagram showing the relationships between a sensor, some components of the transmission system shown in <figref>Figure 1</figref> and corresponding health indexes;</li><br/><li> <figref>Figure 4</figref> shows a block diagram showing the relationships between two helicopters and corresponding data structures;</li><br/><li> <figref>Figure 5</figref> shows a flight data structure;</li><br/><li> <figref>Figure 6</figref> shows in detail a portion of the flight data structure shown in <figref>Figure 5</figref>;</li><br/><li> <figref>Figures 8</figref> and <figref>9</figref> show diagrams of data structures relative to helicopter training flights;</li><br/><li> <figref>Figures 10</figref> and <figref>11</figref> show diagrams of data structures relative to unknown flights of the helicopter to which <figref>Figures 8</figref> and <figref>9</figref> refer;</li><br/><li> <figref>Figure 7</figref>, <figref>12</figref>, <figref>14, 15</figref> and <figref>17</figref> shows a block diagram relative to operations according to the present method;</li><br/><li> <figref>Figures 13A</figref> and <figref>19</figref> show block diagrams of classification operations;</li><br/><li> <figref>Figure 13B</figref> shows an example of an output matrix generated by a classifier;</li><br/><li> <figref>Figures 16</figref> and <figref>20</figref> show block diagrams relative to data vectors generated according to the present method;</li><br/><li> <figref>Figure 18</figref> shows a Cartesian plane relative to a two-dimensional hyperspace, showing boundaries of confidence hyperspaces.</li></ul></p><p><span class=\"paragraph-number\">[0057]   </span>The present method is inspired by the possibility of having the aforementioned flight data structures available, which typically refer to helicopters that did not show any problems during the time periods to which the flight data structures refer; consequently, the health indexes and the flight parameter values contained in the flight data structures stored in the helicopter storage systems, as well as the final time series, typically refer to time periods in which the helicopters have functioned correctly.</p><p><span class=\"paragraph-number\">[0058]   </span>That being said, the present method can be carried out by a computer 19 (shown schematically in <figref>Figure 4</figref>) which is provided with the flight data structures FDS relating to the flights of a number of helicopters. Furthermore, the computer 19 is provided, for each flight of each helicopter, with the corresponding set of final time series SET_TH, relating to the last time interval of duration ΔT of the flight of the helicopter.</p><p><span class=\"paragraph-number\">[0059]   </span>In the following, the method is described, without loss of generality, with reference to the helicopter HC<sub>1</sub> only. As described below, the method provides, among other things, training a plurality of classifiers on the basis of the flight data structures FDS<sub>1</sub> relating to several flights of the helicopter HC<sub>1</sub>, assuming that the transmission system 1 of the helicopter HC<sub>1</sub> has functioned correctly during these flights. To this end, in the following, it is assumed that each flight data structure FDS<sub>1</sub> includes elementary data structures DS<sub>j</sub> relating to, for example, one hundred and eighty acquisition indexes AcqID<sub>j</sub> (with j=1, ..., 180); moreover, it is assumed, purely by way of example, that the sets of flight parameter values SET_ΔT (shown in <figref>Figure 6</figref>) are formed by vectors of eighteen elements, i.e. it is assumed that the flight parameters are eighteen in number; consequently, leaving aside the indications relative to the acquisition index AcqID<sub>j</sub> and to the time interval, each item U<sub>w</sub> of each elementary data structure DS<sub>j</sub> of each flight data structure FDS<sub>1</sub> is a vector of thirty-six elements. In the following, the eighteen flight parameters are indicated individually with FP<sub>1</sub>, ..., FP<sub>18</sub>.</p><p><span class=\"paragraph-number\">[0060]   </span>In detail, as shown in <figref>Figure 7</figref>, the method provides acquiring and merging, by the computer 19, flight data structures FDS<sub>1</sub> relating to flights of the helicopter HC<sub>1</sub> in which the transmission system 1 has functioned correctly. In this way, the computer 19 acquires an aggregate flight data structure, which in the following is referred to as the training flight data structure M_FDS<sub>1</sub>, which has the same structure as the flight data structure FDS<sub>1</sub> and thus comprises one hundred and eighty elementary data structures, again indicated with DS.</p><p><span class=\"paragraph-number\">[0061]   </span>For example, <figref>Figure 8</figref> shows the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, which is obtained by aggregating (i.e., by columnarising in succession) the elementary data structures DS<sub>1</sub> of the flight data structures FDS<sub>1</sub> relating to flights of the helicopter HC<sub>1</sub>, so that the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub> comprises all items U<sub>w</sub> of the elementary data structures DS<sub>1</sub> of the flight data structures FDS<sub>1</sub> relating to flights of the helicopter HC<sub>1</sub>, columnarised together.</p><p><span class=\"paragraph-number\">[0062]   </span>In particular, with reference to a succession of flights of the helicopter HC<sub>1</sub>, the elementary data structures DS<sub>1</sub> of the flight data structures FDS<sub>1</sub> relative to flights of the helicopter HC<sub>1</sub> are columnarised in sequence, in the same temporal order in which the flights of the helicopter HC<sub>1</sub> took place; in this way, the indications of the time intervals of the items U<sub>w</sub> of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub> define a monotonic temporal succession. The same considerations apply to any generic j-th elementary data structure DS<sub>j</sub> of the training flight data structure M_FDS<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0063]   </span>By way of example only, each elementary data structure DS<sub>j</sub> of the training flight data structure M_FDS<sub>1</sub> comprises five hundred and forty-six items U<sub>w</sub>, which are still indexed by the index w, with w=1, ..., 546.</p><p><span class=\"paragraph-number\">[0064]   </span>In addition, the method provides that the computer 19 acquires, for each of the aforementioned flights of the helicopter HC<sub>1</sub> in which the transmission system 1 has functioned correctly, also the corresponding set of final time series SET_TH<sub>1</sub>. In this way, the computer 19 is provided with the sets of the final time series SET_TH<sub>1</sub> relating to the aforementioned flights of the helicopter HC<sub>1</sub>, which are referred to in the following as the group of sets of final time series M_SET_TH<sub>1</sub>, an example of which is schematically shown in <figref>Figure 9</figref>. In this example, the individual sets of the final time series SET_TH<sub>1</sub> are indicated with SET_TH<sub>1,m</sub>, with m=1, ..., Nf. Furthermore, the single final time series of the m-th set are indicated with TH<sub>1,1</sub>(m)-TH<sub>1,Pmax</sub>(m) and are associated with the time interval to which these final time series refer.</p><p><span class=\"paragraph-number\">[0065]   </span>Again with reference to <figref>Figure 7</figref>, the operations that led to the acquisition, by the computer 19, of the training flight data structure M_FDS<sub>1</sub> and of the group of sets of final time series M_SET_TH<sub>1</sub> are indicated with 595.</p><p><span class=\"paragraph-number\">[0066]   </span>Furthermore, the present method provides analysing a number of unknown flights of the helicopter HC<sub>1</sub>, i.e. a number of flights following the aforementioned flights of the helicopter HC<sub>1</sub>, of which it is not known a priori whether the transmission system 1 has functioned correctly. With respect to this number of unknown flights, the computer 19 acquires, in the same manner as described with respect to block 595, a flight data structure M_FDS<sub>x</sub>, which is hereinafter referred to as the unknown flight data structure M_FDS<sub>x</sub>, and a group of sets of final time series M_SET_TH<sub>x</sub>, which is hereinafter referred to as the group of sets of final unknown time series M_SET_TH<sub>x</sub>.</p><p><span class=\"paragraph-number\">[0067]   </span><figref>Figure 10</figref> shows an example of the elementary data structure DS<sub>1</sub> relating to the unknown flight data structure M_FDS<sub>x</sub>, which is assumed to include a number of items U<sub>w</sub> equal to Nx; the health indexes are indicated in the same way as in <figref>Figure 8</figref>, but with the addition of a superscript, as are the sets of flight parameters. <figref>Figure 11</figref> shows an example of the group of sets of final unknown time series M_SET_TH<sub>x</sub>, wherein the sets of final unknown time series are indicated with SET_TH<sub>x,m</sub>, with m=1, ..., Nfx; in addition, the single final unknown time series are indicated with TH'<sub>1,1</sub> (m) - TH'<sub>1,Pmax</sub> (m) and are associated with the time interval to which these final unknown time series refer.</p><p><span class=\"paragraph-number\">[0068]   </span>Again with reference to <figref>Figure 7</figref>, the operations that led to the acquisition of the unknown flight data structure M_FDS<sub>x</sub> and to the group of sets of final unknown time series M_SET_TH<sub>x</sub> are indicated with 597.</p><p><span class=\"paragraph-number\">[0069]   </span>The present method further provides performing a processing (block 600) based on the health indexes stored in the training flight data structure M_FDS<sub>1</sub> and in the unknown flight data structure M_FDS<sub>x</sub> and a processing (block 700) based on the group of sets of final time series M_SET_TH<sub>1</sub> and on the group of sets of final unknown time series M_SET_TH<sub>x</sub>.</p><p><span class=\"paragraph-number\">[0070]   </span>In more detail, as shown in <figref>Figure 12</figref>, processing 600 based on the health indexes provides performing a first and second classification 610, 620, as described hereinbelow.</p><p><span class=\"paragraph-number\">[0071]   </span>In particular, the first classification 610 comprises generating (block 601), for each acquisition index AcqID<sub>j</sub>, a corresponding first-type classifier (shown symbolically in <figref>Figure 13A</figref>, where it is indicated with AE<sub>j</sub>), which is an autoencoder type classifier.</p><p><span class=\"paragraph-number\">[0072]   </span>For example, referring to the acquisition index AcqID<sub>1</sub>, computer 19 performs the operations shown in <figref>Figure 14</figref>. In particular, the computer 19 selects (block 602), starting from the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, a plurality of observation matrices OM, as shown in <figref>Figure 8</figref>.</p><p><span class=\"paragraph-number\">[0073]   </span>For example, each observation matrix OM may be formed by the health indexes and by the sets of values of the flight parameters of thirty-six consecutive items U<sub>w</sub> of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, i.e. it may have a square shape, since, as explained above, by way of example only, it has been assumed that, referring to the generic item U<sub>w</sub>, it comprises the eighteen health indexes HI<sub>1,1</sub>(w)- HI<sub>1,18</sub>(w) and the eighteen flight parameter values FP<sub>1</sub> - FP<sub>18</sub> of the set SET_ΔT<sub>w</sub>.</p><p><span class=\"paragraph-number\">[0074]   </span>Still by way of example, the selection of the observation matrices OM may take place through the use of a mobile window MW (shown in <figref>Figure 8</figref>), which is translated along the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, with a step equal to a single item U<sub>w</sub> and has precisely the dimension of thirty-six items per thirty-six elements (eighteen health indexes and eighteen flight parameters); in this case, for each position assumed by the mobile window MW with respect to the elementary data structure DS<sub>1</sub>, the mobile window MW selects a corresponding portion of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, the selected portion forming a corresponding observation matrix OM.</p><p><span class=\"paragraph-number\">[0075]   </span>In particular, <figref>Figure 8</figref> shows the mobile window MW in the respective second position (in solid line) and in the respective third position (in broken line), in which it allows the selection, respectively, of a pair of observation matrices indicated with OM<sub>2</sub> and OM<sub>3</sub>.</p><p><span class=\"paragraph-number\">[0076]   </span>In the following, referring to the generic item U<sub>w</sub> of the elementary data structure DS<sub>j</sub> relating to the j-th acquisition index AcqIDj of the training flight data structure M_FDS<sub>1</sub>, reference is made to the corresponding record RC<sub>w</sub> to indicate the set of the eighteen health indexes HI<sub>j,1</sub>(w)- HI<sub>j,18</sub>(w) and of the eighteen flight parameter values FP<sub>1</sub> - FP<sub>18</sub> of the set SET_ΔT<sub>w</sub>.</p><p><span class=\"paragraph-number\">[0077]   </span>Subsequently, for each acquisition index AcqID<sub>j</sub>, the computer 19 trains (block 603, <figref>Figure 14</figref>) the first-type classifier AE<sub>j</sub> on the basis of the observation matrices OM selected starting from the corresponding elementary data structure DS<sub>j</sub> of the training flight data structure M_FDS<sub>1</sub>, in a per se known manner. In this regard, being an autoencoder-type classifier, each first-type classifier AE<sub>j</sub> comprises a number of inputs, for example, equal to thirty-six (that is, equal to the dimensions of each observation matrix OM), a number of outputs equal to the number of inputs and a number of hidden layers, for example, equal to five; for simplicity's sake, it is assumed that this number of inputs and the number of hidden layers do not vary as the acquisition index AcqID<sub>j</sub> varies. Furthermore, in a per se known manner, the first-type classifier AE<sub>j</sub> is defined by a plurality of weights, relating to the links present between inputs, outputs and hidden layers. Consequently, the training of each first-type classifier AE<sub>j</sub> on the basis of the corresponding observation matrices OM previously selected provides iteratively refining the values of the weights.</p><p><span class=\"paragraph-number\">[0078]   </span>In practice, for each acquisition index AcqID<sub>j</sub>, the corresponding first-type classifier AE<sub>j</sub> is trained to be a function also of the evolution over time of the health indexes HI<sub>j,1</sub>- HI<sub>j,18</sub> that are relative to this acquisition index AcqID<sub>j</sub>, as well as the evolution over time of the values of the flight parameter sets SET_ΔT.</p><p><span class=\"paragraph-number\">[0079]   </span>Again with reference to <figref>Figure 12</figref>, the second classification 620 comprises generating (block 621), for each acquisition index AcqID<sub>j</sub>, a first, a second, a third and a fourth corresponding second-type classifier (shown symbolically in <figref>Figure 13A</figref>, where they are indicated respectively with DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub> and DBUC4<sub>j</sub>), which are of unsupervised type.</p><p><span class=\"paragraph-number\">[0080]   </span>In particular, in the following assumption is made that the first and the second second-type classifier DBUC1<sub>j</sub>, DBUC2<sub>j</sub> are respectively an \"isolation forest\" type (iFOREST) classifier and an \"angle-based\" outlier detection (ABOD) classifier; furthermore, assumption is made that the third and the fourth second-type classifier DBUC3<sub>j</sub>, DBUC4<sub>j</sub> are respectively a \"K-nearest neighbours\" (K-NN) classifier and a \"local outlier factor\" (LOF) classifier.</p><p><span class=\"paragraph-number\">[0081]   </span>For example, referring to the acquisition index AcqID<sub>1</sub>, computer 19 performs the operations shown in <figref>Figure 15</figref>. In particular, the computer 19 selects (block 622) the portion of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub> that includes the health indexes HI<sub>1,1</sub>-HI<sub>1,18</sub> and the sets of flight parameter values SET_ΔT, then discards the indications relating to the time intervals and to the acquisition index AcqID<sub>1</sub>. In practice, considering the example shown in <figref>Figure 8</figref>, the portion of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub> selected by the computer 19 has dimensions equal to five hundred and forty-six per thirty-six.</p><p><span class=\"paragraph-number\">[0082]   </span>Subsequently, referring for example again to the acquisition index AcqID<sub>1</sub>, in a per se known manner, the computer 19 trains (block 623) each of the first, the second, the third and the fourth second-type classifier DBUC1<sub>1</sub>, DBUC2<sub>1</sub>, DBUC3<sub>1</sub>, DBUC4<sub>1</sub> relating to the acquisition index AcqID<sub>1</sub>, on the basis of the selected portion of the elementary data structure DS<sub>1</sub> of the training flight data structure M_FDS<sub>1</sub>, which represents a set of training data; the health indexes HI<sub>1,1</sub> (w) -HI<sub>1,18</sub> (w) and the sets of the flight parameter values SET_ΔT<sub>w</sub> of each w-th item U<sub>w</sub> of the elementary data structure DS<sub>1</sub> (i.e., each record RC<sub>w</sub>) represent a corresponding basic unit of this training data set.</p><p><span class=\"paragraph-number\">[0083]   </span>In this way, each of the first, the second, the third and the fourth second-type classifier DBUC1<sub>1</sub>, DBUC2<sub>1</sub>, DBUC3<sub>1</sub>, DBUC4<sub>1</sub> relating to the acquisition index AcqID<sub>1</sub> determines, in a per se known manner, the statistical properties characterising the so-called healthy distribution, i.e. the statistical properties of the set of records RC<sub>w</sub> employed during the training.</p><p><span class=\"paragraph-number\">[0084]   </span>In more detail, the first and the fourth second-type classifiers DBUC1<sub>j</sub>, DBUC4<sub>j</sub> are so-called \"density-based\" classifiers, i.e. they are classifiers that detect high and low density zones of the training data set and classify as anomalies the input vectors that fall within low density zones. The second and the third second-type classifiers DBUC2<sub>j</sub>, DBUC3<sub>j</sub> are \"distance-based\" classifiers, i.e. they are classifiers that determine the centre of the cluster formed by the set of the training data and classify as anomalies the input vectors that are farther than a certain distance from this centre.</p><p><span class=\"paragraph-number\">[0085]   </span>In addition, for each acquisition index AcqID<sub>j</sub>, the corresponding first, second, third and fourth second-type classifier DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub>, DBUC4<sub>j</sub> are trained independently from the time evolution of the health indexes HI<sub>j,1</sub> (w) -HI<sub>j,18</sub> (w) relating to that acquisition index AcqID<sub>j</sub>, as well as independently from the time evolution of the values of the flight parameter sets SET_ΔT<sub>w</sub>.</p><p><span class=\"paragraph-number\">[0086]   </span>Again with reference to <figref>Figure 12</figref>, the first classification 610 envisages performing the following operations after performing the operations referred to in block 601.</p><p><span class=\"paragraph-number\">[0087]   </span>In detail, for each acquisition index AcqID<sub>j</sub>, the computer 19 selects (block 604), starting from the elementary data structure DS<sub>j</sub> relating to the acquisition index AcqID<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, a plurality of respective observation matrices OMX, in the same way as described with reference to the elementary data structure DS<sub>j</sub> relating to the acquisition index AcqID<sub>j</sub> of the training flight data structure M_FDS<sub>1</sub>, therefore by translating the aforementioned mobile window MW along the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, with a step equal to a single item U. In this way, for each position assumed by the mobile window MW with respect to the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, the mobile window MW selects a corresponding portion of the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, which forms a corresponding observation matrix OMX.</p><p><span class=\"paragraph-number\">[0088]   </span>Each observation matrix OMX selected from the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub> has dimensions equal to thirty-six per thirty-six. In the following, observation matrices OMX selected starting from the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub> are referred to the unknown observation matrices OMX; furthermore, the records of the unknown flight data structure M_FDS<sub>x</sub> are indicated with RCX.</p><p><span class=\"paragraph-number\">[0089]   </span>Two examples of unknown observation matrices, indicated respectively with OMX<sub>1</sub>, OMX<sub>2</sub> and relating to the acquisition index AcqID<sub>1</sub> are shown in <figref>Figure 10</figref>; they correspond to the selections made by the mobile window MW when it assumes the first position (in solid line) and the second position (in broken line), respectively.</p><p><span class=\"paragraph-number\">[0090]   </span>Subsequently, for each acquisition index AcqID<sub>j</sub>, the computer 19 applies (block 605, <figref>Figure 12</figref>) the corresponding first-type classifier AE<sub>j</sub> to the corresponding unknown observation matrices OMX, selected starting from the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, so as to obtain, for each of these unknown observation matrices OMX, a corresponding output matrix MV<sub>Aj</sub>.</p><p><span class=\"paragraph-number\">[0091]   </span>An example of an output matrix MV<sub>Aj</sub> is shown in <figref>Figure 13B</figref>, with respect to the acquisition index AcqID<sub>1</sub> (in this example, the values of the health indexes and of the sets of flight parameter values contained in the output matrix MV<sub>A1</sub> are marked with an asterisk).</p><p><span class=\"paragraph-number\">[0092]   </span>The output matrix MV<sub>Aj</sub> may be obtained for example by initial generation, by the first-type classifier AE<sub>j</sub> and as a function of the unknown observation matrix OMX, of a reconstructed matrix (not shown) having the same dimensions as the unknown observation matrix OMX, and subsequent calculation of the difference between the reconstructed matrix and the unknown observation matrix OMX; in this way, the output matrix MV<sub>Aj</sub> is formed by thirty-six per thirty-six elements, each of which is equal to a respective value, which represents a kind of elementary reconstruction error and is indicative of the probability that the corresponding element of the unknown observation matrix OMX is anomalous with respect to the training of the first-type classifier AE<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0093]   </span>Then, starting from each output matrix MV<sub>Aj</sub>, computer 19 determines (block 606) a corresponding first detection vector V<sub>Aj</sub>, obtained by column-wise sum of the elements of the output matrix MV<sub>Aj</sub>, such that the first detection vector V<sub>Aj</sub> is formed by thirty-six elements; in addition, the computer 19 calculates, for each output matrix MV<sub>Aj</sub>, a corresponding first partial anomaly index ANV1<sub>j</sub>, as explained below.</p><p><span class=\"paragraph-number\">[0094]   </span>In particular, again with reference to the generic j-th acquisition index AcqID<sub>j</sub>, each first detection vector V<sub>Aj</sub> is formed by respective thirty-six elements, each of which is respectively associated to a corresponding health index HI<sub>j,1</sub> - HI<sub>j,18</sub> or to a corresponding flight parameter FP<sub>1</sub> - FP<sub>18</sub>. An example of the first detection vector V<sub>Aj</sub> is shown in <figref>Figure 16</figref>; furthermore, the numerical values of the thirty-six elements V<sub>Aj</sub> (1), ..., V<sub>Aj</sub> (36) of the first detection vector V<sub>Aj</sub> are shown symbolically in <figref>Figure 16</figref>. In addition, <figref>Figure 16</figref> shows the associations present between each of the thirty-six elements V<sub>Aj</sub> (1), ..., V<sub>Aj</sub> (36) of the first detection vector V<sub>Aj</sub> and the corresponding health index HI<sub>j,1</sub> - HI<sub>j,18</sub> or flight parameter FP<sub>1</sub> - FP<sub>18</sub>.</p><p><span class=\"paragraph-number\">[0095]   </span>In more detail, each of the thirty-six elements V<sub>Aj</sub>(1), ..., V<sub>Aj</sub> (36) of the first detection vector V<sub>Aj</sub> has a value that represents a corresponding anomaly estimate, since it is indicative of the probability that the thirty-six values of the corresponding health index HI<sub>j,1</sub> - HI<sub>j,18</sub> or flight parameter FP<sub>1</sub> - FP<sub>18</sub> contained in the unknown observation matrix OMX to which the first-type classifier AE<sub>j</sub> has been applied exhibit anomalous behaviour compared to the training to which the first-type classifier AE<sub>j</sub> has been subjected. Furthermore, the first detection vector V<sub>Aj</sub> can be associated, for example, with the time interval to which the first record RCX of the unknown observation matrix OMX refers.</p><p><span class=\"paragraph-number\">[0096]   </span>In addition, for each first detection vector V<sub>Aj</sub>, the corresponding first partial anomaly index ANV1<sub>j</sub> is calculated by summing the values of the thirty-six elements of the first detection vector V<sub>Aj</sub>; in this way, the first partial anomaly index ANV1<sub>j</sub> is indicative of the probability that the unknown observation matrix OMX is, overall, anomalous and is associated with the same time interval as the first detection vector V<sub>Aj</sub>.</p><p><span class=\"paragraph-number\">[0097]   </span>Again with reference to <figref>Figure 12</figref>, the second classification 620 envisages performing the following operations after performing the operations referred to in block 621.</p><p><span class=\"paragraph-number\">[0098]   </span>In detail, for each acquisition index AcqID<sub>j</sub>, the computer 19 selects (block 624), starting from the elementary data structure DS<sub>j</sub> relative to the acquisition index AcqID<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, single records RCX of this elementary data structure DS<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0099]   </span>Subsequently, the computer 19 applies (block 625) to each of the selected records RCX the first, the second, the third and the fourth second-type classifier DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub> and DBUC4<sub>j</sub> relating to the acquisition index AcqID<sub>j</sub>, so as to obtain, respectively, a first, a second, a third and a fourth value V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub>, to which reference is made respectively as the first, second, third and fourth overall unsupervised classification value V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub>, as shown qualitatively in <figref>Figure 13A</figref>.</p><p><span class=\"paragraph-number\">[0100]   </span>Considering each of the aforementioned first, second, third and fourth overall unsupervised classification values V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub>, it is a value that represents a corresponding anomaly estimate, since it is indicative of the probability, estimated by the corresponding second-type classifier, that the record RCX is overall anomalous with respect to the training to which said corresponding second-type classifier has been subjected.</p><p><span class=\"paragraph-number\">[0101]   </span>Then, for each record RCX, the computer 19 performs a normalization (block 626, <figref>Figure 12</figref>; optional) of the corresponding first, second, third and fourth overall unsupervised classification values V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub> (e.g., by subtraction of the mean and subsequent division of the result by the standard deviation) and subsequently calculates (block 627) a corresponding second partial anomaly index ANV2<sub>j</sub> (an example shown in <figref>Figure 16</figref>), as a function of the corresponding first, second, third and fourth overall unsupervised classification value V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub>, e.g. by averaging them.</p><p><span class=\"paragraph-number\">[0102]   </span>Since different second-type classifiers may have varying reliability (i.e., ability to detect anomalies), depending on the type of anomaly occurring, each second partial anomaly index ANV2<sub>j</sub> is more likely to correctly indicate the occurrence of an anomaly than the corresponding first, second, third and fourth overall unsupervised classification value V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub> and Vʺʺ<sub>Bj</sub>. Furthermore, each second partial anomaly index ANV2<sub>j</sub> is associated with the time interval to which the corresponding record RCX refers.</p><p><span class=\"paragraph-number\">[0103]   </span>Again with reference to <figref>Figure 12</figref>, the computer 19 associates (block 628) the first partial anomaly indexes ANV1<sub>j</sub> obtained by carrying out the operations referred to in block 606 with corresponding second partial anomaly indexes ANV2<sub>j</sub> obtained by carrying out the operations referred to in block 627, possibly after carrying out further normalisation operations of the first and second partial anomaly indexes ANV1<sub>j</sub>, ANV2<sub>j</sub>. In general, the exact mechanism of association is irrelevant for the purposes of the present invention.</p><p><span class=\"paragraph-number\">[0104]   </span>For example, considering any acquisition index AcqID<sub>j</sub> and considering any second partial anomaly index ANV2<sub>j</sub> calculated starting from a certain record RCX of the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, and thus associated to the time interval to which the corresponding record RCX refers, this second partial anomaly index ANV2<sub>j</sub> may be associated with the first partial anomaly index ANV1<sub>j</sub> which results to be associated with the same time interval to which the aforementioned certain record RCX refers, i.e. with the first partial anomaly index ANV1<sub>j</sub> which has been calculated starting from the unknown observation matrix OMX in which the aforementioned certain record RCX occupies the first row of the unknown observation matrix OMX.</p><p><span class=\"paragraph-number\">[0105]   </span>The computer 19 further associates to each pair formed by a first and a second partial anomaly index ANV1<sub>j</sub>, ANV2<sub>j</sub> associated between them a corresponding time interval, which may for example be equal to the time interval relating to the record RCX on the basis of which the second partial anomaly index ANV2<sub>j</sub> was calculated, which, as mentioned, coincides with the time interval associated with the first detection vector V<sub>Aj</sub> on the basis of which the first partial anomaly index ANV1<sub>j</sub> was calculated.</p><p><span class=\"paragraph-number\">[0106]   </span>Again with reference to the aforementioned association operation, it may result, depending on the position of the aforementioned predetermined row, in that some second partial anomaly indexes ANV2<sub>j</sub> cannot be associated with any corresponding first partial anomaly index ANV1<sub>j</sub>, e.g. because said second partial anomaly indexes ANV2<sub>j</sub> are relative to the last thirty-five records RCX of the elementary data structure DS<sub>j</sub> of the unknown flight data structure M_FDS<sub>x</sub>, in which case they may for example be discarded. These details are however irrelevant for the purpose of this method.</p><p><span class=\"paragraph-number\">[0107]   </span>Then, the computer 19 calculates (block 629), for each pair formed by a first and a second partial anomaly index ANV1<sub>j</sub>, ANV2<sub>j</sub> associated with each other, a corresponding anomaly index IND1<sub>j</sub> (one shown in <figref>Figure 16</figref>), which is relative to the j-th acquisition index AcqID<sub>j</sub> and is equal to an average of the first and the second partial anomaly index ANV1<sub>j</sub>, ANV2<sub>j</sub> associated with each other. The anomaly index IND1<sub>j</sub> is also associated with the time interval associated with the pair formed by the first and second partial anomaly index ANV1<sub>j</sub>, ANV2<sub>j</sub>, which is referred to in the following as the time interval TV1<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0108]   </span>The anomaly index IND1<sub>j</sub> is equal to a value that represents a refined estimate of the probability that an anomaly has occurred, since it benefits from the different capabilities of detecting anomalies that characterise the first and the second classification 610, 620 respectively. Furthermore, the anomaly index IND1<sub>j</sub> is associated with the corresponding first detection vector V<sub>Aj</sub>, i.e. the first detection vector V<sub>Aj</sub> used to calculate the first partial anomaly index ANV1<sub>j</sub>, whose thirty-six elements, as previously mentioned, are such that each of them represents an estimate of whether any anomaly is attributable to the corresponding health index HI<sub>j,1</sub> - HI<sub>j,18</sub> or flight parameter FP<sub>1</sub> - FP<sub>18</sub>.</p><p><span class=\"paragraph-number\">[0109]   </span>Again with reference to <figref>Figure 7</figref>, the aforementioned processing 700 based on the sets of the final time series is described below with reference to any of the final time series TH<sub>p</sub> (with p ranging between 1 and Pmax); however, the operations are iterated for all final time series TH<sub>1</sub>- TH<sub>Pmax</sub>.</p><p><span class=\"paragraph-number\">[0110]   </span>As shown in <figref>Figure 17</figref>, the computer 19 calculates (block 702) a corresponding reference series REF_TH<sub>p</sub>, e.g. by averaging the final time series TH<sub>1,p</sub> stored in the p-th column of the group of sets of final time series M_SET_TH<sub>1</sub> shown in <figref>Figure 9</figref>.</p><p><span class=\"paragraph-number\">[0111]   </span>Next, the computer 19 calculates (block 704) the so-called cepstrum (e.g. of order fifteen, i.e. including fifteen values) of the reference series REF_TH<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0112]   </span>Then, for each of the sets of final unknown time series SET_TH<sub>x,1</sub> - SET_TH<sub>x,Nfx</sub> of the group of sets of final unknown time series M_SET_TH<sub>x</sub>, the computer 19 performs what is described below with reference to a generic m-th set of final unknown time series SET_TH<sub>x,m</sub>; furthermore, in the following reference is made to the p-th final unknown time series TH'<sub>1,p</sub>(m) of the m-th set of final unknown time series SET_TH<sub>x,m</sub> as to the time series to be analysed.</p><p><span class=\"paragraph-number\">[0113]   </span>In detail, the computer 19 calculates (block 706) the cepstrum (e.g. of order fifteen) of the time series to be analysed.</p><p><span class=\"paragraph-number\">[0114]   </span>Subsequently, the computer 19 calculates (block 708) the so-called Martin distance between the cepstrum of the reference series REF_TH<sub>p</sub> and the cepstrum of the time series to be analysed, so as to obtain a first feature of the time series to be analysed, said first feature being equal to a value which is the higher the more the time series to be analysed is anomalous with respect to the corresponding reference series REF_TH<sub>p</sub>, and in particular the more the spectrum of the time series to be analysed is different with respect to the spectrum of the corresponding reference series REF_TH<sub>p</sub>. In this regard, it is anticipated that in general it is possible to adopt a quantity other than the Martin distance; in fact, for the purposes of the present method it is sufficient that the aforementioned first feature is indicative of the similarity between the spectrum of the time series to be analysed and the frequency behaviour (spectrum) of the reference series REF_TH<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0115]   </span>Furthermore, the computer 19 calculates (block 710) the maximum of the cross-correlation function between the time series to be analysed and the reference series REF_TH<sub>p</sub>, so as to obtain a second feature of the time series to be analysed, said second feature being equal to a value which is the lower the more anomalous the time series to be analysed is with respect to the corresponding reference series REF_TH<sub>p</sub>. Even in this case, we anticipate that it is possible to adopt a quantity other than the maximum of the cross-correlation function; in fact, for the purposes of this method it is sufficient that the aforementioned second feature is indicative of the similarity in time between the time series to be analysed and the reference series REF_TH<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0116]   </span>In practice, the operations described so far make it possible to extract a first and a second feature of the time series to be analysed, i.e. they make it possible to determine the position of a corresponding point P_TH<sub>p</sub> in the hyperplane (first feature, second feature), as shown in <figref>Figure 18</figref>.</p><p><span class=\"paragraph-number\">[0117]   </span>In addition, the computer 19 has a number of further classifiers, which are classifiers of the \"one-class support-vector machine (one-class SVM)\" type, and which are referred to as single-class classifiers.</p><p><span class=\"paragraph-number\">[0118]   </span>In particular, the computer 19 has, for each of the final time series TH<sub>p</sub> (with <i>p</i> ranging between 1 and Pmax), a corresponding single-class classifier SCLASS<sub>p</sub>, which has been trained in a per se known manner on the basis of the p-th final time series TH<sub>1,p</sub>(m) of the sets of final time series SET_TH<sub>1,1</sub> - SET_TH<sub>1,Nf</sub> of the group of sets of final time series M_SET_TH<sub>1</sub>, which, as explained above, is relative to flights where no anomalies occurred.</p><p><span class=\"paragraph-number\">[0119]   </span>In particular, considering the training of the p-th single-class classifier SCLASS<sub>p</sub> and referring to the training population (<figref>Figure 19</figref>) to indicate overall the p-th final time series TH<sub>1,p</sub> (m) of the sets of final time series SET_TH<sub>1,1</sub> - SET_TH<sub>1,Nf</sub> of the group of sets of final time series M_SET_TH<sub>1</sub> shown in <figref>Figure 9</figref>, the training (indicated with 711 in <figref>Figure 19</figref>) may be performed by calculating, on the basis of the aforementioned training population, a corresponding training reference series, and subsequently by calculating on the basis of this training reference series and in the same way described with reference to blocks 704-710, a corresponding pair of values of the first and second feature, for each of the p-th final time series TH<sub>1,p</sub> (m) of the sets of final time series SET_TH<sub>1,1</sub> - SET_TH<sub>1,Nf</sub> of the group of sets of final time series M_SET_TH<sub>1</sub>, that is, by calculating a corresponding point in the aforementioned hyperplane, and finally by training the single-class classifier SCLASS<sub>p</sub> on the basis of the points thus determined.</p><p><span class=\"paragraph-number\">[0120]   </span>As shown in <figref>Figure 18</figref>, thanks to the training, each single-class classifier SCLASS<sub>p</sub> is biunivocally associated, in a per se known manner, with a plurality of corresponding confidence hyperplanes (indicated with HP<sub>p1</sub>, HP<sub>p2</sub>, etc.) and with a respective confidence centre (indicated with CC<sub>p</sub>).</p><p><span class=\"paragraph-number\">[0121]   </span>Again with reference to <figref>Figure 17</figref>, the computer 19 calculates (block 714) a distance present between the point P_TH<sub>p</sub> and the corresponding confidence centre CC<sub>p</sub>, as a function of the position of the point P_TH<sub>p</sub> with respect to the confidence hyperplanes HP<sub>p1</sub>, HP<sub>p2</sub>,.... In practice, the computer 19 can adopt any metric to obtain a quantity indicative of the distance of the point P_TH<sub>p</sub> from the corresponding confidence centre CC<sub>p</sub>, this quantity being therefore indicative of the probability that the time series to be analysed is anomalous with respect to the time series on the basis of which the single-class classifier SCLASS<sub>p</sub> has been trained.</p><p><span class=\"paragraph-number\">[0122]   </span>As shown purely by way of example in <figref>Figure 18</figref>, by indicating with (x<sub>p</sub>,y<sub>p</sub>) and with (x<sub>c</sub>,y<sub>c</sub>) the coordinates in the hyperplane of the point P_TH<sub>p</sub> and of the confidence centre CC<sub>p</sub>, the computer 19 may calculate the distance as the sum of a first weighted distance Δx along the abscissas, relative to the segment present between the point P_TH<sub>p</sub> and an intermediate point P<sub>p</sub> with coordinates (x<sub>c</sub>,y<sub>p</sub>), and of a second weighted distance Δy along the ordinates, relative to the segment present between the intermediate point P<sub>p</sub> and the confidence centre CC<sub>p</sub>. For each of the first and second weighted distance Δx, Δy, the respective segment is formed by corresponding subsegments (<figref>Figure 18</figref> shows the segments Δy<sub>1</sub>-Δy<sub>2</sub>, relative to the second weighted distance Δy, and the segments Δx<sub>1</sub>-Δx<sub>4</sub>, relative to the first weighted distance Δx), each of which extends alternately in a respective zone interposed between a pair of adjacent confidence hyperplanes or in the zone extending between the confidence centre CC<sub>p</sub> and the first confidence hyperplane HP<sub>p1</sub>; each of the first and second weighted distance Δx, Δy is thus calculated as the sum of the lengths of the respective subsegments, each length being weighted by a coefficient indicative of the zone in which the corresponding subsegment extends, the coefficients having increasing weight as the zones move away from the confidence centre CC<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0123]   </span>Considering again a generic m-th set of final unknown time series SET_TH<sub>x,m</sub> of the group of sets of final unknown time series M_SET_TH<sub>x</sub>, the operations described with reference to <figref>Figure 17</figref> are carried out for all the final time series TH'<sub>1,1</sub>(m)- TH'<sub>1,Pmax</sub>(m), so as to obtain a second detection vector V<sub>c</sub>, which comprises a number of elements equal to Pmax, the p-th element being equal to the distance calculated for the final time series TH'<sub>1,p</sub>(m), thus being equal to an estimate of the probability that the final time series TH'<sub>1,p</sub>(m) is anomalous with respect to the time series on the basis of which the p-th single-class classifier SCLASS<sub>p</sub> has been trained. Furthermore, although not shown in detail, the computer 19 may perform an (optional) normalisation operation of the second detection vector V<sub>c</sub>, e.g. by subtracting the mean of all its elements and dividing the result by the standard deviation of the elements. In the following, for simplicity's sake reference is made to the second detection vector V<sub>c</sub> to indicate the outcome of the normalisation.</p><p><span class=\"paragraph-number\">[0124]   </span>In addition, each second detection vector V<sub>C</sub> is associated with a corresponding time interval, which is referred to in the following as the time interval TV2. In particular, referring, for example, to the second detection vector V<sub>c</sub> corresponding to the m-th set of final unknown time series SET_TH<sub>x,m</sub>, the corresponding time interval TV2 may be equal to, for example, the temporal interval associated with the final unknown time series TH'<sub>1,1</sub>(m) -TH'<sub>1,Pmax</sub>(m) of said m-th set of final unknown time series SET_TH<sub>x,m</sub>.</p><p><span class=\"paragraph-number\">[0125]   </span>Again with reference to <figref>Figure 7</figref>, the computer 19 is provided, for each acquisition index AcqID<sub>j</sub>, with the corresponding anomaly indexes IND1<sub>j</sub>, each of which is associated with the corresponding time interval TV1<sub>j</sub> and with the corresponding first detection vector V<sub>Aj</sub>, and further has the second detection vectors V<sub>c</sub>, each of which is associated with the corresponding time interval TV2, as shown in <figref>Figure 20</figref>.</p><p><span class=\"paragraph-number\">[0126]   </span>The computer 19 performs (block 800), for each acquisition index AcqID<sub>j</sub>, a first filtering, i.e. it selects only the anomaly indexes IND1<sub>j</sub> which exceed an anomaly threshold and are associated to first anomaly vectors V<sub>Aj</sub> whose element having a maximum value is associated with a corresponding health index HI<sub>j,1</sub> - HI<sub>j,18</sub>; in this way, even in the presence of an anomaly index IND1<sub>j</sub> exceeding the anomaly threshold, no reporting is generated, if the maximum of the corresponding first anomaly vector V<sub>Aj</sub> is associated with one of the flight parameters FP<sub>1</sub> - FP<sub>18</sub>, since this situation does not correspond to a real anomaly of the transmission system. In this way, the generation of false positives is reduced.</p><p><span class=\"paragraph-number\">[0127]   </span>Subsequently, for each acquisition index AcqID<sub>j</sub>, the computer 19 performs (block 802) a second filtering, i.e. it selects, among the anomaly indexes IND1<sub>j</sub> previously selected during the execution of the operations referred to in block 800, the only groups formed by anomaly indexes IND1<sub>j</sub> i) that are associated with first consecutive detection vectors V<sub>Aj</sub> that have a shared anomaly field, i.e. they have respective maxima which are relative to the same health index HI<sub>j,1</sub> - HI<sub>j,18</sub> and ii) are associated with corresponding time intervals TV1<sub>j</sub> which, overall, are distributed over a time span T<sub>span</sub> (an example shown in a simplified manner in <figref>Figure 20</figref>) having an extension greater than a threshold duration (e.g. equal to one week). In other words, the second filtering envisages selecting only those anomalies that have been detected continuously over a period of at least a predetermined duration, and on the basis of the same health index HI<sub>j,1</sub> - HI<sub>j,18</sub>.</p><p><span class=\"paragraph-number\">[0128]   </span>Furthermore, for each group of anomaly indexes IND1<sub>j</sub> selected during the second filtering 802, the computer 19 checks (block 804) whether the presence of the anomaly is confirmed on the basis of the second detection vectors V<sub>c</sub> whose corresponding time intervals TV2 fall within the time span T<sub>span</sub>, in which case it reports (block 806) the anomaly.</p><p><span class=\"paragraph-number\">[0129]   </span>For example, the operations of block 804 may comprise checking whether all second detection vectors V<sub>c</sub> whose corresponding time intervals TV2 fall within the time span T<sub>span</sub> have respective elements relating to at least one same p-th final time series TH<sub>1,p</sub> with values above a verification threshold.</p><p><span class=\"paragraph-number\">[0130]   </span>The operations referred to in block 804 make it possible to further reduce the number of false positives, since the Applicant has observed that generally, in the presence of real anomalies, at least one final unknown time series is anomalous. Furthermore, although not described in detail, the operations referred to in block 804 may vary with respect to what is described, for example by providing for checking whether at least part of the second detection vectors V<sub>c</sub> whose corresponding time intervals TV2 fall within the time span T<sub>span</sub> have respective elements relating to at least one same p-th final time series TH<sub>1,p</sub> with values above the verification threshold, or by providing that the anomaly is confirmed only if all or part of the second detection vectors V<sub>c</sub> whose corresponding time intervals TV2 fall within the time span T<sub>span</sub> have respective elements relating to at least a predetermined number of final time series with values above the verification threshold and/or corresponding thresholds.</p><p><span class=\"paragraph-number\">[0131]   </span>It is also possible that the operations in block 804 are performed on the second detection vectors V<sub>c</sub> whose corresponding time intervals TV2 fall within an extended time span, which includes the aforementioned time span T<sub>span</sub>, but has a greater time extension.</p><p><span class=\"paragraph-number\">[0132]   </span>In case the anomaly is confirmed, the computer 19 identifies (block 808) the component/zone of the transmission system 1 to which the anomaly refers, on the basis of the acquisition index AcqID<sub>j</sub> to which the anomaly index group IND1<sub>j</sub> selected during the second filtering 802 refers, as well as on the basis of the aforementioned shared anomaly field, i.e. on the basis of the health index associated with the maxima of the first detection vectors V<sub>Aj</sub> associated with the anomaly indexes IND1<sub>j</sub> of the group.</p><p><span class=\"paragraph-number\">[0133]   </span>According to an alternative, instead of implementing the operations referred to in block 804, i.e. instead of implementing some kind of additional filtering on the basis of the final unknown time series, the computer 19 calculates a confidence score. In particular, for each group of anomaly indexes IND1<sub>j</sub> selected during the second filtering 802, the computer 19 performs the operations in blocks 806 and 808, then reports the anomaly, and calculates a confidence score on the basis of the second detection vectors V<sub>C</sub> whose corresponding time intervals TV2 fall within the time span T<sub>span</sub>; this confidence score is indicative of the probability that the anomaly reporting is correct.</p><p><span class=\"paragraph-number\">[0134]   </span>The advantages that the present method allows to obtain emerge clearly from the previous description.</p><p><span class=\"paragraph-number\">[0135]   </span>In particular, the method makes it possible to detect any damage to the transmission system very quickly and accurately. In this respect, the Applicant has observed that often the components of the transmission system, instead of breaking down instantaneously, deteriorate slowly; the present method makes it possible to detect such slow deterioration at an early stage, before the functional block of the transmission system occurs, thus enabling timely maintenance actions to be undertaken, with obvious advantages in terms of safety and optimisation of maintenance activities.</p><p><span class=\"paragraph-number\">[0136]   </span>Furthermore, this method is less prone to the phenomenon of false positives due to the analysis of time series as well as health indexes. Furthermore, a considerable reduction in false positives is achieved thanks to the mechanism of discarding possible anomaly indications that are attributed, by the first-type classifiers, to the flight parameters.</p><p><span class=\"paragraph-number\">[0137]   </span>Clearly, changes may be made to the method and system described and shown herein without, however, departing from the scope of the present invention, as defined in the accompanying claims.</p><p><span class=\"paragraph-number\">[0138]   </span>For example, the health indexes and the processing of the primary signals, and thus the pre-processed signals and the final time series, may be different from what has been described above. Examples of primary signal processing and calculation of health indexes are described in <patcit dnum=\"EP0889313B1\">EP0889313B1</patcit>, <patcit dnum=\"EP0889315B1\">EP0889315B1</patcit> and <patcit dnum=\"EP0889316B1\">EP0889316B1</patcit>.</p><p><span class=\"paragraph-number\">[0139]   </span>The dimensions of the observation windows and the sizing of the first-type classifiers may be different from what is described.</p><p><span class=\"paragraph-number\">[0140]   </span>The operations referred to in block 700, based on the final time series, may be omitted, although this entails a greater probability of false positives.</p><p><span class=\"paragraph-number\">[0141]   </span>Furthermore, the time series of the group of sets of final time series M_SET_TH<sub>1</sub> and of the group of sets of final unknown time series M_SET_TH<sub>x</sub> may be acquired in additional time intervals, other than the aforementioned last time intervals of duration ΔT of each flight, although this may require the use of a more capable or complex storage system. In general, it is possible that the time series of one or more sets of the group of sets of final time series M_SET_TH<sub>1</sub> and/or of the group of sets of final unknown time series M_SET_TH<sub>x</sub> refer to time intervals to which no health index of the training flight data structure M_FDS<sub>1</sub> and/or of the unknown flight data structure M_FDS<sub>x</sub> refers. Furthermore, for each flight, several sets of final time series may be stored instead of just one.</p><p><span class=\"paragraph-number\">[0142]   </span>Similarly, the temporal link present between each set of health indexes and the corresponding set of flight parameter values SET_ΔT<sub>w</sub> may be different; for example, considering any item U<sub>w</sub> and any acquisition index AcqID<sub>j</sub>, and then considering a corresponding set of health indexes relating to the time interval T<sub>w</sub> and associated to the acquisition index AcqID<sub>j</sub>, the corresponding set SET_ΔT<sub>w</sub> of the values of the flight parameters may be acquired during any instant of the time interval T<sub>w</sub>, independently of the effective temporal extension of the temporal sub-domain to which the portion of the primary signal employed to calculate the aforementioned set of health indexes that are associated to the acquisition index AcqID<sub>j</sub> refers.</p><p><span class=\"paragraph-number\">[0143]   </span>Regarding block 600, the first-type classifiers may be different from what is described; for example, they may be \"recurrent neural network\" (RNN) classifiers of the \"long short-term memory\" (LSTM) type or \"convolutional neural network\" (CNN). Similarly, the second-type classifiers may be different in number and/or of a different type than described. Moreover, even in the case of first-type and second-type classifiers described above, it is possible that they are trained, and therefore also applied, on the basis of health indexes alone, and therefore without considering flight parameters. In this case, the first filtering envisages selecting the anomaly indexes IND1<sub>j</sub> that exceed the anomaly threshold.</p><p><span class=\"paragraph-number\">[0144]   </span>Where appropriate, the second classification in block 620 may be absent, although this will reduce the detection accuracy. In this case, each anomaly index IND1<sub>j</sub> coincides with a corresponding first partial anomaly index ANV1<sub>j</sub>.</p><p><span class=\"paragraph-number\">[0145]   </span>All filtering policies may be different, and possibly even absent, from what is described, although this may lead to an increase in false positives.</p><p><span class=\"paragraph-number\">[0146]   </span>The operations described above may be carried out in a different order than described; if necessary, at least some of the operations described may be carried out in parallel.</p><p><span class=\"paragraph-number\">[0147]   </span>The acquisition of the primary signals and the relative digitisation may also take place in different ways; for example, sensors may generate primary signals that are already digital. Furthermore, the processing system 10 may at least partially parallelize the query of the sensors, in which case it is for example possible that all or part of the primary signals relating to each time interval of duration ΔT extend over at least partially overlapping time domains (possibly, coinciding with the entire time interval of duration ΔT). Similarly, referring to a single sensor, it is possible that at least part of the corresponding pre-processed signals, and thus also the corresponding health indexes derived therefrom, refer to the same portion of the primary signal generated by the sensor, rather than to portions of the primary signal relative to different temporal sub-domains. However, in general, temporal sub-domains relative to the same primary signal may be at least partially overlapping.</p><p><span class=\"paragraph-number\">[0148]   </span>Again, with reference to the determination of the time intervals of duration ΔT and of the time intervals TV1<sub>j</sub> and TV2, they may be different from what has been described. In general, instead of the temporal quantities described, correlated temporal quantities may be calculated.</p><p><span class=\"paragraph-number\">[0149]   </span>For example, each first detection vector V<sub>Aj</sub> may be associated with the time interval to which any record RCX of the corresponding unknown observation matrix OMX refers. Similarly, the time interval TV2 associated with each second detection vector V<sub>C</sub> may be offset from the time interval to which the corresponding final unknown time series SET_TH<sub>x,m</sub> refer.</p><p><span class=\"paragraph-number\">[0150]   </span>In general, temporal relationships can be modified because the time scale typical of the damage phenomena of a transmission system is large enough and also because, once a damage has occurred, it is not repaired by itself. Therefore, referring for example to block 804, it may be based on the second anomaly detection vectors V<sub>C</sub> whose corresponding time intervals TV2 fall within a time span offset with respect to the aforementioned time span T<sub>span</sub>.</p><p><span class=\"paragraph-number\">[0151]   </span>The sensors could be sensors of a different type with respect to what has been described, in which case also the pre-processed signals, and therefore the final time series, can be relative to quantities different from accelerations.</p><p><span class=\"paragraph-number\">[0152]   </span>Finally, the present method can be applied to any type of aircraft, such as for example airplanes, tiltrotors, multi-copters, etc.</p>",
            "CLMS": "(EP4091945)<br/><p>1. Computer-implemented method (19) for detecting anomalies in a transmission system (1) of an aircraft (HC<sub>1</sub>) equipped with a monitoring system (10,MS) including a number of sensors (A1-A13) coupled to the transmission system (1), the monitoring system (10,MS) being configured to determine, for each flight of the aircraft (HC<sub>1</sub>) a number of respective time intervals (ΔT) and to acquire through each sensor (A1-A13), for each of said time intervals (T<sub>w</sub>), a corresponding primary signal (s<sub>i</sub>) indicative of a corresponding dynamic quantity dependent on the functioning of the transmission system (1) during at least part of said time interval (ΔT); and wherein, for each sensor (A1-A13), the monitoring system (10,MS) is configured to determine, starting from each primary signal (s<sub>i</sub>) acquired through the sensor (A1-A13) during a corresponding time interval (T<sub>w</sub>), a corresponding set of values of at least one corresponding group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) ;<br/> said method comprising the step of acquiring an unknown flight data structure (M_FDS<sub>x</sub>) that is relative to a number of flights to be analysed of the aircraft (HC<sub>1</sub>) and includes, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) , a plurality of respective records (RCX), each record (RCX) comprising a respective set of values (HI'<sub>1,1</sub>(1) -HI'<sub>1,18</sub>(1)) of the synthetic indexes of the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>), said respective set of values (HI'<sub>1,1</sub>(1)-HI'<sub>1,18</sub>(1)) being relative to a corresponding time interval (T'<sub>1</sub>) of said number of flights to be analysed; said method further comprising, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) :<br/>  - selecting (604) a plurality of corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), each subset (OMX) being formed by a number of records (RCX) of the unknown flight data structure (M_FDS<sub>x</sub>) that are relative to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) and to a corresponding sequence of time intervals (T'<sub>1</sub>-T'<sub>36</sub>), the subsets (OMX) also being temporally offset from each other; and<br/>  - by application (605,606) of a first classifier (AE<sub>j</sub>) corresponding to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) to each of said corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), generating, for each of said corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), a corresponding first detection vector (V<sub>Aj</sub>), which comprises, for each synthetic index (HI<sub>1,1</sub>-HI<sub>1,18</sub>) of the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) , a corresponding estimate of the probability that the values of the subset (OMX) relating to said synthetic index (HI<sub>1,1</sub>-HI<sub>1,18</sub>) are anomalous with respect to a training condition of said corresponding first classifier (AE<sub>j</sub>);<br/> said method further comprising the step of detecting (800,802,804,806) anomalies in the transmission system (1) on the basis of the first detection vectors (V<sub>Aj</sub>).</p><p>2. Method according to claim 1, further comprising for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>):<br/> - selecting individually (624) the records (RCX) of the unknown flight data structure (M_FDS<sub>x</sub>) that are relative to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) ; and<br/> - applying (625) to each selected record (RCX) a number of second classifiers (DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub>, DBUC4<sub>j</sub>) that correspond to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) , so as to generate corresponding overall estimates (V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub>, Vʺʺ<sub>Bj</sub>), each overall estimate being indicative of the probability that the selected record (RCX) is anomalous with respect to a training condition of the corresponding second classifier (DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub>, DBUC4<sub>j</sub>);<br/>and wherein said step of detecting (800,802,804,806) anomalies of the transmission system (1) comprises detecting anomalies of the transmission system (1) as a function of the first detection vectors (V<sub>Aj</sub><br/>) and of the overall estimates (V'<sub>Bj</sub><br/>, V\"<sub>Bj</sub><br/>, V‴<sub>Bj</sub><br/>, Vʺʺ<sub>Bj</sub><br/>).</p><p>3. Method according to claim 2, wherein said number of second classifiers (DBUC1<sub>j</sub>, DBUC2<sub>j</sub>, DBUC3<sub>j</sub>, DBUC4<sub>j</sub>) that correspond to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) includes \"distance-based\" and/or \"density-based\" type classifiers.</p><p>4. Method according to claim 2 or 3, further comprising for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>):<br/> - determining (606), on the basis of each corresponding first detection vector (V<sub>Aj</sub>), a corresponding first partial anomaly index (ANV1<sub>j</sub>); and<br/> - for each corresponding individually selected record (RCX), generating a corresponding second partial anomaly index (ANV2<sub>j</sub>), as a function of the corresponding overall estimates (V'<sub>Bj</sub>, V\"<sub>Bj</sub>, V‴<sub>Bj</sub>, Vʺʺ<sub>Bj</sub>) ; and<br/> - associating (628) second partial anomaly indexes (ANV2<sub>j</sub>) with corresponding first partial anomaly indexes (ANV1<sub>j</sub>), as a function of the time intervals (T'<sub>1</sub>) relating to the corresponding individually selected records (RCX) and as a function of the sequences of time intervals (T'<sub>1</sub>-T'<sub>36</sub>) relating to the corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>) ; and<br/> - determining (628), on the basis of each pair formed by a first and a second partial anomaly index (ANV1<sub>j</sub>,ANV2<sub>j</sub>) associated with each other, a corresponding anomaly index (IND1<sub>j</sub>) ;<br/>said method comprising comparing (800) the anomaly indexes (IND1<sub>j</sub><br/>) with an anomaly threshold; and wherein the step of detecting (800,802,804,806) anomalies in the transmission system (1) is a function of the outcomes of the comparisons between the anomaly indexes (IND1<sub>j</sub><br/>) and the anomaly threshold.</p><p>5. Method according to claim 4, wherein the aircraft (HC<sub>1</sub>) is additionally equipped with a number of additional sensors (8) configured to detect corresponding flight parameters (FP<sub>1</sub>-FP<sub>18</sub>) of the aircraft (HC<sub>1</sub>) ; and wherein, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) , each corresponding record (RCX) of the unknown flight data structure (M_FDS<sub>x</sub>) comprises a respective set of values (SET_ΔT') of the flight parameters (FP<sub>1</sub>-FP<sub>18</sub>), which have been detected during the time interval (T'<sub>1</sub>) to which the set of values (HI'<sub>1,1</sub>(1)-HI'<sub>1,18</sub>(1)) of the record (RCX) refers; and wherein the step of selecting (604) a plurality of corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>) is such that, for each subset (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), the respective records (RCX) comprise the sets of values (SET ΔT'<sub>1</sub>-SET_ΔT'<sub>36</sub>) of the flight parameters (FP<sub>1</sub>-FP<sub>18</sub>) relating to the corresponding sequence of time intervals (T'<sub>1</sub>-T'<sub>36</sub>); and wherein, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) , said step of generating, for each of the corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), a corresponding first detection vector (V<sub>Aj</sub>) is such that said corresponding first detection vector (V<sub>Aj</sub>) comprises, for each flight parameter (FP<sub>1</sub>-FP<sub>18</sub>), a corresponding estimate of the probability that the values of the subset (OMX) relating to said flight parameter (FP<sub>1</sub>-FP<sub>18</sub>) are anomalous with respect to the training condition of the first classifier (AE<sub>j</sub>) corresponding to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>); and wherein the step of detecting (800,802,804,806) anomalies of the transmission system (1) comprises, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>):<br/> - selecting (800) respective anomaly indexes (IND1<sub>j</sub>) that exceed the anomaly threshold and correspond to first detection vectors (V<sub>Aj</sub>) having maximum probability estimates that are each relative to a corresponding synthetic index (HI<sub>1,1</sub>-HI<sub>1,18</sub>) ; and<br/> - detecting (802,804,806) anomalies of the transmission system (1) as a function of the selected anomaly indexes (IND1<sub>j</sub>).</p><p>6. Method according to claim 5, wherein said step of determining (628), for each pair formed by a first and a second partial anomaly index (ANV1<sub>j</sub>, ANV2<sub>j</sub>) associated with each other, a corresponding anomaly index (IND1<sub>j</sub>) comprises associating (628) to the anomaly index (IND1<sub>j</sub>j) a corresponding time interval (IND1<sub>j</sub>); said method further comprising, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>):<br/> - starting from the respective selected anomaly indexes (IND1<sub>j</sub>), selecting (802) groups of anomaly indexes (IND1<sub>j</sub>) formed, each, by a plurality of selected successive anomaly indexes (IND1<sub>j</sub>), which correspond to first detection vectors (V<sub>Aj</sub>) having maximum probability estimates that are relative to the same synthetic index (HI<sub>1,1</sub>-HI<sub>1,18</sub>) and are associated with time intervals (TV1<sub>j</sub>) distributed over a time span (T<sub>span</sub>) having an extension greater than a duration threshold;<br/>and wherein the step of detecting (802,804,806) anomalies of the transmission system (1) as a function of the selected anomaly indexes (IND1<sub>j</sub><br/>) comprises detecting anomalies of the transmission system (1) as a function of the groups of selected anomaly indexes (IND1<sub>j</sub><br/>).</p><p>7. Method according to claim 6, wherein, for each primary signal (S<sub>i</sub>) acquired through a corresponding sensor (A1-A13) in a corresponding time interval (T<sub>w</sub>), the monitoring system (10,MS) is configured to perform, on at least a portion of the primary signal (<sub>si</sub>), at least one corresponding set of processing operations (100;200;300;400;500), so as to generate at least one corresponding pre-processed signal (s'<sub>i</sub>, s\"<sub>i,k,hf</sub>, s\"<sub>i,k,lf</sub>, s\"<sub>i,k,filt</sub>, s‴<sub>i,hf</sub>, s‴<sub>i,lf</sub>, s‴<sub>i,filt</sub>, sʺʺ<sub>i</sub>), the monitoring system (10,MS) being further configured to determine said corresponding set of values of said at least one corresponding group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) by feature extraction (110,210,310,410,510) of said at least one corresponding pre-processed signal (s'<sub>i</sub>, s\"<sub>i,k,hf</sub>, s\"<sub>i,k,lf</sub>, s\"<sub>i,k,filt</sub>, s‴<sub>i,1</sub>, s‴<sub>i,2</sub>, sʺʺ<sub>i</sub>).</p><p>8. Method according to claim 7, wherein the monitoring system (10,MS) is further configured to determine, for each flight of the aircraft (HC<sub>1</sub>), at least one respective additional time interval (T<sub>w</sub>) and to acquire through each sensor (A1-A13) at least one corresponding additional primary signal (S<sub>i</sub>), which is a function of a corresponding dynamic quantity that depends on the functioning of the transmission system (1) during at least part of said additional time interval (T<sub>w</sub>); and wherein, for each flight of the aircraft (HC<sub>1</sub>) and for each sensor (A1-A13), the monitoring system (10,MS) is further configured to perform, on the additional primary signal (S<sub>i</sub>) acquired through the sensor (A1-A13) during the corresponding additional time interval (T<sub>w</sub>), said at least one set of processing operations (100;200;300;400;500) corresponding to the sensor (A1-A13), so as to generate at least one corresponding additional pre-processed signal (s'<sub>i</sub>, sʺ<sub>i,k,hf</sub>, sʺ<sub>i,k,if</sub>, s\"<sub>i,k,filt</sub>, s‴<sub>i,hf</sub>, s‴<sub>i,lf</sub>, s‴<sub>i,filt</sub>, sʺʺ<sub>i</sub>), relating to said at least one group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) that corresponds to the sensor (A1-A13); said method further comprising the step of:<br/> - for each of the flights to be analysed of the aircraft (HC<sub>1</sub>), acquiring a corresponding set of time series to be analysed (SET_TH<sub>x,1</sub>-SET_TH<sub>x,Nfx</sub>), each time series to be analysed (TH'<sub>1,1</sub>- TH'<sub>1,Pmax</sub>) being formed by a corresponding additional pre-processed signal among the additional pre-processed signals (s'<sub>i</sub>, s\"<sub>i,k,hf</sub>, s\"<sub>i,k,lf</sub>, s\"<sub>i,k,filt</sub>, s‴<sub>i,1</sub>, s‴<sub>i,2</sub>, s‴<sub>i</sub>) generated by the monitoring system (10,MS) during the additional time interval (T'<sub>w</sub>) of the flight to be analysed;<br/>said method further comprising, for each set of time series to be analysed (SET_TH<sub>x,1</sub>-SET_TH<sub>x,Nfx</sub>), determining (700) a corresponding second detection vector (V<sub>C</sub>), relating to the corresponding additional time interval (T'<sub>w</sub>), said step of determining (700) a corresponding second detection vector (V<sub>C</sub>) comprising, for each time series to be analysed (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>) of the set of time series to be analysed (SET_TH<sub>x,1</sub>-SET_TH<sub>x,Nfx</sub>):<br/> - determining (708,710) a corresponding first feature and a corresponding second feature, which are indicative of the similarity, respectively in time and frequency, between the time series to be analysed (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>) and a corresponding reference series, said reference series being equal to an average of the time series to be analysed (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>) that refer to the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) to which the time series to be analysed (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>) refers;<br/> - in a corresponding hyperplane including a respective confidence centre (CC<sub>p</sub>), determining (714) a distance between the point (P_TH<sub>p</sub>) having coordinates equal to said corresponding first and second feature and said confidence centre (CC<sub>P</sub>), said distance being a function of the position of said point (P_TH<sub>p</sub>) with respect to a plurality of confidence hyperplanes (HP<sub>p1</sub>,HP<sub>p2</sub>) that have been determined, together with the confidence centre (CC<sub>p</sub>), by training a corresponding single-class classifier (SCLASS<sub>p</sub>) on the basis of additional pre-processed signals (TH<sub>1,1</sub>-TH<sub>1,Pmax</sub>) acquired by the monitoring system (10,MS) during aircraft test flights (HC<sub>1</sub>) and relating to the same group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>) to which the time series to be analysed refers (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>);<br/> - setting equal to said distance an element of the second detection vector (V<sub>C</sub>) that refers to the time series to be analysed (TH'<sub>1,1</sub>-TH'<sub>1,Pmax</sub>);<br/>and wherein said step of detecting (802) anomalies of the transmission system (1) as a function of the selected groups of anomaly indexes (IND1<sub>j</sub><br/>) comprises checking, for each selected group of anomaly indexes (IND1<sub>j</sub><br/>), whether the second detection vectors (V<sub>C</sub><br/>) relating to additional time intervals (T'<sub>w</sub><br/>) that respect a time relation with the corresponding time span (T<sub>span</sub><br/>) respect an anomaly confirmation condition and reporting an anomaly, if the anomaly confirmation condition is respected, otherwise not reporting the anomaly.</p><p>9. Method according to any one of the preceding claims, wherein, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>), the corresponding first classifier (AE<sub>j</sub>) is an autoencoder-type classifier, which is configured to generate, starting from each of said corresponding subsets (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), a corresponding output matrix (MV<sub>Aj</sub>) having dimensions equal to the dimensions of the subset (OMX) of the unknown flight data structure (M_FDS<sub>x</sub>), said method further comprising the step of generating said corresponding first detection vector (V<sub>Aj</sub>) starting from the corresponding output matrix (MV<sub>Aj</sub>).</p><p>10. Method according to claim 9, wherein, for each group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>), the corresponding first classifier (AEj) was trained on the basis of a plurality of sets of values (HI'<sub>1,1</sub>(1)-HI'<sub>1,18</sub>(1)) of the synthetic indexes of the group of synthetic indexes (HI<sub>1,1</sub>-HI<sub>1,18</sub>), which were determined during corresponding time intervals (T<sub>1</sub>) of aircraft test flights (HC<sub>1</sub>).</p><p>11. Processing system comprising means (19) configured to carry out the method according to any one of the preceding claims.</p><p>12. Computer program comprising instructions such that, when executed by a computer (19), they cause the computer (19) to perform the method according to any of the preceding claims.</p><p>13. Computer medium storing the computer program according to claim 12.</p>",
            "NPR": "2",
            "APID": "160917772",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64C-027/12<br/>B64D-045/00<br/>B64F-005/60",
            "ID": "102706978",
            "AB": "(EP4091945)<br/>A computer-implemented method is described (19) for detecting anomalies in a transmission system (1) of an aircraft (HC1) equipped with a monitoring system (10,MS), which includes a number of sensors (A1-A13) coupled to the transmission system (1) and determines, for each flight of the aircraft (HC1) a number of respective time intervals (ΔT) and acquires through each sensor (A1-A13), for each of the time intervals (Tw), a corresponding primary signal (si) indicative of a corresponding dynamic quantity dependent on the operation of the transmission system (1) during at least part of the time interval (ΔT). For each sensor (A1-A13), the monitoring system (10,MS) determines, starting from each primary signal (si) acquired through the sensor (A1-A13) during a corresponding time interval (Tw), a corresponding set of values of at least one corresponding group of synthetic indexes (HI1,1-HI1,18). The method includes detecting (800,802,804,806) anomalies of the transmission system (1) on the basis of the groups of synthetic indexes.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fN6eJLTNKSLjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2021-05-18",
            "PA": "LEONARDO<br/>POLITECNICO DI MILANO",
            "PAAD": "(EP4091945)<br/>(PUB:EP-4091945B1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/>(PUB:EP-4091945A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/>NAME=Politecnico di Milano Piazza Leonardo da Vinci 32 , CITY=20133 Milano , COUNTRY=IT , REG=101672175<br/><br/><br/>(US20240228057)<br/>(PUB:US-20240228057A1-2)NAME=LEONARDO S.P.A.  , CITY=ROMA , COUNTRY=IT , ATYP=Non-US Company<br/><br/><br/>(WO2022243764)<br/>(PUB:WO-2022/243764A1-3)NAME=LEONARDO S.P.A Piazza Monte Grappa, 4 00195 ROMA , POSTCODE=00195 , COUNTRY=IT<br/>NAME=POLITECNICO DI MILANO Piazza Leonardo da Vinci, 32 20133 MILANO , POSTCODE=20133 , COUNTRY=IT<br/><br/><br/>(CN117730032)<br/>(PUB:CN-117730032A-168)NAME=LEONARDO SPA  , COUNTRY=IT<br/><br/><br/>(KR20240032722)<br/>(PUB:KR-10-2024-0032722A-113)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "102706978",
            "TI": "Method and system for detecting anomalies relating to components of a transmission system of an aircraft, in particular a helicopter",
            "TECD": "Transport",
            "EPD": "2022-11-23",
            "ICLM": "(EP4091945)<br/><p>1. Computer-implemented method (19) for detecting anomalies in a transmission system (1) of an aircraft (HC1) equipped with a monitoring system (10,MS) including a number of sensors (A1-A13) coupled to the transmission system (1), the monitoring system (10,MS) being configured to determine, for each flight of the aircraft (HC1) a number of respective time intervals (ΔT) and to acquire through each sensor (A1-A13), for each of said time intervals (Tw), a corresponding primary signal (si) indicative of a corresponding dynamic quantity dependent on the functioning of the transmission system (1) during at least part of said time interval (ΔT); and wherein, for each sensor (A1-A13), the monitoring system (10,MS) is configured to determine, starting from each primary signal (si) acquired through the sensor (A1-A13) during a corresponding time interval (Tw), a corresponding set of values of at least one corresponding group of synthetic indexes (HI1,1-HI1,18) ; said method comprising the step of acquiring an unknown flight data structure (M_FDSx) that is relative to a number of flights to be analysed of the aircraft (HC1) and includes, for each group of synthetic indexes (HI1,1-HI1,18) , a plurality of respective records (RCX), each record (RCX) comprising a respective set of values (HI'1,1(1) -HI'1,18(1)) of the synthetic indexes of the group of synthetic indexes (HI1,1-HI1,18), said respective set of values (HI'1,1(1)-HI'1,18(1)) being relative to a corresponding time interval (T'1) of said number of flights to be analysed; said method further comprising, for each group of synthetic indexes (HI1,1-HI1,18) : - selecting (604) a plurality of corresponding subsets (OMX) of the unknown flight data structure (M_FDSx), each subset (OMX) being formed by a number of records (RCX) of the unknown flight data structure (M_FDSx) that are relative to the group of synthetic indexes (HI1,1-HI1,18) and to a corresponding sequence of time intervals (T'1-T'36), the subsets (OMX) also being temporally offset from each other; and - by application (605,606) of a first classifier (AEj) corresponding to the group of synthetic indexes (HI1,1-HI1,18) to each of said corresponding subsets (OMX) of the unknown flight data structure (M_FDSx), generating, for each of said corresponding subsets (OMX) of the unknown flight data structure (M_FDSx), a corresponding first detection vector (VAj), which comprises, for each synthetic index (HI1,1-HI1,18) of the group of synthetic indexes (HI1,1-HI1,18) , a corresponding estimate of the probability that the values of the subset (OMX) relating to said synthetic index (HI1,1-HI1,18) are anomalous with respect to a training condition of said corresponding first classifier (AEj); said method further comprising the step of detecting (800,802,804,806) anomalies in the transmission system (1) on the basis of the first detection vectors (VAj).</p>",
            "CTN": "(EP4091945)<br/>EP-889315 14031742 WHO=EXAMINER SELF=N CAT=A CAT=D<br/>EP-407179 1459916 WHO=EXAMINER SELF=N CAT=A<br/>US20200165995 87399748 WHO=EXAMINER SELF=N CAT=A<br/>XP085433353 none WHO=EXAMINER SELF=N CAT=A<br/>CN111540471 90199689 WHO=EXAMINER SELF=N CAT=A<br/>EP-889313 14034453 WHO=APPLICANT SELF=N<br/>EP-889315 14031742 WHO=APPLICANT SELF=N<br/>EP-889316 14031744 WHO=APPLICANT SELF=N<br/><br/>(WO2022243764)<br/>EP-889315 14031742 WHO=EXAMINER SELF=N CAT=A CAT=D<br/>EP-407179 1459916 WHO=EXAMINER SELF=N CAT=A<br/>US20200165995 87399748 WHO=EXAMINER SELF=N CAT=A<br/>XP085433353 none WHO=EXAMINER SELF=N CAT=A<br/>CN111540471 90199689 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2024-11-18",
                    "XAP": "2022WO-IB53734",
                    "APD": "2022-04-21",
                    "APID": "160921834",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2022243764&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=rffe6YvmXRtrw1GN5TacvLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2022/243764",
                            "KIND": "A1",
                            "XPN": "WO2022243764",
                            "V_PNID": "WO-2022/243764A1-3",
                            "DATE": "2022-11-24",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCCwKXHCCGbG4d0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2022243764&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=rffe6YvmXRtrw1GN5TacvLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-04-21",
                            "XAP": "2022US-18559698",
                            "APD": "2022-04-21",
                            "APID": "169636010",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/18559698",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=O2%252BM3Y82Bdjx%252FXn5mYuykMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US20240228057",
                                    "KIND": "A1",
                                    "XPN": "US20240228057",
                                    "V_PNID": "US-20240228057A1-2",
                                    "DATE": "2024-07-11",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcM26RvbCfCuX8/J3aSBKS3mbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20240228057&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=O2%252BM3Y82Bdjx%252FXn5mYuykMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-04-21",
                            "XAP": "2022CN-80036197",
                            "APD": "2022-04-21",
                            "APID": "168980775",
                            "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=m4fBQrz0LOZfMARn96Nt25NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CN117730032",
                                    "KIND": "A",
                                    "XPN": "CN117730032",
                                    "V_PNID": "CN-117730032A-168",
                                    "DATE": "2024-03-19",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=hXP7Q1+dwoRFATLxkglS88k/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN117730032&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=m4fBQrz0LOZfMARn96Nt25NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2042-04-21",
                            "XAP": "2023KR-7041452",
                            "APD": "2022-04-21",
                            "APID": "168908137",
                            "REG_LINK": "http://link.kipris.or.kr/link/main/KPAXML.jsp?APPLNO=1020237041452",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8oOEhYlmhgX02VmilcacNMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "KR10-2024-0032722",
                                    "KIND": "A",
                                    "XPN": "KR20240032722",
                                    "V_PNID": "KR-10-2024-0032722A-113",
                                    "DATE": "2024-03-12",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aJxR8iNWnopz8/r6FOJ+DoDOQ6NLC580ETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=KR20240032722&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8oOEhYlmhgX02VmilcacNMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2041-05-18",
                    "XAP": "2021EP-0425025",
                    "APD": "2021-05-18",
                    "APID": "160917772",
                    "REG_LINK": "https://register.epo.org/application?number=EP21425025",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fN6eJLTNKSLjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4091945",
                            "KIND": "B1",
                            "XPN": "EP4091945",
                            "V_PNID": "EP-4091945B1-8",
                            "DATE": "2023-09-06",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=x0jAXD9vGYvIu+z3skiU5KxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4091945&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fN6eJLTNKSLjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP4091945",
                            "KIND": "A1",
                            "XPN": "EP4091945",
                            "V_PNID": "EP-4091945A1-8",
                            "DATE": "2022-11-23",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=x0jAXD9vGYvIu+z3skiU5PEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4091945&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fN6eJLTNKSLjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4091945_B1",
            "EPRD": "2021-05-18",
            "PN": "EP4091945           B1 2023-09-06 [EP4091945]<br/>EP4091945           A1 2022-11-23 [EP4091945]<br/>US20240228057       A1 2024-07-11 [US20240228057]<br/>WO2022/243764       A1 2022-11-24 [WO2022243764]<br/>CN117730032         A  2024-03-19 [CN117730032]<br/>KR10-2024-0032722   A  2024-03-12 [KR20240032722]",
            "ADB": "(EP4091945)<br/><p>In particular, the method makes it possible to detect any damage to the transmission system very quickly and accurately. In this respect, the Applicant has observed that often the components of the transmission system, instead of breaking down instantaneously, deteriorate slowly; the present method makes it possible to detect such slow deterioration at an early stage, before the functional block of the transmission system occurs, thus enabling timely maintenance actions to be undertaken, with obvious advantages in terms of safety and optimisation of maintenance activities.</p><p>In practice, the operations described so far make it possible to extract a first and a second feature of the time series to be analysed, i.e. they make it possible to determine the position of a corresponding point P_THp in the hyperplane (first feature, second feature), as shown in Figure 18 .</p><p>The operations referred to in block 804 make it possible to further reduce the number of false positives, since the Applicant has observed that generally, in the presence of real anomalies, at least one final unknown time series is anomalous.</p><p>As is well known, helicopters are extremely complex and vulnerable aircraft, since there is a transmission system between the engine(s) and the rotors, which includes critical components.</p><p>In the following, the method is described, without loss of generality, with reference to the helicopter HC1 only.</p><p>The present method is inspired by the possibility of having the aforementioned flight data structures available, which typically refer to helicopters that did not show any problems during the time periods to which the flight data structures refer; consequently, the health indexes and the flight parameter values contained in the flight data structures stored in the helicopter storage systems, as well as the final time series, typically refer to time periods in which the helicopters have functioned correctly.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=4<br/>PNAAGE=1<br/>NBPA=1; <br/>ALLCT=11; SCT=0; NSCT=11; <br/>ALLCTG=2; SCTG=0; NSCTG=2; <br/>AFS=4; ACC=4; AMCC=3; <br/>IGEN=0.0; IORG=0.81; IRAD=0.99; <br/>IMPI=2.98; MACI=1.09; PASI=2.64; PAVI=3.09; ",
            "PTCC": "(EP4083660)<br/>CC=EP EED=2042-04-13 STATUS=PENDING APID=160529315 APD=2022-04-13 XPN=EP4083660 PD=2022-11-02 EPD=2022-11-02 LPD=2022-11-02 <br/><br/>(US20220350028)<br/>CC=US EED=2042-04-27 STATUS=PENDING APID=160518121 APD=2022-04-27 XPN=US20220350028 PD=2022-11-03 EPD=2022-11-03 LPD=2022-11-03 <br/><br/>(DE102021002239)<br/>CC=DE EED=2041-04-28 STATUS=PENDING APID=160530296 APD=2021-04-28 XPN=DE102021002239 PD=2022-11-03 EPD=2022-11-03 LPD=2022-11-03 <br/><br/>(JP7369822)<br/>CC=JP EED=2042-04-28 STATUS=GRANTED APID=160676829 APD=2022-04-28 XPN=JP2022170737 PD=2022-11-10 PD=2023-10-26 EPD=2022-11-10 LPD=2023-10-26 PDG=2023-10-26 <br/>",
            "EPN": "EP4083660",
            "CTGN": "(US20220350028)<br/>US11921236 104357344 WHO=EXAMINER SELF=N<br/><br/>(JP7369822)<br/>JP7278521 104994035 WHO=EXAMINER SELF=N",
            "LAPD": "2022-04-28",
            "STDN": "",
            "NPN": "4",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application claims the benefit of German Patent Application Serial No. 10 2021 002 239.4, filed on Apr. 28, 2021, entitled “Doppler Lidar for the Detection of Wind and/or Vortex Situations”, the disclosure of which is incorporated by reference herein in its entirety.</p><p><span class=\"paragraph-number\">[0002]   </span>The invention relates to a Doppler lidar for detecting wind and/or vortex situations.</p><p><span class=\"paragraph-number\">[0003]   </span>As known from DE 10316762 B4, weather radar systems have the problem that they require large suspended particles of high density, such as water droplets in clouds, for their backscatter measurement and are therefore only suitable for early warning of weather clouds at greater distances of up to several 10 kilometers. In contrast, the most common airflow with clear view, such as wind shear and so-called clear air turbulences in the troposphere and jet streams in the stratosphere, cannot be detected by weather radar, because the wavelengths of a few centimeters to millimeters are relatively long compared to the size of the air particles.</p><p><span class=\"paragraph-number\">[0004]   </span>Therefore, attempts were made to develop LIDAR (light detection and ranging) systems with shorter wavelengths and higher pulse frequency, which allow additional scanning in the optical region of the spectrum where the smaller air particles can be detected. In order to achieve high measurement reliability in all weather conditions, Doppler shifted backscattering from air molecules was used in addition to aerosol scattering. However, Doppler lidar measurements have the general problem of low intensity of the backscatter signal from both molecules and aerosols. Nevertheless, to keep the laser power low, which is required for reliable measurements, it is necessary to use the most sensitive photodetector possible while efficiently suppressing the influence of noise due to background radiation from the atmosphere and electronic noise in the detector and amplifier. Integration of weak backscatter signals over several seconds would require winds to be stable over time. However, such conditions generally do not exist. Instead, signal evaluation must be performed in only a few tens of milliseconds, i.e., in real time.</p><p><span class=\"paragraph-number\">[0005]   </span>As known from DE 10 2005 034 729 B3, meteorological measuring devices installed on the ground, such as Doppler radars and Doppler lidars, provide a global overview of the weather, wind and vortex situation, especially at airport areas. To ensure the safety of take-off and landing at airports, the wind speed in the atmosphere must be measured permanently. Long-range measurements in clear weather conditions can only be carried out with Doppler lidar systems.</p><p><span class=\"paragraph-number\">[0006]   </span>Even this is only sufficient for a common warning of critical wind and wake vortex situations at all affected aircrafts, without taking into account the risk to an individual aircraft. In future, a general shortening of take-off and landing sequences at all airports will only be possible when each aircraft has its own on-board measurement system, which can detect individual vortices and wake vortexes from taking-off or landing aircraft on their flight path in all weather conditions in time and directly assess their hazard potential due to forces and torques occurring. However, Doppler lidars for measurement in the clear atmosphere are not as compact as Doppler radars and still complicated overall.</p><p><span class=\"paragraph-number\">[0007]   </span>The article “Two-channel direct-detection Doppler lidar employing a charge coupled device as a detector” by Irgang, Todd D., Applied Optics, Vol. 41, No. 6, Feb. 20, 2002, describes a two-channel Doppler lidar that has a CCD (charge-coupled device) as a detector. The lidar system measures wind motion using backscattered light from aerosols and molecules in two separate channels, with light from one channel guided into the other. However, the measuring system is not sufficiently compact to make the inhomogeneity and movement of the air visible in an extended area, i.e. over a larger angular range, simultaneously along and across the measuring axis.</p><p><span class=\"paragraph-number\">[0008]   </span>Measuring wind and turbulence conditions for wind farms is also important for large-scale use of wind as a renewable energy source. For wind farms, the effectiveness of power generation depends on the proper placement of rotors in relation to local wind and turbulence conditions. For these reasons, accurate non-contact measurement of the characteristic wind and turbulence field at the selected site under varying weather conditions prior to their construction as well as during operation is of particular importance for efficient and safe operation of wind farms. The measurement of these air data with meteorological measuring stations and occasionally with Doppler lidar systems is still complex, expensive and inaccurate.</p><p><span class=\"paragraph-number\">[0009]   </span>In the state of the art known Doppler lidars are in particular pulsed coherent Doppler lidar systems that use the Doppler effect to detect the wind speed in a spatial volume. For this purpose, a laser pulse is emitted into the atmosphere or in the direction of any target to measure. The reflected laser light is detected and coherently mixed with a local oscillator. The heterodyne detection amplifies the backscattered signal and the frequency of the beat signal can be used to determine the Doppler shift. There are two main ways to increase the signal strength. First, the transmit pulse energy can be further increase, which increases also the backscattered signal strength. Second, the pulse repetition rate can increase to increase the number of information per unit of time.</p><br/><p><h1>BRIEF DESCRIPTION OF DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0010]   </span>For measuring radial wind speed with a single-channel Doppler lidar known in the prior art, which comprises an optical transmitter, a transmit/receive switch (duplexer), a scanner, for example a two-axis scanner, a heterodyne receiver and a signal processor. A typical setup is described below with reference to <a href=\"#DRAWINGS\">FIG. 1</a>.</p><p><span class=\"paragraph-number\">[0011]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows a configuration with a master oscillator (MO) generating a continuous laser light, which is used for pulse generation on the one hand and serves as a local oscillator on the other hand. An amplitude modulator (AM) generates the pulses of desired length and shape. A frequency shifter (FV) is also used to detect positive and negative directions of motion. These pulses are amplified (Av) and sent beam expanded into the atmosphere. A two-axis scanner (Sc) defines the measurement direction. The scattered light detected by a telescope (TK) and coupled into the optical system is guided to the balanced detector (Det.) by means of a transmit/receive splitter, here with the aid of a circulator (ZI). The backscattered signal can be mixed coherently (heterodyne) with the local oscillator, whereby only the low-frequency beat frequencies are measured by the detector and processed in the signal processing (SV). From this beat frequency the wind speed component can be calculated.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The invention relates to a Doppler Lidar for detecting wind and/or vortex situations.</p><p><span class=\"paragraph-number\">[0002]   </span>As from <patcit dnum=\"DE10316762B4\">DE 103 16 762 B4</patcit> it is known that in weather radar systems there is the problem that they require large suspended particles of high density, such as, for example, water drops in clouds, for their backscatter measurement and are therefore only suitable for early warning of weather clouds at a greater distance of up to a few tens of kilometers. The most frequent air flows in clear view, such as shear winds and so-called \"clear air turbulences\" in the troposphere and jet streams in the stratosphere, on the other hand, cannot be detected by the weather radar, since the wavelengths of a few centimeters to millimeters are relatively long compared to the size of the air particles.</p><p><span class=\"paragraph-number\">[0003]   </span>Attempts have therefore been made to develop LIDAR (light detection and ranging) systems with shorter wavelengths and higher pulse frequency, which permit additional scanning in the optical range of the spectrum in which the smaller air particles can be detected. In order to achieve high measurement reliability under all weather conditions, Doppler-shifted backscattering on air molecules was also used in addition to aerosol scattering. In Doppler lidar measurements, however, there is the general problem of the low intensity of backscattering both of molecules and of aerosols. In order nevertheless to keep the laser power, which is necessary for reliable measurements, low, a photodetector which is as sensitive as possible must be used and at the same time the influence of noise due to background radiation of the atmosphere and electronic noise in the detector and amplifier must be efficiently suppressed. integration of weak backscatter signals over several seconds would require winch to be stable over a longer period of time. However, such prerequisites are generally not met. Rather, the signal evaluation must take place in only a few tens of milliseconds, i.e. in real time.</p><p><span class=\"paragraph-number\">[0004]   </span>As from <patcit dnum=\"DE102005034729B3\">DE 10 2005 034 729 B3</patcit> as is known, the meteorological measuring instruments such as Doppler radar and Doppler Lidars set up on the ground provide a global overview of the weather, wind and vortex situation, in particular at airports. In order to ensure the safety of takeoff and landing at airports, the wind speed in the atmosphere must be measured permanently. wide measurements in clear weather can only be carried out with Doppler Lidars.</p><p><span class=\"paragraph-number\">[0005]   </span>This also suffices only for common warning of critical wind and vortex situations on all aircraft concerned, without taking into account the danger of individual aircraft. A future general shortening of the takeoff and landing sequences at all airports will only be possible when each aircraft has its own on-board measurement system, which detects individual vortices and wake vortices of takeoff or landing aircraft on their flight path in time under all weather conditions and directly evaluates their danger potential by occurring forces and torques. Doppler Lidars for measurement in the clear atmosphere, however, are not as compact as Doppler radars and, overall, are still complicated.</p><p><span class=\"paragraph-number\">[0006]   </span>In the article \"<nplcit npl-type=\"s\">Two-channel Direct Detection Doppler lidar employing a charge coupled device as a detector \"by Irgang, Todd D., Applied Optics, Vol. 41, No. 6, February 20, 2002</nplcit>A two-channel Doppler lidar is described which has a CCD (charge-coupled device) as a detector. The Lidar system measures wind movements with the aid of the light backscattered on aerosols and molecules in two separate channels, the light of one channel being guided into the other. However, the measuring system is not sufficiently compact to make visible the inhomogeneity and movement of the air in an extended area, i.e. over a larger angular range, simultaneously along and transversely to the measuring axis.</p><p><span class=\"paragraph-number\">[0007]   </span>The measurement of wind and turbulence conditions for wind farms is also important for the large-scale industrial utilization of wind as a renewable energy source. In wind farms, the effectiveness of the power generation depends on the correct installation of the rotors with respect to local wind and turbulence conditions. For these reasons, an accurate, contactless measurement of the characteristic wind and vortex field at the selected location is of particular importance for efficient and reliable operation of wind farms under different weather conditions before their construction and also during operation. The measurement of these air data with meteorological measuring stations and individually with a Doppler lidar system has hitherto been complicated, expensive and imprecise.</p><p><span class=\"paragraph-number\">[0008]   </span>The Doppler Lidar known in the prior art are, in particular, pulsed coherent Doppler lidar systems which utilize the Doppler effect in order to detect the wind speed in a spatial volume. For this purpose, a laser pulse is emitted into the atmosphere or in the direction of any desired measurement target. The reflected radiation is detected and coherently superimposed with a local oscillator. As a result of the superposition, the backscattered signal is amplified and the Doppler shift can be determined by the frequency of the beat signal. In order to increase the signal strength, essentially two possibilities are available. The transmission pulse energy can be increased further, as a result of which the signal strength is increased. Further, the pulse repetition rate may be increased to increase the number of messages per unit time.</p><p><span class=\"paragraph-number\">[0009]   </span>In order to measure the radial wind speed with a single-channel Doppler lidar known in the prior art, this Lidar comprises an optical transmitter, a transmit/receive switch (Duplexer), an, for example, 2-axis scanner, a heterodyne receiver and a signal processor. A typical construction will be described below with reference to Fig. 1.</p><p><span class=\"paragraph-number\">[0010]   </span>Fig. 1 shows a configuration with a Master oscillator (MO) which generates a continuous laser light which, on the one hand, is used for pulse generation and, on the other hand, serves as a local oscillator. An amplitude modulator (AM) generates the pulses of desired length and shape. A frequency shift (FV) is additionally used to detect positive and negative directions of movement. These pulses are amplified (Av) and transmitted expanded into the atmosphere. A 2-axis scanner (Sc) predetermines the measuring direction. The scattered light detected with a telescope (TK) and coupled into the optical system is conducted by means of a transmitting/receiving switch, here with the aid of a circulator (ZI), to the symmetrical detector (Det.) and can be mixed here coherently (heterodyne) with the local oscillator, wherein only the low-frequency beat frequencies are registered by the detector and processed in the signal processing unit (SV). The wind speed component can be calculated from this beat frequency.</p><p><span class=\"paragraph-number\">[0011]   </span>The purpose of a Doppler lidar consists in the spatially resolved measurement of the radial velocity of the wind and preferably of the turbulence, for example at airports. The main problem here is the achievement of a high range with simultaneous high spatial resolution, high measuring accuracy and high volume scanning speed.</p><p><span class=\"paragraph-number\">[0012]   </span>The range is determined by the sensitivity of the system, which is given by the Lidar equation: </p><p><maths num=\"gl. 1\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 150mm; height: 11mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0001.tif&width=150mm&height=11mm\"/></maths></p><p>TABLE 1</p><p><tables num=\"0001\"><table frame=\"all\"><tgroup cols=\"5\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"13mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"41mm\"/><colspec colname=\"col3\" colnum=\"3\" colwidth=\"6mm\"/><colspec colname=\"col4\" colnum=\"4\" colwidth=\"20mm\"/><colspec colname=\"col5\" colnum=\"5\" colwidth=\"88mm\"/><tbody><row><entry>PRX:</entry><entry>received power</entry><entry morerows=\"2\"/><entry morerows=\"2\">K<sub>SYS</sub>:</entry><entry morerows=\"2\">System constant (aperture of receiving optics, system efficiency, overlap of transmit and receive beams</entry></row><row><entry>P<sub>TX</sub>:</entry><entry>Transmitter pulse power</entry></row><row><entry>C:</entry><entry>Speed of light</entry></row><row><entry>τ:</entry><entry>Pulse duration</entry><entry/><entry>β<sub>A</sub>(R,λ):</entry><entry>Atmospheric backscatter coefficient</entry></row><row><entry>n</entry><entry>Number of Measurements</entry><entry/><entry>L[α(R,λ)]:</entry><entry>Propagation attenuation function</entry></row></tbody></tgroup></table></tables></p><p><span class=\"paragraph-number\">[0013]   </span>Equation 1 describes the power which is received after the emission of an individual pulse.</p><p><span class=\"paragraph-number\">[0014]   </span>For technical considerations, it is often more clear to use the signal-to-noise ratio (SNR): </p><p><maths num=\"gl. 2\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 11mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0002.tif&width=151mm&height=11mm\"/></maths></p><p><span class=\"paragraph-number\">[0015]   </span>In order to increase the sensitivity, the powers of a plurality of successively emitted pulses can be added and then the mean value can be calculated. Since this form of integration is incoherent, the signal-to-noise ratio of the measured value for PRX does not increase with the number n of integrated measurements but with </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 8mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0003.tif&width=8mm&height=7mm\"/></maths></p><p>.</p><p><span class=\"paragraph-number\">[0016]   </span>For a predetermined SNR, the maximum range values R can accordingly be determined.<sub>max</sub> up to which the Lidar can still detect targets: </p><p><maths num=\"gl. 3\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 13mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0004.tif&width=151mm&height=13mm\"/></maths></p><p><span class=\"paragraph-number\">[0017]   </span>The parameters which determine the influence of the lidar transmitter on the sensitivity or the range of the lidar are summarized in the Figure of Merit (FOM) of the transmitter: </p><p><maths num=\"gl. 4\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0005.tif&width=151mm&height=8mm\"/></maths></p><p><span class=\"paragraph-number\">[0018]   </span>This results in the following for the maximum range: </p><p><maths num=\"gl. 5\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 13mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0006.tif&width=151mm&height=13mm\"/></maths></p><p><span class=\"paragraph-number\">[0019]   </span>The spatial resolution ΔR is: </p><p><maths num=\"gl. 6\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0007.tif&width=151mm&height=7mm\"/></maths></p><p><span class=\"paragraph-number\">[0020]   </span>The number of measurements n results from the pulse repetition frequency f.<sub>P</sub>, the effective beam width θ of the system and the rotational speed of the scanner <sub>ω</sub>: </p><p><maths num=\"gl. 7\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0008.tif&width=151mm&height=7mm\"/></maths></p><p><span class=\"paragraph-number\">[0021]   </span>The range R<sub>UA</sub>Until which the measurements are still unambiguous: </p><p><maths num=\"gl. 8\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 151mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0009.tif&width=151mm&height=8mm\"/></maths></p><p><span class=\"paragraph-number\">[0022]   </span>The maximum range R<sub>NaX</sub> may be increased by increasing the transmit pulse power P<sub>TX</sub> and/or the pulse duration τ are increased. However, both parameters are limited by the optical properties of the amplifier material. An extension of the pulse duration would also increase (deteriorate) the spatial resolution. As long as only a single amplifier is used, only the number of measurements n can be increased.</p><p><span class=\"paragraph-number\">[0023]   </span>The transmission pulse power P<sub>TX</sub> and the system constant K<sub>SYS</sub> are predetermined by the state of the art available commercially or can be optimized for the application (transmitting/receiving optics). The critical target parameters for the measurement quality are then still</p><p><ul compact=\"compact\" list-style=\"dash\"><li> the spatial resolution ΔR,</li><br/><li> the maximum range Rmax or the FOM,</li><br/><li> the unique range R<sub>UA</sub>.</li></ul></p><p><span class=\"paragraph-number\">[0024]   </span>The available optimization parameters are the pulse width, the pulse repetition frequency f.<sub>P</sub> (or the number of measurements n) and the pulse shape (rectangle, Gaussian or combination of the two). The target parameters behave in opposite directions when the optimization parameters are varied, as shown in Table 1.</p><p><tables num=\"0002\"><table frame=\"all\"><title><b>Table 1</b></title><tgroup cols=\"4\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"22mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"20mm\"/><colspec colname=\"col3\" colnum=\"3\" colwidth=\"21mm\"/><colspec colname=\"col4\" colnum=\"4\" colwidth=\"24mm\"/><thead valign=\"top\"><row><entry/><entry>increase τ</entry><entry>F<sub>P</sub> increase</entry><entry>Rect → Gaussian</entry></row></thead><tbody><row><entry>ΔR</entry><entry>worse</entry><entry>Neutral</entry><entry>Worse</entry></row><row><entry>Rmax, FOM</entry><entry>better</entry><entry>Better</entry><entry>Better</entry></row><row><entry>Rua</entry><entry>neutral</entry><entry>Worse</entry><entry>Neutral</entry></row></tbody></tgroup></table></tables></p><p><span class=\"paragraph-number\">[0025]   </span>The Dilemma of a single-channel system can be significantly reduced if several channels are used instead of one channel, each of which has its Master oscillator (MO) and receiver (Det.), each channel operating with an optimized pulse shape. For stable and reliable operation of simultaneously several wavelengths n, an extension with a pulse control system (PRS) is necessary, as shown in Fig. 2.</p><p><span class=\"paragraph-number\">[0026]   </span>In the case of a system having a plurality of wavelengths n, each wavelength represents its own measuring channel. Different channels can be optimized for different tasks. This optimization possibility already exists if only two channels are present.</p><p><span class=\"paragraph-number\">[0027]   </span>The Master oscillator (MO) generates and amplifies the continuous laser light on N channels. The wavelengths are selected such that they are not absorbed by the constituents of the atmosphere. The minimum spacing of the wavelengths between the channels corresponds to the wavelengths which can still be separated using customary optical methods. The maximum distance between the wavelengths is determined by the amplification bandwidth or amplification properties of the optical amplifier (Av). The number of wavelength channels is not limited.</p><p><span class=\"paragraph-number\">[0028]   </span>The amplitude modulation (AM) can take place both jointly for all channels and separately for each individual channel. In this case, the pulse length or pulse shape is freely selectable. The generated pulses are frequency-shifted (FV).</p><p><span class=\"paragraph-number\">[0029]   </span>The generated and frequency-shifted pulses are jointly amplified in an optical amplifier (Av). A circulator (ZI) conducts the pulses to the telescope (TK) which expands the laser beam of all wavelengths and transmits it into the atmosphere. The backscattered light of all wavelength channels is collected again by the telescope and guided through the circulator (ZI) to the detectors (n × Det.). The local oscillator is superimposed for each channel separately on the respective detector (Det.), so that a separate heterodyne signal is present for each channel. The signal processing (SV) and the digitization (DV) initially take place separately for each of the n channels.</p><p><span class=\"paragraph-number\">[0030]   </span>The combinations of pulse shape, pulse duration and pulse spacing of the various wavelengths or channels are referred to below as wave shape. The embodiment shown in Fig. 3 makes it possible to optimize the range and the spatial resolution at the same time. At wavelength 1, long pulses are emitted which increase the sensitivity and thus the range. Wavelength 2 operates with short pulses which permit a high spatial resolution, but whose range is shorter. As long as a predefined SNR threshold is not undershot, the data channel of wavelength is used, after which a switch is made to wavelength. In this way, measurement is carried out in the near range with high spatial resolution and in the far range with coarser resolution, but higher range. In Fig. 3 shows the waveform with two wavelengths of different pulse widths and is shown in Fig. 4 the associated receiving function.</p><p><span class=\"paragraph-number\">[0031]   </span>It is also possible to add the signal powers of both channels in order to obtain a better SNR. The resulting spatial resolution is at least as good as that of the channel with the longer pulse width. By means of the Addition, it is possible to achieve that the sensitivity and thus the range is once again somewhat increased.</p><p><span class=\"paragraph-number\">[0032]   </span>The selection of the pulse shape has an additional influence on an increased range or spatial resolution. A square-wave pulse has an increased spatial resolution, while a Gaussian pulse has an increased range due to the smaller system bandwidth. These properties are additionally used to extend the possible measurement range. This is achieved by setting the channel for the far range a Gaussian pulse and for the near range channel a rectangular pulse with edges which are as steep as possible.</p><p><span class=\"paragraph-number\">[0033]   </span>One possible pulse shape and pulse length combination is the convolution between the Gaussian and rectangular pulses of different pulse lengths. In the following formula, this is expressed with the coefficient D, which can assume a value of 0 to 1. </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 84mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP0000000009380822&ekey=2258&cc=EP&producerName=imgb0010.tif&width=84mm&height=7mm\"/></maths></p><p><span class=\"paragraph-number\">[0034]   </span>In general, any desired pulse shapes or combinations of different pulse shapes can be used in order to adapt the system-inherent pulse bandwidth and the spatial resolution.</p><p><span class=\"paragraph-number\">[0035]   </span>In the case of the channels with shorter pulses, a shorter range results, as a result of which the pulse repetition frequency can be set higher in the case of the channel. A higher pulse repetition frequency has a positive effect on the SNR of the respective channel.</p><p><span class=\"paragraph-number\">[0036]   </span>The result of an example measurement is shown in Fig. 5. Two wavelength channels were used for this purpose. One channel () was parameterized with a pulse length of 100 ns, and the other channel () was parameterized with a pulse length of 800 ns. Both pulse shapes of the wavelengths were rectangular and were used at the same pulse repetition rate.</p><p><span class=\"paragraph-number\">[0037]   </span>The SNR of the channel (1) with the short pulse supplies a small SNR due to the lower energy and higher bandwidth, which leads to a small range. This channel covers the close range (range A+B: here up to 500 m) with high spatial resolution (the full spatial resolution is given here by the distance between the points in the image). The channel (2) supplies usable data with considerably poorer spatial resolution only after 150 m, but with an increased range (range B+C: here up to 2.5 km). The area of intersection (area B) is covered by both channels. Here, measurement data with increased spatial resolution and speed resolution are available.</p><p><span class=\"paragraph-number\">[0038]   </span>Single-channel systems would supply only one of the two measurement series. Thus, the user of conventional methods always compromises between minimum range, spatial resolution and maximum range.</p><p><span class=\"paragraph-number\">[0039]   </span>A higher average power and thus a higher sensitivity permit individual amplifiers (A1), (A2) to (An) for each channel. The system is shown in Fig. 6.</p><p><span class=\"paragraph-number\">[0040]   </span>By a time offset of the transmit pulses of wavelengths 1 and 2, as shown in Fig. 7, the transmit amplifier may be used more efficiently and the PRF may be doubled to effectively yield PRFv. However, the unambiguous distance range results from the PRF<sub>K</sub> of the individual channels.</p><p><span class=\"paragraph-number\">[0041]   </span>By increasing the number of measured values, the sensitivity of the lidar and thus its range was increased.</p><p><span class=\"paragraph-number\">[0042]   </span>Even during operation with different pulse widths, the pulses can be emitted in an offset manner, as shown in Fig. 8. Here, too, the effectiveness of the transmission amplifier can be improved.</p><p><span class=\"paragraph-number\">[0043]   </span>A disadvantage is that although the sensitivity of a lidar can be increased via the PRF, it is possible, as in Eq. Fig. 2 shows, however, a higher PRF reduces the unambiguous distance range, even when a plurality of channels with mutually offset pulses are used.</p><p><span class=\"paragraph-number\">[0044]   </span>In addition, the waveform of the lidar, which results from the superposition of the individual channels, i.e. the PRF, the pulse duration and the pulse shape of each individual channel, must be adapted manually to any weather situation, which makes automatic operation more difficult.</p><p><span class=\"paragraph-number\">[0045]   </span>SUMMARY of the invention It is therefore an object of the invention to provide a Doppler Lidar which makes atmospheric effects visible in clear weather and at the same time makes it possible to optimize the range, the spatial resolution and the speed resolution. The Doppler Lidar should be compactly constructed. Furthermore, the transmission pulse power should be optimally selectable for different fields of application.</p><p><span class=\"paragraph-number\">[0046]   </span>This object is achieved by the features of claim 1.</p><p><span class=\"paragraph-number\">[0047]   </span>This creates a Doppler Lidar which is based on the use of a multi-wavelength Doppler lidar system. Fig. 9 shows the block diagram of such a system. This system can be realized both as free-beam optics or as fiber technology.</p><p><span class=\"paragraph-number\">[0048]   </span>The Doppler Lidar, which is the subject of the invention, uses a plurality of channels N, it being possible for each channel, in addition to the individual pulse shape, to operate with its own pulse Repetition frequency PRF (pulse repetition frequency) or Pulse repetition Time period PRT. The prior art only describes the operation with the same BUT mutually offset PRT for each channel. The individual control of PRF/PRT is controlled by the timing modulator (TM). The scanning is optimized because each channel has its own unambiguous distance range. Thus, it is possible, for example, to operate a plurality of channels with a very high PRF in order to achieve a high sensitivity, one channel running in parallel with a low PRF in order to check whether the channels running with a high PRF detect targets in overrange (2nd trip echoes).</p><p><span class=\"paragraph-number\">[0049]   </span>The use of different pulse repetition frequencies/pulse intervals for each channel is thus essential to the invention.</p><p><span class=\"paragraph-number\">[0050]   </span>Each of the plurality of channels is preferably equipped with its own frequency modulator in addition to the individual pulse shape. The frequency modulator can switch off each channel individually. The use of individual frequency modulators for each channel makes it possible to expand the measurable ranges of the wind speeds.</p><p><span class=\"paragraph-number\">[0051]   </span>Furthermore, the use of adaptive/cognitive waveform optimization is preferably carried out. The Lidar may use its own measurement data to optimize its waveform itself. The optimization can also be carried out with the aid of external sensors.</p><p><span class=\"paragraph-number\">[0052]   </span>Brief DESCRIPTION of the drawings Further embodiments of the invention can be gathered from the following description and the subclaims.</p><p><span class=\"paragraph-number\">[0053]   </span>The construction and method of operation of the invention, however, together with additional objects and advantages thereof will be best understood from the following description of specific embodiments when read in connection with the accompanying drawings.</p><p><ul compact=\"compact\" list-style=\"none\"><li> Fig. 1 shows a block diagram of a single-channel Doppler lidar according to the prior art,</li><br/><li> Fig. 2 shows a block diagram of a multi-channel Doppler lidar with an individual pulse shape according to the prior art,</li><br/><li> Fig. 3 shows waveforms with two wavelengths of different pulse widths according to the prior art.</li><br/><li> Fig. 4 shows a receiving function according to Fig. 3,</li><br/><li> Fig. 5 shows an example measurement with two wavelength channels,</li><br/><li> Fig. 6 shows a block diagram of a multi-channel Doppler lidar with individual pulse shape and individual amplifiers according to the prior art,</li><br/><li> Fig. 7 shows the time offset of the transmission pulses of wavelengths 1 and 2 according to the prior art,</li><br/><li> Fig. 8 shows the time offset of the transmission pulses of wavelengths 1 and 2 with different pulse widths according to the prior art,</li><br/><li> Fig. 9 shows a block diagram of a multi-channel Doppler lidar with individual pulse shape and its own pulse repetition frequency(PRF)/pulse intervals (PRT) according to a first exemplary embodiment of the invention,</li><br/><li> Fig. 10 shows an example according to Fig. 9 for individual timing with four channels,</li><br/><li> Fig. 11 shows a block diagram of a multi-channel Doppler lidar with individual pulse shape, preferably its own pulse repetition frequency(PRF)/pulse intervals (PRT) (not shown) and individual frequency modulation according to a second embodiment of the invention,</li><br/><li> Fig. 12 shows a block diagram according to Fig. 11 with optimization of the waveform according to a third exemplary embodiment of the invention,</li><br/><li> Figures 13.1 to 13.4 show non-optimized and optimized pulse sequences for every two/four channels according to the invention,</li><br/><li> Fig. 14 shows a block diagram of a multi-channel Doppler lidar with individual pulse shape, its own pulse repetition frequency(PRF)/pulse intervals (PRT), individual frequency modulation and optimization of the waveform by self-optimization according to a fourth exemplary embodiment of the invention,</li><br/><li> Fig. 15 shows a block diagram of a multi-channel Doppler lidar with individual pulse shape, its own pulse repetition frequency(PRF)/pulse intervals (PRT), individual frequency modulation and optimization of the waveform by self-optimization and/or optimization with the aid of external sensors or numerical models according to a fifth exemplary embodiment of the invention,</li><br/><li> Fig. 16 shows a block diagram corresponding to Fig. 16 and individual amplifiers according to a sixth exemplary embodiment.</li></ul></p><p><span class=\"paragraph-number\">[0054]   </span>The invention relates to a multiple wavelength Doppler Lidar as shown in Fig. 9 according to a first exemplary embodiment.</p><p><span class=\"paragraph-number\">[0055]   </span>In the system with several wavelengths n, each wavelength represents its own measuring channel. Different channels can be optimized for different tasks.</p><p><span class=\"paragraph-number\">[0056]   </span>The Master oscillator (MO) generates and amplifies the coherent laser light onto N channels. Coherent light pulses, which are in particular ultrashort light pulses, are preferably generated. The wavelengths are selected such that they are not absorbed by the constituents of the atmosphere. The minimum spacing of the wavelengths between the channels corresponds to the wavelengths which can still be separated using customary optical methods. The maximum distance between the wavelengths is determined by the amplification bandwidth or amplifier properties of the optical amplifier (Av). The number of wavelength channels is not limited.</p><p><span class=\"paragraph-number\">[0057]   </span>The wavelengths are preferably in the near-infrared spectrum (1.55 μm). On the basis of this characteristic wavelength, the signal is scattered on aerosol particles and cloud droplets as it passes through the atmosphere. A portion of the backscattered infrared signal is received by the Doppler lidar detector. The cause of detected frequency shifts is the natural movement of the back-scattering aerosol and cloud particles (Doppler effect), from which the radial wind is derived.</p><p><span class=\"paragraph-number\">[0058]   </span>The amplitude modulation (AM) can take place both jointly for all channels and separately for each individual channel. In this case, the pulse length or pulse shape is freely selectable. The generated pulses are frequency-shifted (FV).</p><p><span class=\"paragraph-number\">[0059]   </span>The generated and frequency-shifted pulses are jointly amplified in an optical amplifier (Av). A circulator (ZI) conducts the pulses to the telescope (TK) which expands the laser beam of all wavelengths and transmits it into the atmosphere. The backscattered light of all wavelength channels is collected again by the telescope and guided through the circulator (ZI) to the detectors (n × Det.). The local oscillator is superimposed for each channel separately on the respective detector (Det.), so that a separate heterodyne signal is present for each channel. The signal processing (SV) and any digitization (DV) are initially carried out separately for each of the n channels.</p><p><span class=\"paragraph-number\">[0060]   </span>The combinations of pulse shape, pulse duration and pulse spacing of the various wavelengths or channels are referred to below as wave shape.</p><p><span class=\"paragraph-number\">[0061]   </span>The Doppler Lidar, which is the subject of the invention, uses a plurality of channels N, it being possible for each channel, in addition to the individual pulse shape, to operate with its own pulse Repetition frequency PRF (pulse repetition frequency) or Pulse repetition Time period PRT. The individual control of PRF/PRT is controlled by the timing modulator (TM). The scanning is optimized because each channel has its own unambiguous distance range. Thus, it is possible, for example, to operate a plurality of channels with a very high PRF in order to achieve a high sensitivity, one channel running in parallel with a low PRF in order to check whether the channels running with a high PRF detect targets in overrange (2nd trip echoes). An example of individual timing is shown in Fig. 10.</p><p><span class=\"paragraph-number\">[0062]   </span>The Doppler Lidar according to the invention can consequently simultaneously generate and evaluate different repetition frequencies, pulse shapes and pulse durations. In this case, all N channels can be combined or compared with one another using different algorithms. The result is an increase in the spatial resolution with simultaneous increase in the range by means of different pulse repetition rates, pulse shapes and pulse intervals.</p><p><span class=\"paragraph-number\">[0063]   </span>Fig. 11 shows a second embodiment of the invention with individual frequency modulators. The Doppler Lidar, which is the subject of the invention, uses a plurality of channels N, each channel being equipped with its own frequency modulator in addition to the individual pulse shape. This is controlled by the frequency modulator FV. The frequency modulator can individually switch off each channel, as a result of which no interfering light passes into the system in the pause times of the channel between the pulses. In addition, a different frequency offset (Δv1, Δv2,.) can be selected for each channel, as a result of which the unambiguous range of wind speeds which the Lidar can measure is expanded. Preferably, this Doppler lidar system also uses the timing modulator (not shown) as shown in Fig. 9.</p><p><span class=\"paragraph-number\">[0064]   </span>Fig. 12 shows a third embodiment of the invention with an automatic optimization of the wave shape. The Doppler Lidar, which is the subject of the invention, uses a plurality of channels N, the individual pulse shape of the channels or the waveform being automatically adapted to the respective measurement situation and task. The situation is determined by the current state of the environment (e.g. aerosol density, weather condition, temperature, air pressure, air humidity). The state can be detected by external sensors ES or derived from the signal or data processing SV, DV of the lidar. The sensor data are acquired by an optimizer OPT. The optimizer can determine the optimum waveform on the basis of historical data and known physical relationships. It is also capable of independently optimizing the wave shape by varying it. Known techniques of artificial intelligence (KI) or Machine Learning, for example, can be used for this purpose.</p><p><span class=\"paragraph-number\">[0065]   </span>Thus, for example, shorter pulses measure more effectively with increased turbulence. Thus, with increased turbulence in the atmosphere, shorter pulses with a higher PRF would have to be expected with a higher range. The unambiguous range could then also be increased by different PRFs by \"second trip recovery\".</p><p><span class=\"paragraph-number\">[0066]   </span>In summary, the technical effect of the features described above and preferably embodied according to the invention provides the advantages/effects listed in Table 2. The features according to the invention can be combined independently of one another. They are preferably implemented together.</p><p><tables num=\"0003\"><table frame=\"all\"><title><b>Table 2</b></title><tgroup cols=\"2\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"49mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"117mm\"/><thead valign=\"top\"><row><entry><b>Features according to the invention</b></entry><entry><b>Effects of the features according to the invention</b></entry></row></thead><tbody><row><entry>Individual PRF/PRT</entry><entry>Higher unique range by different second trip detection (PRFs)</entry></row><row rowsep=\"0\"><entry>Individual frequency modulators</entry><entry>Increasing sensitivity by turning off channels during their pause times</entry></row><row><entry/><entry>Increasing the unique speed range by different frequency offsets</entry></row><row><entry>Automatic optimization of waveform</entry><entry>Interventions by the user and the operational care effort are drastically reduced.</entry></row></tbody></tgroup></table></tables></p><p><span class=\"paragraph-number\">[0067]   </span>Fig. 13.1 and Fig. 13.2 show an example of an optimized pulse sequence for second trip correction with different PRFs.</p><p><span class=\"paragraph-number\">[0068]   </span>Fig. 13.1 shows a non-optimized pulse sequence for channel 1 and channel 2. the mean pulse interval is approximately (100 μs+100 μs)/2 = 100 μs. Fig. 13.2 shows optimized pulse intervals of the minimum mean time of approximately (50 μs+100 μs+50 μs)/3= 66 μs. This reduces the spontaneous emission ASE (Amplified spontaneous emission) in the fiber amplifier and increases the pulse energy and thus the performance of the overall system. In this example, the amplifier operates optimally at approximately 15 kHz.</p><p><span class=\"paragraph-number\">[0069]   </span>Fig. 13.3 and Fig. 13.4 show an example of an optimized pulse sequence for reducing the \"blind Range\" with different PRFs and pulse lengths for, for example, 4 channels.</p><p><span class=\"paragraph-number\">[0070]   </span>As Fig. 13.2 shows, there is an unambiguous range of 60 km, but the optical amplifier is poorly seeded (7.5 kHz). Fig. 13.2 shows an unambiguous range of 60 km, the optical amplifier now being optimally seeded (15 kHz). Fig. Fig. 14 shows a fourth embodiment of the invention with an automatic optimization of the wave shape. The Doppler Lidar, which is the subject of the invention, uses a plurality of channels N, it being possible for the individual pulse shape of the channels or the waveform to be adapted automatically to the respective measurement situation and measurement task. The situation can be determined by the current state of the environment (e.g. aerosol density, weather condition, temperature, air pressure, air humidity). The Lidar uses its own measurement data in order to optimize its waveform itself. This is done by an optimizer (OPT). The optimizer (OPT) is preferably a computer with suitable software which can control the function blocks amplitude modulation (AM), timing modulator (TM) and frequency modulator (FV). The software may implement execution from programmed algorithms that calculate the optimal waveform based on historical data and known physical relationships. Furthermore, it is possible to use an artificial intelligence which trains itself or which is trained.</p><p><span class=\"paragraph-number\">[0071]   </span>For example, shorter pulses measure more effectively in the case of increased turbulence, and thus, in the case of increased turbulence in the atmosphere, shorter pulses with a higher PRF can be expected to have a higher range. The unambiguous range can then also be increased by different PRFs by \"second trip recovery\".</p><p><span class=\"paragraph-number\">[0072]   </span>An example of self-optimization is shown in Table 3. In this case, the Lidar is optimized in such a way that the energy Dissipation rate is optimally measured.</p><p><tables num=\"0004\"><table frame=\"all\"><title><b>Table 3 Case differentiation according to \"energy Dissipation rate\" or \"Reactive turbulence\"</b></title><tgroup cols=\"4\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"29mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"34mm\"/><colspec colname=\"col3\" colnum=\"3\" colwidth=\"48mm\"/><colspec colname=\"col4\" colnum=\"4\" colwidth=\"27mm\"/><thead valign=\"top\"><row><entry>EDR O.Cn<sup>2</sup></entry><entry>Pulse length (FWHM)</entry><entry>Pulse shape</entry><entry>eff. PRF</entry></row></thead><tbody><row><entry>Calm</entry><entry>1000 ns</entry><entry>Gaussian</entry><entry>15 kHz</entry></row><row><entry>Weak</entry><entry>800 ns</entry><entry>0.75Gauss*0.25Rect</entry><entry>16 kHz</entry></row><row><entry>Middle</entry><entry>500 ns</entry><entry>0.25Gauss*0.75Rect</entry><entry>18 kHz</entry></row><row><entry>Strong</entry><entry>300 ns</entry><entry>Rect</entry><entry>20 kHz</entry></row></tbody></tgroup></table></tables></p><p><span class=\"paragraph-number\">[0073]   </span>Fig. 15 shows a fifth exemplary embodiment of the invention, in which, in addition to the above-described self-optimization according to the fourth exemplary embodiment, the optimization can also take place with the aid of external sensors (ES). In addition to external sensors (ES), data can also be supplied to the optimizer (opt) from numerical models (NUM).</p><p><span class=\"paragraph-number\">[0074]   </span>Fig. 16 shows a sixth exemplary embodiment of the invention in which, in addition to the design of the Doppler Lidar according to the fifth exemplary embodiment, individual amplifiers (A1), (A2) to (An) are provided for each channel. a higher average power and thus a higher sensitivity is thereby made possible.</p><p><span class=\"paragraph-number\">[0075]   </span>The invention makes it possible to accurately measure the wind speed vector in real time with the aid of pulsed laser beams backscattered on air molecules and aerosols. On account of the construction of the Lidar according to the invention and the evaluation method according to the invention, a large range can be achieved, to be precise only at low backscatter intensities. In particular, the use of different pulse repetition frequencies/pulse intervals for each channel opens up advantageous measuring systems. Thus, for example, 2nd trip recovery means that one is able to cancel or prevent superimpositions. If a lidar channel with a low PRF and a correspondingly high unambiguous range is allowed to run, then this goal can be detected at a large distance, but the superimposition on the lidar channels with a high PRF can at most be reversed where no 1 st trip echoes have been measured.</p><p><span class=\"paragraph-number\">[0076]   </span>In addition to the applications on the ground, for example for detecting wind speeds, shear winds, turbulences and other wind and weather situations, in particular at airports, the Doppler Lidar according to the invention can be used with possibly adapted transmission pulse power, for example on wind wheels and/or on board land, air and/or water vehicles.</p><p><span class=\"paragraph-number\">[0077]   </span>In summary, the invention relates to a Doppler Lidar for detecting wind speeds with a device (MO) for generating pulsed coherent laser light on N wavelength channels, wherein an amplitude modulation (AM) for individually shaping the pulse for each channel takes place separately for each individual wavelength channel, a device (TK, SC) for emitting generated, frequency-shifted and amplified pulses of the laser light in predetermined spatial directions, a detector (n x Det.) for receiving the generated and backscattered laser light on N wavelength channels and an electronic evaluation device (n x SV) for determining a Doppler shift amount between the transmitted light and the received light on N wavelength channels, wherein a timing modulator (TM) is assigned to the N wavelength channels for individual control of a pulse repetition frequency (PRF) and/or pulse repetition period (PRT) in addition to the pulse shape for wavelength channels.</p><p><span class=\"paragraph-number\">[0078]   </span>The timing modulator (TM) controls different pulse repetition frequencies (PRF) and/or pulse repetition periods (PRT) for each of the N wavelength channels.</p><p><span class=\"paragraph-number\">[0079]   </span>Individual frequency modulators for frequency shifting (FV) are provided so that the generated pulses or pulse sequences can be frequency-shifted separately for each of the N wavelength channels.</p><p><span class=\"paragraph-number\">[0080]   </span>The laser light is emitted into the atmosphere at a frequency f (T) as transmitted light and at a frequency f(R) as received light, which is received by scattering the laser light on the basis of aerosol present in the atmosphere, in order thereby to determine a wind speed of the air flow in a remote region.</p><p><span class=\"paragraph-number\">[0081]   </span>In order to automatically optimize the individual pulse shape of the N-wavelength channels, an optimizer (OPT) is provided which detects meteorological phenomena such as wind, wind shear and turbulence by means of at least one external sensor (SE) and adapts the wave shape to the respective measuring situation.</p><p><span class=\"paragraph-number\">[0082]   </span>The optimizer (OPT) is designed for self-optimization of the waveform, for which purpose its own measurement data are fed to the optimizer (OPT) and the latter has control access to the amplitude modulation (AM), the timing modulator (TM) and/or the individual frequency modulators (FV).</p><p><span class=\"paragraph-number\">[0083]   </span>The optimizer (OPT) is designed as a computer with its own software, the software implementing an optimum waveform for the wavelength channels on the basis of historical data and physical relationships.</p><p><span class=\"paragraph-number\">[0084]   </span>An artificial intelligence for learning the optimizer (OPT) is provided.</p>",
            "CLMS": "(EP4083660)<br/><p>1. Doppler Lidar for detecting wind speeds, having a device (MO) for generating pulsed coherent laser light on N wavelength channels, amplitude modulation (AM) for individually shaping the pulse for each channel being carried out separately for each individual wavelength channel, a device (TK, SC) for emitting generated, frequency-shifted and amplified pulses of the laser light in predetermined spatial directions, a detector (n x Det.) for receiving the generated and backscattered laser light on N wavelength channels and an electronic evaluation device (n x SV) for determining a Doppler shift amount between the transmitted light and the received light on N wavelength channels, <b>characterized in that</b> a timing modulator (TM) is assigned to the N wavelength channels for individually controlling a pulse repetition frequency (PRF) and/or pulse repetition period (PRT) in addition to the pulse shape for wavelength channels.</p><p>2. Doppler Lidar according to Claim 2, <b>characterized in that</b> the timing modulator (TM) controls different pulse repetition frequencies (PRF) and/or pulse repetition periods (PRT) for each of the N wavelength channels.</p><p>3. Doppler Lidar according to Claim 1 or 2, <b>characterized in that</b> individual frequency modulators are provided for frequency shifting (FV) so that the generated pulses or pulse sequences can be frequency shifted separately for each of the N wavelength channels.</p><p>4. Doppler Lidar according to one of Claims 1 to 3, <b>characterized in that</b> emitting the laser light into the atmosphere at a frequency f (T) as transmitted light and at a frequency f(R) as received light received by scattering the laser light due to aerosol present in the atmosphere to thereby determine a wind velocity of the airflow in a remote area.</p><p>5. Doppler Lidar according to one of Claims 1 to 4, <b>characterized in that</b> for automatic optimization of the individual pulse shape of the N-wavelength channels, an optimizer (OPT) is provided which detects meterological phenomena such as winch, wind shear and turbulence by at least one external sensor (SE) and adapts the wave shape to the respective measurement situation.</p><p>6. Doppler Lidar according to one of Claims 1 to 5, <b>characterized in that</b> the optimizer (OPT) is designed for self-optimization of the waveform, for which purpose the own measurement data are fed to the optimizer (OPT) and the latter has control access to the amplitude modulation (AM), the timing modulator (TM) and/or the individual frequency modulators (FV).</p><p>7. Doppler Lidar according to Claim 5 or 6, <b>characterized in that</b> the optimizer (OPT) is designed as a computer with its own software, wherein the software implements an optimum waveform for the wavelength channels on the basis of historical data and physical relationships.</p><p>8. Doppler Lidar according to one of Claims 5 to 7, <b>characterized in that</b> an artificial intelligence is provided for learning the optimizer (OPT).</p>",
            "NPR": "1",
            "APID": "160529315",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G01P-005/26<br/>G01S-007/484<br/>G01S-007/497<br/>G01S-017/50<br/>G01S-017/58<br/>G01S-017/95<br/>G01W-001/00<br/>G06K-009/00",
            "ID": "102302504",
            "AB": "(EP4083660)<br/>Doppler Lidar for detecting wind speeds, having a device (MO) for generating pulsed coherent laser light on N wavelength channels, wherein an amplitude modulation (AM) for individually shaping the pulse for each channel takes place separately for each individual wavelength channel, a device (TK, SC) for emitting generated, frequency-shifted and amplified pulses of the laser light in predetermined spatial directions, a detector (n x Det.) for receiving the generated and backscattered laser light on N wavelength channels and an electronic evaluation device (n x SV) for determining a Doppler shift amount between the transmitted light and the received light on N wavelength channels, wherein a timing modulator (TM) is assigned to the N wavelength channels for individual control of a pulse repetition frequency (PRF) and/or pulse repetition period (PRT) in addition to the pulse shape for wavelength channels.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=zZVoaFk6F%252FbVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2021-04-28",
            "PA": "LEONARDO GERMANY",
            "PAAD": "(EP4083660)<br/>(PUB:EP-4083660A1-8)NAME=LEONARDO Germany GmbH Raiffeisenstr. 1 , CITY=41470 Neuss , COUNTRY=DE , REG=101945108<br/><br/><br/>(US20220350028)<br/>(PUB:US-20220350028A1-2)NAME=LEONARDO Germany GmbH  , CITY=Neuss , COUNTRY=DE<br/><br/><br/>(DE102021002239)<br/>(PUB:DE-102021002239A1-6)NAME=LEONARDO Germany GmbH  , CITY=Neuss , POSTCODE=41470 , COUNTRY=DE<br/><br/><br/>(JP7369822)<br/>(PUB:JP-7369822B2-198)NAME=LEONARDO GERMANY GMBH  , REG=522172575<br/><br/>(PUB:JP-2022170737A-198)NAME=LEONARDO GERMANY GMBH  , REG=522172575<br/>",
            "FAN": "102302504",
            "TI": "Doppler lidar for detecting wind and / or vortex flows",
            "TECD": "Computer technology<br/>Measurement",
            "EPD": "2022-11-02",
            "ICLM": "(EP4083660)<br/><p>1. Doppler Lidar for detecting wind speeds, having a device (MO) for generating pulsed coherent laser light on N wavelength channels, amplitude modulation (AM) for individually shaping the pulse for each channel being carried out separately for each individual wavelength channel, a device (TK, SC) for emitting generated, frequency-shifted and amplified pulses of the laser light in predetermined spatial directions, a detector (n x Det.) for receiving the generated and backscattered laser light on N wavelength channels and an electronic evaluation device (n x SV) for determining a Doppler shift amount between the transmitted light and the received light on N wavelength channels, characterized in that a timing modulator (TM) is assigned to the N wavelength channels for individually controlling a pulse repetition frequency (PRF) and/or pulse repetition period (PRT) in addition to the pulse shape for wavelength channels.</p>",
            "CTN": "(EP4083660)<br/>XP055917285 none WHO=EXAMINER SELF=N CAT=X CAT=I<br/>XP055917286 none WHO=EXAMINER SELF=N CAT=A<br/>XP055917287 none WHO=EXAMINER SELF=N CAT=A<br/>EP3232226 80765166 WHO=EXAMINER SELF=N CAT=A<br/>EP3413087 76913899 WHO=EXAMINER SELF=N CAT=A<br/>DE10316762 853794 WHO=APPLICANT SELF=N<br/>DE102005034729 955197 WHO=APPLICANT SELF=N<br/><br/>(DE102021002239)<br/>DE10316762 853794 WHO=APPLICANT SELF=N<br/>DE102005034729 955197 WHO=APPLICANT SELF=N<br/>EP3232226 80765166 WHO=UNKNOWN SELF=N<br/>EP3413087 76913899 WHO=UNKNOWN SELF=N<br/><br/>(JP7369822)<br/>WO201692705 80765166 WHO=EXAMINER SELF=N CAT=Y<br/>WO2016181493 80767176 WHO=EXAMINER SELF=N CAT=Y<br/>JP2010127840 33135587 WHO=EXAMINER SELF=N CAT=Y<br/>WO2019202676 86383259 WHO=EXAMINER SELF=N CAT=Y<br/>JP2014505861 17030965 WHO=EXAMINER SELF=N<br/>JP2011013138 33248018 WHO=EXAMINER SELF=N<br/>JP2010127918 33135900 WHO=EXAMINER SELF=N<br/>CN108594253 81481400 WHO=EXAMINER SELF=N",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2042-04-28",
                    "XAP": "2022JP-0074249",
                    "APD": "2022-04-28",
                    "APID": "160676829",
                    "REG_LINK": "https://www.j-platpat.inpit.go.jp/web/all/top/BTmTopEnglishPage",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ZNM2lsokdKmseLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "JP7369822",
                            "KIND": "B2",
                            "XPN": "JP7369822",
                            "V_PNID": "JP-7369822B2-198",
                            "DATE": "2023-10-26",
                            "STG": "Published granted patent (Second level)  from 01-03-1996 onwards (Published examined patent application (Second level) 1971-1996)",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=h4fuNf5WSX+OCSZOOFmMo0DJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=JP7369822&kind=B2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ZNM2lsokdKmseLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "JP2022170737",
                            "KIND": "A",
                            "XPN": "JP2022170737",
                            "V_PNID": "JP-2022170737A-198",
                            "DATE": "2022-11-10",
                            "STG": "Published application",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=N5221X+da388yKdaQ6yhNAMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=JP2022170737&kind=A",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=mF9SBoW1uZg4dMVSORGyLbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2042-04-27",
                    "XAP": "2022US-17730740",
                    "APD": "2022-04-27",
                    "APID": "160518121",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/17730740",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=oo%252Fv95nc5oNqHAg67%252Fi8GcRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US20220350028",
                            "KIND": "A1",
                            "XPN": "US20220350028",
                            "V_PNID": "US-20220350028A1-2",
                            "DATE": "2022-11-03",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcNTtSirHtIdVLxtUVS6odf4bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20220350028&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=oo%252Fv95nc5oNqHAg67%252Fi8GcRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2042-04-13",
                    "XAP": "2022EP-0168120",
                    "APD": "2022-04-13",
                    "APID": "160529315",
                    "REG_LINK": "https://register.epo.org/application?number=EP22168120",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=zZVoaFk6F%252FbVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4083660",
                            "KIND": "A1",
                            "XPN": "EP4083660",
                            "V_PNID": "EP-4083660A1-8",
                            "DATE": "2022-11-02",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=x0jAXD9vGYuJwtRou/DB/fEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4083660&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=zZVoaFk6F%252FbVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2041-04-28",
                    "XAP": "2021DE-10002239",
                    "APD": "2021-04-28",
                    "APID": "160530296",
                    "REG_LINK": "http://www.orbit.com/getDPMARegisterUrl?PN=DE102021002239",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=YIvqL50msnPxDseWrKXZzsExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "DE102021002239",
                            "KIND": "A1",
                            "XPN": "DE102021002239",
                            "V_PNID": "DE-102021002239A1-6",
                            "DATE": "2022-11-03",
                            "STG": "Doc. laid open (First publication)",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=J3Tsdu44efg+JxBLW67xbTjagrjiAOzzO3DJpHhvzNq8mcFoz1yzz1k0PkWksrrN&n=1&xpn=DE102021002239&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=YIvqL50msnPxDseWrKXZzsExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4083660_A1",
            "EPRD": "2021-04-28",
            "PN": "EP4083660           A1 2022-11-02 [EP4083660]<br/>US20220350028       A1 2022-11-03 [US20220350028]<br/>DE102021002239      A1 2022-11-03 [DE102021002239]<br/>JP7369822           B2 2023-10-26 [JP7369822]<br/>JP2022170737        A  2022-11-10 [JP2022170737]",
            "ADB": "(EP4083660)<br/><p>In addition, the waveform of the lidar, which results from the superposition of the individual channels, i.e. the PRF, the pulse duration and the pulse shape of each individual channel, must be adapted manually to any weather situation, which makes automatic operation more difficult. SUMMARY of the invention It is therefore an object of the invention to provide a Doppler Lidar which makes atmospheric effects visible in clear weather and at the same time makes it possible to optimize the range, the spatial resolution and the speed resolution.</p><p>The embodiment shown in Fig. 3 makes it possible to optimize the range and the spatial resolution at the same time.</p><p>The use of individual frequency modulators for each channel makes it possible to expand the measurable ranges of the wind speeds.</p><p>As from DE 103 16 762 B4 it is known that in weather radar systems there is the problem that they require large suspended particles of high density, such as, for example, water drops in clouds, for their backscatter measurement and are therefore only suitable for early warning of weather clouds at a greater distance of up to a few tens of kilometers. The most frequent air flows in clear view, such as shear winds and so-called \"clear air turbulences\" in the troposphere and jet streams in the stratosphere, on the other hand, cannot be detected by the weather radar, since the wavelengths of a few centimeters to millimeters are relatively long compared to the size of the air particles.</p><p>In Doppler lidar measurements, however, there is the general problem of the low intensity of backscattering both of molecules and of aerosols.</p><p>The main problem here is the achievement of a high range with simultaneous high spatial resolution, high measuring accuracy and high volume scanning speed.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=5<br/>PNAAGE=22<br/>NBPA=1; <br/>ALLCT=3; SCT=0; NSCT=3; <br/>ALLCTG=3; SCTG=2; NSCTG=1; <br/>AFS=20; ACC=20; AMCC=5; <br/>IGEN=0.9; IORG=0.83; IRAD=0.92; <br/>IMPI=2.99; MACI=1.5; PASI=3.15; PAVI=3.65; ",
            "PTCC": "(EP4016221)<br/>CC=EP EED=2040-12-18 STATUS=GRANTED APID=158203255 APD=2020-12-18 XPN=EP4016221 PD=2022-06-22 PD=2023-06-14 EPD=2022-06-22 LPD=2023-06-14 PDG=2023-06-14 <br/>CC=DE EED=2040-12-18 STATUS=GRANTED APID=158203255 XPN=EP4016221 PDG=2023-06-14 <br/>CC=FR EED=2040-12-18 STATUS=GRANTED APID=158203255 XPN=EP4016221 PDG=2023-06-14 <br/>CC=IT EED=2040-12-18 STATUS=GRANTED APID=158203255 XPN=EP4016221 PDG=2023-06-14 <br/><br/>(US20240105065)<br/>CC=US EED=2041-12-17 STATUS=PENDING APID=167508429 APD=2021-12-17 XPN=US20240105065 PD=2024-03-28 EPD=2024-03-28 LPD=2024-03-28 <br/><br/>(WO2022130334)<br/>CC=CN EED=2041-12-17 STATUS=PENDING APID=167911845 APD=2021-12-17 XPN=CN117413232 PD=2024-01-16 EPD=2024-01-16 LPD=2024-01-16 <br/>CC=KR EED=2041-12-17 STATUS=PENDING APID=165942257 APD=2021-12-17 XPN=KR20230135580 PD=2023-09-25 EPD=2023-09-25 LPD=2023-09-25 <br/>CC=US EED=2041-12-17 STATUS=PENDING APID=167508429 APD=2021-12-17 XPN=US20240105065 PD=2024-03-28 EPD=2024-03-28 LPD=2024-03-28 <br/><br/>(CN117413232)<br/>CC=CN EED=2041-12-17 STATUS=PENDING APID=167911845 APD=2021-12-17 XPN=CN117413232 PD=2024-01-16 EPD=2024-01-16 LPD=2024-01-16 <br/><br/>(KR20230135580)<br/>CC=KR EED=2041-12-17 STATUS=PENDING APID=165942257 APD=2021-12-17 XPN=KR20230135580 PD=2023-09-25 EPD=2023-09-25 LPD=2023-09-25 <br/>",
            "EPN": "EP4016221",
            "CTGN": "(EP4016221)<br/>EP4163750 104539134 WHO=APPLICANT SELF=Y<br/>EP4198842 105386908 WHO=APPLICANT SELF=Y<br/><br/>(WO2022130334)<br/>US11761380 91737212 WHO=EXAMINER SELF=N",
            "LAPD": "2021-12-17",
            "STDN": "",
            "NPN": "5",
            "DESC": "<p><h1>CROSS-REFERENCE TO RELATED APPLICATIONS</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This patent application claims priority from European patent application no. 20425059.1 filed on Dec. 18, 2020, the entire disclosure of which is incorporated herein by reference.</p><br/><p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates to a method and system for detecting and classifying manoeuvres executed by an aircraft on the basis of measures acquired during a flight of the aircraft.</p><p><h1>BACKGROUND ART</h1></p><p><span class=\"paragraph-number\">[0003]   </span>As is known, in aeronautics the need to monitor the state of fatigue, and more generally the state of health, of the components of an aircraft is particularly felt, in order to be able to accurately estimate the remaining life time of each component, and therefore to optimize maintenance activities, without compromising flight safety.</p><p><span class=\"paragraph-number\">[0004]   </span>In particular, it is known that the state of fatigue to which the components of an aircraft are subjected depends on the manoeuvres to which, during usage, the aircraft has been subjected, since the loads to which each component is subjected depend on the manoeuvres carried out by the aircraft. Consequently, the need is felt to correctly identify the manoeuvres executed by an aircraft, so that the so-called “real usage spectrum” can then be determined. To this end, it is known to equip aircraft with monitoring systems adapted to detect the time trends of quantities relative to the flight; this allows to acquire a large number of measurements, which can be analysed to study the history of the manoeuvres carried out by the aircraft. However, the Applicant has observed that, even having such measurements, the correct identification of the executed manoeuvres requires the execution of advanced data processing techniques and is also hampered by the fact that different manoeuvres typically have different durations, which complicates the analysis of the aforementioned time trends.</p><p><span class=\"paragraph-number\">[0005]   </span>EP 2384971 discloses a method for determining a manoeuver performed by an aircraft having sensors for monitoring motion data, the method including: periodically sampling the sensors to electronically determine segments of motion data of the aircraft; aggregating sequences of the segments of the motion data; comparing the aggregated segments of motion data to models of particular manoeuvers; and determining the manoeuver performed by the aircraft.</p><p><span class=\"paragraph-number\">[0006]   </span>EP 2270618 discloses a method for fault determination for an aircraft, which includes: generating a predicted manoeuver based on a model of aircraft performance; determining an actual manoeuver of the aircraft using information obtained from an inertial measurement system; and comparing the predicted manoeuver and the actual manoeuver.</p><p><span class=\"paragraph-number\">[0007]   </span>EP 3462266 discloses a method for maintaining an aircraft based on a plurality of maintenance messages generated during operation of the aircraft.</p><p><h1>DISCLOSURE OF INVENTION</h1></p><p><span class=\"paragraph-number\">[0008]   </span>Aim of the present invention to provide a method for detecting the type of manoeuvres executed during the flight of an aircraft, which at least partially satisfies the aforementioned requirement.</p><p><span class=\"paragraph-number\">[0009]   </span>According to the present invention, there are provided a method and a system for detecting and classifying, as defined in the appended claims.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0010]   </span>For a better understanding of the present invention, embodiments thereof are now described, purely by way of non-limiting example, with reference to the accompanying drawings, in which:</p><p><span class=\"paragraph-number\">[0011]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b>A</a> is a schematic view of aircrafts equipped with monitoring systems;</p><p><span class=\"paragraph-number\">[0012]   </span><a href=\"#DRAWINGS\">FIG. <b>1</b>B</a> shows examples of trends over time of values of quantities acquired through monitoring systems;</p><p><span class=\"paragraph-number\">[0013]   </span><a href=\"#DRAWINGS\">FIG. <b>2</b></a> shows a block diagram which exemplifies a possible subdivision into macrocategories of a set of manoeuvres that can be executed by an aircraft;</p><p><span class=\"paragraph-number\">[0014]   </span><a href=\"#DRAWINGS\">FIGS. <b>3</b> and <b>6</b></a> show block diagrams relative to a training step according to a first strategy;</p><p><span class=\"paragraph-number\">[0015]   </span><a href=\"#DRAWINGS\">FIG. <b>4</b></a> shows a block diagram of a training data structure;</p><p><span class=\"paragraph-number\">[0016]   </span><a href=\"#DRAWINGS\">FIG. <b>5</b>A</a> schematically shows a part of the training data structure and the arrangement of a time window;</p><p><span class=\"paragraph-number\">[0017]   </span><a href=\"#DRAWINGS\">FIGS. <b>5</b>B and <b>5</b>C</a> schematically show the part of the training data structure shown in <a href=\"#DRAWINGS\">FIG. <b>5</b>A</a> and the arrangement of time windows having two different time durations, respectively;</p><p><span class=\"paragraph-number\">[0018]   </span><a href=\"#DRAWINGS\">FIG. <b>7</b></a> shows two block diagrams exemplifying training operations according to the first strategy and according to a second strategy;</p><p><span class=\"paragraph-number\">[0019]   </span><a href=\"#DRAWINGS\">FIG. <b>8</b></a> shows tables exemplifying part of the operations shown in <a href=\"#DRAWINGS\">FIG. <b>3</b></a>;</p><p><span class=\"paragraph-number\">[0020]   </span><a href=\"#DRAWINGS\">FIG. <b>9</b></a> shows a block diagram relative to analysis operations according to the first strategy;</p><p><span class=\"paragraph-number\">[0021]   </span><a href=\"#DRAWINGS\">FIG. <b>10</b></a> schematically shows a part of a non-labelled data structure and the arrangement of windows having different time durations;</p><p><span class=\"paragraph-number\">[0022]   </span><a href=\"#DRAWINGS\">FIG. <b>11</b></a> shows two block diagrams exemplifying analysis operations according to the first and second strategy;</p><p><span class=\"paragraph-number\">[0023]   </span><a href=\"#DRAWINGS\">FIGS. <b>12</b> and <b>13</b></a> show block diagrams relative to a training step according to the second strategy;</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIG. <b>14</b></a> schematically shows the part of the training data structure shown in <a href=\"#DRAWINGS\">FIGS. <b>5</b>A-<b>5</b>C</a> and the arrangement of time windows used during training according to the second strategy;</p><p><span class=\"paragraph-number\">[0025]   </span><a href=\"#DRAWINGS\">FIG. <b>15</b></a> shows a table exemplifying part of the operations shown in <a href=\"#DRAWINGS\">FIGS. <b>12</b> and <b>13</b></a>;</p><p><span class=\"paragraph-number\">[0026]   </span><a href=\"#DRAWINGS\">FIG. <b>16</b></a> shows a block diagram relative to analysis operations according to the second strategy;</p><p><span class=\"paragraph-number\">[0027]   </span><a href=\"#DRAWINGS\">FIG. <b>17</b></a> shows a block diagram relative to training and analysis operations according to a third strategy;</p><p><span class=\"paragraph-number\">[0028]   </span><a href=\"#DRAWINGS\">FIG. <b>18</b></a> is a block diagram exemplifying training operations according to the third strategy;</p><p><span class=\"paragraph-number\">[0029]   </span><a href=\"#DRAWINGS\">FIG. <b>19</b></a> is a block diagram exemplifying analysis operations according to the third strategy;</p><p><span class=\"paragraph-number\">[0030]   </span><a href=\"#DRAWINGS\">FIGS. <b>20</b>A-<b>20</b>B</a> show block diagrams relative to classification operations carried out according to the first strategy;</p><p><span class=\"paragraph-number\">[0031]   </span><a href=\"#DRAWINGS\">FIG. <b>21</b></a> shows a block diagram relative to training and analysis operations according to a fourth strategy;</p><p><span class=\"paragraph-number\">[0032]   </span><a href=\"#DRAWINGS\">FIG. <b>22</b></a> shows two block diagrams exemplifying, respectively, training and analysis operations according to the fourth strategy;</p><p><span class=\"paragraph-number\">[0033]   </span><a href=\"#DRAWINGS\">FIGS. <b>23</b> and <b>26</b></a> show block diagrams relative to operations carried out, respectively, according to a first and a second variant of the present method;</p><p><span class=\"paragraph-number\">[0034]   </span><a href=\"#DRAWINGS\">FIG. <b>24</b></a> shows a block diagram exemplifying analysis operations according to the second variant;</p><p><span class=\"paragraph-number\">[0035]   </span><a href=\"#DRAWINGS\">FIGS. <b>25</b> and <b>27</b></a> show tables relative to the first and second variants of the present method, respectively; and</p><p><span class=\"paragraph-number\">[0036]   </span><a href=\"#DRAWINGS\">FIG. <b>28</b></a> shows a block diagram relative to operations according to the present method.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and system for detecting and classifying manoeuvres executed by an aircraft on the basis of measures acquired during a flight of the aircraft.</p><p><span class=\"paragraph-number\">[0002]   </span>As is known, in aeronautics the need to monitor the state of fatigue, and more generally the state of health, of the components of an aircraft is particularly felt, in order to be able to accurately estimate the remaining life time of each component, and therefore to optimize maintenance activities, without compromising flight safety.</p><p><span class=\"paragraph-number\">[0003]   </span>In particular, it is known that the state of fatigue to which the components of an aircraft are subjected depends on the manoeuvres to which, during usage, the aircraft has been subjected, since the loads to which each component is subjected depend on the manoeuvres carried out by the aircraft. Consequently, the need is felt to correctly identify the manoeuvres executed by an aircraft, so that the so-called \"real usage spectrum\" can then be determined. To this end, it is known to equip aircraft with monitoring systems adapted to detect the time trends of quantities relative to the flight; this allows to acquire a large number of measurements, which can be analysed to study the history of the manoeuvres carried out by the aircraft. However, the Applicant has observed that, even having such measurements, the correct identification of the executed manoeuvres requires the execution of advanced data processing techniques and is also hampered by the fact that different manoeuvres typically have different durations, which complicates the analysis of the aforementioned time trends.</p><p><span class=\"paragraph-number\">[0004]   </span><patcit dnum=\"EP2384971A1\">EP 2 384 971 A1</patcit> discloses determining aircraft manoeuvres based on sensor measurements in a Health and Usage Monitoring Systems (HUMS) to determine the usage spectrum of the aircraft and then the health status.</p><p><span class=\"paragraph-number\">[0005]   </span>Aim of the present invention to provide a method for detecting the type of manoeuvres executed during the flight of an aircraft, which at least partially satisfies the aforementioned requirement.</p><p><span class=\"paragraph-number\">[0006]   </span>According to the present invention, there are provided a method and a system for detecting and classifying, as defined in the appended claims.</p><p><span class=\"paragraph-number\">[0007]   </span>For a better understanding of the present invention, embodiments thereof are now described, purely by way of nonlimiting example, with reference to the accompanying drawings, in which:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1A</figref> is a schematic view of aircrafts equipped with monitoring systems;</li><br/><li> <figref>Figure 1B</figref> shows examples of trends over time of values of quantities acquired through monitoring systems;</li><br/><li> <figref>Figure 2</figref> shows a block diagram which exemplifies a possible subdivision into macrocategories of a set of manoeuvres that can be executed by an aircraft;</li></ul></p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figures 3</figref> and <figref>6</figref> show block diagrams relative to a training step according to a first strategy;</li><br/><li> <figref>Figure 4</figref> shows a block diagram of a training data structure;</li><br/><li> <figref>Figure 5A</figref> schematically shows a part of the training data structure and the arrangement of a time window;</li><br/><li> <figref>Figures 5B</figref> and <figref>5C</figref> schematically show the part of the training data structure shown in <figref>Figure 5A</figref> and the arrangement of time windows having two different time durations, respectively;</li><br/><li> <figref>Figure 7</figref> shows two block diagrams exemplifying training operations according to the first strategy and according to a second strategy;</li><br/><li> <figref>Figure 8</figref> shows tables exemplifying part of the operations shown in <figref>Figure 3</figref>;</li><br/><li> <figref>Figure 9</figref> shows a block diagram relative to analysis operations according to the first strategy;</li><br/><li> <figref>Figure 10</figref> schematically shows a part of a non-labelled data structure and the arrangement of windows having different time durations;</li><br/><li> <figref>Figure 11</figref> shows two block diagrams exemplifying analysis operations according to the first and second strategy;</li><br/><li> <figref>Figures 12</figref> and <figref>13</figref> show block diagrams relative to a training step according to the second strategy;</li><br/><li> <figref>Figure 14</figref> schematically shows the part of the training data structure shown in <figref>Figures 5A-5C</figref> and the arrangement of time windows used during training according to the second strategy;</li><br/><li> <figref>Figure 15</figref> shows a table exemplifying part of the operations shown in <figref>figures 12</figref> and <figref>13</figref>;</li><br/><li> <figref>Figure 16</figref> shows a block diagram relative to analysis operations according to the second strategy;</li><br/><li> <figref>Figure 17</figref> shows a block diagram relative to training and analysis operations according to a third strategy;</li><br/><li> <figref>Figure 18</figref> is a block diagram exemplifying training operations according to the third strategy;</li><br/><li> <figref>Figure 19</figref> is a block diagram exemplifying analysis operations according to the third strategy;</li><br/><li> <figref>Figures 20A-20B</figref> show block diagrams relative to classification operations carried out according to the first strategy;</li><br/><li> <figref>Figure 21</figref> shows a block diagram relative to training and analysis operations according to a fourth strategy;</li><br/><li> <figref>Figure 22</figref> shows two block diagrams exemplifying, respectively, training and analysis operations according to the fourth strategy;</li><br/><li> <figref>Figures 23</figref> and <figref>26</figref> show block diagrams relative to operations carried out, respectively, according to a first and a second variant of the present method;</li><br/><li> <figref>Figure 24</figref> shows a block diagram exemplifying analysis operations according to the second variant;</li><br/><li> <figref>Figures 25</figref> and <figref>27</figref> show tables relative to the first and second variants of the present method, respectively; and</li><br/><li> <figref>Figure 28</figref> shows a block diagram relative to operations according to the present method.</li></ul></p><p><span class=\"paragraph-number\">[0008]   </span>The present method builds on the fact that it is currently possible to equip an aircraft (for example, a helicopter) with numerous sensors, which allow to determine the trends of corresponding quantities that characterize the flight of the aircraft, that is, during the execution of a succession of manoeuvres. In other words, it is possible to monitor the values that are assumed by said characteristic quantities during the flight. For example, <figref>Figure 1A</figref> shows a helicopter 1, which is equipped with a monitoring system 2, which includes, for example, a sensor for measuring the bank angle of the helicopter 1 and thus provides, in use, the values (i.e., the samples) of the bank angle, with a given sampling frequency, for example of the order of ten Hertz. In the continuation reference is made to the aforementioned quantities as to the primary quantities and it is assumed that they are in a number equal to N; purely by way of example, the primary quantities may include: aircraft kinematics variables (such as pitch angle, roll angle, yaw angle, heading angle, vertical acceleration, vertical velocity, longitudinal acceleration, lateral acceleration, roll rate, pitch rate, yaw rate, Northward velocity, Eastward velocity, main rotor velocity); aircraft control variables (such as for example collective control position, lateral cyclic control position, longitudinal cyclic control position, pedal position); environmental variables (such as for example air speed, radar altitude, barometric altitude, wind speed, wind direction, total air temperature, take-off weight); variables related to energy systems (such as motor torque, motor turbine rotation speed, motor generator rotation speed).</p><p><span class=\"paragraph-number\">[0009]   </span>Purely by way of example, <figref>Figure 1B</figref> shows the trends over time of five primary quantities (indicated respectively as quantities 1-5; hence N=5), which are monitored by corresponding sensors of the monitoring system 2, which periodically provide the corresponding samples. For simplicity's sake, and without any loss of generality, it is assumed that the sensors operate synchronously, with the same sampling frequency f<sub>c</sub> (for example, equal to 12.5 Hz); in fact, even if the sensors operated natively with different sampling frequencies, it would be in any case possible to return to the same sampling frequency, for example through oversampling, subsampling and interpolation operations.</p><p><span class=\"paragraph-number\">[0010]   </span>Still by way of example, <figref>Figure 1B</figref> shows a first and a second time interval T1, T2, in which a first and a second test manoeuvre M1, M2, respectively, of a first test flight of the helicopter 1, as signalled by the pilot, take place. In addition, in <figref>Figure 1B</figref>, NMP1, NMP2, NMP3 respectively indicate three periods of time spaced with respect to the first and second time interval T1, T2, in which no manoeuvres are signalled by the pilot, as described in greater detail below. Hereinafter, the periods of time NMP1, NMP2, NMP3 are referred to as non-labelled periods.</p><p><span class=\"paragraph-number\">[0011]   </span>As shown in <figref>Figure 2</figref>, the set (indicated with 5) of the manoeuvres that can be carried out by an aircraft can be subdivided into a plurality of subsets, to which in the continuation reference is made as to macrocategories (indicated with MC). Each macrocategory MC groups subclasses of manoeuvres (indicated with SC in <figref>Figure 2</figref>) with similar features. For example, <figref>Figure 2</figref> shows macrocategories MC related, respectively, to the level flight, to the bank turn, to the vertical take-off, to the climbing, etc. In turn, the macrocategory relative to the level flight may include a plurality of manoeuvres (only four shown in <figref>Figure 2</figref>, indicated by \"forty-node level flight\", \"sixty-node level flight\", \"ninety-node level flight\" and \"one hundred and fifty-node level flight\"). In other words, each macrocategory MC represents a corresponding class (or type) of manoeuvres. Moreover, as described in greater detail below, given a macrocategory MC, the manoeuvres belonging to such macrocategory MC can be distinguished from each other in a deterministic manner, for example on the basis of the corresponding trends of one or more primary quantities (for example, on the basis of on average speeds or average roll angle values, etc.)</p><p><span class=\"paragraph-number\">[0012]   </span>In the following it is assumed that the macrocategories MC are in a number equal to NUM_MC.</p><p><span class=\"paragraph-number\">[0013]   </span>In consideration of the foregoing, the present method provides, as shown in <figref>Figure 3</figref>, for acquiring (block 100) a training data structure 10, an example of which is shown qualitatively in <figref>Figure 4</figref>. As shown again in <figref>Figure 4</figref>, the training data structure 10 can be stored in a computer 12.</p><p><span class=\"paragraph-number\">[0014]   </span>In detail, the training data structure 10 stores the time series (intended as successions of samples connected to corresponding time instants) formed by the values of the primary quantities detected by the monitoring system 2 of the helicopter 1 during test flights, as well as by monitoring systems (not shown) of other aircraft (not shown) during respective test flights. Moreover, as mentioned above with reference to the first and second test manoeuvres M1, M2 shown in <figref>Figure 1B</figref>, the training data structure 10 stores the initial instant and the end instant of each test manoeuvre, signalled by the aircraft pilot. In addition, the training data structure 10 stores, for each test manoeuvre, the macrocategory MC to which the test manoeuvre belongs.</p><p><span class=\"paragraph-number\">[0015]   </span>For example, assuming that the first and second manoeuvre M1 and M2 belong to the same macrocategory MC1, the training data structure 10 shown in <figref>Figure 4</figref> stores the values of the primary quantities 1-5 during the first and second time interval T1, T2, in both cases, connecting them to the macrocategory MC1. In other words, the training data structure 10 stores a first cluster of data (indicated as DG1 in <figref>Figures 1B</figref> and <figref>4</figref>), formed by the values assumed by the quantities 1-5 during the first time interval T1, and a second cluster of data (indicated with DG2 in <figref>Figures 1B</figref> and <figref>4</figref>), formed by the values assumed by the quantities 1-5 during the second time interval T2; moreover, either for the first or for the second cluster of data DG1, DG2, the detection data structure 10 stores the connection to the macrocategory MC1. In <figref>Figure 4</figref>, the storage of the macrocategories connected to the test manoeuvres is qualitatively represented, by connecting each cluster of data to the corresponding pair (test manoeuvre, macrocategory).</p><p><span class=\"paragraph-number\">[0016]   </span>Again with reference to the first test flight, the training data structure 10 also stores the values assumed by the primary quantities 1-5 during the aforementioned non-labelled periods NMP1, NMP2, NMP3, which, as previously mentioned, represent periods in which the pilot has not specified the manoeuvre executed.</p><p><span class=\"paragraph-number\">[0017]   </span>Again with reference to the training data structure 10 shown in <figref>Figure 4</figref>, it also stores the time series formed by the values of the primary quantities detected by the corresponding sensors during a second test flight, executed for example with an aircraft other than the helicopter 1 with which the first test flight was executed, and in which two other test manoeuvres were signalled, which took place respectively in a third and a fourth time interval T3, T4. In general, the values acquired during each test flight have a respective time axis, with origin coinciding with the start of the flight; the alignment of the time axes of different flights can be managed in a per se known manner and is irrelevant for the purposes of this method. The first and fourth time interval T3, T4 are alternated with other three non-labelled periods NMP4, NMP5, NMP6. In addition, in the third and fourth time interval T3, T4, a third and fourth test manoeuvre have taken place respectively, which belong for example to the macrocategory MC2 and to the macrocategory MC3, respectively.</p><p><span class=\"paragraph-number\">[0018]   </span>In practice, the training data structure 10 comprises a number of sub-blocks SB, which are referred to hereinafter as training sub-structures SB. Each training sub-structure SB stores the time series formed by the values assumed of the quantities during a corresponding test flight. Each cluster of data DG therefore belongs to a single corresponding training sub-structure SB.</p><p><span class=\"paragraph-number\">[0019]   </span>Again with reference to <figref>Figure 3</figref>, the computer 12 processes (block 110) the detection data structure 10, for example so as to remove any abnormal data or incorrectly labelled manoeuvres. Such processing takes place in a per se known manner and is optional; in the following it is assumed, for simplicity's sake, that such processing does not alter the content of the training data structure 10; otherwise, the operations described below are executed on the training data structure processed.</p><p><span class=\"paragraph-number\">[0020]   </span>Subsequently, for each test manoeuvre, the computer 12 extracts (block 120) from the training data structure 10 a vector of statistical quantities, which is calculated as described below, in which for simplicity's sake reference is made as to a m-th test manoeuvre M<sub>m</sub>, which belongs to a macrocategory MC<sub>m</sub> and takes place during a time interval T<sub>m</sub> of a test flight connected to a m-th training sub-structure SB<sub>m</sub>. Moreover, it is assumed that the values assumed by the primary quantities during the time interval T<sub>m</sub> form a cluster of data DG<sub>m</sub>. In consideration of the foregoing, the computer 12 extracts, on the basis of the cluster of data DG<sub>m</sub>, a vector, to which reference is made hereinafter as to the feature vector of entire manoeuvre training FV<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0021]   </span>In particular, the feature vector of entire manoeuvre training FV<sub>m</sub> is calculated as shown in <figref>Figure 5A</figref>, i.e. on the basis of the entire cluster of data DG<sub>m</sub>. In other words, the computer 12 adopts a first type of time window TW<sub>m</sub>, which coincides with the time interval T<sub>m</sub>, and therefore with the duration of the test manoeuvre M<sub>m</sub>. For example, the time interval T<sub>m</sub> extends between an instant t<sub>start</sub> and an instant t<sub>end</sub>, which refer to a time indicated as flight_time, which has a discretization equal to the inverse of the sampling frequency f<sub>c</sub>, i.e. equal to the sampling period, hereinafter indicated with Δ<sub>c</sub> (shown qualitatively in <figref>Figure 5A</figref>).</p><p><span class=\"paragraph-number\">[0022]   </span>In greater detail, the feature vector of entire manoeuvre training FV<sub>m</sub> is formed by a number of elements, each of which is equal to the value of a statistical quantity calculated on the basis of the values assumed in the time window TW<sub>m</sub> (and therefore, during the entire test manoeuvre M<sub>m</sub>) by a corresponding primary quantity. Purely by way of example, the feature vector of entire manoeuvre training FV<sub>m</sub> may be formed by NUM_Ftot = NUM_F * N elements (with integer NUM F), in which case it occurs that, for example, the first N elements of the feature vector of entire manoeuvre training FV<sub>m</sub> are respectively equal to (for example) time averages of the values assumed, respectively, by the primary quantities during the time window TW<sub>m</sub>, while the second N elements of the feature vector of entire manoeuvre training FV<sub>m</sub> are equal to (for example) variances of the values assumed, respectively, by the primary quantities during time window TW<sub>m</sub>, and so on. For example, in addition to the means and the variances, other statistical quantities can be calculated, such as for example: maximum, minimum, median, mean of the first derivative, mean of the second derivative, angular coefficient of the trend line, etc. As explained, the statistical quantities are calculated over the entire duration of the manoeuvre M<sub>m</sub>. Moreover, the feature vector of entire manoeuvre training FV<sub>m</sub> is connected to the macrocategory MC<sub>m</sub> of the corresponding test manoeuvre M<sub>m</sub> to which the vector refers, as shown qualitatively in <figref>Figure 5A</figref>.</p><p><span class=\"paragraph-number\">[0023]   </span>In practice, assuming for example that a number NUM_M of test manoeuvres has been executed, the operations of block 120 allow to generate a number equal to NUM_M of feature vectors of entire manoeuvre training FV, each of which is connected to the corresponding macrocategory MC to which the test manoeuvre refers.</p><p><span class=\"paragraph-number\">[0024]   </span>Then, the computer 12 trains (block 130) a classifier 131 (shown in <figref>Figure 7</figref>), to which reference is made hereinafter as to the first first-level classifier 131, on the basis of the feature vectors of entire manoeuvre training FV and of the macrocategories MC connected to the latter, as determined for test manoeuvres. In other words, the computer 12 executes a supervised and multi-class training; moreover, the first first-level classifier 131 is a type known per se, such as for example a random forest classifier.</p><p><span class=\"paragraph-number\">[0025]   </span>Then, the computer 12 extracts (block 140), for each test manoeuvre, a number of further feature vectors, to which reference is made hereinafter as to the feature vectors of extended manoeuvre training FV'<sub>mpj</sub>, in which the index 'm' indexes the test manoeuvres, while the indexes 'p' and 'j' are explained below. Moreover, the computer 12 uses a number NUM_TW of time durations TW' (for example, NUM_TW=4), which are shared among all the test manoeuvres, that is, they do not vary with the variation of the test manoeuvre considered.</p><p><span class=\"paragraph-number\">[0026]   </span>In detail, for each test manoeuvre, the computer 12 executes the operations mentioned in <figref>Figure 6</figref> and shown in <figref>Figure 5B</figref>, the latter figure referring again to the aforementioned m-th test manoeuvre M<sub>m</sub> and to a first time duration TW'<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0027]   </span>In greater detail, the computer 12 has its own time base (indicated by time_clk) with period Δ<sub>clk</sub>, on the basis of which the computer 12 determines (block 200, <figref>Figure 6</figref>) a succession of time instants t<sub>clk</sub> (shown in <figref>Figure 5B</figref>). For example, the period Δ<sub>clk</sub> is equal to a multiple of the sampling period Δ<sub>c</sub>; for example, the period Δ<sub>clk</sub> is equal to twenty-five times the sampling period Δ<sub>c</sub>.</p><p><span class=\"paragraph-number\">[0028]   </span>Moreover, the computer 12 detects (block 210) the time instants t<sub>clkj</sub> falling in the time interval T<sub>m</sub>, and thus falling during the test manoeuvre M<sub>m</sub>. For example, in <figref>Figure 5B</figref>, it is shown j=0, ..., 4. Hereinafter, for brevity's sake, reference is made to the aforementioned time instants t<sub>clkj</sub> falling in the time interval T<sub>m</sub> as to the intermediate time instants t<sub>clkj</sub>; furthermore, reference is made to NUM_J to indicate the number of intermediate time instants t<sub>clkj</sub>, said number being a function of the time interval T<sub>m</sub> and of the period Δ<sub>clk</sub> and being independent of the time duration TW' considered. For example, in <figref>figure 5B</figref>, it is shown NUM J=5. The value NUM_J depends on the duration of the test manoeuvre considered and the alignment thereof with time_clk.</p><p><span class=\"paragraph-number\">[0029]   </span>Subsequently, for each time duration TW'<sub>p</sub> (with p=1, ...NUM_TW, used to index the time duration TW'), the computer 12 selects (block 220), for each intermediate time instant t<sub>clkj</sub>, the subset of the values of the m-th training sub-structure Sbm<sub>m</sub> falling into the time window between t<sub>clkj</sub> - (TW'<sub>p</sub>/2) and t<sub>clkj</sub> + (TW'<sub>p</sub>/2). In other words, each time duration TW'<sub>p</sub> identifies a corresponding time window of equal duration, which is translated and centred (i.e. aligned) in each of the intermediate time instants t<sub>clkj</sub>, so as to select the values of the training sub-structure SB relating to the test manoeuvre considered which fall into said translated time window. As can be noted in <figref>Figure 5B</figref>, it is possible that, depending on the intermediate time instant t<sub>clkj</sub> and on the time duration TW' considered, the corresponding subset of selected values of the training sub-structure SB includes portions of time series of the primary quantities adjacent to the time interval in which the test manoeuvre considered has taken place, that is, it includes values assumed by the primary quantities in a waiting period preceding/following the test manoeuvre or during a test manoeuvre preceding/following the test manoeuvre considered. Purely by way of example, in <figref>Figure 5B</figref> it has been assumed that the m-th test manoeuvre M<sub>m</sub> is preceded by a non-labelled period NMP<sub>x</sub> and is immediately followed by an m+1-th test manoeuvre M<sub>m+1</sub>. Moreover, when the time window with extension equal to the first time duration TW'<sub>1</sub> is aligned (centred) with the intermediate time instant t<sub>clk0</sub> or with the intermediate time instant t<sub>clk1</sub>, it occurs that the corresponding subset of selected values of the training sub-structure SB<sub>m</sub> also includes values assumed by the primary quantities during part of the previous non-labelled period NMP<sub>x</sub>. Moreover, when the time window with extension equal to the first time duration TW'<sub>1</sub> is centred at the intermediate time instant t<sub>clk3</sub> or at the intermediate time instant t<sub>clk4</sub>, it occurs that the corresponding subset of selected values of the training sub-structure SB<sub>m</sub> also includes values assumed by the primary quantities during part of the subsequent test manoeuvre M<sub>m+1</sub>.</p><p><span class=\"paragraph-number\">[0030]   </span>Subsequently, on the basis of each selected subset of the values of the training sub-structure SB<sub>m</sub>, the computer 12 extracts (block 230) a corresponding feature vector of extended manoeuvre training FV'<sub>mpj</sub>. Consequently, for each test manoeuvre, NUM_TW*NUM_J feature vectors of extended manoeuvre training FV'<sub>mpj</sub> are calculated, all of which are connected to the macrocategory MC<sub>m</sub> of the corresponding test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0031]   </span>The feature vectors of extended manoeuvre training FV'<sub>mpj</sub> have the same dimensions as the feature vectors of entire manoeuvre training FV<sub>m</sub> and are calculated in the same way, i.e. they refer to the same statistical quantities, however, these statistical quantities are calculated on the basis of subsets of the values assumed by the primary quantities during each test manoeuvre, instead of on the basis of the values assumed by the primary quantities during the entire test manoeuvre. In particular, each element of each feature vector of extended manoeuvre training FV'<sub>mpj</sub> is equal to the value of a corresponding statistical quantity calculated on the basis of the values assumed by a corresponding primary quantity during the time window t<sub>clkj</sub>-(TW'<sub>p</sub>/<sub>2</sub>) and t<sub>clkj</sub>+(TW'<sub>p</sub>/<sub>2</sub>).</p><p><span class=\"paragraph-number\">[0032]   </span>By way of example, <figref>Figure 5C</figref> again relates to the m-th test manoeuvre M<sub>m</sub> and shows the selection of the subsets of the training sub-structure SB<sub>m</sub>, relating to the second time duration TW'<sub>2</sub>, which for example has a duration twice the first time duration TW'<sub>1</sub>. This selection allows to calculate the five feature vectors of extended manoeuvre training FV'<sub>m20</sub>-FV'<sub>m24</sub>, which, like the feature vectors of extended manoeuvre training FV'<sub>m10</sub>-FV'<sub>m14</sub> shown in <figref>Figure 5B</figref>, are connected to the macrocategory MC<sub>m</sub> of the m-th test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0033]   </span>Again with reference to <figref>Figure 3</figref>, for each test manoeuvre, the computer 12 applies (block 150), for each of the corresponding intermediate time instants t<sub>clkj</sub>, the first first-level classifier 131 to each of the feature vectors of extended manoeuvre training FV'<sub>mpj</sub>, so as to obtain a number equal to NUM_TW of first strategy training prediction vectors PV'<sub>mpj</sub>, which can be indexed in the same way as the feature vectors of extended manoeuvre training FV'<sub>mpj</sub>.</p><p><span class=\"paragraph-number\">[0034]   </span>Each first strategy training prediction vector PV'<sub>mpj</sub> has a number of elements equal to the number NUM_MC of macrocategories MC, each element being indicative of the probability that the corresponding feature vector of extended manoeuvre training FV'<sub>mpj</sub> is connected to the macrocategory MC that corresponds to the element.</p><p><span class=\"paragraph-number\">[0035]   </span>Moreover, for each test manoeuvre, the computer 12 aggregates (block 160), for each of the intermediate time instants t<sub>clkj</sub>, the first strategy training prediction vectors PV'<sub>mpj</sub> (in a number equal to NUM_TW), so as to form a corresponding macrovector, which is still connected to the macrocategory MC of the test manoeuvre, and to which reference is made hereinafter as to the corresponding first training prediction macrovector MPV'<sub>mj</sub>.</p><p><span class=\"paragraph-number\">[0036]   </span>For example, <figref>Figure 7</figref> refers to the m-th test manoeuvre M<sub>m</sub> and shows a graphical example of the operations of blocks 150 and 160, with reference to a single intermediate time instant t<sub>clkj</sub> (in the example shown, the intermediate time instant t<sub>clk0</sub>). In particular, <figref>Figure 7</figref> shows how the application of the first first-level classifier 131 to the four feature vectors of extended manoeuvre training FV'<sub>m10</sub> - FV'<sub>m40</sub> leads to the generation, respectively, of the corresponding four first strategy training prediction vectors PV'<sub>m10</sub> - PV'<sub>m40</sub>, which are aggregated into the first training prediction macrovector MPV'<sub>m0</sub>, which is connected to the macrocategory MC<sub>m</sub> of the test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0037]   </span>In addition, <figref>Figure 8</figref> refers to the m-th test manoeuvre M<sub>m</sub> and shows how, for each of the four time durations TW'<sub>1</sub>-TW'<sub>4</sub>, each of the five intermediate time instants t<sub>clk0</sub>-t<sub>clk4</sub> is connected to a corresponding first strategy training prediction vector PV', each of which, as said, includes a number of elements equal to the number NUM_MC of macrocategories. Moreover, <figref>Figure 8</figref> shows that each of the five intermediate time instants t<sub>clk0</sub>-t<sub>clk4</sub> is connected to a corresponding first training prediction macrovector MPV'<sub>m0</sub>-MPV'<sub>m4</sub>, which is also connected to the macrocategory MC<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0038]   </span>Again with reference to <figref>Figure 3</figref>, after executing the operations of block 160, the computer 12 trains (block 170) a first second-level classifier 151 (shown in <figref>Figure 7</figref>), on the basis of the first training prediction macrovectors MPV'<sub>mj</sub> calculated for the test manoeuvres, as well as on the basis of the macrocategories MC connected to said macrovectors.</p><p><span class=\"paragraph-number\">[0039]   </span>In practice, the first second-level classifier 151 is trained in a supervised manner. Furthermore, purely by way of example, the first second-level classifier 151 may be a classifier of the logistic regression type.</p><p><span class=\"paragraph-number\">[0040]   </span>Once the first first-level classifier 131 and the first second-level classifier 151 have been trained, it is possible to determine the macrocategory to which an unknown manoeuvre (therefore, with unknown duration) belongs, executed, for example, by an unknown helicopter 3 (an example of which is shown in <figref>Figure 1A</figref>), equipped with a respective monitoring system 4 including sensors (not shown) suitable for monitoring the aforementioned primary quantities. More precisely, during an unknown flight of the unknown helicopter 3, that is, during a flight in which the executed manoeuvres are not known, it is possible to identify the occurrence of a manoeuvre belonging to one of the aforementioned macrocategories MC, used during the training of the first first-level classifier 131 and of the first second-level classifier 151. For this purpose, the operations shown in <figref>Figure 9</figref> are executed.</p><p><span class=\"paragraph-number\">[0041]   </span>In detail, a new data structure (shown in <figref>Figure 10</figref>, where it is indicated by 205) is acquired (block 300), to which reference is made hereinafter as to the non-labelled data structure 205, since it is formed by the time series of the values assumed by the primary quantities, as measured by the monitoring system 4 equipping the unknown helicopter 3 during the unknown flight. In practice, the non-labelled data structure 205 is formed by a single training sub-structure SB. Furthermore, since the manoeuvres executed during the unknown flight are unknown, the non-labelled data structure 205 does not store any connection to the macrocategories MC.</p><p><span class=\"paragraph-number\">[0042]   </span>Like in the case of the training data structure 10, also in the non-labelled data structure 205 the values of each primary quantity are connected to the corresponding sampling instants, i.e. they are distributed along the aforementioned flight_time, which has a discretization still equal to the sampling period Δ<sub>c</sub>. In practice, by assuming that the unknown flight extends along a time interval W<sub>tot</sub>, to which reference is made hereinafter as to the total time interval W<sub>tot</sub>, each time series connected to a corresponding primary quantity includes a number of values equal to W<sub>tot</sub>*f<sub>c</sub>.</p><p><span class=\"paragraph-number\">[0043]   </span>The computer 12 still has the time base time_clk, with period Δ<sub>clk</sub>, which generates the time instants t_<sub>clk</sub>. Furthermore, given a generic k-th time instant t<sub>clkk</sub> (shown in <figref>Figure 10</figref>), the computer 12 selects (block 310) a number equal to NUM_TW of subsets of values of the non-labelled data structure 205. In particular, for each of the time durations TW'<sub>p</sub> (with p=1, ...NUM_TW), the computer 12 selects the subset of the values of the non-labelled data structure 205 that fall into the time window ranging between t<sub>clkk</sub> - (TW'<sub>p</sub>/2) and t<sub>clkk</sub> +(TW'<sub>p</sub>/2). If the time window ranging between t<sub>clkk</sub> -(TW'<sub>NUM_TW</sub>/2) and t<sub>clkk</sub> + (TW'<sub>NUM_TW</sub>/2) (that is, the broadest time window) extends beyond the boundaries of the non-labelled data structure 205, it is possible to adopt a different centring of the NUM_TW time windows with respect to the time instant t<sub>clkk</sub>, so that the time windows fall entirely into the non-labelled data structure 205, or the time instant t<sub>clkk</sub> can be discarded, or also the corresponding subsets of the non-labelled data structure 205 may include only the values actually available; these details are irrelevant for the purposes of executing this method.</p><p><span class=\"paragraph-number\">[0044]   </span>Then, for each selected subset of the values of the non-labelled data structure 205, the computer 12 extracts (block 320) a corresponding vector of features, which is referred to hereinafter as to the input feature vector FVX<sub>kp</sub>. Consequently, for the generic k-th time instant t<sub>clkk</sub> provided by the time base time_clk, a number equal to NUM_TW of input feature vectors FVX<sub>kp</sub>, without any connections to any macrocategory MC, are calculated.</p><p><span class=\"paragraph-number\">[0045]   </span>The input feature vectors FVX<sub>kp</sub> have the same dimensions as the feature vectors of extended manoeuvre training FV'<sub>mpj</sub> and of the feature vectors of entire manoeuvre training FV<sub>m</sub> and are calculated in the same way, i.e. they refer to the same statistical quantities, however, these statistical quantities are calculated on the basis of subsets of the values assumed by the primary quantities during the unknown flight. In particular, each element of the input feature vector FVX<sub>kp</sub> is equal to the value of a corresponding statistical quantity calculated on the basis of the values assumed by a corresponding primary quantity in the time window t<sub>clkk</sub>-(TW'<sub>p</sub>/2) and t<sub>clkk</sub>+(TW'<sub>p</sub>/2).</p><p><span class=\"paragraph-number\">[0046]   </span>Then, referring for example to the generic k-th time instant t<sub>clkk</sub>, the computer 12 applies (block 330) the first first-level classifier 131 to the corresponding input feature vectors FVX<sub>kp</sub>, so as to obtain a number equal to NUM_TW of first strategy input prediction vectors PVX'<sub>kp</sub>, as qualitatively exemplified in <figref>Figure 11</figref>, in which the four first strategy input prediction vectors PVX'<sub>k1</sub>- PVX'<sub>k4</sub> are shown, which derive from the application of the first first-level classifier 131 to, respectively, the four input feature vectors FVX<sub>k1</sub>-FVX<sub>k4</sub>.</p><p><span class=\"paragraph-number\">[0047]   </span>Each first strategy input prediction vector PVX'<sub>kp</sub> has a number of elements equal to the number NUM_MC of macrocategories MC, each element being indicative of the probability that the corresponding input feature vector FVX<sub>kp</sub> is connected to the macrocategory MC that corresponds to the element, and therefore of the probability that at the corresponding k-th time instant t<sub>clkk</sub> the unknown helicopter 3 was executing a manoeuvre belonging to such macrocategory MC.</p><p><span class=\"paragraph-number\">[0048]   </span>Again with reference to the k-th time instant t<sub>clkk</sub>, the computer 12 aggregates (block 335) the first strategy input prediction vectors PVX'<sub>kp</sub> (in a number equal to NUM_TW), so as to form a corresponding macrovector, to which reference is made hereinafter as to the first strategy input macrovector MPVX'<sub>k</sub>.</p><p><span class=\"paragraph-number\">[0049]   </span>Again with reference to the k-th time instant t<sub>clkk</sub>, the computer 12 then applies (block 338) the first second-level classifier 151 to the first strategy input macrovector MPVX'<sub>k</sub>, so as to obtain a first output vector OUT_A<sub>k</sub>, which has a number of elements equal to the number NUM_MC of macrocategories, each element being indicative of the probability that the corresponding input feature vector FVX<sub>kp</sub> is connected to the macrocategory MC that corresponds to the element, and therefore the probability that, at the k-th time instant t<sub>clkk</sub>, the unknown helicopter 3 was executing a manoeuvre belonging to this macrocategory MC. In practice, the first output vector OUT_A<sub>k</sub> represents an improvement of the probabilities contained in the first strategy input prediction vectors PVX'<sub>kp</sub>, as explained below with reference to all the mentioned second-level classifiers.</p><p><span class=\"paragraph-number\">[0050]   </span>Alternatively or in addition to what has been described so far, the computer 12 may implement a different strategy, which is now described with reference to <figref>Figure 12</figref> and provides for training, starting from the training data structure 10, a plurality of second first-level classifiers CLASS and a second one 251, as qualitatively shown in <figref>Figure 7</figref>. What has been said above as regards to blocks 100 and 110 of <figref>Figure 3</figref> also applies to this strategy.</p><p><span class=\"paragraph-number\">[0051]   </span>Initially, for each test manoeuvre, the computer 12 extracts (block 340, <figref>Figure 12</figref>) a number of feature vectors, to which reference is made hereinafter as to the feature vectors of partial manoeuvre training FV\"; to this end, the computer 12 executes the operations described in <figref>Figure 13</figref> and exemplified in <figref>Figure 14</figref>, the latter figure referring again to the aforementioned m-th test manoeuvre M<sub>m</sub>, which, as explained above, extends between the instant t<sub>start</sub> and the instant t<sub>end</sub>, which are referred to as flight_time.</p><p><span class=\"paragraph-number\">[0052]   </span>In greater detail, the computer 12 makes use of a synchronized time base, to which reference is made hereinafter as to time_clk_sync, since it has a period equal to the period Δ<sub>clk</sub> and is synchronized with respect to the instant t<sub>start</sub>, so as to have origin coinciding with the instant t<sub>start</sub>. In other words, the computer 12 determines (block 400, <figref>Figure 13</figref>) a succession of time instants t<sub>clk sync</sub> (shown in <figref>Figure 14</figref>).</p><p><span class=\"paragraph-number\">[0053]   </span>Moreover, the computer 12 detects (block 410, <figref>Figure 13</figref>) the time instants t<sub>clk_sync_u</sub> falling within the time interval T<sub>m</sub>, and therefore falling during the test manoeuvre M<sub>m</sub>. For example, in <figref>Figure 14</figref> it is shown u=1, ..., 5; the time instant t<sub>clk_sync_0</sub> is not detected, since it coincides with the instant t<sub>start</sub>. Hereinafter, for brevity's sake, reference is made to the aforementioned time instants t<sub>clk_sync_u</sub> falling into the time interval T<sub>m</sub> as to the synchronized intermediate time instants t<sub>clk_sync_u</sub>; furthermore, NUM_U is referred to as to indicate the number of synchronized intermediate time instants t<sub>clk_sync_u</sub>, said number NUM_U being a function of the time interval T<sub>m</sub> and of the period Δ<sub>clk</sub>.</p><p><span class=\"paragraph-number\">[0054]   </span>Subsequently, for each time duration TW'<sub>p</sub> (with p=1, ...NUM_TW, used to index the time duration TW'), the computer 12 selects, for each test manoeuvre, a number of subsets (possibly also an entire subset, as explained hereinafter) of the cluster of data DG corresponding to the test manoeuvre, as described hereinafter, again with reference to the generic p-th time duration TW'<sub>p</sub> and to the m-th test manoeuvre M<sub>m</sub>, and as shown in <figref>Figure 14</figref> with reference to the first time duration TW'<sub>1</sub>.</p><p><span class=\"paragraph-number\">[0055]   </span>In detail, the computer 12 checks (block 420) whether the time interval T<sub>m</sub> in which the m-th test manoeuvre M<sub>m</sub> has taken place has a duration lower than or equal to the p-th time duration TW'<sub>p</sub>, in which case (output YES of block 420) the computer 12 selects (block 430) the entire cluster of data DG<sub>m</sub> and then extracts (block 440) from the entire cluster of data DG<sub>m</sub> a single feature vector of partial manoeuvre FV\"<sub>mp0</sub>, which is equal to the aforementioned feature vector of entire manoeuvre FV<sub>m</sub> and is connected to the macrocategory MC<sub>m</sub> of the corresponding test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0056]   </span>On the contrary, if the time interval T<sub>m</sub> in which the m-th test manoeuvre M<sub>m</sub> has taken place has a duration greater than the p-th time duration TW'<sub>p</sub> (output NO of block 420), the computer 12 selects (block 450) each synchronized intermediate time instant t<sub>clk_sync_u</sub> such that the time window t<sub>clk_sync_u</sub> - (TW<sub>p</sub>'/2) and t<sub>clk_sync_u</sub> + (TW<sub>p</sub>'/2) falls entirely within the time interval T<sub>m</sub>. For example, with reference to <figref>Figure 14</figref>, it is assumed therein that the first time duration TW'<sub>1</sub> is equal to four times the period Δ<sub>clk</sub>, so the computer 12 only selects the synchronized intermediate time instants t<sub>clk_sync_2</sub> and t<sub>clk_sync_3.</sub> In the continuation reference is made to the synchronized intermediate time instants t<sub>clk_sync_u</sub> selected during the operations of block 450 as to the active synchronized time instants; they vary as a function of the time duration TW'<sub>p</sub> considered.</p><p><span class=\"paragraph-number\">[0057]   </span>Moreover, for each active synchronized intermediate time instant t<sub>clk_sync_u</sub>, the computer 12 selects (block 460) the subset of the values of the cluster of data DG<sub>m</sub> falling into the time window falling between t<sub>clk_sync_u</sub> -(TW'<sub>p</sub>/2) and t<sub>clk_sync_u</sub> +(TW'<sub>p</sub>/2). In other words, for each active synchronized intermediate time instant t<sub>clk_sync_u</sub>, a time window of duration equal to the time duration TW'<sub>p</sub> is centred thereon, this window being used to select the values of the cluster of data DG<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0058]   </span>Subsequently, for each selected subset of the values of the cluster of data DG<sub>m</sub>, the computer 12 extracts (block 470) a corresponding feature vector of partial manoeuvre training FV\"<sub>mpu</sub>, which is connected to the macrocategory MC<sub>m</sub> of the corresponding test manoeuvre M<sub>m</sub>, has the same dimensions as the feature vectors of extended manoeuvre training FV'<sub>mpj</sub> and is calculated in the same way, i.e. it refers to the same statistical quantities, which are calculated on the basis of a subset which includes the values assumed by the primary quantities during a subportion of the test manoeuvre. By way of example, the two feature vectors of partial manoeuvre training FV\"<sub>m12</sub> and FV\"<sub>m13</sub> are indicated in <figref>Figure 14</figref>.</p><p><span class=\"paragraph-number\">[0059]   </span>Again with reference to <figref>Figure 12</figref>, at the end of the operations in block 340, the computer 12 has, for each of the time durations TW', a corresponding set of feature vectors of partial manoeuvre training FV\"<sub>mpu</sub>. For example, considering the p-th time duration TW'<sub>p</sub>, the computer 12 has a set SET<sub>p</sub> which includes, for each test manoeuvre, a corresponding subset of feature vectors of partial manoeuvre training FV\"<sub>mpu</sub>; the latter subset includes, in the case of a test manoeuvre with duration lower than the time duration TW'<sub>p</sub>, the only feature vector of partial manoeuvre FV\"<sub>mp0</sub> (equal to the corresponding feature vector of entire manoeuvre FV<sub>m</sub>), otherwise it includes a number of feature vectors of partial manoeuvre training FV\"<sub>mpu</sub> which depends on the duration of the test manoeuvre and on the time duration TW'<sub>p</sub>. In any case, given the p-th time duration TW'<sub>p</sub>, the corresponding set SET<sub>p</sub> of feature vectors of partial manoeuvre training FV\"<sub>mpu</sub> contains feature vectors calculated on the basis of portions of the corresponding clusters of data DG which have extensions not higher than the same time duration TW'<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0060]   </span>By way of example, <figref>Figure 15</figref> shows the set (indicated as SET<sub>1</sub>) of feature vectors of partial manoeuvre training relating to the first time duration TW'<sub>1</sub>, the subset of which (indicated as mSET<sub>1</sub>) relating to the m-th manoeuvre M<sub>m</sub> is formed by the aforementioned two feature vectors of partial manoeuvre training FV\"<sub>m12</sub> and FV\"<sub>m13</sub>, which refer respectively to the active synchronized intermediate time instants t<sub>clk_sync_2</sub> and t<sub>clk_sync_3</sub>.</p><p><span class=\"paragraph-number\">[0061]   </span>In consideration of the foregoing and again with reference to <figref>Figure 12</figref>, for each time duration TW', the computer 12 trains (block 350) a corresponding second first-level classifier CLASS, on the basis of the corresponding set SET of feature vectors of partial manoeuvre training FV\"<sub>mpu</sub> and of the macrocategories MC connected to these vectors. In other words, the computer 12 executes trainings of the supervised and multiclass type, so as to obtain a number of second first-level classifiers equal to NUM_TW, as shown qualitatively in <figref>Figure 7</figref>, in which four second first-level classifiers CLASS<sub>1</sub>-CLASS<sub>4</sub> are shown, which correspond respectively to the time durations TW<sub>1</sub>'- TW<sub>4</sub>'.</p><p><span class=\"paragraph-number\">[0062]   </span>The second first-level classifiers CLASS are of a type known per se, such as for example random forest classifiers. Moreover, as stated above, referring for example to the p-th second first-level classifier CLASS<sub>p</sub>, it has been trained on the basis of feature vectors calculated on portions of clusters of data DG relating to test manoeuvres, said portions having time extensions not higher than the p-th time duration TW'<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0063]   </span>Once the second first-level classifiers CLASS have been trained, the computer 12 applies (block 360) the second first-level classifiers CLASS to the aforementioned feature vectors of extended manoeuvre training FV'<sub>mpj</sub>, in the following manner.</p><p><span class=\"paragraph-number\">[0064]   </span>In detail, for each test manoeuvre, and for each of the corresponding intermediate time instants t<sub>clkj</sub>, the computer 12 applies the p-th second first-level classifier CLASS<sub>p</sub> (with p=1,..., NUM_TW) to the corresponding feature vector of extended manoeuvre training FV'<sub>mpj</sub>, that is, to the feature vector of extended manoeuvre training FV'<sub>mpj</sub> obtained by applying a time window having a duration equal to the time duration TW'<sub>p</sub>, that is equal to the duration of the time window used to train the same second first-level classifier CLASS<sub>p</sub>, and it obtains a corresponding second strategy training prediction vector PV\"<sub>mpj</sub>, which is connected to the macrocategory MC of the test manoeuvre.</p><p><span class=\"paragraph-number\">[0065]   </span>Following the operations of block 360, the computer 12 has, for each of the corresponding intermediate time instants t<sub>clkj</sub> of each test manoeuvre, a number equal to NUM_TW of second strategy training prediction vector PV\"<sub>mpj</sub>.</p><p><span class=\"paragraph-number\">[0066]   </span>By way of example, <figref>Figure 7</figref> shows the four second strategy training prediction vectors PV\"<sub>m10</sub>- PV\"<sub>m40</sub> relating to the intermediate time instant t<sub>clk0</sub> of the m-th test manoeuvre M<sub>m</sub>, generated respectively by the four second first-level classifiers CLASS<sub>1</sub> - CLASS<sub>4</sub> connected respectively to the time durations TW<sub>1</sub>'-TW<sub>4</sub>', respectively starting from the four feature vectors of extended manoeuvre training FV'<sub>m10</sub> -FV'<sub>m40</sub>.</p><p><span class=\"paragraph-number\">[0067]   </span>Then, for each test manoeuvre, the computer 12 aggregates (block 370, <figref>Figure 12</figref>), for each of the intermediate time instants t<sub>clkj</sub>, the second strategy training prediction vectors of PV\"<sub>mpj</sub> (in a number equal to NUM_TW), so as to form a corresponding macrovector, which is again connected to the macrocategory MC of the test manoeuvre, and to which reference is made hereinafter as to the corresponding second training prediction macrovector MPV\"<sub>mj</sub>.</p><p><span class=\"paragraph-number\">[0068]   </span>For example, with reference to <figref>Figure 7</figref>, the four second strategy training prediction vectors PV\"<sub>m10</sub>- PV\"<sub>m40</sub> are aggregated into a second training prediction macrovector MPV\"<sub>m0</sub>, which is connected to the macrocategory MC<sub>m</sub> of the test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0069]   </span>Again with reference to <figref>Figure 12</figref>, the computer 12 trains (block 380) a second second-level classifier 251 (shown in <figref>Figure 7</figref>), on the basis of the second training prediction macrovectors MPV\"<sub>mj</sub> calculated for the intermediate time instants t<sub>clkj</sub> of each test manoeuvre.</p><p><span class=\"paragraph-number\">[0070]   </span>In practice, the second second-level classifier 251 is trained in a supervised manner, on the basis of the second training prediction macrovectors MPV\"<sub>mj</sub> and of the macrocategories connected thereto. Furthermore, purely by way of example, the second second-level classifier 251 can be a classifier of the logistic regression type.</p><p><span class=\"paragraph-number\">[0071]   </span>Once the second first-level classifiers CLASS and the second second-level classifier 251 have been trained, it is possible to determine a second output vector OUT_B<sub>k</sub>, relative to the unknown flight indicative of the macrocategory to which an unknown manoeuvre belongs, which takes place in the k-th time instant t<sub>clkk</sub>. To this end, the computer 12 executes the operations shown in <figref>Figure 16</figref> and exemplified in <figref>Figure 11</figref>.</p><p><span class=\"paragraph-number\">[0072]   </span>In detail, for each k-th time instant t<sub>clkk</sub> provided by the time base time_clk, the computer 12 applies (block 500, <figref>Figure 16</figref>) the aforementioned input feature vectors FVX<sub>kp</sub> (in a number equal to NUM_TW) to the second first-level classifiers CLASS, in the following manner.</p><p><span class=\"paragraph-number\">[0073]   </span>In detail, for each k-th time instant t<sub>clkk</sub>, the computer 12 applies the p-th second first-level classifier CLASS<sub>p</sub> to the p-th input feature vector FVX<sub>kp</sub>, so as to obtain a corresponding p-th second strategy input prediction vector PVX\"<sub>kp</sub>. In other words, each input feature vector FVX<sub>kp</sub> is classified through the second first-level classifier CLASS which has been trained on the basis of subsets of the clusters of data DG having a duration equal to or lower than the duration of the subset of the non-labelled data structure 205 to which the same input feature vector FVX<sub>kp</sub> refers.</p><p><span class=\"paragraph-number\">[0074]   </span>In greater detail, the second strategy input prediction vectors PVX\"<sub>kp</sub> have the same dimensions as the first strategy input prediction vectors PVX'<sub>kp</sub>; moreover, each element of any second strategy input prediction vector PVX<sub>kp</sub>\" is indicative of the probability that the corresponding input feature vector FVX<sub>kp</sub> is connected to the macrocategory MC corresponding to the same element, and therefore that, at the k-th time instant t<sub>clkk</sub>, the unknown helicopter 3 was executing a manoeuvre belonging to said macrocategory MC.</p><p><span class=\"paragraph-number\">[0075]   </span>Again with reference to the generic k-th time instant t<sub>clkk</sub>, the computer 12 aggregates (block 510) the second strategy input prediction vectors PVX\"<sub>kp</sub> (in a number equal to NUM_TW), so as to form a corresponding macrovector, to which reference is made hereinafter as to the second strategy input macrovector MPVX\"<sub>k</sub>.</p><p><span class=\"paragraph-number\">[0076]   </span>Subsequently, the computer 12 applies (block 520) the second second-level classifier 151 to the second strategy input macrovector MPVX\"<sub>k</sub>, so as to obtain a second output vector OUT_B<sub>k</sub>, in which each element is indicative of the probability that the corresponding input feature vector FVX<sub>kp</sub> is connected to the macrocategory MC that corresponds to the element, and therefore that, at the k-th time instant t<sub>clkk</sub>, the unknown helicopter 3 was executing a manoeuvre belonging to said macrocategory MC. In practice, the second output vector OUT_B<sub>k</sub> represents an improvement of the probabilities contained in the second strategy input prediction vectors PVX\"<sub>kp</sub>.</p><p><span class=\"paragraph-number\">[0077]   </span>In general, the information contained in the first and second output vectors OUT_A<sub>k</sub>, OUT_B<sub>k</sub> can be used as an alternative, in order to identify the macrocategory of the unknown manoeuvre executed in the corresponding k-th time instant t<sub>clkk</sub>. Moreover, the Applicant has observed that the indications contained in the second output vector OUT_B<sub>k</sub> are generally more accurate than those contained in the first output vector OUT_A<sub>k</sub>, in particular in the case of manoeuvres characterized by trends of relatively constant primary quantities during manoeuvres. However, in some cases, and in particular in the presence of manoeuvres, each characterized by the presence of very characteristic initial and final portions (so-called \"entry\" and \"recovery\" steps), the opposite occurs. In fact, training based on portions of manoeuvres may be not very effective, compared to training based on entire manoeuvres, in the presence of manoeuvres with characteristic portions arranged at the beginning and at the end of the manoeuvre, if such characteristic portions have durations very different from the durations of the training windows. On the contrary, training based on portions of manoeuvres tends to be more effective in the case of manoeuvres in which there occurs, for example, a gradual variation of a quantity (for example, a speed) between an initial value and a final value; in fact, in this case, a classifier trained on the basis of entire manoeuvres tends to recognize only manoeuvres in which this quantity exactly assumes such initial and final values, while a classifier based on portions of manoeuvres has the possibility of suitably weighing the trend (variation) of the quantity in each portion of the manoeuvre.</p><p><span class=\"paragraph-number\">[0078]   </span>According to a further variant, the first and second strategy may be combined by using a third second-level classifier 651, which is trained as described in <figref>Figure 17</figref> and exemplified in <figref>Figure 18</figref>.</p><p><span class=\"paragraph-number\">[0079]   </span>In detail, for each test manoeuvre, the computer 12 aggregates (block 700, <figref>Figure 17</figref>), for each of the corresponding intermediate time instants t<sub>clkj</sub>, the corresponding first strategy training prediction vectors PV'<sub>mpj</sub> (in a number equal to NUM_TW), generated by the first first-level classifier 131, and the second strategy training prediction vectors PV\"<sub>mpj</sub> each generated by a corresponding second first-level classifier CLASS, so as to obtain a third training prediction macrovector MPV‴<sub>mj</sub>, which is still connected to the macrocategory MC of the test manoeuvre that is taking place in the intermediate time instant t<sub>clkj</sub>.</p><p><span class=\"paragraph-number\">[0080]   </span>For example, <figref>Figure 18</figref> qualitatively shows the aggregation of the first strategy training prediction vectors PV'<sub>m10</sub> - PV'<sub>m40</sub> with the second strategy training prediction vectors PV\"<sub>m10</sub>- PV\"<sub>m40</sub>, in order to form the third training prediction macrovector MPV‴<sub>m0</sub>.</p><p><span class=\"paragraph-number\">[0081]   </span>Subsequently, the computer 12 trains (block 710) the third second-level classifier 651, on the basis of the third training prediction macrovectors MPV‴<sub>mj</sub> relating to the intermediate time instants t<sub>clkj</sub> of the test manoeuvres and to the macrocategories MC connected to said third training prediction macrovectors MPV‴<sub>mj</sub>. The third second-level classifier 651 is then trained in a supervised manner and may be for example of the same type as the first and second second-level classifier 151, 251.</p><p><span class=\"paragraph-number\">[0082]   </span>Once the third second-level classifier 651 has been trained, the computer 12 can analyse the unknown flight. To this end, referring for example to the generic k-th time instant t<sub>clkk</sub>, the computer 12 aggregates (block 720) the corresponding first strategy input prediction vectors PVX'<sub>kp</sub> with the second strategy input prediction vectors PVX\"<sub>kp</sub>, to form a corresponding third strategy input macrovector MPVX‴<sub>k</sub>, to which the computer 12 applies (block 730) the third second-level classifier 651, so as to obtain a third output vector OUT_C<sub>k</sub>.</p><p><span class=\"paragraph-number\">[0083]   </span>For example, <figref>Figure 19</figref> shows the generation of the third strategy input macrovector MPVX‴<sub>k</sub> by aggregation of the first strategy input prediction vectors PVX'<sub>k1</sub> - PVX'<sub>k4</sub> and of the second strategy input prediction vectors PVX\"<sub>k1</sub> - PVX\"<sub>k4</sub>.</p><p><span class=\"paragraph-number\">[0084]   </span>In general, the first, second and third output vectors OUT_A<sub>k</sub>, OUT_B<sub>k</sub>, OUT_C<sub>k</sub> all benefit from the action of the corresponding second-level classifiers, which allow to improve the classification provided by the first-level classifiers, for the reasons explained below with reference, for brevity's sake, to the first strategy only, and therefore to the first output vector OUT_A<sub>k</sub>. In particular, hereinafter reference is made to <figref>Figures 20A</figref> and <figref>20B</figref>, which refer to a simplified case, in which NUM MC is equal to two (only a first and a second macrocategory MC1, MC2 are available) and furthermore NUM_TW is equal to two (only a first and a second time duration TW'<sub>1</sub>, TW'<sub>2</sub> are available). Furthermore, in <figref>Figures 20A</figref> and <figref>20B</figref> reference is made to the effect of the training of the first second-level classifier 151 by means of the feature vectors of extended manoeuvre training FV'<sub>m11</sub> and FV'<sub>m21</sub> relating to the intermediate time instant t<sub>clk1</sub> of the m-th manoeuvre M<sub>m</sub>, which belongs to the first macrocategory MC1, and whose time interval T<sub>m</sub> is assumed to have an extension falling between the first and the second time duration TW'<sub>1</sub>, TW'<sub>2</sub>. The intermediate time instant t<sub>clk1</sub> falls about half the time interval T<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0085]   </span>In consideration of the foregoing, the first first-level classifier 131 generates the two first strategy training prediction vectors PV'<sub>m11</sub> and PV'<sub>m21</sub>, starting respectively from the feature vectors of extended manoeuvre training, FV'<sub>m11</sub> and FV'<sub>m21</sub>. The element of the first strategy training prediction vector PV'<sub>m11</sub> relating to the macrocategory MC1 has, correctly, a high value (0.9), while the element relative to the macrocategory MC2 has, correctly, a low value (0.1). On the contrary, the element of the first strategy training prediction vector PV'<sub>m21</sub> relating to the macrocategory MC1 has, erroneously, a low value (0.1), while the element relative to the macrocategory MC2 has, erroneously, a high value (0.9). This is due to the fact that, while the feature vector of extended manoeuvre training FV'<sub>m11</sub> refers to a time window that has a duration similar to that of the time interval T<sub>m</sub>, a significant part of the time window to which the feature vector of extended manoeuvre training FV'<sub>m21</sub> refers falls outside the time interval T<sub>m</sub>. However, since both feature vectors of extended manoeuvre training FV'<sub>m11</sub> and FV'<sub>m21</sub> are connected to the macrocategory MC1, the training of the first second-level classifier 151 causes it to assign, for the macrocategory MC1, a greater weight to the corresponding element of the first strategy training prediction vector PV'<sub>m11</sub>, instead of to the corresponding element of the first strategy training prediction vector PV'<sub>m21</sub>. Consequently, as shown in <figref>Figure 20B</figref>, in which a possible output vector OUT_TRAIN<sub>1</sub> generated by the first second-level classifier 151 when applied to the first training prediction macrovector MPV'<sub>m1</sub> is reported (obtained by aggregation of the first strategy training prediction vectors PV'<sub>m11</sub> and PV<sub>m21</sub>), the elements relating to the macrocategories MC1 and MC2 of the output vector OUT_TRAIN<sub>1</sub> are correctly equal to, respectively, one and zero.</p><p><span class=\"paragraph-number\">[0086]   </span>In addition, the third output vector OUT_C<sub>k</sub> is typically more accurate than the first and second output vectors OUT_A<sub>k</sub>, OUT_B<sub>k</sub>, since the relative generation mechanism adapts to either the case of manoeuvres in which the primary quantities are relatively constant (i.e. stationary), or to the case of manoeuvres with rapidly variable primary quantities.</p><p><span class=\"paragraph-number\">[0087]   </span>According to a further variant, shown in <figref>Figure 21</figref> and exemplified in <figref>Figure 22</figref>, the computer 12 trains a fourth second-level classifier 751, as described below, so as to implement a fourth strategy.</p><p><span class=\"paragraph-number\">[0088]   </span>In detail, for each test manoeuvre, the computer 12 aggregates (block 800), for each of the corresponding intermediate time instants t<sub>clkj</sub>, the corresponding feature vectors of extended manoeuvre training FV'<sub>mpj</sub>, so as to obtain a training feature macrovector MFV<sub>mj</sub>, which is connected to the macrocategory MC of the test manoeuvre. For example, <figref>Figure 22</figref> shows the aggregation of the four feature vectors of extended manoeuvre training FV'<sub>m10</sub> -FV'<sub>m40</sub> in the training feature macrovector MFV<sub>m0</sub>, which is connected to the macrocategory MC<sub>m</sub> of the m-th test manoeuvre M<sub>m</sub>.</p><p><span class=\"paragraph-number\">[0089]   </span>Subsequently, the computer 12 trains (block 810) the fourth second-level classifier 751, as a function of the training feature macrovectors MFV<sub>mj</sub> and of the macrocategories MC connected thereto. In practice, the fourth second-level classifier 751 is trained in a supervised manner and may be, for example, a random forest type classifier.</p><p><span class=\"paragraph-number\">[0090]   </span>With respect to the unknown flight, for each k-th time instant t<sub>clkk</sub>, the computer aggregates (block 820) the input feature vectors FVX<sub>kp</sub>, so as to obtain a corresponding input feature macrovector MFVX<sub>k</sub>, to which the computer 12 applies (block 830) the fourth second-level classifier 751, so as to obtain a fourth output vector OUT_D<sub>k</sub>. <figref>Figure 22</figref> shows, for example, the aggregation of the input feature vectors FVX<sub>k1</sub> - FVX<sub>k4</sub>.</p><p><span class=\"paragraph-number\">[0091]   </span>Also in this case, the presence of the fourth second-level classifier 751 allows to obtain the same benefits described with reference to the first, second and third second-level classifier 151, 251, 651. Moreover, this strategy is characterized by a lower complexity since it provides for a single level of classification.</p><p><span class=\"paragraph-number\">[0092]   </span>In general, the Applicant has noted that, thanks to the fact that the probability estimates contained in the output vectors OUT_A<sub>k</sub>, OUT_B<sub>k</sub>, OUT_C<sub>k</sub> and OUT_D<sub>k</sub> are generated by means of classification algorithms executed starting from feature vectors generated by selecting, through time windows having different dimensions, portions of the non-labelled data structure 205, these estimates are satisfactory substantially irrespective of the duration of the manoeuvres.</p><p><span class=\"paragraph-number\">[0093]   </span>In practice, the variants described above allow to identify with considerable accuracy the occurrence, during an unknown flight, of a manoeuvre belonging to one of the aforementioned macrocategories MC. However, the Applicant has observed that, if two or more manoeuvres are executed at the same time during the unknown flight, the accuracy of the identification may be reduced. To obviate this drawback, the Applicant observes that it is possible to implement the following.</p><p><span class=\"paragraph-number\">[0094]   </span>As shown in <figref>Figure 23</figref>, the computer trains (block 900) a plurality of classifiers 910, which are referred to hereinafter as single-class classifiers SCC (shown in <figref>Figure 24</figref>) .</p><p><span class=\"paragraph-number\">[0095]   </span>In detail, for each macrocategory MC, the computer 12 trains a corresponding single-class classifier SCC, on the basis of the vectors of entire manoeuvre features FV<sub>m</sub>. In particular, considering for example an i-th single-class classifier SCC<sub>I</sub> (with i=1, ..., NUM_MC), it is trained on the basis of the feature vectors of entire manoeuvre FV<sub>m</sub> connected to test manoeuvres, which, if they are related to manoeuvres belonging to the i-th macrocategory MC<sub>i</sub>, are connected for example to a first label (for example, unitary), otherwise they are connected to a second label (for example, invalid); in other words, the label is indicative of the match/mismatch between the macrocategory MC of the test manoeuvre and the macrocategory MC<sub>i</sub> which corresponds to the i-th single-class classifier SCC<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0096]   </span>Subsequently, considering the unknown flight and the generic k-th time instant t<sub>clkk</sub>, the computer 12 applies (block 910) each input feature vector FVX<sub>kp</sub> (with p=1,..., NUM_TW) to the single-class classifiers SCC, so as to obtain, for each input feature vector FVX<sub>kp</sub>, a corresponding single-class probability vector SCV<sub>kp</sub>, wherein the i-th element represents the probability that the input feature vector FVX<sub>kp</sub> refers to the i-th macrocategory MC<sub>i</sub>, as calculated by the i-th single-class classifier SCC<sub>i</sub>.</p><p><span class=\"paragraph-number\">[0097]   </span>For example, <figref>Figure 24</figref> shows the application to the four input feature vectors FVX<sub>k1</sub>-FVX<sub>k4</sub> of four single-class classifiers SCC<sub>1</sub>-SCC<sub>4</sub> and the consequent generation of the single-class probability vectors SCV<sub>k1</sub> - SCV<sub>k4</sub>; examples of the latter vectors are shown in <figref>Figure 25</figref>.</p><p><span class=\"paragraph-number\">[0098]   </span>Then, the computer 12 generates (block 920) an update vector OUT_UPDATE<sub>k</sub>, so that it has a number of elements equal to the number NUM_MC, the generic i-th element being equal to the maximum among the values of the i-th elements of the single-class probability vectors SCV<sub>kp</sub>, that is, to the maximum among the values provided by the i-th single-class classifier SCC<sub>i</sub> when it is applied to the input feature vectors FVX<sub>kp</sub> of the k-th time instant t<sub>clkk</sub> (in a number equal to NUM_TW). Although not further described, it is however possible that, in order to generate the update vector OUT_UPDATE<sub>k</sub>, the i-th element of the latter is set equal to a statistical quantity (for example, the mean) calculated on the basis of the i-th elements of the single-class probability vectors SCV<sub>kp</sub>, instead of the aforementioned maximum.</p><p><span class=\"paragraph-number\">[0099]   </span>Subsequently, the computer 12 detects (block 930), on the basis of the update vector OUT_UPDATE<sub>k</sub>, whether in the k-th time instant t<sub>_clkk</sub> two or more manoeuvres belonging to different macrocategories MC are executed (that is, it detects a condition of multiple macrocategories), for example, by detecting whether two or more elements of the update vector OUT_UPDATE<sub>k</sub> exceed a predetermined threshold. For example, with reference to <figref>Figure 25</figref>, in which a threshold equal to 0.5 is assumed, the computer 12 detects that, at the time instant t<sub>clkk</sub>, two manoeuvres belonging respectively to a macrocategory MC2 and a macrocategory MC4 are executed simultaneously. In general, although not further described, the detection of multiple macrocategories may also provide for varying the value of the aforementioned threshold, for example by connecting to each macrocategory MC a corresponding threshold, and/or an additional control, downstream of the detection of the multiple macrocategories, in order to exclude possible combinations of multiple macrocategories without physical meaning (for example, in order to exclude multiple macrocategories including macrocategories relative to opposite manoeuvres).</p><p><span class=\"paragraph-number\">[0100]   </span>In the continuation reference is made to the multiclass strategy output vector OUT_Y<sub>k</sub> to indicate the vector alternately equal to the first, second, third or fourth output vector OUT_A<sub>k</sub>, OUT_B<sub>k</sub>, OUT_C<sub>k</sub> ,OUT_D<sub>k</sub>, depending on the program implemented by the computer 12. In consideration of the foregoing, in the event that no manoeuvres belonging to different macrocategories MC are detected (output NO of block 930), the computer 12 sets (block 940) a final vector OUT_FIN<sub>k</sub> equal to the multiclass strategy output vector OUT_Y<sub>k</sub>, since, in the time instant t<sub>clkk</sub>, manoeuvres belonging to different macrocategories MC were not taking place, and therefore the probabilities of the multiclass strategy output vector OUT_Y<sub>k</sub> are reliable. In the opposite case, i.e. in the case where manoeuvres belonging to different macrocategories MC are detected (output YES of block 930), the computer 12 sets (block 950) the final vector OUT_FIN<sub>k</sub> equal to the update vector OUT_UPDATE<sub>k</sub>, since, in this particular circumstance (simultaneous execution of manoeuvres belonging to different macrocategories), the probabilities contained in the latter tend to be more accurate than those of the multiclass strategy output vector OUT_Y<sub>k</sub>.</p><p><span class=\"paragraph-number\">[0101]   </span>On the basis of the final vector OUT_FIN<sub>k</sub>, the computer 12 detects (block 951) the macrocategory MC of the manoeuvre executed in the time instant t<sub>clkk</sub>, for example by selecting, in case of non-detection of manoeuvres belonging to different macrocategories MC, the macrocategory MC connected to the highest value contained in the final vector OUT_FIN<sub>k</sub>, or by selecting, in the case of detection of manoeuvres belonging to different macrocategories MC, the macrocategory MC connected to the highest value contained in the final vector OUT_FIN<sub>k</sub> or by selecting, among the multiple macrocategories detected during the operations referred to in block 930, the macrocategory that is the most relevant from the point of view of fatigue of the components of the unknown helicopter 3.</p><p><span class=\"paragraph-number\">[0102]   </span>According to a further variant shown in <figref>Figure 26</figref>, the computer 12 trains (block 960), for each time duration TW', a corresponding number of single-class classifiers SCC' (shown in <figref>Figure 27</figref>) equal to the number of macrocategories NUM_MC, to which reference is made hereinafter as to single-class single-window classifiers SCC'. The calculator 12 thus trains a number equal to NUM_TW*NUM_MC of single-class single-window classifiers SCC', which are then indexed by means of the index `p' and the index 'i'.</p><p><span class=\"paragraph-number\">[0103]   </span>In detail, considering the single-class single-window classifier SCC'<sub>pi</sub>, it is trained on the basis of feature vectors of partial manoeuvre FV\"<sub>mpu</sub> relating to the p-th time duration TW'<sub>p</sub>, which, if they are related to manoeuvres belonging to the i-th macrocategory MC<sub>i</sub>, are connected, for example, to a first label (for example, unitary), otherwise they are connected to a second label (for example, invalid), that is, they are connected to a label indicative of the match/mismatch between the macrocategory MC of the test manoeuvre and the macrocategory MC<sub>i</sub> which corresponds to the single-class single-window classifier SCC'<sub>pi</sub>.</p><p><span class=\"paragraph-number\">[0104]   </span>The generic single-class single-window classifier SCC'<sub>pi</sub> is therefore trained on the basis of feature vectors calculated on portions of clusters of data DG which have time extensions not higher than the corresponding time duration TW'<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0105]   </span>Subsequently, considering the unknown flight and the generic k-th time instant t<sub>clkk</sub>, the computer 12 applies (block 970) each input feature vector FVX<sub>kp</sub> (with p=1,..., NUM_TW), relating to the p-th time duration TW'<sub>p</sub>, to the corresponding single-class single-window classifiers SCC'<sub>pi</sub> (in a number equal to NUM_MC) relating to the same p-th time duration TW'<sub>p</sub>, so as to obtain, for each input feature vector FVX<sub>kp</sub>, a corresponding single-class single-window probability vector SCV'<sub>kp</sub>, in which the i-th element represents the probability that the input feature vector FVX<sub>kp</sub> refers to the i-th macrocategory MC<sub>i</sub>, as calculated by the single-class single-window classifier SCC'<sub>pi</sub>.</p><p><span class=\"paragraph-number\">[0106]   </span>For example, <figref>Figure 27</figref> shows the four input feature vectors FVX<sub>k1</sub>-FVX<sub>k4</sub> which are classified by, respectively, the following single-class single-window classifiers SCC'<sub>11</sub>-SCC'<sub>14</sub>; SCC'<sub>21</sub>- SCC'<sub>24</sub>; SCC'<sub>31</sub>- SCC'<sub>34</sub>; and SCC'<sub>41</sub>- SCC'<sub>44</sub>; in this way, the single-class single-window probability vectors SCV'<sub>k1</sub>- SCV'<sub>k4</sub> are generated. Only for the simplicity's sake, the same values used in <figref>Figure 25</figref> have been adopted in <figref>Figure 27</figref>, although in reality there may be differences.</p><p><span class=\"paragraph-number\">[0107]   </span>Then, the computer 12 generates (block 980) a single-window update vector OUT_UPDATE'<sub>k</sub>, so that it has a number of elements equal to the number NUM_MC, the generic i-th element being equal to the maximum among the values of the i-th elements of the single-class single-window probability vectors SCV'<sub>kp</sub>, with p=1, ..., NUM_TW. Although not described further, it is, however, possible that, in order to generate the single-window update vector OUT_UPDATE'<sub>k</sub>, the i-th element of the latter is set equal to a statistical quantity (for example, the mean) calculated on the basis of the i-th elements of the single-class single-window probability vectors SCV'<sub>kp</sub>, instead of at the aforementioned maximum.</p><p><span class=\"paragraph-number\">[0108]   </span>Subsequently, the computer 12 detects (block 985), on the basis of the single-window update vector OUT_UPDATE'<sub>k</sub>, whether in the k-th time instant t<sub>clkk</sub> two or more manoeuvres belonging to different macrocategories MC are executed (that is, it detects a condition of multiple macrocategories), for example, by detecting whether two or more elements of the single-window update vector OUT_UPDATE'<sub>k</sub> exceed a predetermined threshold. Furthermore, although not further described, the detection of multiple macrocategories may provide for further threshold controls/variation mechanisms, as described with reference to block 930.</p><p><span class=\"paragraph-number\">[0109]   </span>In the event that no manoeuvres belonging to different macrocategories MC are detected (output NO of block 985), the computer 12 executes the operations of block 940. Otherwise, that is if manoeuvres belonging to different macrocategories MC are detected (output YES of block 985), the computer 12 sets (block 990) the final vector OUT_FIN<sub>k</sub> equal to the single-window update vector OUT_UPDATE'<sub>k</sub> and then performs the operations of block 951.</p><p><span class=\"paragraph-number\">[0110]   </span>The operations of blocks 960-990 are characterized by a greater computational burden and by the creation of a high number of classifiers compared to the operations of blocks 900-950, however, they can guarantee good performance, in particular in the case of manoeuvres with quantities having relatively constant trends.</p><p><span class=\"paragraph-number\">[0111]   </span>Regardless of the strategy adopted, the computer 12 may use the macrocategory detected through the operations indicated in block 951 to carry out also a detection (identification) of the corresponding manoeuvre carried out. This identification can take place in a deterministic way on the basis of the values of one or more primary quantities and is represented by block 991 shown either in <figref>Figure 23</figref> or in <figref>Figure 26</figref>.</p><p><span class=\"paragraph-number\">[0112]   </span>In detail, given a macrocategory detected at block 951 and relating to a manoeuvre executed in the k-th time instant t<sub>clkk</sub>, the computer 12 can identify said manoeuvre on the basis of the detected macrocategory and of at least a value of at least one primary quantity of the non-labelled data structure 205, such as, for example, a value relating to a speed in the k-th time instant t<sub>clkk</sub> or in other time instants t<sub>clk</sub>.</p><p><span class=\"paragraph-number\">[0113]   </span>In general, the information on the detected macrocategories, as well as, if necessary, on the detected manoeuvres, can be used to determine the state of usage of the unknown helicopter 3, for example in order to plan efficiently the maintenance of the unknown helicopter 3.</p><p><span class=\"paragraph-number\">[0114]   </span>For example, as shown in <figref>Figure 28</figref>, the computer 12 may store (block 992) information correlating the loads to which one or more components of the helicopter 1 have been subjected, when the latter has executed corresponding manoeuvres, which belong to corresponding macrocategories MC; to this end, the helicopter 1 was equipped, during the execution of the manoeuvres, with a load detection system 17, which is configured to detect the loads to which the components are subjected.</p><p><span class=\"paragraph-number\">[0115]   </span>Moreover, referring for brevity's and simplicity's sake to a single component of the unknown helicopter 3, and in the hypothesis in which the unknown helicopter 3 is equal to the helicopter 1, the computer 12 determines (block 993), for each manoeuvre identified through the operations of block 991, the load to which this component of the unknown helicopter 3 has been subjected during this manoeuvre, on the basis of the stored load corresponding to this manoeuvre. On the basis of the determined load, the computer 12 determines (block 994) the state of fatigue and therefore the residual fatigue life of the component.</p><p><span class=\"paragraph-number\">[0116]   </span>On the basis of the residual fatigue life of the components of the unknown helicopter 3 thus determined, it is also possible to plan any maintenance operations of the unknown helicopter 3.</p><p><span class=\"paragraph-number\">[0117]   </span>The advantages that the present method allows to obtain emerge clearly from the previous description.</p><p><span class=\"paragraph-number\">[0118]   </span>In particular, the present system allows to precisely detect the macrocategories of the manoeuvres executed by an aircraft, irrespective of the type, and therefore of the duration, of the macrocategories. Such measurements can therefore be used reliably to estimate the fatigue state and therefore the residual fatigue life of the components of an aircraft; consequently, such measurements can be used, for example, to optimise the maintenance operations of a fleet of aircrafts, respecting the safety requirements.</p><p><span class=\"paragraph-number\">[0119]   </span>Clearly, changes may be made to the method and system described and shown herein without, however, departing from the scope of the present invention, as defined in the accompanying claims.</p><p><span class=\"paragraph-number\">[0120]   </span>For example, the first- and second-level classifiers may be of a different type with respect to what has been described.</p><p><span class=\"paragraph-number\">[0121]   </span>The time windows may be aligned differently from the time instants, instead of being centred with respect thereto. For example, referring to the operations of block 220, relating to the selection, for each of the time durations TW'<sub>p</sub>, of a subset of values of the non-labelled data structure 205, this subset may be formed by the values of the non-labelled data structure 205 that fall into the time window ranging between t<sub>clkk</sub> and t<sub>clkk</sub> +TW'<sub>p</sub>.</p><p><span class=\"paragraph-number\">[0122]   </span>Finally, in general at least some of the macrocategories may include a limited number of manoeuvres (at the limit, only a corresponding manoeuvre).</p>",
            "CLMS": "(EP4016221)<br/><p>1. Method implemented through a computer (12) for detecting the execution, by an aircraft (3), of a manoeuvre belonging to a macrocategory among a plurality of macrocategories (MC), comprising the steps of:<br/> - receiving a data structure (205) including a plurality of time series of values of quantities relating to a flight of the aircraft (3), said values having been acquired through a monitoring system (4) coupled to the aircraft (3);<br/> said method further comprising performing, for each time instant (t<sub>clkk</sub>) of a first succession of time instants (t<sub>clk</sub>), the steps of:<br/>  - for each time duration (TW'<sub>p</sub>) among a plurality of predetermined time durations (TW'), selecting (310) a corresponding subset of the data structure (205), which has a time extension equal to the time duration (TW'<sub>p</sub>), the selected subsets of the data structure (205) having a same time distance from the time instant (t<sub>clkk</sub>);<br/>  - from each selected subset of the data structure (205), extracting (320) a corresponding feature vector (FVX<sub>kp</sub>);<br/>  - on the basis of the feature vectors (FVX<sub>kp</sub>), generating (330,335;500,510;720;820) a corresponding input macrovector (MPVX'<sub>k</sub>; MPVX\"<sub>k</sub>, MPVX‴<sub>k</sub>; MFVX<sub>k</sub>), alternatively by aggregation (820) of the feature vectors (FVX<sub>kp</sub>) or by:<br/>   - executing classifications (330;500) of the feature vectors (FVX<sub>kp</sub>), said classifications being executed so as to generate a plurality of input prediction vectors (PVX'<sub>kp</sub>; PVX\"<sub>kp</sub>), each of which is indicative, for each of said macrocategories (MC), of a corresponding probability that, in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the aircraft (3) was executing a manoeuvre belonging to said macrocategory (MC); and<br/>   - subsequent aggregation (335;510;720) of said plurality of input prediction vectors (PVX'<sub>kp</sub>;PVX\"<sub>kp</sub>);<br/> said method further comprising performing, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/>  - applying (338;520;730;830) to the input macrovector (MPVX'<sub>k</sub>; MPVX\"<sub>k</sub>, MPVX‴<sub>k</sub>; MFVX<sub>k</sub>) an output classifier (151;251;561;721), which is configured to generate a corresponding output vector (OUT_A<sub>k</sub>; OUT_B<sub>k</sub>; OUT_C<sub>k</sub>; OUT_D<sub>k</sub>) including, for each of said macrocategories (MC), a corresponding estimate of the probability that, in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the aircraft (3) was executing a manoeuvre belonging to said macrocategory (MC); and<br/>  - on the basis of the output vector (OUT_A<sub>k</sub>; OUT_B<sub>k</sub>; OUT_C<sub>k</sub>; OUT_D<sub>k</sub>), detecting (940, 950, 951, 990) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) belongs.</p><p>2. Method according to claim 1, wherein said output classifier (151;251;651;751) has been generated starting from a training data structure (10) including a plurality of time series of values of said quantities relating to aircraft flights (1) in which, during corresponding time intervals (T<sub>m</sub>), test manoeuvres (M<sub>m</sub>) belonging to said macrocategories (MC) have been executed, the values of the training data structure (10) relating to the time interval (T<sub>m</sub>) of each test manoeuvre (M<sub>m</sub>) being labelled with a label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs, said output classifier (151;251;651;751) having been generated by executing, for each time instant (t<sub>clkj</sub>) of a second succession of time instants (t<sub>clk</sub>) that falls within a time interval (T<sub>m</sub>) of a test manoeuvre (M<sub>m</sub>), of the steps of:<br/> - selecting (220), for each time duration (TW'<sub>p</sub>) among said predetermined time durations (TW'), a corresponding subset of the training data structure (10) having a time extension equal to the time duration (TW'<sub>p</sub>), the selected subsets of the training data structure (10) having a same time distance from the time instant (t<sub>clkj</sub>) of the second succession of time instants (t<sub>clk</sub>);<br/> - from each selected subset of the training data structure (10), extracting (230) a corresponding first training feature vector (FV'<sub>mpj</sub>);<br/> - on the basis of the first training feature vectors (FV'<sub>mpj</sub>), generating (150,160; 360,370; 150,160,360,370,700; 800) a corresponding training macrovector (MPV'<sub>mj</sub>; MPV\"<sub>mj</sub>; MPV‴<sub>mj</sub>; MFV<sub>mj</sub>), alternatively by aggregation (800) of the first training feature vectors (FV'<sub>mpj</sub>) or by:<br/>  - execution of classifications (150; 360; 150,360) of the first training feature vectors (FV'<sub>mpj</sub>), said classifications being executed so as to generate a plurality of training prediction vectors (PV'<sub>mpj</sub>;PV\"<sub>mpj</sub>) , each of which is indicative, for each of said macrocategories (MC), of a corresponding probability that the test manoeuvre (M<sub>m</sub>) belongs to said macrocategory (MC); and<br/>  - subsequent aggregation (160;370;700) of said plurality of training prediction vectors (PV'<sub>mpj</sub>;PV\"<sub>mpj</sub>) ;<br/>said output classifier (151;251;651;751) having further been generated by performing, for each time instant (t<sub>clkj</sub><br/>) of the second succession of time instants (t<sub>clk</sub><br/>) that falls within a time interval (T<sub>m</sub><br/>) of a test manoeuvre (M<sub>m</sub><br/>), the step of:<br/> - training (170;380;710;810) the output classifier (151;251;651;751) in a supervised manner, on the basis of the corresponding training macrovector (MPV'<sub>mj</sub>; MPV\"<sub>mj</sub>; MPV‴<sub>mj</sub>; MFV<sub>mj</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs.</p><p>3. Method according to claim 2, wherein said step of generating (330,335) a corresponding input macrovector (MPVX'<sub>k</sub>) comprises, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/> - to each of the corresponding feature vectors (FVX<sub>kp</sub>), applying (330) a first classifier (131), which is configured to generate a corresponding first strategy input prediction vector (PVX'<sub>kp</sub>), the first strategy input prediction vectors (PVX'<sub>kp</sub>) forming said plurality of input prediction vectors (PVX'<sub>kp</sub>) ;<br/> - aggregating (335) the first strategy input prediction vectors (PVX'<sub>kp</sub>) into a first strategy input macrovector (MPVX'<sub>k</sub>), which forms said input macrovector (MPVX'<sub>k</sub>);<br/>and wherein the output classifier is formed by a first output classifier (151); and wherein said step of applying (338), for each time instant (t<sub>clkk</sub><br/>) of the first succession of time instants (t<sub>clk</sub><br/>) , an output classifier (151) to the corresponding input macrovector (MPVX'<sub>k</sub><br/>) comprises applying (338) the first output classifier (151) to the corresponding first strategy input macrovector (MPVX'<sub>k</sub><br/>).</p><p>4. Method according to claim 3, wherein said first classifier (131) has been generated by performing the steps of:<br/> - for each of said test manoeuvres (M<sub>m</sub>), extracting (120) a corresponding entire manoeuvre feature vector (FV<sub>m</sub>), starting from the portions of the time series of the training data structure (10) that extend in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>); and<br/> - training (130) the first classifier (131) in a supervised manner on the basis of the entire manoeuvre feature vectors (FV<sub>m</sub>) and of the labels indicative of the macrocategories (MC) to which the corresponding test manoeuvres (M<sub>m</sub>) belong;<br/>and wherein the first output classifier (151) has been generated by performing, for each time instant (t<sub>clkj</sub><br/>) of the second succession of time instants (t<sub>clk</sub><br/>) that falls within a time interval (T<sub>m</sub><br/>) of a test manoeuvre (M<sub>m</sub><br/>), the steps of:<br/> - applying (150) the first classifier (131) to the corresponding first training feature vectors (FV'<sub>mpj</sub>), so as to obtain a number of first strategy training prediction vectors (PV'<sub>mpj</sub>) equal to the number of time durations (TW'), said first strategy training prediction vectors (PV'<sub>mpj</sub>) forming said plurality of training prediction vectors (PV'<sub>mpj</sub>); and<br/> - aggregating (160) said number of first strategy training prediction vectors (PV'<sub>mpj</sub>), so as to form a corresponding first training prediction macrovector (MPV'<sub>mj</sub>), which forms said training macrovector (MPV'<sub>mj</sub>);<br/> - training (170) the first output classifier (151) in a supervised manner on the basis of the corresponding first training prediction macrovector (MPV'<sub>mj</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs.</p><p>5. Method according to claim 2, wherein said step of generating (500,510) a corresponding input macrovector (MPVX\"<sub>k</sub>) comprises, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/> - for each time duration (TW'<sub>p</sub>) among said predetermined time durations (TW'), applying (500) to the feature vector (FVX<sub>kp</sub>) relating to said time instant (t<sub>clkk</sub>) and to said time duration (TW'<sub>p</sub>) a corresponding second classifier (CLASS<sub>p</sub>) among a number of different second classifiers (CLASS) equal to said number of predetermined time durations (TW'), said corresponding second classifier (CLASS<sub>p</sub>) being configured to generate a corresponding second strategy input prediction vector (PVX\"<sub>kp</sub>), the second strategy input prediction vectors (PVX\"<sub>kp</sub>) forming said plurality of input prediction vectors (PVX\"<sub>kp</sub>) ;<br/> - aggregating (510) the second strategy input prediction vectors (PVX\"<sub>kp</sub>) into a second strategy input macrovector (MPVX\"<sub>k</sub>), which forms said input macrovector (MPVX\"<sub>k</sub>) ;<br/>and wherein the output classifier is formed by a second output classifier (251); and wherein said step of applying, for each time instant (t<sub>clkk</sub><br/>) of the first succession of time instants (t<sub>clk</sub><br/>) , an output classifier (251) to the corresponding input macrovector (MPVX\"<sub>k</sub><br/>) comprises applying (520) the second output classifier (251) to the corresponding second strategy input macrovector (MPVX\"<sub>k</sub><br/>).</p><p>6. Method according to claim 5, wherein each second classifier (CLASS<sub>p</sub>) has been generated by performing, for each of said test manoeuvres (M<sub>m</sub>), the steps of:<br/> - selecting (430,460) a number of corresponding subsets of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), each of the selected subsets having a time extension not higher than the time duration (TW'<sub>p</sub>) corresponding to the second classifier (CLASS<sub>p</sub>);<br/> - from each selected subset of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), extracting (440,470) a corresponding second training feature vector (FV\"<sub>mpu</sub>); and<br/> - training (350) the second classifier (CLASS<sub>p</sub>) in a supervised manner on the basis of the extracted second training feature vectors (FV\"<sub>mpu</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs;<br/>and wherein the second output classifier (251) has been generated by performing, for each time instant (t<sub>clkj</sub><br/>) of the second succession of time instants (t<sub>clk</sub><br/>) that falls within a time interval (T<sub>m</sub><br/>) of a test manoeuvre (M<sub>m</sub><br/>), the steps of:<br/> - for each time duration (TW'<sub>p</sub>), applying (360) the second classifier (CLASS<sub>p</sub>) that corresponds to the time duration (TW'<sub>p</sub>) to the first training feature vector (FV'<sub>mpj</sub>) that corresponds to said time instant (t<sub>clkj</sub>) and has been extracted from the selected subset of the training data structure (10) having a time extension equal to the time duration (TW'<sub>p</sub>), so as to obtain a corresponding second strategy training prediction vector (PV\"<sub>mpj</sub>), the second strategy training prediction vectors (PV\"<sub>mpj</sub>) forming said plurality of training prediction vectors (PV\"<sub>mpj</sub>);<br/> - aggregating (370) the second strategy training prediction vectors (PV\"<sub>mpj</sub>), so as to form a corresponding second training prediction macrovector (MPV\"<sub>mj</sub>), which forms said training macrovector (MPV\"<sub>mj</sub>);<br/> - training (380) the second output classifier (251) in a supervised manner on the basis of the corresponding second training prediction macrovector (MPV\"<sub>mj</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs.</p><p>7. Method according to claim 2, wherein said step of generating (720) a corresponding input macrovector (MPVX‴<sub>k</sub>) comprises, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/> - to each of the corresponding feature vectors (FVX<sub>kp</sub>), applying (330) a first classifier (131), which is configured to generate a corresponding first strategy input prediction vector (PVX' <sub>kp</sub>) ;<br/> - for each time duration (TW'<sub>p</sub>) among said predetermined time durations (TW'), applying (500) to the feature vector (FVX<sub>kp</sub>) relating to said time instant (t<sub>clkk</sub>) and to said time duration (TW'<sub>p</sub>) a corresponding second classifier (CLASS<sub>p</sub>) among a number of different second classifiers (CLASS) equal to said number of predetermined time durations (TW'), said corresponding second classifier (CLASS<sub>p</sub>) being configured to generate a corresponding second strategy input prediction vector (PVX\"<sub>kp</sub>), the first and second strategy input prediction vectors (PVX'<sub>kp</sub>, PVX\"<sub>kp</sub>) forming said plurality of input prediction vectors (PVX' <sub>kp</sub>, PVX\"<sub>kp</sub>) ;<br/> - aggregating (720) the first and second strategy input prediction vectors (PVX'<sub>kp</sub>, PVX\"<sub>kp</sub>) into a third strategy input macrovector (MPVX‴<sub>k</sub>), which forms said input macrovector (MPVX‴<sub>k</sub>);<br/>and wherein the output classifier is formed by a third output classifier (651); and wherein said step of applying, for each time instant (t<sub>clkk</sub><br/>) of the first succession of time instants (t<sub>clk</sub><br/>), an output classifier (651) to the corresponding input macrovector (MPVX‴<sub>k</sub><br/>) comprises applying (730) the third output classifier (651) to the corresponding third strategy input macrovector (MPVX‴<sub>k</sub><br/>).</p><p>8. Method according to claim 7, wherein the first classifier (131) was generated by performing the steps of:<br/> - for each of said test manoeuvres (M<sub>m</sub>), extracting (120) a corresponding entire manoeuvre feature vector (FV<sub>m</sub>), starting from the portions of the time series of the training data structure (10) that extend in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>); and<br/> - training (130) the first classifier (131) in a supervised manner on the basis of the entire manoeuvre feature vectors (FV<sub>m</sub>) and of the labels indicative of the macrocategories (MC) to which the corresponding test manoeuvres (M<sub>m</sub>) belong;<br/>and wherein each second classifier (CLASS<sub>p</sub><br/>) has been generated by performing, for each of said test manoeuvres (M<sub>m</sub><br/>), the steps of:<br/> - selecting (430,460) a number of corresponding subsets of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), each of the selected subsets having a time extension not higher than the time duration (TW'<sub>p</sub>) corresponding to the second classifier (CLASS<sub>p</sub>);<br/> - from each selected subset of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), extracting (440,470) a corresponding second training feature vector (FV<i>\"</i><sub>mpu</sub>) ; and<br/> - training (350) the second classifier (CLASS<sub>p</sub>) in a supervised manner on the basis of the extracted second training feature vectors (FV\"<sub>mpu</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs;<br/>and wherein the third output classifier (651) has been generated by performing, for each time instant (t<sub>clkj</sub><br/>) of the second succession of time instants (t<sub>clk</sub><br/>) that falls within a time interval (T<sub>m</sub><br/>) of a test manoeuvre (M<sub>m</sub><br/>), the steps of:<br/> - applying (150) the first classifier (131) to the corresponding first training feature vectors (FV'<sub>mpj</sub>), so as to obtain a number of first strategy training prediction vectors (PV'<sub>mpj</sub>) equal to the number of predetermined time durations (TW');<br/> - for each time duration (TW'<sub>p</sub>), applying (360) the second classifier (CLASS<sub>p</sub>) that corresponds at the time duration (TW'<sub>p</sub>) to the first training feature vector (FV'<sub>mpj</sub>) that corresponds to said time instant (t<sub>clkj</sub>) and has been extracted from the selected subset of the training data structure (10) having a time extension equal to the time duration (TW'<sub>p</sub>), so as to obtain a corresponding second strategy training prediction vector (PV\"<sub>mpj</sub>), the first and second strategy training prediction vectors (PV'<sub>mpj</sub>, PV\"<sub>mpj</sub>) forming said plurality of training prediction vectors (PV' <sub>mpj</sub>, PV\"<sub>mpj</sub>) ;<br/> - aggregating (700) said number of first and second strategy training prediction vectors (PV'<sub>mpj</sub>, PV\"<sub>mpj</sub>), so as to form a corresponding third training prediction macrovector (MPV‴<sub>mj</sub>), which forms said training macrovector (MPV‴<sub>mj</sub>);<br/> - training (710) the third output classifier (651) in a supervised manner on the basis of the corresponding third training prediction macrovector (MPV‴<sub>mj</sub>) and of the label indicative of the macrocategory (MC) to which the test manoeuvre (M<sub>m</sub>) belongs.</p><p>9. Method according to any one of the preceding claims, further comprising performing, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/> - for each time duration (TW'<sub>p</sub>), applying (910) to the feature vector (FVX<sub>kp</sub>) that corresponds to said time duration (TW'<sub>p</sub>) and to said time instant (t<sub>clkk</sub>) a number of single-class classifiers (SCC<sub>i</sub>) equal to the number of macrocategories (MC), each single-class classifier (SCC<sub>i</sub>) being configured to generate a corresponding probability value, which is indicative of the probability that in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) the aircraft (3) was executing a manoeuvre belonging to a macrocategory (MC) corresponding to the single-class classifier (SCC<sub>i</sub>) ;<br/> - for each single-class classifier (SCC<sub>i</sub>), calculating (920) a corresponding statistical quantity on the basis of the probability values generated by the single-class classifier (SCC<sub>i</sub>) ;<br/> - on the basis of the calculated statistical quantities (OUT_UPDATE<sub>k</sub>), detecting (930) the execution of manoeuvres belonging to multiple macrocategories; and<br/> - in case of non-detection of the execution of manoeuvres belonging to multiple macrocategories, performing said step of detecting (940,951) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) belongs on the basis of the output vector (OUT_A<sub>k</sub>; OUT_B<sub>k</sub>; OUT_C<sub>k</sub>; OUT_D<sub>k</sub>), otherwise executing a step of detecting (950,951) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) belongs on the basis of said calculated statistical quantities (OUT_UPDATE<sub>k</sub>) .</p><p>10. Method according to claim 9 when dependent on claim 2, wherein each single-class classifier (SCC<sub>i</sub>) has been generated by performing, for each of said test manoeuvres (M<sub>m</sub>), the steps of:<br/> - extracting (120) a corresponding entire manoeuvre feature vector (FV<sub>m</sub>), starting from the portions of the time series of the training data structure (10) that extend in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>); and<br/> - training the single-class classifier (SCC<sub>i</sub>) in a supervised manner on the basis of the extracted entire manoeuvre feature vector (FV<sub>m</sub>) and of a label which is indicative of the match between the macrocategory (MC) of the test manoeuvre (M<sub>m</sub>) and the macrocategory (MC<sub>i</sub>) that corresponds to the single-class classifier (SCC<sub>i</sub>).</p><p>11. Method according to any one of claims 1 to 8, further comprising performing, for each time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), the steps of:<br/> - for each time duration (TW'<sub>p</sub>), applying (910) to the feature vector (FVX<sub>kp</sub>) that corresponds to said time duration (TW'<sub>p</sub>) and to said time instant (t<sub>clkk</sub>) a plurality of respective single-class classifiers (SCC'<sub>pi</sub>) that correspond to said time duration (TW'<sub>p</sub>), each of which is configured to generate a corresponding probability value indicative of the probability that in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) the aircraft (3) was executing a manoeuvre belonging to a macrocategory (MC) corresponding to the single-class classifier (SCC<sub>pi</sub>);<br/> - for each macrocategory (MC<sub>i</sub>), calculating (980) a corresponding statistical quantity on the basis of probability values generated by the single-class classifiers (SCC<sub>pi</sub>) that correspond to said macrocategory (MC<sub>i</sub>) and, respectively, to the time durations (TW'<sub>p</sub>);<br/> - on the basis of the calculated statistical quantities (OUT_UPDATE'<sub>k</sub>), detecting (985) the execution of manoeuvres belonging to multiple macrocategories; and<br/> - in case of non-detection of the execution of manoeuvres belonging to multiple macrocategories, performing said step of detecting (940,951) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) belongs on the basis of the output vector (OUT_A<sub>k</sub>; OUT_B<sub>k</sub>; OUT_C<sub>k</sub>; OUT_D<sub>k</sub>), otherwise performing a step of detecting (951,990) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) belongs on the basis of said calculated statistical quantities (OUT_UPDATE'<sub>k</sub>).</p><p>12. Method according to claim 11 when dependent on claim 2, wherein each single-class classifier (SCC'<sub>pi</sub>) has been generated by performing, for each of said test manoeuvres (M<sub>m</sub>), the steps of:<br/> - selecting (430,460) a number of corresponding subsets of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), each of the selected subsets having a time extension not higher than the time duration (TW'<sub>p</sub>) corresponding to the second single-class classifier (SC AC'<sub>pi</sub>);<br/> - from each selected subset of the portion (DG<sub>m</sub>) of the training data structure (10) that extends in the time interval (T<sub>m</sub>) of the test manoeuvre (M<sub>m</sub>), extracting (440,470) a corresponding second training feature vector (FV\"<sub>mpu</sub>) ; and<br/> - training (960) in a supervised manner the single-class classifier (SCC'<sub>pi</sub>), on the basis of the extracted second training feature vectors (FV\"<sub>mpu</sub>) and of a label indicative of the match between the macrocategory (MC) of the test manoeuvre (M<sub>m</sub>) and the macrocategory (MC<sub>i</sub>) corresponding to the single-class classifier (SCC'<sub>pi</sub>).</p><p>13. Method according to any one of claims 1 to 8, further comprising the step of:<br/> - on the basis of the macrocategory (MC) detected, identifying (991) the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>), on the basis of at least a value of at least one among said quantities relating to the flight of the aircraft (3).</p><p>14. Method according to any one of claims 9 to 12, further comprising the steps of:<br/> - in case of non-detection of the execution of manoeuvres belonging to multiple macrocategories, identifying (991) the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) on the basis of the macrocategory (MC) detected on the basis of the output vector (OUT_A<sub>k</sub>; OUT_B<sub>k</sub>; OUT_C<sub>k</sub>; OUT_D<sub>k</sub>) and of at least one value of at least one among said quantities relating to the flight of the aircraft (3) ;<br/> - in case of detection of the execution of manoeuvres belonging to multiple macrocategories, identifying (991) the manoeuvre executed by the aircraft (3) in said time instant (t<sub>clkk</sub>) of the first succession of time instants (t<sub>clk</sub>) on the basis of the macrocategory (MC) detected on the basis of said calculated statistical quantities (OUT_UPDATE<sub>k</sub>; OUT_UPDATE'<sub>k</sub>) and of at least one value of at least one among said quantities relating to the flight of the aircraft (3).</p><p>15. Computer-implemented method for determining the state of usage of an aircraft (3), comprising:<br/> - storing information correlating load data to manoeuvres;<br/> - carrying out the method according to claim 13 or 14;<br/> - determining at least one quantity indicative of said state of usage on the basis of the identified manoeuvre.</p><p>16. Processing system comprising means configured to carry out the method according to any one of the preceding claims.</p><p>17. Computer program comprising instructions which, when the program is executed by a computer (12), cause the execution of the method according to any one of claims 1 to 15.</p><p>18. Computer medium readable by a computer (12), on which the computer program according to claim 17 is stored.</p>",
            "NPR": "2",
            "APID": "158203255",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64D-045/00<br/>G05B-023/02<br/>G07C-005/08<br/>G08G-005/00",
            "ID": "100568507",
            "AB": "(EP4016221)<br/>Method implemented through a computer (12) for detecting the execution, by an aircraft (3), of a manoeuvre belonging to a macrocategory among a plurality of macrocategories (MC), including: receiving a data structure (205) with a plurality of time series of values of quantities relating to a flight of the aircraft (3); for each time duration (TW&apos;p) among a plurality of predetermined time durations (TW&apos;), selecting (310) a corresponding subset of the data structure (205) and extracting (320) a corresponding feature vector (FVXkp); on the basis of the feature vectors (FVXkp), generating (330,335;500,510;720;820) a corresponding input macrovector (MPVX&apos;k; MPVX&quot;k, MPVX&apos;&apos;&apos;k; MFVXk) and applying (338;520;730;830) to the input macrovector (MPVX&apos;k; MPVX&quot;k, MPVX&apos;&apos;&apos;k; MFVXk) an output classifier (151;251;561;721) to generate estimates indicative of the probability that the aircraft (3) was performing manoeuvres belonging to the macrocategories (MC).",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=w5MSaZHeU0Yuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2020-12-18",
            "PA": "LEONARDO<br/>POLITECNICO DI MILANO",
            "PAAD": "(EP4016221)<br/>(PUB:EP-4016221B1-8)NAME=LEONARDO S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101759152<br/><br/>(PUB:EP-4016221A1-8)NAME=LEONARDO S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101759152<br/>NAME=Politecnico di Milano Piazza Leonardo da Vinci 32 , CITY=20133 Milano , COUNTRY=IT , REG=101672175<br/><br/><br/>(US20240105065)<br/>(PUB:US-20240105065A1-2)NAME=LEONARDO S.P.A.  , CITY=Roma , COUNTRY=IT<br/><br/><br/>(WO2022130334)<br/>(PUB:WO-2022/130334A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 Roma , POSTCODE=00195 , COUNTRY=IT<br/>NAME=POLITECNICO DI MILANO Piazza Leonardo da Vinci, 32 20133 Milano , POSTCODE=20133 , COUNTRY=IT<br/><br/><br/>(CN117413232)<br/>(PUB:CN-117413232A-168)NAME=LEONARDO SPA  , COUNTRY=IT<br/><br/><br/>(KR20230135580)<br/>(PUB:KR-10-2023-0135580A-113)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "100568507",
            "TI": "Method and system for detecting and classifying manoeuvres executed by an aircraft on the basis of measures acquired during a flight of the aircraft",
            "TECD": "Control<br/>Transport",
            "EPD": "2022-06-22",
            "ICLM": "(EP4016221)<br/><p>1. Method implemented through a computer (12) for detecting the execution, by an aircraft (3), of a manoeuvre belonging to a macrocategory among a plurality of macrocategories (MC), comprising the steps of: - receiving a data structure (205) including a plurality of time series of values of quantities relating to a flight of the aircraft (3), said values having been acquired through a monitoring system (4) coupled to the aircraft (3); said method further comprising performing, for each time instant (tclkk) of a first succession of time instants (tclk), the steps of: - for each time duration (TW'p) among a plurality of predetermined time durations (TW'), selecting (310) a corresponding subset of the data structure (205), which has a time extension equal to the time duration (TW'p), the selected subsets of the data structure (205) having a same time distance from the time instant (tclkk); - from each selected subset of the data structure (205), extracting (320) a corresponding feature vector (FVXkp); - on the basis of the feature vectors (FVXkp), generating (330,335;500,510;720;820) a corresponding input macrovector (MPVX'k; MPVX\"k, MPVX‴k; MFVXk), alternatively by aggregation (820) of the feature vectors (FVXkp) or by: - executing classifications (330;500) of the feature vectors (FVXkp), said classifications being executed so as to generate a plurality of input prediction vectors (PVX'kp; PVX\"kp), each of which is indicative, for each of said macrocategories (MC), of a corresponding probability that, in said time instant (tclkk) of the first succession of time instants (tclk), the aircraft (3) was executing a manoeuvre belonging to said macrocategory (MC); and - subsequent aggregation (335;510;720) of said plurality of input prediction vectors (PVX'kp;PVX\"kp); said method further comprising performing, for each time instant (tclkk) of the first succession of time instants (tclk), the steps of: - applying (338;520;730;830) to the input macrovector (MPVX'k; MPVX\"k, MPVX‴k; MFVXk) an output classifier (151;251;561;721), which is configured to generate a corresponding output vector (OUT_Ak; OUT_Bk; OUT_Ck; OUT_Dk) including, for each of said macrocategories (MC), a corresponding estimate of the probability that, in said time instant (tclkk) of the first succession of time instants (tclk), the aircraft (3) was executing a manoeuvre belonging to said macrocategory (MC); and - on the basis of the output vector (OUT_Ak; OUT_Bk; OUT_Ck; OUT_Dk), detecting (940, 950, 951, 990) the macrocategory (MC) to which the manoeuvre executed by the aircraft (3) in said time instant (tclkk) of the first succession of time instants (tclk) belongs.</p>",
            "CTN": "(EP4016221)<br/>EP2384971 15033457 WHO=EXAMINER SELF=N CAT=A<br/>EP2270618 15002680 WHO=EXAMINER SELF=N CAT=A<br/>EP3462266 84023204 WHO=EXAMINER SELF=N CAT=A<br/>EP2384971 15033457 WHO=APPLICANT SELF=N<br/><br/>(WO2022130334)<br/>EP2384971 15033457 WHO=EXAMINER SELF=N CAT=A<br/>EP2270618 15002680 WHO=EXAMINER SELF=N CAT=A<br/>EP3462266 84023204 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2024-06-18",
                    "XAP": "2021WO-IB61957",
                    "APD": "2021-12-17",
                    "APID": "158213916",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2022130334&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=3FDIiHQbBk%252FNLQLgYSW9fLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2022/130334",
                            "KIND": "A1",
                            "XPN": "WO2022130334",
                            "V_PNID": "WO-2022/130334A1-3",
                            "DATE": "2022-06-23",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDTo/di1WRJIN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2022130334&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=3FDIiHQbBk%252FNLQLgYSW9fLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2041-12-17",
                            "XAP": "2021US-18267576",
                            "APD": "2021-12-17",
                            "APID": "167508429",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/18267576",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=v4p5FmLukez5SmIQPfQobsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US20240105065",
                                    "KIND": "A1",
                                    "XPN": "US20240105065",
                                    "V_PNID": "US-20240105065A1-2",
                                    "DATE": "2024-03-28",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcNlM3deGJ3gQVq5LJ03xVJIbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20240105065&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=v4p5FmLukez5SmIQPfQobsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2041-12-17",
                            "XAP": "2021CN-80093901",
                            "APD": "2021-12-17",
                            "APID": "167911845",
                            "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=uE31PGl7pL3PYMV8dQED5ZNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CN117413232",
                                    "KIND": "A",
                                    "XPN": "CN117413232",
                                    "V_PNID": "CN-117413232A-168",
                                    "DATE": "2024-01-16",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=hXP7Q1+dwoSmRNN2sils+Mk/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN117413232&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=uE31PGl7pL3PYMV8dQED5ZNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2041-12-17",
                            "XAP": "2023KR-7024432",
                            "APD": "2021-12-17",
                            "APID": "165942257",
                            "REG_LINK": "http://link.kipris.or.kr/link/main/KPAXML.jsp?APPLNO=1020237024432",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=vrVMCdBIzzEN2cAcknOiCsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "KR10-2023-0135580",
                                    "KIND": "A",
                                    "XPN": "KR20230135580",
                                    "V_PNID": "KR-10-2023-0135580A-113",
                                    "DATE": "2023-09-25",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aJxR8iNWnoocYBOPNPZYAkGd4JhdgzD3ETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=KR20230135580&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=vrVMCdBIzzEN2cAcknOiCsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2040-12-18",
                    "XAP": "2020EP-0425059",
                    "APD": "2020-12-18",
                    "APID": "158203255",
                    "REG_LINK": "https://register.epo.org/application?number=EP20425059",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=w5MSaZHeU0Yuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP4016221",
                            "KIND": "B1",
                            "XPN": "EP4016221",
                            "V_PNID": "EP-4016221B1-8",
                            "DATE": "2023-06-14",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=x0jAXD9vGYs3v7StOIH9f6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4016221&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=w5MSaZHeU0Yuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP4016221",
                            "KIND": "A1",
                            "XPN": "EP4016221",
                            "V_PNID": "EP-4016221A1-8",
                            "DATE": "2022-06-22",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=x0jAXD9vGYs3v7StOIH9f/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP4016221&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=w5MSaZHeU0Yuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP4016221_B1",
            "EPRD": "2020-12-18",
            "PN": "EP4016221           B1 2023-06-14 [EP4016221]<br/>EP4016221           A1 2022-06-22 [EP4016221]<br/>US20240105065       A1 2024-03-28 [US20240105065]<br/>WO2022/130334       A1 2022-06-23 [WO2022130334]<br/>CN117413232         A  2024-01-16 [CN117413232]<br/>KR10-2023-0135580   A  2023-09-25 [KR20230135580]",
            "ADB": "(EP4016221)<br/><p>In particular, the present system allows to precisely detect the macrocategories of the manoeuvres executed by an aircraft, irrespective of the type, and therefore of the duration, of the macrocategories.</p><p>Such processing takes place in a per se known manner and is optional; in the following it is assumed, for simplicity's sake, that such processing does not alter the content of the training data structure 10; otherwise, the operations described below are executed on the training data structure processed.</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=5<br/>PNAAGE=20<br/>NBPA=1; <br/>ALLCT=70; SCT=1; NSCT=69; <br/>ALLCTG=5; SCTG=0; NSCTG=5; <br/>AFS=15; ACC=15; AMCC=3; <br/>IGEN=0.85; IORG=0.91; IRAD=0.98; <br/>IMPI=3.88; MACI=1.32; PASI=3.32; PAVI=4.02; ",
            "PTCC": "(EP3887854)<br/>CC=EP EED=2039-11-27 STATUS=GRANTED APID=152991241 APD=2019-11-27 XPN=EP3887854 PD=2021-10-06 PD=2022-09-21 EPD=2021-10-06 LPD=2022-09-21 PDG=2022-09-21 <br/>CC=DE EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/>CC=ES EED=2039-11-27 STATUS=GRANTED APID=161534861 APD=2019-11-27 XPN=ES2930577 PD=2022-12-19 EPD=2022-12-19 LPD=2022-12-19 PDG=2022-12-19 <br/>CC=FR EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/>CC=GB EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/>CC=IT EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/>CC=NL EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/>CC=PL EED=2039-11-27 STATUS=GRANTED APID=163118567 APD=2019-11-27 XPN=PL3887854 PD=2023-03-20 EPD=2023-03-20 LPD=2023-03-20 PDG=2023-03-20 <br/>CC=SE EED=2039-11-27 STATUS=GRANTED APID=152991241 XPN=EP3887854 PDG=2022-09-21 <br/><br/>(US20220036748)<br/>CC=US EED=2039-11-27 STATUS=PENDING APID=155621591 APD=2019-11-27 XPN=US20220036748 PD=2022-02-03 EPD=2022-02-03 LPD=2022-02-03 <br/><br/>(WO2020110040)<br/>CC=EP EED=2039-11-27 STATUS=GRANTED APID=152991241 APD=2019-11-27 XPN=EP3887854 PD=2021-10-06 PD=2022-09-21 EPD=2021-10-06 LPD=2022-09-21 PDG=2022-09-21 <br/>CC=ES EED=2039-11-27 STATUS=GRANTED APID=161534861 APD=2019-11-27 XPN=ES2930577 PD=2022-12-19 EPD=2022-12-19 LPD=2022-12-19 PDG=2022-12-19 <br/>CC=PL EED=2039-11-27 STATUS=GRANTED APID=163118567 APD=2019-11-27 XPN=PL3887854 PD=2023-03-20 EPD=2023-03-20 LPD=2023-03-20 PDG=2023-03-20 <br/>CC=US EED=2039-11-27 STATUS=PENDING APID=155621591 APD=2019-11-27 XPN=US20220036748 PD=2022-02-03 EPD=2022-02-03 LPD=2022-02-03 <br/><br/>(PL3887854)<br/>CC=PL EED=2039-11-27 STATUS=GRANTED APID=163118567 APD=2019-11-27 XPN=PL3887854 PD=2023-03-20 EPD=2023-03-20 LPD=2023-03-20 PDG=2023-03-20 <br/><br/>(ES2930577)<br/>CC=ES EED=2039-11-27 STATUS=GRANTED APID=161534861 APD=2019-11-27 XPN=ES2930577 PD=2022-12-19 EPD=2022-12-19 LPD=2022-12-19 PDG=2022-12-19 <br/>",
            "EPN": "WO2020/110040",
            "CTGN": "(US20220036748)<br/>CN115240475 102280339 WHO=EXAMINER SELF=N CAT=A<br/>US11542004 93612791 WHO=EXAMINER SELF=N<br/>CN115547117 103241960 WHO=EXAMINER SELF=N CAT=X<br/>CN117294705B 107897460 WHO=EXAMINER SELF=N<br/><br/>(WO2020110040)<br/>EP4189430 98938893 WHO=EXAMINER SELF=N CAT=X CAT=I",
            "LAPD": "2019-11-27",
            "STDN": "",
            "NPN": "5",
            "DESC": "<p><h1>CROSS-REFERENCE TO RELATED APPLICATIONS</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This patent application claims priority from European patent application no. 18425087.6 filed on 27 Nov. 2018 and Italian patent application no. 102019000021105 filed on 13 Nov. 2019, the entire disclosure of which is incorporated herein by reference.</p><br/><p><h1>TECHNICAL FIELD OF INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates, in general, to a system for monitoring a predetermined suborbital region conveniently comprised between approximately 20/22 km and approximately 120/150 km from the earth's surface (preferably, between flight level (FL) 650 and approximately 150 km from the earth's surface) and, in particular, to a system for monitoring objects in said suborbital region and to detect potentially hazardous situations for said objects (e.g. situations of potential collision between said objects). More specifically, the present invention concerns a suborbital space traffic control system.</p><p><h1>STATE OF THE ART</h1></p><p><span class=\"paragraph-number\">[0003]   </span>As is known, a suborbital space flight (also simply referred to as a suborbital flight) is a space flight where the space vehicle (e.g. a spaceplane) reaches space with a trajectory that intersects the atmosphere (or, more in general, the surface of the gravitational body from which it left), without completing a complete orbital revolution.</p><p><span class=\"paragraph-number\">[0004]   </span>Currently, experimental activities in HOTOL (HOrizontal Take-Off and Landing) suborbital flights are in progress, for example, from Spaceport America located in New Mexico in the USA (while in Italy, the definition of the relevant regulations is underway in order to be able to conduct the first experimental suborbital flights).</p><p><span class=\"paragraph-number\">[0005]   </span>With regard to this, <a href=\"#DRAWINGS\">FIG. 1</a> shows, very schematically, an example of a HOTOL suborbital flight. In particular, <a href=\"#DRAWINGS\">FIG. 1</a> shows a trajectory (indicated as a whole by <b>11</b>) followed by a horizontal take-off and landing spaceplane (not shown) that takes off from a spaceport <b>12</b>, reaches space beyond 100 km from earth (for example, reaching an altitude of approximately 110 km with zero gravity), and then returns to earth, landing at the spaceport <b>12</b>. In addition, <a href=\"#DRAWINGS\">FIG. 1</a> also shows an example of segregated airspace <b>13</b> associated with the spaceport <b>12</b> for conducting HOTOL suborbital flights.</p><p><span class=\"paragraph-number\">[0006]   </span>As is known, alternative solutions can be based on the use of two-stage systems, in which a main aircraft that transports a spaceplane takes off and reaches a predetermined altitude (e.g. approximately 15 km). The spaceplane is then released/uncoupled and can thus autonomously reach space beyond the 100 km altitude, and then re-enter (for example, by gliding) the spaceport of departure.</p><p><span class=\"paragraph-number\">[0007]   </span>In addition, further solutions can be conveniently based on vertical take-off and landing (e.g. based on the use of Vertical Take-off, Vertical Landing (VTVL) rockets).</p><p><span class=\"paragraph-number\">[0008]   </span>Looking ahead, suborbital flights can have numerous applications. For example, neglecting the initial application focused on “space tourism” with take-off and landing at the same spaceport, a quite interesting application concerns the possibility of taking off from one spaceport A and then landing at a spaceport B, with incredible potentialities, such as a drastic reduction of traditional flight times (for example, a flight from Rome to New York of this type might last around one hour).</p><p><span class=\"paragraph-number\">[0009]   </span>In addition, a further application relates to the manufacture of low-cost launch vehicles for microsatellites.</p><p><span class=\"paragraph-number\">[0010]   </span>On the other hand, the suborbital flight sector could also be advantageously exploited for:</p><p><ul type=\"none\"><li><span class=\"paragraph-number\">[0011]   </span>- scientific experiments (e.g. in life sciences in microgravity, physical sciences in microgravity, aero-medical sciences, health physics, Earth sciences, etc.); and</li><br/><li><span class=\"paragraph-number\">[0012]   </span>- test and/or training activities (for example, for testing devices intended for space use and/or for training astronauts).</li></ul></p><p><span class=\"paragraph-number\">[0013]   </span>Unfortunately, as can be easily guessed, the introduction of suborbital space flight could give rise to many risks in terms of safety, both for the actual suborbital flights and for traditional air traffic and the population (for example, in the event of accidents and/or collisions). With regard to this, it is important to note that no systems currently exist that allow limiting these risks, nor authorities/agencies delegated to controlling suborbital flights. In fact, until now test missions have always been autonomously managed and controlled by the companies responsible for these missions, without control by third-party agencies/systems. For the future, an external control for this type of flight will certainly be necessary, as well as coordination between the various operators working in this sector (and also with the traditional air traffic operators).</p><p><span class=\"paragraph-number\">[0014]   </span>On the other hand, it should be remembered that nowadays space debris represents a serious safety risk for traditional plane flights, for the ground infrastructures and for the population, while in the near future it could also represent a risk for suborbital space flights.</p><p><span class=\"paragraph-number\">[0015]   </span>Various solutions have thus been proposed in recent years for the detection, tracking and monitoring of this debris. For example, solutions of this type are set forth in:</p><p><ul type=\"none\"><li><span class=\"paragraph-number\">[0016]   </span>- U.S. Pat. No. 9,586,704 B2, which describes a system for modelling and simulating the propagation of space debris in order to predict potential collisions between space objects;</li></ul></p><p><span class=\"paragraph-number\">[0017]   </span>CN106507959B, which describes a two-dimensional array ground radar system for the detection of space debris;</p><p><ul type=\"none\"><li><span class=\"paragraph-number\">[0018]   </span>- CN107529385B, which describes another radar solution for the detection of space debris and for the generation of early warnings;</li><br/><li><span class=\"paragraph-number\">[0019]   </span>- CN102042820A, which describes a system for the detection of small pieces of space debris based on spectroscopy; and</li><br/><li><span class=\"paragraph-number\">[0020]   </span>- CN108226888A, which describes a method for the detection of multiple space targets (e.g. space debris) based on synthetic aperture imaging.</li></ul></p><p><h1>OBJECT AND SUMMARY OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0021]   </span>In light of what has previously been explained, the Applicant has felt the need to carry out in-depth research in order to develop an innovative system that would enable monitoring and controlling suborbital space flights in an extremely reliable manner by reducing the associated risks, in this way arriving at the present invention.</p><p><span class=\"paragraph-number\">[0022]   </span>Thus, the object of the present invention is to provide a system able to monitor and control suborbital space traffic in an extremely reliable manner, thereby reducing the associated risks.</p><p><span class=\"paragraph-number\">[0023]   </span>This and other objects are achieved by the present invention in so far as it relates to a suborbital space traffic control system, as defined in the appended claims.</p><p><span class=\"paragraph-number\">[0024]   </span>In particular, the present invention concerns a suborbital space traffic control system that comprises:</p><p><ul type=\"none\"><li><span class=\"paragraph-number\">[0025]   </span>- a radar system configured to    <br/><ul type=\"none\"><li><span class=\"paragraph-number\">[0026]   </span> - monitor a predetermined suborbital region and</li><br/><li><span class=\"paragraph-number\">[0027]   </span> - detect and track objects present in said predetermined suborbital region, wherein said objects include vehicles and space debris; and</li></ul></li><br/><li><span class=\"paragraph-number\">[0028]   </span>- a suborbital space traffic monitoring system configured to    <br/><ul type=\"none\"><li><span class=\"paragraph-number\">[0029]   </span> - receive, from the radar system, tracking data related to the objects detected and tracked by said radar system,</li><br/><li><span class=\"paragraph-number\">[0030]   </span> - monitor, based on the tracking data, trajectories of the objects in the predetermined suborbital region by using one or more predetermined machine-learning techniques to detect potentially hazardous situations for the vehicles in said predetermined suborbital region and,</li><br/><li><span class=\"paragraph-number\">[0031]   </span> - if a potentially hazardous situation for one or more given vehicles is detected, transmit corresponding alarm messages to said given vehicle(s).</li></ul></li></ul></p><p><span class=\"paragraph-number\">[0032]   </span>In detail, said radar system includes:</p><p><ul type=\"none\"><li><span class=\"paragraph-number\">[0033]   </span>- a primary radar sensor equipped with an electronically scanned array antenna;</li><br/><li><span class=\"paragraph-number\">[0034]   </span>- an ADS-B receiver based on Automatic Dependent Surveillance—Broadcast technology; and</li><br/><li><span class=\"paragraph-number\">[0035]   </span>- a radar processing unit, which is connected to the primary radar sensor and to the ADS-B receiver to receive data therefrom, and configured to    <br/><ul type=\"none\"><li><span class=\"paragraph-number\">[0036]   </span> - detect and track objects in the predetermined suborbital region on the basis of the data received from said primary radar sensor and from said ADS-B receiver,</li><br/><li><span class=\"paragraph-number\">[0037]   </span> - generate tracking data related to said detected and tracked objects, and</li><br/><li><span class=\"paragraph-number\">[0038]   </span> - supply the suborbital space traffic monitoring system with said tracking data.</li></ul></li></ul></p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0039]   </span>For a better understanding of the present invention, some preferred embodiments, provided by way of non-limitative example, will now be described with reference to the accompanying drawings (not to scale), in which:</p><p><span class=\"paragraph-number\">[0040]   </span><a href=\"#DRAWINGS\">FIG. 1</a> schematically shows an example of HOTOL suborbital space flight;</p><p><span class=\"paragraph-number\">[0041]   </span><a href=\"#DRAWINGS\">FIG. 2</a> schematically shows a suborbital space traffic control system according to a preferred embodiment of the present invention;</p><p><span class=\"paragraph-number\">[0042]   </span><a href=\"#DRAWINGS\">FIG. 3</a> shows a radar system of the suborbital space traffic control system of <a href=\"#DRAWINGS\">FIG. 2</a> in greater detail;</p><p><span class=\"paragraph-number\">[0043]   </span><a href=\"#DRAWINGS\">FIG. 4</a> schematically shows the installation of the suborbital space traffic control system of <a href=\"#DRAWINGS\">FIG. 2</a> at a spaceport; and</p><p><span class=\"paragraph-number\">[0044]   </span><a href=\"#DRAWINGS\">FIG. 5</a> schematically shows an example of architecture of a suborbital space traffic monitoring system of the suborbital space traffic control system of <a href=\"#DRAWINGS\">FIG. 2</a>.</p><br/><p><heading><b><u>TECHNICAL FIELD OF INVENTION</u></b></heading></p><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates, in general, to a system for monitoring a predetermined suborbital region conveniently comprised between approximately 20/22 km and approximately 120/150 km from the earth's surface (preferably, between flight level (FL) 650 and approximately 150 km from the earth's surface) and, in particular, to a system for monitoring objects in said suborbital region and to detect potentially hazardous situations for said objects (e.g. situations of potential collision between said objects) . More specifically, the present invention concerns a suborbital space traffic control system.</p><p><heading><b><u>STATE OF THE ART</u></b></heading></p><p><span class=\"paragraph-number\">[0002]   </span>As is known, a suborbital space flight (also simply referred to as a suborbital flight) is a space flight where the space vehicle (e.g. a spaceplane) reaches space with a trajectory that intersects the atmosphere (or, more in general, the surface of the gravitational body from which it left), without completing a complete orbital revolution.</p><p><span class=\"paragraph-number\">[0003]   </span>Currently, experimental activities in HOTOL (HOrizontal Take-Off and Landing) suborbital flights are in progress, for example, from Spaceport America located in New Mexico in the USA (while in Italy, the definition of the relevant regulations is underway in order to be able to conduct the first experimental suborbital flights).</p><p><span class=\"paragraph-number\">[0004]   </span>With regard to this, <figref>Figure 1</figref> shows, very schematically, an example of a HOTOL suborbital flight. In particular, <figref>Figure 1</figref> shows a trajectory (indicated as a whole by 11) followed by a horizontal take-off and landing spaceplane (not shown) that takes off from a spaceport 12, reaches space beyond 100 km from earth (for example, reaching an altitude of approximately 110 km with zero gravity), and then returns to earth, landing at the spaceport 12. In addition, <figref>Figure 1</figref> also shows an example of segregated airspace 13 associated with the spaceport 12 for conducting HOTOL suborbital flights.</p><p><span class=\"paragraph-number\">[0005]   </span>As is known, alternative solutions can be based on the use of two-stage systems, in which a main aircraft that transports a spaceplane takes off and reaches a predetermined altitude (e.g. approximately 15 km). The spaceplane is then released/uncoupled and can thus autonomously reach space beyond the 100 km altitude, and then re-enter (for example, by gliding) the spaceport of departure.</p><p><span class=\"paragraph-number\">[0006]   </span>In addition, further solutions can be conveniently based on vertical take-off and landing (e.g. based on the use of Vertical Take-off, Vertical Landing (VTVL) rockets).</p><p><span class=\"paragraph-number\">[0007]   </span>Looking ahead, suborbital flights can have numerous applications. For example, neglecting the initial application focused on \"space tourism\" with take-off and landing at the same spaceport, a quite interesting application concerns the possibility of taking off from one spaceport A and then landing at a spaceport B, with incredible potentialities, such as a drastic reduction of traditional flight times (for example, a flight from Rome to New York of this type might last around one hour).</p><p><span class=\"paragraph-number\">[0008]   </span>In addition, a further application relates to the manufacture of low-cost launch vehicles for microsatellites.</p><p><span class=\"paragraph-number\">[0009]   </span>On the other hand, the suborbital flight sector could also be advantageously exploited for:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> scientific experiments (e.g. in life sciences in microgravity, physical sciences in microgravity, aero-medical sciences, health physics, Earth sciences, etc.); and</li><br/><li> test and/or training activities (for example, for testing devices intended for space use and/or for training astronauts).</li></ul></p><p><span class=\"paragraph-number\">[0010]   </span>Unfortunately, as can be easily guessed, the introduction of suborbital space flight could give rise to many risks in terms of safety, both for the actual suborbital flights and for traditional air traffic and the population (for example, in the event of accidents and/or collisions). With regard to this, it is important to note that no systems currently exist that allow limiting these risks, nor authorities/agencies delegated to controlling suborbital flights. In fact, until now test missions have always been autonomously managed and controlled by the companies responsible for these missions, without control by third-party agencies/systems. For the future, an external control for this type of flight will certainly be necessary, as well as coordination between the various operators working in this sector (and also with the traditional air traffic operators).</p><p><span class=\"paragraph-number\">[0011]   </span>On the other hand, it should be remembered that nowadays space debris represents a serious safety risk for traditional plane flights, for the ground infrastructures and for the population, while in the near future it could also represent a risk for suborbital space flights.</p><p><span class=\"paragraph-number\">[0012]   </span>Various solutions have thus been proposed in recent years for the detection, tracking and monitoring of this debris. For example, solutions of this type are set forth in:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> <patcit dnum=\"US9586704B2\">US9586704B2</patcit>, which describes a system for modelling and simulating the propagation of space debris in order to predict potential collisions between space objects;</li><br/><li> <patcit dnum=\"CN106507959B\">CN106507959B</patcit>, which describes a two-dimensional array ground radar system for the detection of space debris;</li></ul></p><p><ul compact=\"compact\" list-style=\"bullet\"><li> <patcit dnum=\"CN107529385B\">CN107529385B</patcit>, which describes another radar solution for the detection of space debris and for the generation of early warnings;</li><br/><li> <patcit dnum=\"CN102042820A\">CN102042820A</patcit>, which describes a system for the detection of small pieces of space debris based on spectroscopy; and</li><br/><li> <patcit dnum=\"CN108226888A\">CN108226888A</patcit>, which describes a method for the detection of multiple space targets (e.g. space debris) based on synthetic aperture imaging.</li></ul></p><p><span class=\"paragraph-number\">[0013]   </span>Additionally, <nplcit npl-type=\"b\">Pengfei Duan's paper entitled \"ADS-B feasibility study for commercial space flight operations\", Digital Avionics Systems Conference (DASC), 2010 IEEE/AIAA 29th, IEEE, Piscataway, NJ, USA, 3 October 2010, pages 3.A.1-1 - 3.A.1-11</nplcit>, concerns a feasibility study on the use of ADS-B to aid the integration of commercial space flight operations with conventional aviation operations, in the framework of surveillance services of the future suborbital commercial space vehicles, accommodating commercial space vehicles and conventional aircraft under the same air traffic system by using ADS-B. In particular, this paper suggests that Air Traffic Management (ATM) system should be updated to a Space and Air Traffic Management (SATM) system such that to coordinate space vehicles with aircraft, wherein tracking data and other information from space vehicles and aircraft can be collected to support the SATM system, which includes a Decision Support Tool (DST) designed to assist air traffic controllers in managing airspace allocations, being able to predict potentially hazardous situations based on imported data from space vehicles and environmental conditions. More specifically, this paper teaches that falling debris caused by the break-up of a space vehicle located above Flight Level (FL) 600 could cause catastrophic accident to cruising aircraft below. The DST can, hence, help aircraft to change their trajectories to avoid a potential risky area.</p><p><span class=\"paragraph-number\">[0014]   </span>Moreover, both the paper of <nplcit npl-type=\"s\">Riahi Manesh Mohsen et al. entitled \"Analysis of vulnerabilities, attacks, countermeasures and overall risk of the Automatic Dependent Surveillance-Broadcast (ADS-B) system\" (International Journal on Critical Infrastructure Protection, vol. 19, 31 October 2017, pages 16-31</nplcit>) and the paper of <nplcit npl-type=\"b\">Dastner Kaeye et al. entitled \"Classification of Military Aircraft in Real-time Radar Systems based on Supervised Machine Learning with Labelled ADS-B Data\" (2018 Sensor Data Fusion: Trends, Solutions, Applications (SDF), IEEE, 9 October 2018, pages 1-6</nplcit>) disclose the use of machine-learning techniques, respectively for error/threat/attack/inconsistency detection with respect to data fusion of radar and ADS-B signals and for identifying/classifying military aircraft.</p><p><span class=\"paragraph-number\">[0015]   </span>Finally, <patcit dnum=\"US2018246205A1\">US 2018/246205 A1</patcit> discloses a radar system with weather and object detection capabilities, which comprises a phased-array radar device.</p><p><heading><b><u>OBJECT AND SUMMARY OF THE INVENTION</u></b></heading></p><p><span class=\"paragraph-number\">[0016]   </span>In light of what has previously been explained, the Applicant has felt the need to carry out in-depth research in order to develop an innovative system that would enable monitoring and controlling suborbital space flights in an extremely reliable manner by reducing the associated risks, in this way arriving at the present invention.</p><p><span class=\"paragraph-number\">[0017]   </span>Thus, the object of the present invention is to provide a system able to monitor and control suborbital space traffic in an extremely reliable manner, thereby reducing the associated risks.</p><p><span class=\"paragraph-number\">[0018]   </span>This and other objects are achieved by the present invention in so far as it relates to a suborbital space traffic control system, as defined in the appended claims.</p><p><heading><b><u>BRIEF DESCRIPTION OF THE DRAWINGS</u></b></heading></p><p><span class=\"paragraph-number\">[0019]   </span>For a better understanding of the present invention, some preferred embodiments, provided by way of non-limitative example, will now be described with reference to the accompanying drawings (not to scale), in which:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> <figref>Figure 1</figref> schematically shows an example of HOTOL suborbital space flight;</li><br/><li> <figref>Figure 2</figref> schematically shows a suborbital space traffic control system according to a preferred embodiment of the present invention;</li><br/><li> <figref>Figure 3</figref> shows a radar system of the suborbital space traffic control system of <figref>Figure 2</figref> in greater detail;</li><br/><li> <figref>Figure 4</figref> schematically shows the installation of the suborbital space traffic control system of <figref>Figure 2</figref> at a spaceport; and</li><br/><li> <figref>Figure 5</figref> schematically shows an example of architecture of a suborbital space traffic monitoring system of the suborbital space traffic control system of <figref>Figure 2</figref>.</li></ul></p><p><heading><u>DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS OF THE INVENTION</u></heading></p><p><span class=\"paragraph-number\">[0020]   </span><figref>Figure 2</figref> schematically shows a suborbital space traffic control system (indicated as a whole by 20) according to a preferred (but absolutely non-limitative and non-binding) embodiment of the present invention. In particular, <figref>Figure 2</figref> shows (by means of a functional block diagram) a high-level architecture of the Suborbital Space Traffic Control System (SSTCS) 20.</p><p><span class=\"paragraph-number\">[0021]   </span>In detail, said SSTCS 20 includes:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> a radar system 21 configured to<ul compact=\"compact\" list-style=\"dash\"><li>monitor a predetermined suborbital region 30 (preferably, said predetermined suborbital region 30 is comprised between a first predetermined altitude of approximately 20/22 km and a second predetermined altitude of approximately 120/150 km from the earth's surface; more preferably, said predetermined suborbital region 30 is comprised between the flight level (FL) 650 and approximately 150 km from the earth's surface), and</li><br/><li> detect and track objects present (e.g. transiting) in said predetermined suborbital region 30, wherein said objects include vehicles 41 (e.g. spaceplanes, rockets, launch vehicles, aerostats, etc.) and space debris 42;</li></ul></li><li> a Suborbital Space Traffic Monitoring System (SSTMS) 22 configured to<ul compact=\"compact\" list-style=\"dash\"><li>receive, from the radar system 21, tracking data related to the objects detected and tracked by said radar system 21,</li><br/><li> monitor, based on the tracking data, trajectories of the objects in the predetermined suborbital region 30 by using one or more predetermined machine-learning techniques, preferably one or more predetermined deep-learning techniques, to detect potentially hazardous situations for the vehicles 41 in said predetermined suborbital region 30 (e.g. potential collision situations) and,</li><br/><li> if said SSTMS 22 detects a potentially hazardous situation for one or more given vehicles 41, transmit corresponding alarm messages to said given vehicle(s) 41; and</li></ul></li><li> a communications infrastructure 23 configured to allow said SSTMS 22 to carry out<ul compact=\"compact\" list-style=\"dash\"><li>ground-air and air-ground communications 51 with the vehicles 41 in said predetermined suborbital region 30 and</li><br/><li> ground-ground communications 52 with systems for Air Traffic Control (ATC) 61 and/or other systems (e.g. mission control systems 62 for suborbital space flights, air/space defence systems 63, etc.).</li></ul></li></ul></p><p><span class=\"paragraph-number\">[0022]   </span>Conveniently, said SSTMS 22 is configured to monitor the trajectories of the objects in the predetermined suborbital region 30 not only on the basis of the tracking data provided by the radar system 21, but also on the basis of data received from external systems, such as satellite tracking systems and/or anti-ballistic missile radar systems.</p><p><span class=\"paragraph-number\">[0023]   </span><figref>Figure 3</figref> shows the radar system 21 in greater detail, the system including:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> at least one primary radar sensor 211 equipped with an electronically scanned array antenna;</li><br/><li> at least one receiver based on Automatic Dependent Surveillance - Broadcast (ADS-B) technology 212 (hereinafter referred to as the \"ADS-B receiver\" for brevity); and</li><br/><li> a radar processing unit 213, which is connected to the primary radar sensor 211 and to the ADS-B receiver 212 to receive respective data therefrom, and is configured to<ul compact=\"compact\" list-style=\"dash\"><li>detect and track the objects in the predetermined suborbital region 30 on the basis of the data received from said primary radar sensor 211 and said ADS-B receiver 212,</li><br/><li> generate corresponding tracking data related to said detected and tracked objects, and</li><br/><li> supply said tracking data to the SSTMS 22.</li></ul></li></ul></p><p><span class=\"paragraph-number\">[0024]   </span>Preferably, said SSTMS 22 is configured to communicate with the vehicles 41 in the predetermined suborbital region 30 (for example, to transmit data and/or information to the latter - e.g. alarm messages) by means of the primary radar sensor 211 (conveniently, by using a technology based on/derived from LDACS (L-band Digital Aeronautical Communication System)). In this way, the primary radar sensor 211 provides the target detection and tracking functionality typical of radar, and also a two-way communications functionality with the vehicles 41 in the predetermined suborbital region 30.</p><p><span class=\"paragraph-number\">[0025]   </span>Conveniently, the ADS-B receiver 212 is configured to receive ADS-B signals directly from the vehicles 41 in the predetermined suborbital region 30 and/or via one or more satellites 71. if said SSTMS 22 detects, on the basis of the monitored trajectories, a potential collision situation between two or more given vehicles 41 in the predetermined suborbital region 30 or between at least one piece of space debris 42 and at least one given vehicle 41 in the predetermined suborbital region 30, it is configured to transmit a corresponding alarm message to the given vehicle(s) 41 (and, conveniently, also to one or more ATC systems 61 and/or one or more mission control systems 62 and/or one or more air/space defence systems 63, etc.).</p><p><span class=\"paragraph-number\">[0026]   </span>if said SSTMS 22 detects a collision between two or more given vehicles 41 in the predetermined suborbital region 30 or between at least one piece of space debris 42 and at least one given vehicle 41 in the predetermined suborbital region 30, or if it detects an explosion of a given vehicle 41 in the predetermined suborbital region 30, it is configured to</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> operate the primary radar sensor 211 to detect and track debris produced by said collision/explosion and</li><br/><li> monitor trajectories of said debris produced by said collision/explosion using the predetermined machine-learning technique(s) (preferably, the predetermined deep-learning technique(s)) to detect hazardous situations caused by said debris in the predetermined suborbital region 30 and/or in one or more underlying airspaces and/or on the earth's surface.</li></ul></p><p><span class=\"paragraph-number\">[0027]   </span>Conveniently, said SSTCS 20 is installed at a spaceport. With regard to this, <figref>Figure 4</figref> schematically shows a spaceport 81 equipped with said SSTCS 20 for monitoring the predetermined suborbital region 30. In addition, <figref>Figure 4</figref> also shows a segregated airspace region 91 that extends between the earth's surface (in particular, between said spaceport 81) and the predetermined suborbital region 30. Only vehicles 41 that take off from the spaceport 81 to reach the predetermined suborbital region 30 and vice versa may transit in said segregated airspace region 91, while this is prohibited for traditional air traffic. Preferably, said SSTMS 22 is also configured to:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> operate the primary radar sensor 211 for tracking aircrafts in airspaces 92 adjacent to the segregated airspace region 91;</li><br/><li> monitor trajectories of said aircrafts using the predetermined machine-learning technique(s) (preferably, the predetermined deep-learning technique(s)) to detect potential collision situations between the vehicles 41 in the segregated airspace region 91 and aircrafts in the airspaces 92 adjacent to the segregated airspace region 91; and,</li></ul></p><p><ul compact=\"compact\" list-style=\"bullet\"><li> if it detects a potential collision situation between a vehicle 41 in the segregated airspace region 91 and an aircraft in an airspace 92 adjacent to the segregated airspace region 91, transmit a corresponding alarm message to said vehicle 41 in the segregated airspace region 91 and to at least one ATC system 61 that controls said aircraft in said airspace 92 adjacent to the segregated airspace region 91.</li></ul></p><p><span class=\"paragraph-number\">[0028]   </span>In other words, the primary radar sensor 211 enables said SSTMS 22 to simultaneously carry out the control of the suborbital space traffic and the tracking of traditional aircraft flights with a critical trajectory. In fact, the use of an electronically scanned array antenna, with electronically controlled narrow and independent beams, allows dedicating some of these beams to the surveillance of traditional airspace, while the other beams are used for tracking/monitoring suborbital flights.</p><p><span class=\"paragraph-number\">[0029]   </span>Conveniently, the vehicles 41 in the predetermined suborbital region 30 can comprise:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> spaceplanes, rockets or more in general, vehicles for HOTOL and/or VTVL suborbital flights;</li><br/><li> drones;</li><br/><li> aerostats, for example dirigibles, airships and/or aerostatic balloons;</li><br/><li> supersonic aircrafts;</li><br/><li> launch vehicles;</li><br/><li> re-entry vehicles and/or satellites;</li><br/><li> etc.</li></ul></p><p><span class=\"paragraph-number\">[0030]   </span>In the light of what has previously been explained, the present invention originates from the Applicant's innovative idea of exploiting different technologies in a synergetic manner (for example, one or more sensors derived from the line of more advanced multi-function radars and integrated in an ad hoc control centre) to produce an extremely reliable and safe system for the control of suborbital space flights (or, more in general, for the monitoring of suborbital vehicles and space debris in the region comprised between approximately 20/22 km (or rather FL 650) and approximately 120/150 km from the earth's surface), as today there are still neither control systems nor controlling authorities/agencies.</p><p><span class=\"paragraph-number\">[0031]   </span>In other words, the field of application of the present invention can be conveniently considered as the joining and integration of space traffic and air traffic control, in that area that still today is neither regulated nor monitored.</p><p><span class=\"paragraph-number\">[0032]   </span>For a better understanding of the present invention, several preferred characteristics (even if absolutely non-limitative) of said SSTCS 20 will be described in detail below.</p><p><heading><b><u>1. System architecture</u></b></heading></p><p><span class=\"paragraph-number\">[0033]   </span>As previously described, in order to control suborbital space traffic, said SSTCS 20 is equipped with:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> an electronically scanned primary radar sensor 211 that also enables two-way communications based on/derived from LDACS;</li><br/><li> an additional surveillance subsystem of a secondary cooperative type, in the specific instance an ADS-B receiver 212 (configured to also receive ADS-B signals from satellites 71);</li><br/><li> an SSTMS 22, conveniently of ATC/ATM (Air Traffic Management) origin, to enable a \"seamless\" transition between the traditional ATC systems 61 and the system according to the present invention; and</li><br/><li> a communications infrastructure 23 for ground-air and air-ground communications 51 and ground-ground communications 52 capable of conveniently exploiting current technologies for aeronautical communications (e.g. Very high frequency Data Link Mode 2 - VDL2, Aeronautical Mobile Airport Communication System - AeroMACS, LDACS, etc.).</li></ul></p><p><span class=\"paragraph-number\">[0034]   </span>However, the following can also be conveniently provided in said SSTCS 20:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> payload management via a SATCOM connection (i.e. satellite communications) and its developments; and</li><br/><li> integration of data supplied by other systems external to said SSTCS 20, such as satellite tracking systems and/or anti-ballistic missile radar systems.</li></ul></p><p><span class=\"paragraph-number\">[0035]   </span>The aforementioned characteristics are conveniently implemented in a system architecture in which:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> said SSTMS 22 can be conveniently implemented in a control centre capable of providing the scenario and payload management on dedicated stations; and</li><br/><li> the communications infrastructure 23 is perfectly integrated into classic ATC communications.</li></ul></p><p><span class=\"paragraph-number\">[0036]   </span>Thanks to the present invention, the mission control systems 62 for suborbital space flights and the air/space defence systems 63 can conveniently receive Control Working Position (CWP) data similar to that of the controllers of said SSTCS 20 - even if the stations of the mission control systems 62 and air/space defence systems 63 are simply watcher stations, not having the right to issue specific orders on the system (unless security override is given by the authorities - e.g. military authorities).</p><p><span class=\"paragraph-number\">[0037]   </span>Obviously, in the event of onboard problems detected by its own telemetry systems, a mission control system 62 could inform both the operator of the SSTCS 20 who controls the suborbital flight and the corresponding air/space defence system 63. Conveniently, a CWP could also be provided in the cockpit of suborbital vehicles with the possibility of integrating the tracking data in the onboard Flight Management System (FMS). All of this allows a complete view of the reference scenario and of any risks related to debris and emergency situations that might jeopardise the mission.</p><p><span class=\"paragraph-number\">[0038]   </span>Furthermore, in time, all of this would allow complete integration of the new SSTCS 20, reducing the ATC segregations to a minimum.</p><p><heading><u>2. Radar system</u></heading></p><p><span class=\"paragraph-number\">[0039]   </span>Regarding the radar system 21, it is important to note that:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> the primary radar sensor 211 can be conveniently designed with low-cost commercial choices (without needing ECCM or EPM parts - namely Electronic Counter-Countermeasures / Electronic Protective Measures), but with similar functionality, in terms of tracking performance, to those intended for detecting satellites and tracking tactical ballistic missiles (TBMs); however, said primary radar sensor 211 could also be conveniently used as a transmitter of a bistatic system (for example, using the radio telescopes of the Italian National Institute of Astrophysics (INAF) as receivers, in a context of collaboration, integration and data merging with similar radars of the Italian Air Force's national network);</li><br/><li> as previously explained, the primary radar sensor 211 is preferably also used for carrying out ground-air and air-ground communications based on/derived from LDACS;</li><br/><li> the ADS-B receiver 212 conveniently has an omnidirectional antenna with a range of up to 463 km and with the ability to also receive ADS-B signals from satellites 71. Conveniently, the radar system 21 can provide the tracking data to the SSTMS 22 in the form of ASTERIX (ATC international standard for radar data exchange) format tracks.</li></ul></p><p><span class=\"paragraph-number\">[0040]   </span>As previously explained, once received by said SSTMS 22, the tracking data can also be conveniently combined by the latter with further tracking data received from satellite tracking systems and/or anti-ballistic missile radar systems.</p><p><heading><b><u>3. Suborbital space traffic monitoring system (SSTMS)</u></b></heading></p><p><span class=\"paragraph-number\">[0041]   </span>The suborbital space traffic monitoring system (SSTMS) 22 represents an innovative control centre for suborbital space flights and for monitoring space debris and, conveniently not based on the enhancement of typical functions of air traffic control (ATC) and also able to integrate any data provided by external systems (e.g. satellite tracking systems and/or anti-ballistic missile radar systems).</p><p><span class=\"paragraph-number\">[0042]   </span>With regard to this, <figref>Figure 5</figref> schematically shows an example of an architecture utilizable for said SSTMS 22 according to a preferred (but absolutely non-limitative and non-binding) embodiment of the present invention. In particular, <figref>Figure 5</figref> shows (by means of a functional block diagram) a high-level architecture of said SSTMS 22.</p><p><span class=\"paragraph-number\">[0043]   </span>In detail, as shown in <figref>Figure 5</figref>, said SSTMS 22 is conveniently designed to implement the following functions derived from traditional ATC:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> Space Multi Tracking Fusion (SMTF) 221, in which the tracks of the suborbital flights provided by the radar system 21 are conveniently enhanced with any other cooperative data originating from satellite control, exploiting SATCOM in the Ka and/or L bands with specific terminals on board the suborbital vehicle; in this way, there is the possibility to extract and/or manage any payload related to the mission;</li><br/><li> Space Flight Data Processor (SFDP) 222 - at altitudes below FL 650, departing flights from one or more spaceports can be controlled substantially like standard flights under Instrument Flight Rules (IFR), with minimal changes in the conventional ATC systems 61 and with opportune management of the segregated areas, i.e. Flexible Use of Airspace (FUA); however, once the altitude limit is reached, the tracks provided by the radar system 21 enable having a trajectory correlated with the specific flight plan of the suborbital flight;</li><br/><li> Space Conflict Alert Detection and Resolution (SCADR) 223 - also in this case, at altitudes below FL 650, the conflicts between suborbital flights and other IFR flights can be managed as normally happens in ATC with typical functions (i.e. Short-Term Conflict Alert - STCA, Medium-Term Conflict Detection - MTCD, etc.); however, above FL 650, the SCADR function 223 is activated, mainly for analysing the trajectories of space debris detected by the radar system 21 with respect to the planned trajectories and the aforesaid suborbital flights; furthermore, through dedicated algorithms, determined in the planning stage, the aborting of a suborbital space mission can also be decided; in addition, in the event of an explosion of a suborbital space vehicle with the consequent production of debris, there is the possibility of dynamically and flexibly managing the emergency in real-time in the underlying ATC area by configuring ad hoc segregated areas based on the positions and trajectories of this new debris detected and tracked by the radar system 21.</li></ul></p><p><span class=\"paragraph-number\">[0044]   </span>Preferably, the SCADR function 223 includes a comparison between the trajectories of the space debris and the trajectories of the suborbital vehicles, where the trajectories of the space debris and/or the suborbital vehicles are conveniently computed through one or more predetermined deep-learning techniques on the basis of historical track data (e.g. big data) archived in a strategic phase. This enables having greater accuracy in computing the trajectories and avoiding potential collisions.</p><p><span class=\"paragraph-number\">[0045]   </span>Conveniently, there is an alignment between said SSTMS 22 and the ATC systems 61 that allows managing the suborbital regions as if they were sectors inside the Flight Information Regions (FIRs), even if they are actually regions at higher altitudes with boundaries defined by the suborbital space missions.</p><p><span class=\"paragraph-number\">[0046]   </span>Conveniently, said SSTMS 22 is able to exchange data with other control centres, airports and stakeholders via System Wide Information Management (SWIM) / Aeronautical Message Handling System (AMHS).</p><p><span class=\"paragraph-number\">[0047]   </span>Furthermore, as previously explained, by exploiting a proprietary connection based on/derived from LDACS (which the applicant has called \"ENH LDACS\"), said SSTMS 22 is able to distribute and integrate a CWP of the suborbital space type, with all its alerts, directly in the cockpit of suborbital vehicles. In this way, a pilot has a real-time representation of the trajectories of their suborbital vehicle and of any nearby space debris, as well as an indication of any alarms (for example, related to potential risks of collision) and/or suggested trajectories for the suborbital vehicle. All of this enables real-time coordination, with optimized emergency management, between the SSTCS 20, the mission control system 62 and the air/space defence system 63.</p><p><span class=\"paragraph-number\">[0048]   </span>Conveniently, as previously explained, it is also possible to integrate the tracking data processed by the SSTMS 22 inside the onboard Flight Management System (FMS). This would enable, for example, an automatic change of course of the suborbital vehicle based on what is suggested by the SCADR function 223.</p><p><heading><b><u>4. Integration between SSTMS and ATC</u></b></heading></p><p><span class=\"paragraph-number\">[0049]   </span>As previously explained, the SSTMS 22 is conveniently designed so as enable an ATC scenario at higher flight levels integrated with the reference FIRs.</p><p><span class=\"paragraph-number\">[0050]   </span>This allows complete interoperability and integration between current ATC systems 61 and the new SSTCS 20, whereby:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> in the new SSTCS 20 (in particular, in said SSTMS 22) it is possible to conveniently have flight plans that are completely aligned with those of the existing Area Control Centres (ACCs) and approach control (APP);</li><br/><li> it is possible to conveniently obtain \"silent\" transfer and coordination of control between the controllers of the ATC systems 61 and those of the SSTCS 20;</li><br/><li> the CWP can be conveniently configured to display suborbital objects (i.e. vehicles 41 + space debris 42) and objects at lower altitudes (i.e. aircrafts) in the same radar image and to provide a single operating position also for the ATC control;</li><br/><li> the SSTCS 20 can conveniently offer a seamless transition between the presentation of suborbital data and traditional flight data due to an adaptive updating of the track symbols based on the type of sensors that contribute to their readings;</li><br/><li> CWP stations of the suborbital space type could be conveniently configured as additional CWP stations in ATC systems 61 for emergency management;</li><br/><li> the SSTCS 20 (and, in particular, the SSTMS 22) could be conveniently configured as the disaster recovery centre of a corresponding ATC system 61, having<ul compact=\"compact\" list-style=\"dash\"><li>physical separation between the places of installation,</li><br/><li> complete alignment of tracks and flight plans between the two systems, and</li><br/><li> CWP stations of the suborbital space type capable of recovering the AIR sectorization of the ATC centre.</li></ul></li></ul></p><p><heading><b><u>5. Communications infrastructure</u></b></heading></p><p><span class=\"paragraph-number\">[0051]   </span>As previously explained, the SSTCS 20 preferably comprises also the integration of an ad hoc communications infrastructure 23 inserted in the classic ATC communications scenario (e.g. VDL2) and its evolution (i.e. LDACS).</p><p><span class=\"paragraph-number\">[0052]   </span>This thus conveniently gives a legitimate LDACS system perfectly integrated in the concept of Future Communication Infrastructure (FCI) contemplated in the ICAO (International Civil Aviation Organization) roadmaps, without of course leaving out voice-based communications with classic VHF (Very High Frequency) radio, and also satellite communications between the pilot, ANSP (Air Navigation Service Provider) and mission control centre. Everything is also conveniently integrated in the ground-ground communications 52 inside the spaceport 81, which could be managed through AeroMACS.</p><p><span class=\"paragraph-number\">[0053]   </span>Furthermore, as previously explained, the electronically scanned array antenna (preferably planar) of the primary radar sensor 211 is conveniently designed to also support LDACS tracking and enable reaching altitudes up to 100-110 Km by latching into the primary radar tracking. Therefore, there is effectively an electronically scanned array antenna in the L Band both for surveillance and for high-altitude ground-air and air-ground communications 51. This allows having suborbital spatial CWP information in the cockpit of suborbital vehicles even at altitudes above 100 km.</p><p><heading><b><u>6. Technical advantages of the invention and final observations</u></b></heading></p><p><span class=\"paragraph-number\">[0054]   </span>From the foregoing description, the innovative characteristics and technical advantages of the present invention are immediately evident to an expert in the field.</p><p><span class=\"paragraph-number\">[0055]   </span>In this respect, it is first of all important to underline that the present invention enables making a completely autonomous system in terms of surveillance, tracking, control and communications, which is easily integrable with all the current ATC systems and airport systems installed around the world, and which is able to manage emergencies arising from the presence of space debris that might jeopardize suborbital spatial missions, as well as the presence of any debris produced by collisions and/or explosions.</p><p><span class=\"paragraph-number\">[0056]   </span>In particular, the suborbital space traffic control system according to the present invention ensures an adequate level of safety both for suborbital flights and for the people and structures on the ground, as well as for all the other users of the underlying airspace and sea, even in the event of collisions or explosions of suborbital vehicles.</p><p><span class=\"paragraph-number\">[0057]   </span>Regarding the future scenario with journeys from one spaceport A to another spaceport B, the present invention could be advantageously installed not just in (a few) specific spaceports, but in all the main aviation hubs.</p><p><span class=\"paragraph-number\">[0058]   </span>In addition, it is worth noting that the present invention also allows gaining the following advantages:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> unlike the currently known solutions for monitoring space debris, which only contemplate the simulation of the trajectories of this debris (in order to predict the descent trajectory and possible area of the earth's surface affected by this falling debris), the present invention instead provides a real-time tracking of the trajectories of the space debris, as well as any debris produced by explosions or collisions, with evident advantages in terms of safety;</li><br/><li> due to the real-time monitoring of space debris (or other objects in the suborbital space region of interest), the present invention enables avoiding the start or re-entry of a suborbital flight in cases where problems related to the presence of debris (or other objects) are detected or, more in general, enables programming suborbital flights with greater precision and safety, reducing the probability of false alarms of possible collision typical of forecasts/planning based on the \"bulletin\" service provided by government agencies in the USA (notoriously affected by significant long-term errors);</li><br/><li> as repeatedly stressed in the foregoing, the present invention enables drastically reducing the risks of missions above FL 650 due to the real-time tracking of debris in the suborbital region of interest, with analysis of the decent trajectories and forecasting of the impact area, so as to alert and empty/evacuate any areas of airspace and/or the earth's surface affected by the falling debris; and</li><br/><li> the present invention represents an integrated solution that not only perfectly responds to the future scenario of suborbital flights, but also enables having a \"seamless\" transition between traditional ATC systems and the suborbital space traffic control system according to the present invention.</li></ul></p><p><span class=\"paragraph-number\">[0059]   </span>Finally, it is important to draw attention to some of the innovative characteristics of the present invention:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> real-time control of suborbital flights and debris and/or objects at altitudes exceeding 20/22 km, i.e. FL 650;</li><br/><li> traditional algorithms strengthened with deep-learning techniques applied to the trajectory analysis;</li><br/><li> earlier and more reliable forecasts of the areas of impact;</li><br/><li> automatic closing of underlying airspace by exploiting the strong integration with traditional ATC systems;</li><br/><li> CWP (Control Working Position) of the suborbital space type installed in the cockpit of the suborbital vehicles for viewing a complete scenario in terms of position of the vehicle, surrounding traffic and any nearby debris, updated in real-time and transmitted from the ground system to the vehicle by exploiting one of the available bands of the primary radar sensor when it \"illuminates\" the vehicle (i.e. \"ENH LDACS\"); and</li><br/><li> automatic evaluation of the optimal course to follow based on the alarms signalled by the SSTMS, this also updated and transmitted in real-time on a service band of the primary radar sensor (i.e. \"ENH LDACS\").</li></ul></p>",
            "CLMS": "(EP3887854)<br/><p>1. A suborbital space traffic control system (20), comprising:<br/> • a radar system (21) configured to<br/>  - monitor a predetermined suborbital region (30) comprised between a first predetermined altitude of 20/22 km and a second predetermined altitude of 120/150 km from earth's surface, and<br/>  - detect and track vehicles (41) and space debris (42) in said predetermined suborbital region (30);<br/> • a suborbital space traffic monitoring system (22); and<br/> • a communications infrastructure (23) configured to allow the suborbital space traffic monitoring system (22) to carry out<br/>  - ground-air and air-ground communications (51) with the vehicles (41) in the predetermined suborbital region (30), and<br/>  - ground-ground communications (52) with other ground systems (61, 62, 63);<br/>wherein the radar system (21) includes:<br/> • a primary radar sensor (211) equipped with an electronically scanned array antenna;<br/> • an ADS-B receiver (212) based on Automatic Dependent Surveillance - Broadcast technology; and<br/> • a radar processing unit (213), which is connected to the primary radar sensor (211) and to the ADS-B receiver (212) to receive data therefrom, and is configured to<br/>  - detect and track the vehicles (41) and the space debris (42) in the predetermined suborbital region (30) on the basis of the data received from said primary radar sensor (211) and from said ADS-B receiver (212),<br/>  - generate tracking data related to said detected and tracked vehicles (41) and space debris (42), and<br/>  - provide the suborbital space traffic monitoring system (22) with said tracking data;<br/>wherein said suborbital space traffic monitoring system (22) is configured to:<br/> • monitor, on the basis of the tracking data received from the radar system (21), trajectories of the vehicles (41) and of the space debris (42) in the predetermined suborbital region (30) by using one or more predetermined machine-learning techniques to detect<br/>  - one or more potential collision situations between/among two or more of the vehicles (41) in the predetermined suborbital region (30),<br/>  - one or more potential collision situations between/among one or more pieces of the space debris (42) and one or more of the vehicles (41) in the predetermined suborbital region (30), and<br/>  - one or more explosions of one or more vehicles (41) in the predetermined suborbital region (30);<br/> • if it detects, on the basis of the monitored trajectories, a potential collision situation between/among two or more first vehicles (41) in the predetermined suborbital region (30), transmit corresponding alarm messages to said first vehicles (41) ;<br/> • if it detects, on the basis of the monitored trajectories, a potential collision situation between/among one or more pieces of the space debris (42) and one or more second vehicles (41) in the predetermined suborbital region (30), transmit one or more corresponding alarm messages to said second vehicle(s) (41) ;<br/> • if it detects a first collision between/among two or more third vehicles (41) in the predetermined suborbital region (30),<br/>  - operate the primary radar sensor (211) to detect and track debris produced by said first collision, and<br/>  - monitor trajectories of said debris produced by said first collision by using the predetermined machine-learning technique(s);<br/> • if it detects a second collision between/among one or more pieces of the space debris (42) and one or more fourth vehicles (41) in the predetermined suborbital region (30),<br/>  - operate the primary radar sensor (211) to detect and track debris produced by said second collision, and<br/>  - monitor trajectories of said debris produced by said second collision by using the predetermined machine-learning technique(s); and,<br/> • if it detects an explosion of a fifth vehicle (41) in the predetermined suborbital region (30),<br/>  - operate the primary radar sensor (211) to detect and track debris produced by said explosion, and<br/>  - monitor trajectories of said debris produced by said explosion by using the predetermined machine-learning technique(s).</p><p>2. The suborbital space traffic control system of claim 1, wherein the predetermined suborbital region (30) is comprised between flight level (FL) 650 and 150 km from earth's surface.</p><p>3. The suborbital space traffic control system according to claim 1 or 2, wherein said predetermined machine-learning technique(s) is/are predetermined deep-learning technique(s).</p><p>4. The suborbital space traffic control system according to any preceding claim, wherein the suborbital space traffic monitoring system (22) is configured to monitor the trajectories of the vehicles (41) and of the space debris (42) in the predetermined suborbital region (30) also on the basis of data received from one or more satellite tracking systems.</p><p>5. The suborbital space traffic control system according to any preceding claim, wherein the suborbital space traffic monitoring system (22) is configured to monitor the trajectories of the vehicles (41) and of the space debris (42) in the predetermined suborbital region (30) also on the basis of data received from one or more anti-ballistic missile radar systems.</p><p>6. The suborbital space traffic control system according to any preceding claim, wherein the suborbital space traffic monitoring system (22) is configured to communicate with the vehicles (41) in the predetermined suborbital region (30) through the primary radar sensor (211) by using a technology based on/derived from L-band Digital Aeronautical Communication System technology.</p><p>7. The suborbital space traffic control system according to any preceding claim, wherein the ADS-B receiver (212) is configured to receive ADS-B signals directly from the vehicles (41) in the predetermined suborbital region (30).</p><p>8. The suborbital space traffic control system according to any preceding claim, wherein the ADS-B receiver (212) is configured to receive ADS-B signals via one or more satellites (71) .</p><p>9. The suborbital space traffic control system according to any preceding claim, wherein a segregated airspace region (91) extends between earth's surface and the predetermined suborbital region (30), with only vehicles (41) that are reaching, or that are coming from, said predetermined suborbital region (30) being allowed to pass through said segregated airspace region (91);<br/>wherein the suborbital space traffic monitoring system (22) is configured to:<br/> • operate the primary radar sensor (211) to track aircraft in airspaces (92) adjacent to the segregated airspace region (91) ;<br/> • monitor trajectories of said aircraft by using the predetermined machine-learning technique(s) to detect potential collision situations between the vehicles (41) in the segregated airspace region (91) and the aircraft in the airspaces (92) adjacent to the segregated airspace region (91); and,<br/> • if it detects a potential collision situation between a vehicle (41) in the segregated airspace region (91) and an aircraft in an airspace (92) adjacent to the segregated airspace region (91), transmit a corresponding alarm message to said vehicle (41) in the segregated airspace region (91) and to at least one air traffic control system (61) that controls said aircraft in said airspace (92) adjacent to the segregated airspace region (91).</p>",
            "NPR": "3",
            "APID": "152991241",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64G-001/00<br/>B64G-001/24<br/>B64G-003/00<br/>G01S-013/66<br/>G01S-013/72<br/>G01S-013/88<br/>G01S-013/933<br/>G08G-005/00<br/>G08G-005/04<br/>H04B-007/185",
            "ID": "89087032",
            "AB": "(EP3887854)<br/>The invention concerns a suborbital space traffic control system (20) that comprises: a radar system (21) configured to monitor a predetermined suborbital region (30) and detect and track objects (41, 42) in said predetermined suborbital region (30), wherein said objects include vehicles (41) and space debris (42); and a suborbital space traffic monitoring system (22) configured to: receive, from the radar system (21), tracking data related to the objects (41, 42) detected and tracked by said radar system (21); monitor, on the basis of the tracking data, trajectories of the objects (41, 42) in the predetermined suborbital region (30) using one or more predetermined machine-learning techniques to detect potentially hazardous situations for the vehicles (41) in said predetermined suborbital region (30); and, if it detects a potentially hazardous situation for one or more given vehicles (41), transmit corresponding alarm messages to said given vehicle(s) (41). The radar system (21) includes a primary radar sensor (211) equipped with an electronically scanned array antenna; an ADS-B receiver (212) based on Automatic Dependent Surveillance - Broadcast technology; and a radar processing unit (213), which is connected to the primary radar sensor (211) and to the ADS-B receiver (212) to receive data therefrom.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CZjXXFvKW%252Fz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2019-11-27",
            "PA": "LEONARDO",
            "PAAD": "(EP3887854)<br/>(PUB:EP-3887854B1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/>(PUB:EP-3887854A1-8)NAME=Leonardo S.p.a. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101897133<br/><br/><br/>(US20220036748)<br/>(PUB:US-20220036748A1-2)NAME=LEONARDO S.P.A.  , CITY=Rome , COUNTRY=IT<br/><br/><br/>(WO2020110040)<br/>(PUB:WO-2020/110040A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 Roma , POSTCODE=00195 , COUNTRY=IT<br/>",
            "FAN": "89087032",
            "TI": "Suborbital space traffic control system with radar system and ads-b receiver",
            "TECD": "Control<br/>Measurement<br/>Telecommunications<br/>Transport",
            "EPD": "2020-06-04",
            "ICLM": "(EP3887854)<br/><p>1. A suborbital space traffic control system (20), comprising: * a radar system (21) configured to - monitor a predetermined suborbital region (30) comprised between a first predetermined altitude of 20/22 km and a second predetermined altitude of 120/150 km from earth's surface, and - detect and track vehicles (41) and space debris (42) in said predetermined suborbital region (30); * a suborbital space traffic monitoring system (22); and * a communications infrastructure (23) configured to allow the suborbital space traffic monitoring system (22) to carry out - ground-air and air-ground communications (51) with the vehicles (41) in the predetermined suborbital region (30), and - ground-ground communications (52) with other ground systems (61, 62, 63); wherein the radar system (21) includes: * a primary radar sensor (211) equipped with an electronically scanned array antenna; * an ADS-B receiver (212) based on Automatic Dependent Surveillance - Broadcast technology; and * a radar processing unit (213), which is connected to the primary radar sensor (211) and to the ADS-B receiver (212) to receive data therefrom, and is configured to - detect and track the vehicles (41) and the space debris (42) in the predetermined suborbital region (30) on the basis of the data received from said primary radar sensor (211) and from said ADS-B receiver (212), - generate tracking data related to said detected and tracked vehicles (41) and space debris (42), and - provide the suborbital space traffic monitoring system (22) with said tracking data; wherein said suborbital space traffic monitoring system (22) is configured to: * monitor, on the basis of the tracking data received from the radar system (21), trajectories of the vehicles (41) and of the space debris (42) in the predetermined suborbital region (30) by using one or more predetermined machine-learning techniques to detect - one or more potential collision situations between/among two or more of the vehicles (41) in the predetermined suborbital region (30), - one or more potential collision situations between/among one or more pieces of the space debris (42) and one or more of the vehicles (41) in the predetermined suborbital region (30), and - one or more explosions of one or more vehicles (41) in the predetermined suborbital region (30); * if it detects, on the basis of the monitored trajectories, a potential collision situation between/among two or more first vehicles (41) in the predetermined suborbital region (30), transmit corresponding alarm messages to said first vehicles (41) ; * if it detects, on the basis of the monitored trajectories, a potential collision situation between/among one or more pieces of the space debris (42) and one or more second vehicles (41) in the predetermined suborbital region (30), transmit one or more corresponding alarm messages to said second vehicle(s) (41) ; * if it detects a first collision between/among two or more third vehicles (41) in the predetermined suborbital region (30), - operate the primary radar sensor (211) to detect and track debris produced by said first collision, and - monitor trajectories of said debris produced by said first collision by using the predetermined machine-learning technique(s); * if it detects a second collision between/among one or more pieces of the space debris (42) and one or more fourth vehicles (41) in the predetermined suborbital region (30), - operate the primary radar sensor (211) to detect and track debris produced by said second collision, and - monitor trajectories of said debris produced by said second collision by using the predetermined machine-learning technique(s); and, * if it detects an explosion of a fifth vehicle (41) in the predetermined suborbital region (30), - operate the primary radar sensor (211) to detect and track debris produced by said explosion, and - monitor trajectories of said debris produced by said explosion by using the predetermined machine-learning technique(s).</p>",
            "CTN": "(EP3887854)<br/>US20180246205 81015751 WHO=EXAMINER SELF=N CAT=I<br/>WO201891607 79811166 WHO=EXAMINER SELF=Y CAT=A<br/>WO2018174822 81442472 WHO=EXAMINER SELF=N CAT=A<br/>US9586704 67853468 WHO=APPLICANT SELF=N<br/>CN106507959 none WHO=APPLICANT SELF=N<br/>CN107529385 none WHO=APPLICANT SELF=N<br/>CN102042820 7303596 WHO=APPLICANT SELF=N<br/>CN108226888 80399628 WHO=APPLICANT SELF=N<br/>US20180246205 81015751 WHO=APPLICANT SELF=N<br/><br/>(US20220036748)<br/>US20220159544 100004096 WHO=EXAMINER SELF=N CAT=103<br/>US20210358311 75542790 WHO=EXAMINER SELF=N<br/>US11175142 72132588 WHO=EXAMINER SELF=N<br/>US10605607 72132597 WHO=EXAMINER SELF=N<br/>US10309784 72132583 WHO=EXAMINER SELF=N<br/>US20170069214 75593671 WHO=EXAMINER SELF=N<br/>US20180233054 73246812 WHO=EXAMINER SELF=N<br/>US20030200024 789154 WHO=EXAMINER SELF=N<br/>US20030093187 1644310 WHO=EXAMINER SELF=N<br/>US20050187677 1644310 WHO=EXAMINER SELF=N<br/>US6965816 1644310 WHO=EXAMINER SELF=N<br/>US10228689 66331245 WHO=EXAMINER SELF=N<br/>US10982935 66016608 WHO=EXAMINER SELF=N<br/>US9250043 72130957 WHO=EXAMINER SELF=N<br/>US9207049 19011099 WHO=EXAMINER SELF=N<br/>US8981989 46623425 WHO=EXAMINER SELF=N<br/>US8963765 68717885 WHO=EXAMINER SELF=N<br/>US8288696 43886681 WHO=EXAMINER SELF=N<br/>US20040075605 1700039 WHO=EXAMINER SELF=N<br/>US6995705 1700039 WHO=EXAMINER SELF=N<br/>US9140784 70922281 WHO=EXAMINER SELF=N CAT=103<br/>US9292792 72448079 WHO=EXAMINER SELF=N<br/>US9225070 71858988 WHO=EXAMINER SELF=N<br/>US20210116558 81442472 WHO=EXAMINER SELF=N<br/>US20190355264 86691909 WHO=EXAMINER SELF=N<br/>US20190162841 84654768 WHO=EXAMINER SELF=N<br/>US20180172797 80065561 WHO=EXAMINER SELF=N<br/>US9824593 77839743 WHO=EXAMINER SELF=N<br/>US20160011318 70756829 WHO=EXAMINER SELF=N<br/>US20130050024 44511169 WHO=EXAMINER SELF=N<br/>US20110169684 43910641 WHO=EXAMINER SELF=N<br/>US20070252760 990501 WHO=EXAMINER SELF=N<br/>US20180227041 75021197 WHO=EXAMINER SELF=N CAT=103<br/>US20110015852 1018286 WHO=EXAMINER SELF=N<br/>US20150355324 71712849 WHO=EXAMINER SELF=N<br/>US20180246205 81015751 WHO=EXAMINER SELF=N<br/>US20230217345 100004096 WHO=EXAMINER SELF=N<br/>US20130147652 45410715 WHO=EXAMINER SELF=N<br/>US10725169 81013372 WHO=EXAMINER SELF=N<br/>US8130135 43832345 WHO=EXAMINER SELF=N<br/>US7570214 990501 WHO=EXAMINER SELF=N<br/>US7383124 43577294 WHO=EXAMINER SELF=N<br/>US20180246200 81013372 WHO=EXAMINER SELF=N CAT=103<br/>US20220371755 99044002 WHO=EXAMINER SELF=N<br/>US20150203218 61132359 WHO=EXAMINER SELF=N<br/>US10302759 84758124 WHO=EXAMINER SELF=N<br/>US20180225976 80794149 WHO=EXAMINER SELF=N<br/>US20200118451 88291995 WHO=EXAMINER SELF=N CAT=103<br/>US11037453 88291995 WHO=EXAMINER SELF=N<br/>US20190019423 83031571 WHO=EXAMINER SELF=N<br/>US20190005828 82825088 WHO=EXAMINER SELF=N<br/>US20180196435 80483931 WHO=EXAMINER SELF=N<br/>US20160196754 73488485 WHO=EXAMINER SELF=N<br/>US20200166956 81997126 WHO=EXAMINER SELF=N<br/>US20080111731 4122643 WHO=EXAMINER SELF=N<br/>US20180199357 75372344 WHO=EXAMINER SELF=N<br/>US20190042748 83332302 WHO=EXAMINER SELF=N<br/>US20190213894 83709205 WHO=EXAMINER SELF=N<br/>US20190213891 85169299 WHO=EXAMINER SELF=N<br/>US20160275801 74199375 WHO=EXAMINER SELF=N<br/>US11041950 84196642 WHO=EXAMINER SELF=N<br/>US10692389 87398185 WHO=EXAMINER SELF=N<br/>US20190050136 83373178 WHO=EXAMINER SELF=N<br/>US20180061252 78872091 WHO=EXAMINER SELF=N<br/>US20130306799 44436024 WHO=EXAMINER SELF=N<br/>US20170285158 46198038 WHO=EXAMINER SELF=N<br/>US10650688 88636274 WHO=EXAMINER SELF=N<br/>US20190357077 86692829 WHO=EXAMINER SELF=N<br/>US20050156777 14444963 WHO=EXAMINER SELF=N<br/>US20110057830 44319313 WHO=EXAMINER SELF=N<br/>US20150228196 69021058 WHO=EXAMINER SELF=N<br/>US20180299530 81611904 WHO=EXAMINER SELF=N<br/>US8380367 43910961 WHO=EXAMINER SELF=N<br/><br/>(WO2020110040)<br/>US20180246205 81015751 WHO=EXAMINER SELF=N CAT=I<br/>XP085267957 none WHO=EXAMINER SELF=N CAT=A<br/>XP033457141 none WHO=EXAMINER SELF=N CAT=A<br/>XP031816268 none WHO=EXAMINER SELF=N CAT=A<br/>XP081417582 none WHO=EXAMINER SELF=N CAT=A<br/>WO201891607 79811166 WHO=EXAMINER SELF=Y CAT=A<br/>WO2018174822 81442472 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2022-05-27",
                    "XAP": "2019WO-IB60247",
                    "APD": "2019-11-27",
                    "APID": "142910801",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2020110040&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FeookijvPhcrvOsLgiiFg7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2020/110040",
                            "KIND": "A1",
                            "XPN": "WO2020110040",
                            "V_PNID": "WO-2020/110040A1-3",
                            "DATE": "2020-06-04",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCCkVZZARvixUN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2020110040&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FeookijvPhcrvOsLgiiFg7msLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2039-11-27",
                            "XAP": "2019EP-0839409",
                            "APD": "2019-11-27",
                            "APID": "152991241",
                            "REG_LINK": "https://register.epo.org/application?number=EP19839409",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CZjXXFvKW%252Fz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP3887854",
                                    "KIND": "B1",
                                    "XPN": "EP3887854",
                                    "V_PNID": "EP-3887854B1-8",
                                    "DATE": "2022-09-21",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=xjIJSEQhK04AisknzjloT6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP3887854&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CZjXXFvKW%252Fz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP3887854",
                                    "KIND": "A1",
                                    "XPN": "EP3887854",
                                    "V_PNID": "EP-3887854A1-8",
                                    "DATE": "2021-10-06",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=xjIJSEQhK04AisknzjloT/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP3887854&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CZjXXFvKW%252Fz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ],
                            "V_APL": [
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "GRANTED",
                                    "ACT_EED": "2039-11-27",
                                    "XAP": "2019PL-0839409",
                                    "APD": "2019-11-27",
                                    "APID": "163118567",
                                    "REG_LINK": "https://eprofil.pue.uprp.gov.pl/public/registry/search?lng=pl",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Hs2PRqgUG3f4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "PL3887854",
                                            "KIND": "T3",
                                            "XPN": "PL3887854",
                                            "V_PNID": "PL-3887854T3-0",
                                            "DATE": "2023-03-20",
                                            "STG": "Translation of ep patent",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=YmHaiqu7dtIAisknzjloT34Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=PL3887854&kind=T3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Hs2PRqgUG3f4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                },
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "GRANTED",
                                    "ACT_EED": "2039-11-27",
                                    "XAP": "2019ES-0839409T",
                                    "APD": "2019-11-27",
                                    "APID": "161534861",
                                    "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=1lluUEN9YVzdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "ES2930577",
                                            "KIND": "T3",
                                            "XPN": "ES2930577",
                                            "V_PNID": "ES-2930577T3-0",
                                            "DATE": "2022-12-19",
                                            "STG": "Translation of granted European patent (former B3)",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=BYnBXfhIA2lO8APkDp/Fy34Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2930577&kind=T3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=1lluUEN9YVzdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "PENDING",
                            "ACT_EED": "2039-11-27",
                            "XAP": "2019US-17297416",
                            "APD": "2019-11-27",
                            "APID": "155621591",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/17297416",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=rSosG92DxorHKwHkq7Pmm8RHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US20220036748",
                                    "KIND": "A1",
                                    "XPN": "US20220036748",
                                    "V_PNID": "US-20220036748A1-2",
                                    "DATE": "2022-02-03",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcOEkoThkZXDUrxtUVS6odf4bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20220036748&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=rSosG92DxorHKwHkq7Pmm8RHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                }
            ],
            "REP": "EP3887854_B1",
            "EPRD": "2018-11-27",
            "PN": "EP3887854           B1 2022-09-21 [EP3887854]<br/>EP3887854           A1 2021-10-06 [EP3887854]<br/>US20220036748       A1 2022-02-03 [US20220036748]<br/>WO2020/110040       A1 2020-06-04 [WO2020110040]<br/>PL3887854           T3 2023-03-20 [PL3887854]<br/>ES2930577           T3 2022-12-19 [ES2930577]",
            "ADB": "(EP3887854)<br/><p>On the other hand, the suborbital flight sector could also be advantageously exploited for: scientific experiments (e.g. in life sciences in microgravity, physical sciences in microgravity, aero-medical sciences, health physics, Earth sciences, etc.); and test and/or training activities (for example, for testing devices intended for space use and/or for training astronauts).</p><p>Regarding the future scenario with journeys from one spaceport A to another spaceport B, the present invention could be advantageously installed not just in (a few) specific spaceports, but in all the main aviation hubs. In addition, it is worth noting that the present invention also allows gaining the following advantages: unlike the currently known solutions for monitoring space debris, which only contemplate the simulation of the trajectories of this debris (in order to predict the descent trajectory and possible area of the earth's surface affected by this falling debris), the present invention instead provides a real-time tracking of the trajectories of the space debris, as well as any debris produced by explosions or collisions, with evident advantages in terms of safety; due to the real-time monitoring of space debris (or other objects in the suborbital space region of interest), the present invention enables avoiding the start or re-entry of a suborbital flight in cases where problems related to the presence of debris (or other objects) are detected or, more in general, enables programming suborbital flights with greater precision and safety, reducing the probability of false alarms of possible collision typical of forecasts/planning based on the \"bulletin\" service provided by government agencies in the USA (notoriously affected by significant long-term errors); as repeatedly stressed in the foregoing, the present invention enables drastically reducing the risks of missions above FL 650 due to the real-time tracking of debris in the suborbital region of interest, with analysis of the decent trajectories and forecasting of the impact area, so as to alert and empty/evacuate any areas of airspace and/or the earth's surface affected by the falling debris; and the present invention represents an integrated solution that not only perfectly responds to the future scenario of suborbital flights, but also enables having a \"seamless\" transition between traditional ATC systems and the suborbital space traffic control system according to the present invention.</p><p>More specifically, this paper teaches that falling debris caused by the break-up of a space vehicle located above Flight Level (FL) 600 could cause catastrophic accident to cruising aircraft below.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=4<br/>PNAAGE=1<br/>NBPA=1; <br/>ALLCT=12; SCT=1; NSCT=11; <br/>ALLCTG=1; SCTG=0; NSCTG=1; <br/>AFS=2; ACC=2; AMCC=1; <br/>IGEN=0.0; IORG=0.95; IRAD=0.98; <br/>IMPI=1.44; MACI=1.06; PASI=1.93; PAVI=3.05; ",
            "PTCC": "(US11436485)<br/>CC=US EED=2041-05-20 STATUS=GRANTED APID=140190822 APD=2019-06-18 XPN=US20190392313 PD=2019-12-26 PD=2022-09-06 EPD=2019-12-26 LPD=2022-09-06 PDG=2022-09-06 <br/><br/>(IT201800006499)<br/>CC=IT EED=2038-06-20 STATUS=PENDING APID=142313314 APD=2018-06-20 XPN=IT201800006499 PD=2019-12-20 EPD=2019-12-20 LPD=2019-12-20 <br/>",
            "EPN": "IT201800006499",
            "CTGN": "(US11436485)<br/>CN113358308B 95998721 WHO=EXAMINER SELF=N CAT=A",
            "LAPD": "2019-06-19",
            "STDN": "",
            "NPN": "4",
            "DESC": "<p><h1>CROSS-REFERENCE TO RELATED APPLICATIONS</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application claims priority to Italian Patent Application No. 102018000006499 filed on Jun. 20, 2018. the entire contents of which is hereby incorporated in its entirety by reference.</p><br/><p><h1>FIELD OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates in general to a method for performing structural diagnostics, and more specifically to a method for performing diagnostics of a mechanical structure, in particular an aircraft structure, suitable for evaluating or monitoring the presence of damage or defects caused in a structure by operating loads and/or events occurring while in service.</p><p><h1>BACKGROUND OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0003]   </span>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p><span class=\"paragraph-number\">[0004]   </span>According to the prior art, in the aeronautical sector the presence of damage or defects in a mechanical structure of an aircraft, such as a metal or composite structure, for example fuselage or wing structure, is diagnosed indirectly by means of a historical reconstruction of events, including events which have resulted in damage due to an accidental impact during production (impact of a tool) or while in service (impact due to hail or foreign objects), and loads withstood by the structure, or by means of estimate of the fatigue withstood by the structure, based on the knowledge of its mechanical strength properties in response to the stresses which typically occur in service conditions. In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally but may cause considerable damage inside the structure (for example, delamination).</p><p><span class=\"paragraph-number\">[0005]   </span>This technique, however, is laborious and imprecise, because it does not reflect in real time the changes and the physical and mechanical conditions of the monitored structure.</p><p><span class=\"paragraph-number\">[0006]   </span>A method for predicting the behavior of a structure subject to loads was developed by the same Applicant and described in the European patent application EP 2,281,224 A1. The method comprises the provision of a mathematical model of the structure, detection of the state (deformation) of the structure in a plurality of primary points and in a plurality of additional points, determination of the loads acting on the structure and associated with the state detected in the primary points on the basis of the aforementioned mathematical model, estimation, using the loads determined, of the state of the structure in the additional points, and comparison between the state of the structure estimated and that detected in the additional points, so that an intact state of the structure is determined if the estimated and detected values of the state parameter match, or a defective state of the structure if these values differ.</p><p><span class=\"paragraph-number\">[0007]   </span>EP 2,682,836 by the same Applicant relates to a method for performing diagnostics of a structure subjected to loads, based on the association with said structure of a sensor arrangement adapted to reveal at least one state of the structure. The method comprises the learning of an associative relationship between the values assumed by an indicative parameter of the state of the structure in a subset of a plurality of relevant detection points of the state of the structure and the values of the state parameter in at least one residual relevant detection point, starting from a plurality of indicative training data of the state of the structure in association with at least one load condition. In an operational phase, the method for performing diagnostics consists of detecting the values assumed by the indicative parameter of the state of the structure in a plurality of relevant detection points under at least one load condition, on the basis of the predetermined association relationship and from the values assumed by the state parameter of the structure in a subset of the plurality of detection points, estimating the values of the state parameter at residual detection points, and finally comparing the estimated and detected values of the state parameter in the residual detection points. An intact state of the structure is determined if the expected and detected values of the state parameter match, whereas a defective state of the structure is determined if the values of the state parameter differ. EP 2,682,836 describes—as a representation of the state of the structure—the deformation thereof.</p><p><span class=\"paragraph-number\">[0008]   </span>The object of the present invention is to provide an improved alternative method for performing structural diagnostics, which is both simple and flexible and allows the physical and mechanical conditions of a structure to be estimated with continuity in a reliable manner.</p><p><span class=\"paragraph-number\">[0009]   </span>A further object of the invention is to provide a method for performing diagnostics which can be applied without the need for excessive calculation and in particular without the need to create a physical/mathematical model of the structure and which can therefore be implemented on-board an aircraft also when in service or during a mission.</p><p><h1>SUMMARY OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0010]   </span>According to the present invention these objects are achieved by means of a method of performing diagnostics on a mechanical structure having the characteristic features defined in Claim <b>1</b>.</p><p><span class=\"paragraph-number\">[0011]   </span>Particular embodiments form the subject of the dependent claims, the contents of which are to be understood as forming an integral or complementary part of the present description.</p><p><span class=\"paragraph-number\">[0012]   </span>The invention also relates to a system and a computer program for performing the diagnostics of a mechanical structure as claimed.</p><p><span class=\"paragraph-number\">[0013]   </span>In short, the present invention is based on the characterization of a mechanical structure under examination which is subject to operating loads able to cause local displacements of points of the structure with respect to a reference system (i.e. to modify the local position of points of the structure with respect to a reference system), and on the correlation in real time of real displacement data (i.e. of the data indicative of the real variation of the position of prechosen points) and presumed displacement data (i.e. of the presumed variation of the position of prechosen points), a comparison thereof being used to deduce the intact or defective condition of the structure.</p><p><span class=\"paragraph-number\">[0014]   </span>Hereinafter in the present treatment, “displacement” means the variation of a spatial position of an element under examination, such as a relevant point of the structure, that is, of the indicative coordinates of said position. If the coordinates of a point before the displacement are indicated x<b>0</b>, y<b>0</b>, z<b>0</b>, and the coordinates of the point after the displacement are indicated x<b>1</b>, y<b>1</b>, z<b>1</b>, the displacement is a vector of components (x<b>1</b>-x<b>0</b>), (y<b>1</b>-y<b>0</b>), (z<b>1</b>-z<b>0</b>). More generally, the displacement of a point P<sub>i </sub>of a body between an instant to and an instant t<sub>1 </sub>is defined as the vector P<sub>i</sub>(t<sub>0</sub>)−P<sub>i</sub>(t<sub>1</sub>), and is characterized by a magnitude having length dimension, by an orientation and by a sense, i.e., by three coordinates of scalar length dimension. The reference system may be either fixed or integral to the structure to which the point belongs.</p><p><span class=\"paragraph-number\">[0015]   </span>Displacement is conceptually and dimensionally different from deformation, described in EP 2,682,836, which is defined with reference to a segment of the structure, the original length l<sub>0 </sub>of which varies due to the deformation of the structure until it reaches the length l<sub>1</sub>, whereby if the difference between the two lengths is indicated Δl, the deformation is defined as ε=Δl/l<sub>0 </sub>as l<sub>0 </sub>trends to 0. As a result, the deformation is a dimensionless parameter (ratio of the lengths).</p><p><span class=\"paragraph-number\">[0016]   </span>A defect of the structure may consist of a hole, a filled hole or other modifications to the surface or volume, for example caused by the insertion of a connection member, impact damage, delamination, porosity, or due to a zone of the structure which has a different resin or fiber intensity. A defect may be concentrated in a point with specific coordinates or spread out in a direction or over an area or within a volume of the structure.</p><p><span class=\"paragraph-number\">[0017]   </span>In a currently preferred embodiment, the structure being examined is equipped with a limited number of displacement sensors or meters located in relevant points, such as mechanical displacement transducers or transducers operating according to optical or interferometric techniques.</p><p><span class=\"paragraph-number\">[0018]   </span>Unlike structural deformation measurement techniques, whereby sensors locally integral to the structure are used to associate the value of the structural deformation with a physical property of the sensor, such as electrical resistance (strain gages) or interference wavelength (fiber optics with Bragg grating), displacement measurement methods are more easily automated.</p><p><span class=\"paragraph-number\">[0019]   </span>It should be noted that, depending on the prechosen arrangement of relevant points (or detection points) on the structure a possible concentrated defect, located far from them, may not cause any variation in the state of the structure at the relevant points, so that a given load or vector of loads gives rise to a displacement vector which is unchanged in the presence of a defect. Obviously, the criterion for choosing the detection points must preferably take into account the sensitivity to the structural defect at said points.</p><p><span class=\"paragraph-number\">[0020]   </span>A neural network, the degree of complexity of which depends on the morphological complexity of the structure, is trained on the basis of the state conditions detected on the structure at the relevant points by means of association with at least one and preferably a plurality of different load conditions. The neural network is designed to estimate a correlation between the displacement or the variations in position detected in a subset of relevant points and the displacement or the variation in position in one or more residual relevant points.</p><p><span class=\"paragraph-number\">[0021]   </span>A presumed variation in position of a relevant point of the structure under examination depending on a given operating load is estimated by means of the neural network which has been suitably trained and is compared with the corresponding real value of position measured by the sensor associated with the relevant point.</p><p><span class=\"paragraph-number\">[0022]   </span>Advantageously, by means of the neural network, for each load situation an associative prediction of the displacement or modification of the position is assigned to a subset of relevant points and preferably to each relevant point of the complete set of relevant points on the basis of the displacement or modifications in the position detected at the other points of the set. Therefore, for each point and any load situation a comparison may be performed between the value of the displacement predicted by the neural network for that point and the real value of the displacement detected by the associated sensor, basically performing a comparison between the expected state of the structure and the detected state.</p><p><span class=\"paragraph-number\">[0023]   </span>The diagnostic evaluation of the structure is performed by means of identification and signaling of the points where the displacement value assumed differs from the expected value by an amount greater than a predetermined tolerance threshold. An intact state of the structure is determined if the expected and detected displacement values match within the predetermined tolerance threshold, or a defective state of the structure is determined if these values differ beyond the predetermined tolerance threshold.</p><p><span class=\"paragraph-number\">[0024]   </span>The diagnostic evaluation may be conveniently verified by considering a plurality of different load situations and therefore measurements of the presumed displacement of the relevant points of the structure, whereby the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a plurality of load situations may be interpreted as a confirmation of the presence of damage or a defect in the structure, while the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a single load situation or in a small number of load situations together with the existence of a match condition between values predicted by means of the neural network and values detected by the sensors in a multiplicity of different load situations may be interpreted as an occasional signal.</p><p><span class=\"paragraph-number\">[0025]   </span>Mapping of the points wherein the presence of damage or a defect in the structure is estimated may be interpreted as a useful indication of the extent of the damage.</p><p><span class=\"paragraph-number\">[0026]   </span>Advantageously, the method according to the invention does not require the construction of a complex model of the diagnostics structure, for example finite-elements model, as described in EP 2,281,224 A1.</p><p><span class=\"paragraph-number\">[0027]   </span>In a further advantageous way, the method according to the invention allows a measurement density on a conceptually continuous structure, unlike known techniques based on the detection of deformations by means of strain gages, by necessity discrete, whereby very small dimensional defects may be detected.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0028]   </span>Further features and advantages of the invention will be described in greater detail in the following detailed description of an embodiment thereof, given by way of non-limiting example, with reference to the accompanying drawings wherein:</p><p><span class=\"paragraph-number\">[0029]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows an example of a diagnostics system according to the invention, applied to a vehicle;</p><p><span class=\"paragraph-number\">[0030]   </span><a href=\"#DRAWINGS\">FIG. 2</a> shows an example of structure and a system of forces acting thereon;</p><p><span class=\"paragraph-number\">[0031]   </span><a href=\"#DRAWINGS\">FIG. 3</a> is a flow diagram of the diagnostics method according to the invention; and</p><p><span class=\"paragraph-number\">[0032]   </span><a href=\"#DRAWINGS\">FIG. 4</a> is a diagram illustrating an example of a neural network according to the invention.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates in general to a method for performing structural diagnostics, and more specifically to a method for performing diagnostics of a mechanical structure, in particular an aircraft structure, suitable for evaluating or monitoring the presence of damage or defects caused in a structure by operating loads and/or events occurring while in service.</p><p><span class=\"paragraph-number\">[0002]   </span>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p><span class=\"paragraph-number\">[0003]   </span>According to the prior art, in the aeronautical sector the presence of damage or defects in a mechanical structure of an aircraft, such as a metal or composite structure, for example fuselage or wing structure, is diagnosed indirectly by means of a historical reconstruction of events, including events which have resulted in damage due to an accidental impact during production (impact of a tool) or while in service (impact due to hail or foreign objects), and loads withstood by the structure, or by means of estimate of the fatigue withstood by the structure, based on the knowledge of its mechanical strength properties in response to the stresses which typically occur in service conditions. In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally but may cause considerable damage inside the structure (for example, delamination).</p><p><span class=\"paragraph-number\">[0004]   </span>This technique, however, is laborious and imprecise, because it does not reflect in real time the changes and the physical and mechanical conditions of the monitored structure.</p><p><span class=\"paragraph-number\">[0005]   </span>A method for predicting the behavior of a structure subject to loads was developed by the same Applicant and described in the European patent application <patcit dnum=\"EP2281224A1\">EP 2,281,224 A1</patcit>. The method comprises the provision of a mathematical model of the structure, detection of the state (deformation) of the structure in a plurality of primary points and in a plurality of additional points, determination of the loads acting on the structure and associated with the state detected in the primary points on the basis of the aforementioned mathematical model, estimation, using the loads determined, of the state of the structure in the additional points, and comparison between the state of the structure estimated and that detected in the additional points, so that an intact state of the structure is determined if the estimated and detected values of the state parameter match, or a defective state of the structure if these values differ.</p><p><span class=\"paragraph-number\">[0006]   </span><patcit dnum=\"EP2682836A\">EP 2,682,836</patcit> by the same Applicant relates to a method for performing diagnostics of a structure subjected to loads, based on the association with said structure of a sensor arrangement adapted to reveal at least one state of the structure. The method comprises the learning of an associative relationship between the values assumed by an indicative parameter of the state of the structure in a subset of a plurality of relevant detection points of the state of the structure and the values of the state parameter in at least one residual relevant detection point, starting from a plurality of indicative training data of the state of the structure in association with at least one load condition. In an operational phase, the method for performing diagnostics consists of detecting the values assumed by the indicative parameter of the state of the structure in a plurality of relevant detection points under at least one load condition, on the basis of the predetermined association relationship and from the values assumed by the state parameter of the structure in a subset of the plurality of detection points, estimating the values of the state parameter at residual detection points, and finally comparing the estimated and detected values of the state parameter in the residual detection points. An intact state of the structure is determined if the expected and detected values of the state parameter match, whereas a defective state of the structure is determined if the values of the state parameter differ. <patcit dnum=\"EP2682836A\">EP 2,682,836</patcit> describes - as a representation of the state of the structure - the deformation thereof.</p><p><span class=\"paragraph-number\">[0007]   </span>The object of the present invention is to provide an improved alternative method for performing structural diagnostics, which is both simple and flexible and allows the physical and mechanical conditions of a structure to be estimated with continuity in a reliable manner.</p><p><span class=\"paragraph-number\">[0008]   </span>A further object of the invention is to provide a method for performing diagnostics which can be applied without the need for excessive calculation and in particular without the need to create a physical/mathematical model of the structure and which can therefore be implemented on-board an aircraft also when in service or during a mission.</p><p><span class=\"paragraph-number\">[0009]   </span>According to the present invention these objects are achieved by means of a method of performing diagnostics on a mechanical structure having the characteristic features defined in Claim 1.</p><p><span class=\"paragraph-number\">[0010]   </span>Particular embodiments form the subject of the dependent claims, the contents of which are to be understood as forming an integral or complementary part of the present description.</p><p><span class=\"paragraph-number\">[0011]   </span>The invention also relates to a system and a computer program for performing the diagnostics of a mechanical structure as claimed.</p><p><span class=\"paragraph-number\">[0012]   </span>In short, the present invention is based on the characterization of a mechanical structure under examination which is subject to operating loads able to cause local displacements of points of the structure with respect to a reference system (i.e. to modify the local position of points of the structure with respect to a reference system), and on the correlation in real time of real displacement data (i.e. of the data indicative of the real variation of the position of prechosen points) and presumed displacement data (i.e. of the presumed variation of the position of prechosen points), a comparison thereof being used to deduce the intact or defective condition of the structure.</p><p><span class=\"paragraph-number\">[0013]   </span>Hereinafter in the present treatment, \"displacement\" means the variation of a spatial position of an element under examination, such as a relevant point of the structure, that is, of the indicative coordinates of said position. If the coordinates of a point before the displacement are indicated x0, y0, z0, and the coordinates of the point after the displacement are indicated x1, y1, z1, the displacement is a vector of components (x1-x0), (y1-y0), (z1-z0). More generally, the displacement of a point P<sub>i</sub> of a body between an instant to and an instant t<sub>1</sub> is defined as the vector P<sub>i</sub>(t<sub>0</sub>) - P<sub>i</sub>(t<sub>1</sub>), and is characterized by a magnitude having length dimension, by an orientation and by a sense, i.e., by three coordinates of scalar length dimension. The reference system may be either fixed or integral to the structure to which the point belongs.</p><p><span class=\"paragraph-number\">[0014]   </span>Displacement is conceptually and dimensionally different from deformation, described in <patcit dnum=\"EP2682836A\">EP 2,682,836</patcit>, which is defined with reference to a segment of the structure, the original length lo of which varies due to the deformation of the structure until it reaches the length l<sub>1</sub>, whereby if the difference between the two lengths is indicated Δ1, the deformation is defined as ε = Δ1 / l<sub>0</sub> as l<sub>0</sub> trends to 0. As a result, the deformation is a dimensionless parameter (ratio of the lengths).</p><p><span class=\"paragraph-number\">[0015]   </span>A defect of the structure may consist of a hole, a filled hole or other modifications to the surface or volume, for example caused by the insertion of a connection member, impact damage, delamination, porosity, or due to a zone of the structure which has a different resin or fiber intensity. A defect may be concentrated in a point with specific coordinates or spread out in a direction or over an area or within a volume of the structure.</p><p><span class=\"paragraph-number\">[0016]   </span>In a currently preferred embodiment, the structure being examined is equipped with a limited number of displacement sensors or meters located in relevant points, such as mechanical displacement transducers or transducers operating according to optical or interferometric techniques.</p><p><span class=\"paragraph-number\">[0017]   </span>Unlike structural deformation measurement techniques, whereby sensors locally integral to the structure are used to associate the value of the structural deformation with a physical property of the sensor, such as electrical resistance (strain gages) or interference wavelength (fiber optics with Bragg grating), displacement measurement methods are more easily automated.</p><p><span class=\"paragraph-number\">[0018]   </span>It should be noted that, depending on the prechosen arrangement of relevant points (or detection points) on the structure a possible concentrated defect, located far from them, may not cause any variation in the state of the structure at the relevant points, so that a given load or vector of loads gives rise to a displacement vector which is unchanged in the presence of a defect. Obviously, the criterion for choosing the detection points must preferably take into account the sensitivity to the structural defect at said points.</p><p><span class=\"paragraph-number\">[0019]   </span>A neural network, the degree of complexity of which depends on the morphological complexity of the structure, is trained on the basis of the state conditions detected on the structure at the relevant points by means of association with at least one and preferably a plurality of different load conditions. The neural network is designed to estimate a correlation between the displacement or the variations in position detected in a subset of relevant points and the displacement or the variation in position in one or more residual relevant points.</p><p><span class=\"paragraph-number\">[0020]   </span>A presumed variation in position of a relevant point of the structure under examination depending on a given operating load is estimated by means of the neural network which has been suitably trained and is compared with the corresponding real value of position measured by the sensor associated with the relevant point.</p><p><span class=\"paragraph-number\">[0021]   </span>Advantageously, by means of the neural network, for each load situation an associative prediction of the displacement or modification of the position is assigned to a subset of relevant points and preferably to each relevant point of the complete set of relevant points on the basis of the displacement or modifications in the position detected at the other points of the set. Therefore, for each point and any load situation a comparison may be performed between the value of the displacement predicted by the neural network for that point and the real value of the displacement detected by the associated sensor, basically performing a comparison between the expected state of the structure and the detected state.</p><p><span class=\"paragraph-number\">[0022]   </span>The diagnostic evaluation of the structure is performed by means of identification and signaling of the points where the displacement value assumed differs from the expected value by an amount greater than a predetermined tolerance threshold. An intact state of the structure is determined if the expected and detected displacement values match within the predetermined tolerance threshold, or a defective state of the structure is determined if these values differ beyond the predetermined tolerance threshold.</p><p><span class=\"paragraph-number\">[0023]   </span>The diagnostic evaluation may be conveniently verified by considering a plurality of different load situations and therefore measurements of the presumed displacement of the relevant points of the structure, whereby the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a plurality of load situations may be interpreted as a confirmation of the presence of damage or a defect in the structure, while the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a single load situation or in a small number of load situations together with the existence of a match condition between values predicted by means of the neural network and values detected by the sensors in a multiplicity of different load situations may be interpreted as an occasional signal.</p><p><span class=\"paragraph-number\">[0024]   </span>Mapping of the points wherein the presence of damage or a defect in the structure is estimated may be interpreted as a useful indication of the extent of the damage.</p><p><span class=\"paragraph-number\">[0025]   </span>Advantageously, the method according to the invention does not require the construction of a complex model of the diagnostics structure, for example finite-elements model, as described in <patcit dnum=\"EP2281224A1\">EP 2,281,224 A1</patcit>.</p><p><span class=\"paragraph-number\">[0026]   </span>In a further advantageous way, the method according to the invention allows a measurement density on a conceptually continuous structure, unlike known techniques based on the detection of deformations by means of strain gages, by necessity discrete, whereby very small dimensional defects may be detected.</p><p><span class=\"paragraph-number\">[0027]   </span>Further features and advantages of the invention will be described in greater detail in the following detailed description of an embodiment thereof, given by way of non-limiting example, with reference to the accompanying drawings wherein:</p><p><ul compact=\"compact\" list-style=\"none\"><li> <figref>Figure 1</figref> shows an example of a diagnostics system according to the invention, applied to a vehicle;</li><br/><li> <figref>Figure 2</figref> shows an example of structure and a system of forces acting thereon;</li><br/><li> <figref>Figure 3</figref> is a flow diagram of the diagnostics method according to the invention; and</li><br/><li> <figref>Figure 4</figref> is a diagram illustrating an example of a neural network according to the invention.</li></ul></p><p><span class=\"paragraph-number\">[0028]   </span>An example of a structural diagnostics system in the preferred application to an aircraft is schematically shown in <figref>Figure 1</figref>.</p><p><span class=\"paragraph-number\">[0029]   </span>Said figure shows the aircraft, denoted overall by A, and some of its structural parts which are to be monitored with regard to their intact or defective condition, for example the fuselage S1, the wing structure S2 and the tail unit S3. A plurality of sensors or meters, denoted overall by P, are shown located on each part in N relevant detection points suitable for detecting a local displacement indicative of the state of the aircraft structures.</p><p><span class=\"paragraph-number\">[0030]   </span>The sensors are connected to an electronic processing unit U to which respective signals representing the displacements detected are transmitted. A database DB is associated with the processing unit and is designed to store a plurality of vectors comprising the values assumed by the displacement detected at the N points in different load conditions. For operation of the system according to the invention, conveniently in a learning step during the first stage of operation of the diagnostics structure, a large number of vectors are recorded.</p><p><span class=\"paragraph-number\">[0031]   </span>The processing unit U comprises a plurality of neural networks which are designed to process data with an approach of the associative type, and the number of vectors which are conveniently recorded during a learning step depends on the number of coefficients used by the neural networks described below, and preferably this number of vectors should be at least five times the number of coefficients.</p><p><span class=\"paragraph-number\">[0032]   </span>For i-th point P<sub>i</sub>, where P lies between 1 and N, a neural network is designed to determine a correlation between the values assumed by the displacement in the N-1 points different from the point P<sub>i</sub> and the value assumed by the displacement in the point P<sub>i</sub>, depending on at least one and preferably a plurality of load conditions.</p><p><span class=\"paragraph-number\">[0033]   </span>Each neural network is a network with Q levels, with d<sub>Q</sub> nodes per level, as shown in <figref>Figure 4</figref>. By way of example, and with reference to the Figure, a correlation of the neural type established between N relevant points X<sub>1</sub>, X<sub>2</sub>,...., X<sub>N</sub> at the input and a relevant point X<sub>F</sub> at the output is described.</p><p><span class=\"paragraph-number\">[0034]   </span>First of all a neural box consisting of Q successive lines (for example 3), each with dimensions d<sub>1</sub>, d<sub>2</sub>,..., d<sub>Q</sub> (for example 3 nodes per line) is established. The correlative logic flow is shown in the figure, so that each node contributes to all the nodes of the next level.</p><p><span class=\"paragraph-number\">[0035]   </span>A respective correlation parameter C is defined for each relevant input point for each neuron (inner node) and for each relevant output point. A crossed correlation function φ is also established and associates with each pair of correlation parameters C<sub>a</sub>,C<sub>b</sub> a crossed correlation parameter K, where K<sub>a,b</sub> = φ (C<sub>a</sub>, C<sub>b</sub>). A function f (typically a hyperbolic function) is defined and, for each successive step, a correlation is established between the N relevant input points and the relevant output point of each calculation step indicated by X<sub>i+1,j</sub> = f((x<sub>i,1,</sub> K<sub>(i,1),(i+1,J)</sub>), (X<sub>i,2,</sub> K<sub>(i,2),(i+1,J)</sub>), ..., (x<sub>i</sub>,N, K<sub>(i,N),(i+1,J)</sub>).</p><p><span class=\"paragraph-number\">[0036]   </span>This having been defined, training of the network, based on the availability of a sufficiently large number of real situations in which the displacement values of the relevant points upstream of the network and the corresponding displacement value of the relevant point downstream of the network are known, consists in defining the parameters C which minimize the difference between the output displacement value calculated by the function f and the optimized parameters C, and its real displacement value. Minimization may be performed, for example, using criteria of the \"minimum squares\" type.</p><p><span class=\"paragraph-number\">[0037]   </span>By means of N neural networks which have been suitably trained, one for each relevant point, for each load situation wherein the displacements in N-1 points are detected, the processing unit is able to provide an associative prediction of the value of the displacement for the remaining point.</p><p><span class=\"paragraph-number\">[0038]   </span>The processing unit is connected moreover to a signaling unit D for indicating to an operator, such as the aircraft pilot or a maintenance engineer, visually by means of written information and mapped points on a screen or electronically by means of issuing of a report, the intact or defective state of the monitored structures.</p><p><span class=\"paragraph-number\">[0039]   </span>An example of a structure being examined by a diagnostics system is shown in <figref>Figure 2</figref>, in the form of a fuselage panel of an aircraft - denoted overall by 10 and shown in a top plan view and side view - which comprises a flat bottom element 20 which has on a surface 22 a series of reinforcing ribs 24.</p><p><span class=\"paragraph-number\">[0040]   </span>L<sub>1</sub>-L<sub>K</sub> indicate the vectors representing the forces acting on the structure (which is essentially two-dimensional) in a predetermined operating condition, by way of example and for the sake of simplicity having components only in the plane in which the structure lies.</p><p><span class=\"paragraph-number\">[0041]   </span>P<sub>i</sub> denotes relevant points on the surface of the structure, which are typically chosen based on a criterion of substantial periodicity, except for any clustering in the vicinity of areas which are more critical from a structural point of view (for example, the skin/reinforcement bonding zone, in order to diagnose any possible detachment of the reinforcements).</p><p><span class=\"paragraph-number\">[0042]   </span>Displacement sensors or meters of the type known per se are located in the N detection points (or relevant points of the structure) P<sub>i</sub>; these sensors may consist, for example, of surface sensors or sensors which are embedded in the structure and which are connected (electrically, optically or wirelessly) to the processing unit of the diagnostics system on-board the aircraft designed to associate the signals acquired by the sensors with displacement values of the points of the structure associated thereto.</p><p><span class=\"paragraph-number\">[0043]   </span>Known sensors may be, for example, mechanical or optical transducers, the latter preferably of interferometric type. In the case of mechanical displacement meters, they are generally made up of at least one mechanical element of variable length bound at one end to a support structure (reference system) and at the other end to the point where one wishes to measure the displacement. In order to obtain displacement measurements on all three coordinates, a complete measuring system requires the use of three mechanical elements, bound at different points, for each point where the displacement is to be measured or an element capable of measuring an elongation and at least two variations in angle with respect to the Cartesian reference axes of the hinge to which the gauge is bound on the fixed structure. In the case of optical deviation meters, the sensors include at least two video cameras and the arrangement on the observed surface of a suitable coloration, preferably in alternating color lines. As far as holographic systems are concerned, they are based on the identification of the position of the relevant points of the structure through the interference of two laser beams after a different path. They may allow very high precision, through strict vibration control.</p><p><span class=\"paragraph-number\">[0044]   </span>The diagnostics method according to the invention is described in detail with reference to the flow diagram shown in <figref>Figure 3</figref>. The diagnostics method is implemented by the on-board processing unit U designed to execute groups or modules of processing and calculation programs stored on a disk or accessible on the network, for performing the procedures described.</p><p><span class=\"paragraph-number\">[0045]   </span>First of all, in step 100, the location of the relevant points on the structure is determined, and the structure displacement sensors are positioned at these points. The sensors may be located on the structure following determination of the topology of relevant points, or vice versa, using a network of pre-existing sensors on the structure a subset (or even the entire set) of corresponding relevant points is identified on the structure.</p><p><span class=\"paragraph-number\">[0046]   </span>During a first step, for example by means of same on-board processing unit, and in a definitive manner (except for system updates), M state vectors Vs<sub>j</sub> = [S<sub>1j</sub>, S<sub>2j</sub>, ..., S<sub>Nj</sub>] are acquired in step 200 for N relevant points and M different load conditions, with 1 &lt; j &lt; M, which are stored in the database DB.</p><p><span class=\"paragraph-number\">[0047]   </span>A state vector V<sub>S</sub> of the structure, with dimension N, is indicated as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 36mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP3584659&ekey=1012&cc=EP&producerName=imgb0001.tif&width=36mm&height=6mm\"/></maths></p><p> where S<sub>1</sub>, ..., S<sub>N</sub> each indicate, in abbreviated form, a value of the displacement (in certain cases the set of three values of the components of displacement in a pre-chosen Cartesian spatial reference system).</p><p><span class=\"paragraph-number\">[0048]   </span>The vector V<sub>S</sub> may assume theoretically infinite values, in view of the infinite nature of the loads which may act on the structure in the different possible operating conditions, or in an infinite number of pluralities of rank-N relevant points of the structure, and with a plurality of possible intensity values.</p><p><span class=\"paragraph-number\">[0049]   </span>For the purposes of the invention it is considered that each element of V<sub>S</sub> may assume a finite discrete number of values, for example owing to measurement discretization of the sensors which are employed on the structure.</p><p><span class=\"paragraph-number\">[0050]   </span>In the currently preferred embodiment, for each load situation the processing unit U acquires N training displacement values [S<sub>11</sub>, S<sub>21</sub>, ..., S<sub>N1</sub>], one for each relevant point P<sub>i</sub>. For M different load conditions, the processing unit therefore acquires M displacement vectors, each of N points, corresponding to Nx3 numerical values, since each vector has three components. The M vectors of N points are stored in the database DB.</p><p><span class=\"paragraph-number\">[0051]   </span>Then, in step 300, a step for training the N neural networks is performed (one for each relevant point), setting for the neural network associated with the i-th point P<sub>i</sub> a condition of input values equal to the values of the displacement detected in the N-1 relevant points different from P<sub>i</sub> and stored in DB, and an output value representing the value of the displacement detected in the i-th relevant point P<sub>i</sub>, which is also stored in DB. Each neural network creates an association between the displacements in N-1 points and the displacement in the relevant point P<sub>i</sub> with which it is associated, so that the processing unit has at its disposal N associative laws, of the type described above, for the value of the displacement of a point P<sub>i</sub> and each of the other N-1 points, for each value of i lying between 1 and N.</p><p><span class=\"paragraph-number\">[0052]   </span>Each neural network is configured during a training step advantageously performed during the first operating step of the structure. For training purposes, preferably the data of M different load conditions are used, where M may be chosen depending on the number of coefficients C used by the neural network and should conveniently be at least five times the number of coefficients C in order to achieve satisfactory training.</p><p><span class=\"paragraph-number\">[0053]   </span>In the case of a plurality of load conditions a comparison may be made, for each point, between the prediction of a displacement obtained by means of the neural network during training using as an input value the other N-1 displacements in the new load condition, and the one effectively detected at the point in this condition. With this approach it is possible to evaluate the degree of progress of training, which may be prolonged, if necessary, for further load conditions.</p><p><span class=\"paragraph-number\">[0054]   </span>Advantageously, for effective training the relevant points are selected based on structural and statistical (variability) criteria.</p><p><span class=\"paragraph-number\">[0055]   </span>At the end of the training procedure, operation of the neural networks may be verified in step 400 by comparing the output values envisaged by the trained network for given input values with the output values used during training, and assessing whether the difference, considered at a specific point and as an average, exceeds a fixed threshold and, in the case where incorrect operation is established (i.e. the difference exceeds, at a specific point and/or as an average, the fixed threshold of at least one or a predetermined minimum number thereof) the number of different load conditions to be used for performing detection of the displacement in the relevant points is increased, generating new training displacement vectors [S<sub>11</sub>, S<sub>21</sub>, ..., S<sub>N1</sub>] which are stored in the database DB (step 200) and on which training of the neural networks (300) is carried out again.</p><p><span class=\"paragraph-number\">[0056]   </span>In the case where the incorrect operation of at least one neural network or a predetermined minimum number of such networks is determined a number of times greater than a predetermined threshold, the topology of relevant points is modified (step 100), by means of the addition or replacement of points, and then the steps for acquiring M' training displacement vectors [S<sub>11</sub>, S<sub>21</sub>, ..., S<sub>N'1]</sub> for N' relevant points and M' different load conditions, storage thereof in the database DB and training of the N' neural networks are repeated in step 300. In the case where incorrect operation persists, in addition to prolonging the training period, it is possible to envisage modifying the number of levels and/or nodes per level of the neural network and/or modifying the function (function type) f and φ.</p><p><span class=\"paragraph-number\">[0057]   </span>If correct operation of the neural networks is established, the processing unit is configured to perform diagnostics of the structure, subject to any (for example periodic) updating of the displacement vectors, and corresponding new training of the neural networks, for example following modifications to the structure or aging thereof.</p><p><span class=\"paragraph-number\">[0058]   </span>The operations for performing diagnostics of the structure are described below.</p><p><span class=\"paragraph-number\">[0059]   </span>Assuming that for a given load or given plurality of loads there is a distribution of displacements S<sub>P</sub> in the grid of N relevant points P<sub>i</sub> of the structure, where 1 &lt; i &lt; N, (S<sub>P</sub>)<sub>q</sub> indicates a distribution of displacements in the grid induced by the same load or plurality of loads in the presence of a structural defect, and more generally (S<sub>P</sub>)<sub>d</sub> indicates a distribution of displacements detected by the sensors.</p><p><span class=\"paragraph-number\">[0060]   </span>At each instant, in step 500 the current displacement (S<sub>P</sub>)<sub>d</sub> of the relevant points of the structure for a given current load condition is detected, for example the current displacement vector [S<sub>1d</sub>, ... S<sub>id</sub>, ..., S<sub>Nd</sub>].</p><p><span class=\"paragraph-number\">[0061]   </span>Then, in step 600, for each point P<sub>i</sub>, with 1 &lt; i &lt; N the value of the displacement P'<sub>i</sub> is calculated by means of the associated neural network previously trained, using inputs including the values of the displacement detected in the other points (S<sub>1d</sub>, ..., S<sub>(i-1)d</sub>, S<sub>(i+1)d</sub>, ..., S<sub>Nd</sub>).</p><p><span class=\"paragraph-number\">[0062]   </span>Thereafter, in step 700, for each point and any load situation a comparison is carried out between the value of the displacement predicted by the neural network and the value of the displacement detected by the sensor. Specifically, the comparison between the value of the displacement S<sub>id</sub> detected at the point P<sub>i</sub> and the value of the displacement S'<sub>i</sub> calculated by the respective neural network in the same point is performed, repeating the comparison for each i, where 1 &lt; i &lt; N.</p><p><span class=\"paragraph-number\">[0063]   </span>An effective diagnostics evaluation is therefore performed by means of the comparison, at each point, between the expected local displacement of the structure and the one detected. Identification of defects in the structure is performed for those points where the detected local displacement of the structure differs from the expected state calculated by means of the respective neural network (namely there is a mismatch) beyond a predetermined percentage threshold.</p><p><span class=\"paragraph-number\">[0064]   </span>If the outcome of the comparison is the recognition of a condition where there is a substantial match of the values, taking into account a predetermined tolerance, the diagnostics method concludes that the structure is intact (800), signaling this condition by means of a signaling unit D to an operator, such as the aircraft pilot or a maintenance engineer, visually by means of written information and mapped points on a screen or electronically by means of issuing of a report, so as to indicate the intact state of the structure monitored.</p><p><span class=\"paragraph-number\">[0065]   </span>If the outcome of the comparison is the recognition of a condition where there is a substantial mismatch between the values, exceeding a predetermined tolerance, the diagnostics method interprets a possible defective condition of the structure (900). Consequently, the method repeats the step 500 for detecting the local displacement of the structure in the relevant points selected, during a successive instant, for the current load condition. It then repeats the step 600 for each point P<sub>i</sub>, where 1 &lt; i &lt; N, calculating the value of the displacement by means of the associated neural network previously trained and, finally, again in step 700, the comparison is made between the value of the displacement detected at the point P<sub>i</sub> and the value of the displacement calculated by the neural network at the same point, for each i, where 1 &lt; i &lt; N.</p><p><span class=\"paragraph-number\">[0066]   </span>The cycle of operations in steps 500-700 is repeated a predetermined number of times, checking whether a predetermined number of repetitions in the comparison step 1000 have been reached, unless a condition where there is substantial match between the values, and therefore an intact condition of the structure, is definitively recognized.</p><p><span class=\"paragraph-number\">[0067]   </span>If in the comparison step 1000 it is determined that the predetermined number of repetitions has been reached and the indication of a defective state of the structure remains, a signal (1100) is emitted, by means of the signaling unit D, to an operator, such as the aircraft pilot or a maintenance engineer, visually in the form of written information and mapped points on a screen or electronically by means of issuing of a report, so as to indicate the defective state of the monitored structure and its location (namely, identification of the point P<sub>i</sub> where there is no match between the value of the displacement detected and the value of the displacement calculated by the neural network).</p><p><span class=\"paragraph-number\">[0068]   </span>The diagnostics evaluation may be further verified by considering different load situations and therefore measurements of the local displacement of the structure: if the mismatch is repeated for different load conditions, this may be interpreted as a confirmation of the presence of damage or a defect in the structure which induces a variation in the predicted displacement. If the mismatch is not repeated, this may be interpreted as being an occasional or spurious signal, not caused by real physical factors.</p><p><span class=\"paragraph-number\">[0069]   </span>The diagnostics evaluation described above is performed for each relevant point of the structure. Mapping of the points where the presence of damage or a defect in the structure is determined provides an indication of the extent of the damage. For example, determination of damage or a defect in various adjacent points is an indication of a delaminated area.</p><p><span class=\"paragraph-number\">[0070]   </span>Obviously, as will be clear to a person skilled in the art, the method concluded as illustrated in the flow diagram shown in the figure may be cyclically repeated, for example at predetermined periodic intervals in accordance with a predetermined monitoring program.</p><p><span class=\"paragraph-number\">[0071]   </span>Advantageously, in order to allow operation of the system also in the case of damage to the structure in the vicinity of some of the detection points, i.e. where there is damage to the sensors, a surplus is created by increasing the number of relevant detection points so as to have a certain number of additional backup sensors.</p><p><span class=\"paragraph-number\">[0072]   </span>The method and system object of the invention make it advantageously possible to identify damage in aeronautical structures, with increased safety, reduced maintenance costs and the creation of less conservative designs and therefore lighter structures.</p><p><span class=\"paragraph-number\">[0073]   </span>Obviously, without affecting the principle of the invention, the embodiments and the constructional details may be greatly modified with respect to that described and illustrated purely by way of a non-limiting example, without thereby departing from the scope of the invention as defined in the accompanying claims.</p>",
            "CLMS": "(EP3584659)<br/><p>1. Method for diagnosing a structure (S1-S3) subjected to loads, in particular an aircraft structure (A), through a sensory arrangement associated with said structure (S1-S3) and adapted to detect at least one local displacement of the structure, which comprises a matrix of sensors (P) arranged in relevant points (P<sub>i</sub>) of the structure (S1-S3), each of which is capable of detecting a physical quantity indicative of the local displacement of the structure (S1-S3) and to emit a respective electrical response signal correlated to the value assumed by said quantity,<br/>the method being <b>characterized in that</b> it comprises,<br/>in a learning phase (100-300):<br/> (a) from a plurality of training data indicative of the local displacement of the structure (S1-S3) at a plurality of relevant sensing points (P<sub>i</sub>) by association with at least one load condition, establishing (300) an associative relationship between the values of the local displacement of the structure in a subset of said plurality of relevant sensing points and the values of the local displacement of the structure in at least one residual relevant sensing point; and<br/>in an operational phase:<br/> (b) detecting (500) the values assumed by the local displacement of the structure in a plurality of relevant sensing points (P<sub>i</sub>) in said at least one load condition;<br/> (c) on the basis of the pre-established association relationship, starting from the values assumed by the local displacement of the structure in a subset of said plurality of sensing points, estimating (600) the values of the local displacement in at least one residual sensing point;<br/> (d) comparing (700) with each other the estimated and detected values of the local displacement in said at least one residual sensing point; and<br/> (e) determining a state of integrity of the structure (800) if the detected and estimated local displacement values substantially match except for predetermined tolerances, or determining a defect state of the structure (900, 1000) if said values of the local displacement are different except for the pre-determined tolerances.</p><p>2. Method according to claim 1, wherein the comparison (700) between the estimated values and the detected values of the local displacement is performed for each relevant sensing point (P<sub>i</sub>).</p><p>3. Method according to claim 1 or 2, wherein said learning phase (100-300) and said operational phase (500-1000) are performed in a plurality of different loading conditions, whereby a defect state of the structure is determined on the basis of the existence of a condition of discrepancy between the estimated and detected values of the local displacement in a multiplicity of load situations, while an episodic indication is determined on the basis of the existence of a condition of discordance between the estimated and detected values of the local displacement in a single load situation or in a number of load situations below a threshold.</p><p>4. Method according to any one of the preceding claims, wherein the learning phase includes the collection (200) of a plurality of training data in the form of vectors comprising the local displacement values detected at the relevant points, in at least one load condition.</p><p>5. Method according to any one of the preceding claims, wherein a plurality of neural networks is respectively associated with said relevant points (P<sub>i</sub>) and the learning phase comprises, for each neural network, the determination of an associative relationship between the values of the local displacement of the structure in at least one load condition at the relevant sensing point corresponding to said network and the values of the local displacement in the remaining plurality of relevant sensing points.</p><p>6. Method according to claim 5, wherein the learning phase comprises, in the case of a plurality of load conditions, a comparison between the value of the local displacement estimated through the neural network during training in at least one relevant point and the value of the local displacement in said at least one relevant point, in a condition of new load.</p><p>7. Method according to claim 6, comprising the check (400) of the learning of the neural networks by comparing the value of the local displacement, estimated in at least one residual relevant point starting from training data indicative of the local displacement of the structure at a subset of said plurality of relevant sensing points, and the training value of the local displacement at said residual relevant point, the learning being considered complete if the difference between the aforementioned values is lower than a pre-set threshold, or unsatisfactory otherwise, whereby the number of different load conditions in which the learning phase is performed is increased, or the topology of the relevant points is modified, or even at least one out of the number of levels, the number of nodes per level and a characteristic function of the neural networks is changed.</p><p>8. Method according to any one of the preceding claims, in which a defect state of the structure is determined if said values of the local displacement are different except for the predetermined tolerances after a temporal succession of a predetermined number of iterations of operations (b), (c), (d).</p><p>9. Method according to any one of the preceding claims, <b>characterized in that</b> it is repeated at predetermined periodic intervals according to a pre-established check plan.</p><p>10. Method according to any one of the preceding claims, wherein a mapping of the relevant points (P<sub>i</sub>) in which the defect of the structure is estimated is interpreted as indicating the extent of said defect.</p><p>11. Method according to any one of the preceding claims, wherein said relevant sensing points (P<sub>i</sub>) are selected with a criterion of periodicity, without prejudice to an intensification near areas of greater structural criticality.</p><p>12. System for diagnosing a structure subject to loads (S1-S3), in particular an aircraft structure (A), comprising:<br/> a sensory arrangement associated with said structure and adapted to detect at least one local displacement of the structure, which comprises a matrix of sensors (P) placed in relevant points (P<sub>i</sub>) of the structure (S1-S3), each of which is capable of detecting a physical quantity indicative of the local displacement of the structure and of emitting a respective electrical response signal correlated to the value assumed by said quantity; and<br/> - electronic learning processing (U) means, of the neural network type, arranged to perform a method according to any one of Claims 1 to 11.</p><p>13. System according to claim 12, wherein said processing means (U) comprise a plurality of neural networks respectively associated to said relevant points (P<sub>i</sub>), in which each neural network is a Q-level network, with d<sub>Q</sub> nodes by level, for each node being defined a respective correlation parameter C, a cross correlation function φ associating to each pair of correlation parameters C<sub>a</sub>, C<sub>b</sub> a cross correlation parameter K, with K<sub>a,b</sub> = φ (C<sub>a</sub>, C<sub>b</sub>), a hyperbolic function determining a correlation between each node of a level X<sub>i+1,j</sub> and the nodes of the previous level X<sub>i,j</sub> as a function of said cross correlation parameter, as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 108mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP3584659&ekey=1012&cc=EP&producerName=imgb0002.tif&width=108mm&height=6mm\"/></maths></p><p> a network training including the determination of C parameters that minimize the difference between the calculated output value and its actual value.</p><p>14. System according to any one of the claims 12 or 13, wherein said processing means (U) are connected to a signaling unit (D), adapted to represent to an operator the state of integrity or defectiveness of the monitored structures.</p><p>15. System according to any one of claims 12 to 14, wherein said sensing sensors (P) include sensors of the local displacement of the structure.</p><p>16. Processing program or group of programs executable by a processing system (U), comprising one or more code modules for implementing a method for diagnosing a structure subjected to loads according to any of the claims 1 to 11.</p>",
            "NPR": "1",
            "APID": "140195300",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64F-005/60<br/>G05B-023/02<br/>G06F-017/15<br/>G06K-009/62<br/>G06N-003/04<br/>G06N-003/08",
            "ID": "87092902",
            "AB": "(EP3584659)<br/>A method for performing diagnostics of a structure subject to loads, in particular an aircraft structure, is described, said method being implemented by means of an arrangement of sensors located at relevant points of the structure and corresponding neural networks, and comprising:training the neural network in order to establish an associative relationship between the local displacement of the structure in a subset of relevant points and the local displacement of the structure in at least one residual relevant point;detecting the local displacement of the structure in a plurality of relevant points under operating conditions;estimating the local displacement of the structure in at least one residual relevant point by means of the associated neural network on the basis of the pre-established associated relationship; andcomparing the local displacement of the estimated structure with the detected local displacement at the residual relevant point,whereby an intact state of the structure is determined if the estimated and detected values of the local displacement match, or a defective state of the structure is determined if these values differ.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FrmUR8kj0Yg1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2018-06-20",
            "PA": "LEONARDO",
            "PAAD": "(EP3584659)<br/>(PUB:EP-3584659A1-8)NAME=Leonardo S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101602613<br/><br/><br/>(US11436485)<br/>(PUB:US-11436485B2-1)NAME=LEONARDO S.p.A.  , CITY=Rome , COUNTRY=IT , ATYP=Non-US Company<br/><br/>(PUB:US-20190392313A1-2)NAME=LEONARDO S.p.A.  , CITY=ROMA , COUNTRY=IT<br/><br/><br/>(CN110618670)<br/>(PUB:CN-110618670A-168)NAME=LEONARDO S.P.A.  , COUNTRY=IT<br/>",
            "FAN": "87092902",
            "TI": "Method for performing diagnostics of a structure subject to loads based on the measurement of displacements and system for implementing said method",
            "TECD": "Computer technology<br/>Control<br/>Transport",
            "EPD": "2019-12-20",
            "ICLM": "(EP3584659)<br/><p>1. Method for diagnosing a structure (S1-S3) subjected to loads, in particular an aircraft structure (A), through a sensory arrangement associated with said structure (S1-S3) and adapted to detect at least one local displacement of the structure, which comprises a matrix of sensors (P) arranged in relevant points (Pi) of the structure (S1-S3), each of which is capable of detecting a physical quantity indicative of the local displacement of the structure (S1-S3) and to emit a respective electrical response signal correlated to the value assumed by said quantity, the method being characterized in that it comprises, in a learning phase (100-300): (a) from a plurality of training data indicative of the local displacement of the structure (S1-S3) at a plurality of relevant sensing points (Pi) by association with at least one load condition, establishing (300) an associative relationship between the values of the local displacement of the structure in a subset of said plurality of relevant sensing points and the values of the local displacement of the structure in at least one residual relevant sensing point; and in an operational phase: (b) detecting (500) the values assumed by the local displacement of the structure in a plurality of relevant sensing points (Pi) in said at least one load condition; (c) on the basis of the pre-established association relationship, starting from the values assumed by the local displacement of the structure in a subset of said plurality of sensing points, estimating (600) the values of the local displacement in at least one residual sensing point; (d) comparing (700) with each other the estimated and detected values of the local displacement in said at least one residual sensing point; and (e) determining a state of integrity of the structure (800) if the detected and estimated local displacement values substantially match except for predetermined tolerances, or determining a defect state of the structure (900, 1000) if said values of the local displacement are different except for the pre-determined tolerances.</p>",
            "CTN": "(EP3584659)<br/>EP2682836 61119843 WHO=EXAMINER SELF=Y CAT=X<br/>EP2281224 1043354 WHO=APPLICANT SELF=N<br/>EP2682836 61119843 WHO=APPLICANT SELF=Y<br/><br/>(US11436485)<br/>US20070006652 44092044 WHO=EXAMINER SELF=N<br/>US20160039527 72186340 WHO=EXAMINER SELF=N<br/>US20170331844 77783845 WHO=EXAMINER SELF=N<br/>US20180354630 82464252 WHO=EXAMINER SELF=N<br/>US20180362190 82565975 WHO=EXAMINER SELF=N<br/>US20190265714 85826211 WHO=EXAMINER SELF=N<br/>EP2682836 61119843 WHO=APPLICANT SELF=Y<br/><br/>(CN110618670)<br/>CA1166277 3797624 WHO=EXAMINER SELF=N CAT=A<br/>CN1198389 43226090 WHO=EXAMINER SELF=N CAT=A<br/>CN102460319 7670007 WHO=EXAMINER SELF=N CAT=A<br/>CN102514709 7735510 WHO=EXAMINER SELF=N CAT=A<br/>US20140012461 61119843 WHO=EXAMINER SELF=Y CAT=X<br/><br/>(IT201800006499)<br/>EP2682836 61119843 WHO=EXAMINER SELF=Y CAT=X",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2023-07-07",
                    "XAP": "2019CN-0533031",
                    "APD": "2019-06-19",
                    "APID": "140215182",
                    "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=iC2MtOnZz6KgoZ7PO1a2o5NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "CN110618670",
                            "KIND": "A",
                            "XPN": "CN110618670",
                            "V_PNID": "CN-110618670A-168",
                            "DATE": "2019-12-27",
                            "STG": "Published application",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=hXP7Q1+dwoTbJU3WqOrGc8k/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN110618670&kind=A",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=iC2MtOnZz6KgoZ7PO1a2o5NXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2041-05-20",
                    "XAP": "2019US-16443995",
                    "APD": "2019-06-18",
                    "APID": "140190822",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/16443995",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=jJraO5CM18%252BuaIz4xNgVNzNfFPLuVTJ9KaVWfLIclG0%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US11436485",
                            "KIND": "B2",
                            "XPN": "US11436485",
                            "V_PNID": "US-11436485B2-1",
                            "DATE": "2022-09-06",
                            "STG": "Granted patent as second publication",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=HCOyy4WOJl7lh33LJ8MaU1vfaQTfGAcAHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=US11436485&kind=B2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=jJraO5CM18%252BuaIz4xNgVNzNfFPLuVTJ9KaVWfLIclG0%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "US20190392313",
                            "KIND": "A1",
                            "XPN": "US20190392313",
                            "V_PNID": "US-20190392313A1-2",
                            "DATE": "2019-12-26",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcPpNEnHEwbcW07S5CYuDst7bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20190392313&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=oywMt916zVlms8g9%252BRH118RHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2021-08-06",
                    "XAP": "2019EP-0180750",
                    "APD": "2019-06-18",
                    "APID": "140195300",
                    "REG_LINK": "https://register.epo.org/application?number=EP19180750",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FrmUR8kj0Yg1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP3584659",
                            "KIND": "A1",
                            "XPN": "EP3584659",
                            "V_PNID": "EP-3584659A1-8",
                            "DATE": "2019-12-25",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=4i+QpXxItqjkjqqjIvshtfEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP3584659&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FrmUR8kj0Yg1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2038-06-20",
                    "XAP": "2018IT-0006499",
                    "APD": "2018-06-20",
                    "APID": "142313314",
                    "REG_LINK": "",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=gF3DvIxVysxA3Wv6jvvndcExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "IT201800006499",
                            "KIND": "A1",
                            "XPN": "IT201800006499",
                            "V_PNID": "IT-201800006499A1-0",
                            "DATE": "2019-12-20",
                            "STG": "Application for patent of invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=PknmpDUQ+ywzz1tHlmpCV1uzMu9fCKL8O3DJpHhvzNq8mcFoz1yzz1k0PkWksrrN&n=1&xpn=IT201800006499&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=gF3DvIxVysxA3Wv6jvvndcExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP3584659_A1",
            "EPRD": "2018-06-20",
            "PN": "EP3584659           A1 2019-12-25 [EP3584659]<br/>US11436485          B2 2022-09-06 [US11436485]<br/>US20190392313       A1 2019-12-26 [US20190392313]<br/>CN110618670         A  2019-12-27 [CN110618670]<br/>IT201800006499      A1 2019-12-20 [IT201800006499]",
            "ADB": "(EP3584659)<br/><p>Each neural network is configured during a training step advantageously performed during the first operating step of the structure.</p><p>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p>The method and system object of the invention make it advantageously possible to identify damage in aeronautical structures, with increased safety, reduced maintenance costs and the creation of less conservative designs and therefore lighter structures.</p><p>Advantageously, in order to allow operation of the system also in the case of damage to the structure in the vicinity of some of the detection points, i.e. where there is damage to the sensors, a surplus is created by increasing the number of relevant detection points so as to have a certain number of additional backup sensors.</p><p>In a currently preferred embodiment, the structure being examined is equipped with a limited number of displacement sensors or meters located in relevant points, such as mechanical displacement transducers or transducers operating according to optical or interferometric techniques.</p><p>In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally but may cause considerable damage inside the structure (for example, delamination).</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=5<br/>PNAAGE=22<br/>NBPA=1; <br/>ALLCT=14; SCT=0; NSCT=14; <br/>ALLCTG=1; SCTG=0; NSCTG=1; <br/>AFS=14; ACC=14; AMCC=4; <br/>IGEN=0.0; IORG=0.83; IRAD=0.89; <br/>IMPI=1.6; MACI=1.88; PASI=3.02; PAVI=4.05; ",
            "PTCC": "(EP3665454)<br/>CC=EP EED=2038-08-09 STATUS=GRANTED APID=143174938 APD=2018-08-09 XPN=EP3665454 PD=2020-06-17 PD=2022-01-26 EPD=2020-06-17 LPD=2022-01-26 PDG=2022-01-26 <br/>CC=DE EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/>CC=FR EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/>CC=GB EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/>CC=IT EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/>CC=NL EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/>CC=SE EED=2038-08-09 STATUS=GRANTED APID=143174938 XPN=EP3665454 PDG=2022-01-26 <br/><br/>(US11187588)<br/>CC=US EED=2038-08-17 STATUS=GRANTED APID=142447152 APD=2018-08-09 XPN=US20200256736 PD=2020-08-13 PD=2021-11-30 EPD=2020-08-13 LPD=2021-11-30 PDG=2021-11-30 <br/><br/>(WO201930705)<br/>CC=EP EED=2038-08-09 STATUS=GRANTED APID=143174938 APD=2018-08-09 XPN=EP3665454 PD=2020-06-17 PD=2022-01-26 EPD=2020-06-17 LPD=2022-01-26 PDG=2022-01-26 <br/>CC=IL EED=2038-08-09 STATUS=GRANTED APID=143191662 APD=2020-03-11 XPN=IL-273218 PD=2020-05-31 PD=2023-06-01 PD=2023-10-01 EPD=2020-05-31 LPD=2023-10-01 PDG=2023-06-01 <br/>CC=JP EED=2038-08-09 STATUS=GRANTED APID=146439786 APD=2018-08-09 XPN=JP2020534513 PD=2020-11-26 PD=2023-08-16 EPD=2020-11-26 LPD=2023-08-16 PDG=2023-08-16 <br/>CC=US EED=2038-08-17 STATUS=GRANTED APID=142447152 APD=2018-08-09 XPN=US20200256736 PD=2020-08-13 PD=2021-11-30 EPD=2020-08-13 LPD=2021-11-30 PDG=2021-11-30 <br/><br/>(JP7328209)<br/>CC=JP EED=2038-08-09 STATUS=GRANTED APID=146439786 APD=2018-08-09 XPN=JP2020534513 PD=2020-11-26 PD=2023-08-16 EPD=2020-11-26 LPD=2023-08-16 PDG=2023-08-16 <br/><br/>(IL-273218)<br/>CC=IL EED=2038-08-09 STATUS=GRANTED APID=143191662 APD=2020-03-11 XPN=IL-273218 PD=2020-05-31 PD=2023-06-01 PD=2023-10-01 EPD=2020-05-31 LPD=2023-10-01 PDG=2023-06-01 <br/>",
            "EPN": "WO2019/030705",
            "CTGN": "(WO201930705)<br/>FR3147475 111688822 WHO=EXAMINER SELF=N CAT=X",
            "LAPD": "2018-08-09",
            "STDN": "",
            "NPN": "5",
            "DESC": "<p><h1>CROSS-REFERENCE TO RELATED PATENT APPLICATIONS</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application is a 35 U.S.C. § 371 National Stage Application of PCT Application No. PCT/IB2018/056010, filed Aug. 9, 2018, which claims priority of European Patent Application No. 17425088.6 filed on Aug. 9, 2017, the entire contents of which are hereby incorporated by reference, in their entirety, for any purposes.</p><p><h1>TECHNICAL FIELD OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention concerns a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments and designed to simulate angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions.</p><p><span class=\"paragraph-number\">[0003]   </span>This apparatus constitutes an improved solution for the production of geometric and radiometric calibration and test equipment, generally known as Optical Ground Support Equipment (OGSE).</p><p><span class=\"paragraph-number\">[0004]   </span>This type of OGSE finds advantageous, although not exclusive, application in the production of electro-optical instruments for Assembly Integration and Test (AIT) and Assembly Integration and Verification (AIV) activities in the space/satellite and defence fields.</p><p><h1>STATE OF THE ART</h1></p><p><span class=\"paragraph-number\">[0005]   </span>Nowadays, OGSE is widely used for geometrically and radiometrically calibrating and testing electro-optical thermal-IR instruments developed both in the space and in the defence fields.</p><p><span class=\"paragraph-number\">[0006]   </span>Most known OGSE uses collimators based on offset parabolas and operate, as a general rule, by projecting, from infinity, an EM point source, commonly known as a source point, the image of which is then processed by the testing system with algorithms for position fixing/image identification and radiation signal measurement. In fact, the source point materializes an elementary source, taking into account that any angularly-extending object can be mathematically represented by the convolution of several source points.</p><p><span class=\"paragraph-number\">[0007]   </span>The convolution approach, in principle correct, has significant effects in terms of accuracy, reducing the test to virtual mathematical modelling and not, as is often requested, a direct measurement with optical stimulus, thus deferring the real operational check of the performance to the field test.</p><p><span class=\"paragraph-number\">[0008]   </span>The method of projecting the source point from infinity, although general from the mathematical standpoint, is not actually easy to use for defining radiometric scenarios that are very complex, static or variable over time and in the angular directions.</p><p><span class=\"paragraph-number\">[0009]   </span>Many known OGSE is equipped with external scanning systems, made with rotating platforms or, in more complex cases, integral with hexapod platforms, in order to scan Units Under Test (UUTs) under different angles of the projected points.</p><p><span class=\"paragraph-number\">[0010]   </span>This entails, on one hand, the use of expensive and accurate movement systems, in relation to the weight and bulk of the OGSE and/or UUTs, and, on the other hand, the need to recalibrate the UUTs based on the mutual position between the illuminators and the UUTs, because the systems are often subject to the perturbing effects of the system itself and of the environment.</p><p><span class=\"paragraph-number\">[0011]   </span>Some OGSE also exists that reproduces angularly-extending IR sources with sharp hot-cold transitions.</p><p><span class=\"paragraph-number\">[0012]   </span>However, such OGSE appear to be both hardly reconfigurable for different scenarios and hardly usable in dynamic situations.</p><p><h1>OBJECT AND SUMMARY OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0013]   </span>In the field of OGSE, the need is felt to develop methodologies and apparatuses of growing complexity for the geometric and radiometric calibration and testing of electro-optical instruments operating in the infrared-thermal band.</p><p><span class=\"paragraph-number\">[0014]   </span>In fact, while up until a few years ago test and calibration surveys were carried out when an electro-optical instrument was delivered and were generally limited to basic functional tests, today, due to an increasingly competitive scenario, instances of optical characterization of borderline situations, albeit operative and real, clearly emerge.</p><p><span class=\"paragraph-number\">[0015]   </span>To give a few examples:</p><p><span class=\"paragraph-number\">[0016]   </span>electro-optical attitude sensors for satellite use, for example on board Low Earth Orbit (LEO) satellites, are known that allow the attitude of a satellite passing over a stretch of land at low altitude (between 400 and 850 km) to be determined. This operating scenario has forced a substantial reassessment of the observation geometries and the radiometric characteristics of existing OGSE. In fact, at low altitudes, the land strip appears geometrically wide and, in contrast with the surrounding cold space, its thermal-IR emission is highly modulated by oblique viewing factors;</p><p><span class=\"paragraph-number\">[0017]   </span>in the avionics field, complex radiometric characterization surveys might become necessary for electro-optical thermal-IR instruments in order to perform optical measurements in the presence of high temperature gradients superimposed on the observed scene.</p><p><span class=\"paragraph-number\">[0018]   </span>In general, these circumstances, where the checks of performances of electro-optical thermal-IR instruments during operating conditions at the limit of the optical measurement methodologies are requested, have led the Applicant to reconsider illumination methods and the associated equipment for extending radiometric test and calibration configurations to complex operating circumstances.</p><p><span class=\"paragraph-number\">[0019]   </span>The object of the present invention is to provide an innovative geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments suitable for the accurate (in the geometric and radiometric sense) reproduction of one or more hot-cold transitions in a real scenario.</p><p><span class=\"paragraph-number\">[0020]   </span>This object is achieved by the present invention in so far as it relates to a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments and designed to simulate angularly-extending thermal-IR sources with different geometries and with emissions containing hot-cold transitions, as defined in the appended claims.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0021]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows a thermal emission of an angularly-extending, thermal-IR source with a thermal-IR emission containing a hot-cold transition.</p><p><span class=\"paragraph-number\">[0022]   </span><a href=\"#DRAWINGS\">FIG. 2</a> is a 3D representation of a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments according to a preferred embodiment of the present invention;</p><p><span class=\"paragraph-number\">[0023]   </span><a href=\"#DRAWINGS\">FIG. 3</a> shows an optical diagram of a telecentric IR collimator forming part of the apparatus shown in <a href=\"#DRAWINGS\">FIG. 2</a>;</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIG. 4</a> shows an optical diagram of a paraxial approximation of the apparatus shown in <a href=\"#DRAWINGS\">FIG. 2</a>; and</p><p><span class=\"paragraph-number\">[0025]   </span><a href=\"#DRAWINGS\">FIG. 5</a> shows a kit of interchangeable masks forming part of the apparatus shown in <a href=\"#DRAWINGS\">FIG. 2</a>.</p><br/><p><heading><u>Cross-Reference to Related Patent Applications</u></heading></p><p><span class=\"paragraph-number\">[0001]   </span>This application claims priority of <patcit dnum=\"EP17425088\" dnum-type=\"L\">European Patent Application No. 17425088.6 filed on 09/08/2017</patcit>.</p><p><heading><b><u>Technical Field of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention concerns a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments and designed to simulate angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions.</p><p><span class=\"paragraph-number\">[0003]   </span>This apparatus constitutes an improved solution for the production of geometric and radiometric calibration and test equipment, generally known as Optical Ground Support Equipment (OGSE).</p><p><span class=\"paragraph-number\">[0004]   </span>This type of OGSE finds advantageous, although not exclusive, application in the production of electro-optical instruments for Assembly Integration and Test (AIT) and Assembly Integration and Verification (AIV) activities in the space/satellite and defence fields.</p><p><heading><b><u>State of the Art</u></b></heading></p><p><span class=\"paragraph-number\">[0005]   </span>Nowadays, OGSE is widely used for geometrically and radiometrically calibrating and testing electro-optical thermal-IR instruments developed both in the space and in the defence fields.</p><p><span class=\"paragraph-number\">[0006]   </span>Most known OGSE uses collimators based on offset parabolas and operate, as a general rule, by projecting, from infinity, an EM point source, commonly known as a source point, the image of which is then processed by the testing system with algorithms for position fixing/image identification and radiation signal measurement. In fact, the source point materializes an elementary source, taking into account that any angularly-extending object can be mathematically represented by the convolution of several source points.</p><p><span class=\"paragraph-number\">[0007]   </span>The convolution approach, in principle correct, has significant effects in terms of accuracy, reducing the test to virtual mathematical modelling and not, as is often requested, a direct measurement with optical stimulus, thus deferring the real operational check of the performance to the field test.</p><p><span class=\"paragraph-number\">[0008]   </span>The method of projecting the source point from infinity, although general from the mathematical standpoint, is not actually easy to use for defining radiometric scenarios that are very complex, static or variable over time and in the angular directions.</p><p><span class=\"paragraph-number\">[0009]   </span>Many known OGSE is equipped with external scanning systems, made with rotating platforms or, in more complex cases, integral with hexapod platforms, in order to scan Units Under Test (UUTs) under different angles of the projected points.</p><p><span class=\"paragraph-number\">[0010]   </span>This entails, on one hand, the use of expensive and accurate movement systems, in relation to the weight and bulk of the OGSE and/or UUTs, and, on the other hand, the need to recalibrate the UUTs based on the mutual position between the illuminators and the UUTs, because the systems are often subject to the perturbing effects of the system itself and of the environment.</p><p><span class=\"paragraph-number\">[0011]   </span>Some OGSE also exists that reproduces angularly-extending IR sources with sharp hot-cold transitions.</p><p><span class=\"paragraph-number\">[0012]   </span>However, such OGSE appear to be both hardly reconfigurable for different scenarios and hardly usable in dynamic situations.</p><p><span class=\"paragraph-number\">[0013]   </span><patcit dnum=\"US5265958A\">US 5,265,958</patcit> discloses a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments and designed to simulate different angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions. The apparatus comprises an IR collimator, a thermal-IR source and a kit of masks.</p><p><heading><b><u>Object and Summary of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0014]   </span>In the field of OGSE, the need is felt to develop methodologies and apparatuses of growing complexity for the geometric and radiometric calibration and testing of electro-optical instruments operating in the infrared-thermal band.</p><p><span class=\"paragraph-number\">[0015]   </span>In fact, while up until a few years ago test and calibration surveys were carried out when an electro-optical instrument was delivered and were generally limited to basic functional tests, today, due to an increasingly competitive scenario, instances of optical characterization of borderline situations, albeit operative and real, clearly emerge.</p><p><span class=\"paragraph-number\">[0016]   </span>To give a few examples:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> electro-optical attitude sensors for satellite use, for example on board Low Earth Orbit (LEO) satellites, are known that allow the attitude of a satellite passing over a stretch of land at low altitude (between 400 and 850 km) to be determined. This operating scenario has forced a substantial reassessment of the observation geometries and the radiometric characteristics of existing OGSE. In fact, at low altitudes, the land strip appears geometrically wide and, in contrast with the surrounding cold space, its thermal-IR emission is highly modulated by oblique viewing factors;</li><br/><li> in the avionics field, complex radiometric characterization surveys might become necessary for electro-optical thermal-IR instruments in order to perform optical measurements in the presence of high temperature gradients superimposed on the observed scene.</li></ul></p><p><span class=\"paragraph-number\">[0017]   </span>In general, these circumstances, where the checks of performances of electro-optical thermal-IR instruments during operating conditions at the limit of the optical measurement methodologies are requested, have led the Applicant to reconsider illumination methods and the associated equipment for extending radiometric test and calibration configurations to complex operating circumstances.</p><p><span class=\"paragraph-number\">[0018]   </span>The object of the present invention is to provide an innovative geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments suitable for the accurate (in the geometric and radiometric sense) reproduction of one or more hot-cold transitions in a real scenario.</p><p><span class=\"paragraph-number\">[0019]   </span>This object is achieved by the present invention in so far as it relates to a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments and designed to simulate angularly-extending thermal-IR sources with different geometries and with emissions containing hot-cold transitions, as defined in the appended claims.</p><p><heading><b><u>Brief Description of the Drawings</u></b></heading></p><p><span class=\"paragraph-number\">[0020]   </span><ul compact=\"compact\" list-style=\"none\"><li> <figref>Figure 1</figref> shows a thermal emission of an angularly-extending, thermal-IR source with a thermal-IR emission containing a hot-cold transition.</li><br/><li> <figref>Figure 2</figref> is a 3D representation of a geometric and radiometric calibration and test apparatus for electro-optical thermal-IR instruments according to a preferred embodiment of the present invention;</li><br/><li> <figref>Figure 3</figref> shows an optical diagram of a telecentric IR collimator forming part of the apparatus shown in <figref>Figure 2</figref>;</li><br/><li> <figref>Figure 4</figref> shows an optical diagram of a paraxial approximation of the apparatus shown in <figref>Figure 2</figref>; and</li><br/><li> <figref>Figure 5</figref> shows a kit of interchangeable masks forming part of the apparatus shown in <figref>Figure 2</figref>.</li></ul></p><p><heading><b><u>Detailed Description of Preferred Embodiments of the Invention</u></b></heading></p><p><span class=\"paragraph-number\">[0021]   </span>The following description is provided to allow a skilled person in the field to implement and use the invention. Various modifications to the embodiments shown will be immediately obvious to experts and the generic principles described herein could be applied to other embodiments and applications without departing from the scope of protection of the present invention as defined in the appended claims. In consequence, the present invention is not intended to be limited to just the embodiments set forth herein, but is to be accorded the widest scope consistent with the principles and features disclosed herein and defined in the appended claims.</p><p><span class=\"paragraph-number\">[0022]   </span><figref>Figure 1</figref> schematically shows a thermal-IR emission of an angularly-extending thermal-IR source in a context where it is statically projected on an electro-optical instrument, or dynamically moved relative thereto, and in which there is a hot-cold transition between two (or more) different temperatures, designated as Thot and Tcold, respectively, the relative intensities of which can have a variable relation, both in terms of relative intensities and of the transition therebetween. In greater detail, <figref>Figure 1</figref> shows an example of a thermal-IR emission containing a sharp (diffractive) hot-cold transition (unbroken line) and a modulated hot-cold transition, in particular a linear one (broken line).</p><p><span class=\"paragraph-number\">[0023]   </span>The present invention concerns a geometric and radiometric calibration and test apparatus for thermal-IR (8÷16 µm) UUTs, for example those intended to be installed on satellites or aircraft, and designed to simulate angularly-extending thermal-IR sources with different geometries and with emissions containing hot-cold transitions.</p><p><span class=\"paragraph-number\">[0024]   </span>The design provides the apparatus with flexibility in angular and geometric morphology, in radiometry, and in the movement of the thermal-IR source.</p><p><span class=\"paragraph-number\">[0025]   </span>In a nutshell, the present invention provides a geometric and radiometric calibration and test apparatus comprising a telecentric wide-angle collimator on the focal plane of which a thermal-IR source is arranged. The source is spatially movable to be positionable and freely movable on the focal plane of the collimator and, expediently, to be also movable along the optical axis of the collimator to compensate for variations in focal length as the ambient temperature and the position of the UUT relative to the source, and also to simulate the response of the UUT to the vibrations of the platform on which the UUT is installed. An accompanying kit of easily interchangeable masks is also provided, each of which acts as a projected object that provide the wavefront of the thermal-IR radiations emitted by the thermal-IR source with geometric and radiometric properties such as to cause the thermal-IR radiations reproduced on the UUT's entrance pupil to contain different the hot-cold transition morphologies.</p><p><span class=\"paragraph-number\">[0026]   </span>The invention is therefore assimilable to a high-quality IR projector, where the angular extension of the thermal-IR emission is apodizable depending on the masks' shapes and on the law of motion that the source movement mechanism can induce to simulate the operating conditions of dynamic, i.e. temporally transitory, phenomena.</p><p><span class=\"paragraph-number\">[0027]   </span>In the case of angularly-extending sources with different geometries, the present invention significantly broadens the fields of application of existing point projectors, with the possibility of reproducing dynamic scenarios in small, thermally-controlled spaces.</p><p><span class=\"paragraph-number\">[0028]   </span>The geometric and radiometric calibration and test apparatus of the present invention enables real scenarios to be reproduced in terms of radiative contrast and related trajectories, which is difficult and laborious to reduce to simple operations of mathematical convolution of point sources.</p><p><span class=\"paragraph-number\">[0029]   </span>A method of illumination and a geometric and radiometric calibration and test apparatus suitable for industrial use in AIV/AIT lines for the production, calibration and testing of electro-optical thermal-IR instruments, for example, instruments intended to be installed on satellites or apparatuses in the defence sector, will now be described according to a preferred, but not limitative, embodiment of the invention.</p><p><span class=\"paragraph-number\">[0030]   </span>In the preferred embodiment shown in <figref>Figures 2</figref>, <figref>3 and 4</figref>, the geometric and radiometric calibration and test apparatus <b>1</b> is designed to illuminate an inlet aperture, indicated hereinafter by the term \"entrance pupil\", of a UUT with angularly-extending thermal-IR radiation containing a hot-cold transition.</p><p><span class=\"paragraph-number\">[0031]   </span>To illuminate the UUT with an angularly-extending thermal-IR radiation containing a hot-cold transition, the geometric and radiometric calibration and test apparatus <b>1</b> comprises:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> a thermal-IR collimator <b>2</b> (also referred hereinafter to as projector) having an optical axis <b>Z</b> and a focal plane <b>F</b> arranged on the opposite side of the collimator <b>2</b> with respect to the UUT's entrance pupil to be illuminated,</li><br/><li> a thermal-IR source <b>3</b> controllably movable relative to the collimator <b>2</b> to be arrangeable and displaceable on the focal plane <b>F</b> of the collimator <b>2,</b> and expediently also displaceable along the optical axis <b>Z</b> of the collimator <b>2,</b> and operable to radiate thermal-IR radiations towards the collimator <b>2,</b> and</li><br/><li> a kit of interchangeable masks <b>4,</b> also known as targets, selectively and removably arrangeable in front of the thermal-IR source <b>3,</b> so as to be integrally movable therewith, and having geometric and radiometric properties such as to cause the thermal-IR radiation reproduced on the UUT's entrance pupil to contain different hot-cold transitions.</li></ul></p><p><span class=\"paragraph-number\">[0032]   </span>The collimator <b>2</b> comprises telecentric collimating optics comprising a pair of spherical positive meniscus lenses orientated such that the concave surfaces face towards the thermal-IR source 3 and towards the UUS's entrance pupil, respectively.</p><p><span class=\"paragraph-number\">[0033]   </span>The meniscus lenses are expediently made of a high electrical and thermal conductivity optical germanium, for example n-doped optical-grade germanium, expediently with resistivity not higher than 3 ohm/cm, with a wide-band non-reflective treatment.</p><p><span class=\"paragraph-number\">[0034]   </span>The collimator <b>2</b> has an effective focal length f and a field angle Ω, the entrance pupil is placed at a distance q from the vertex of the closest lens, and the lenses are physically set apart at a distance d. X and Y are the tangential and sagittal directions normal to the optical axis Z.</p><p><span class=\"paragraph-number\">[0035]   </span>The collimator <b>2</b> is so sized as to be telecentric, i.e. such that every emitting point in its focal plane is projected on the UUT's entrance pupil with the same solid angle for each direction, thereby forming a constant radiometric flux as the field angle changes.</p><p><span class=\"paragraph-number\">[0036]   </span>It should be appreciated that, in the detail of the entrance pupil's dislocation, significantly different portions of the optics work at different directions, such portions being constituted by portions of a sphere identifiable by a certain height, indicated by r and referring to the point of intersection of the \"chief ray\" of the current field with respect to the line containing the optical axis of the collimating optics. This is combined with the specific requirement of using a high thermal and electrical conductivity germanium so as to minimize the creation of spatial thermal gradients that would alter the intensity of the radiation produced as a function of the emission angle.</p><p><span class=\"paragraph-number\">[0037]   </span>This configuration, with optical characteristics at the diffraction limits of the 8-16 micron band, functions as a collimator of a circular area with radius R=f<sup>∗</sup>tg(Ω/2), with f variable based on the chosen configuration and between 100 and 1000 mm, usable with field angles Ω up to 60° for focal lengths in the order of 100 mm, and, in the case of focal lengths of around a metre, up to approximately 20° overall.</p><p><span class=\"paragraph-number\">[0038]   </span>The collimator shown in <figref>Figure 2</figref> is sized to respect the specifications of OGSE designed for an electro-optical instrument for spatial application, equipped with the following first-order characteristics:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> effective focal length - f = 203 mm,</li><br/><li> total field angle - Ω = 40° (+/- 20°), and</li><br/><li> image plane size 2<sup>∗</sup>R=150 mm approx.</li></ul></p><p><span class=\"paragraph-number\">[0039]   </span>It should be appreciated that the above-indicated numerical data fails to represent a limitation on the concepts set forth and only represents an example of reduction to practice, it being clear that other numerical configurations may be expediently adopted.</p><p><span class=\"paragraph-number\">[0040]   </span>The collimator <b>2</b> is kept at a constant temperature just above the ambient temperature, stable within 0.5 °C, in order to ensure the repeatability of the radiometric quantity measurements by the UUT.</p><p><span class=\"paragraph-number\">[0041]   </span>The thermal-IR source <b>3</b> is designed such that:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> it can be mounted on a translational platform (not shown), expediently motorized, movable in the X and Y directions and, expediently, in the Z direction, which directions define a local orthogonal Cartesian reference system (machine coordinates system in jargon),</li><br/><li> it is thermally uncoupled to the collimator <b>2,</b> and</li><br/><li> it is thermally stable.</li></ul></p><p><span class=\"paragraph-number\">[0042]   </span>In one embodiment suitable for spatial applications, in particular LEO satellite applications, the thermal-IR source <b>3</b> may expediently be, but is not limited to being, made by means of a Peltier cell having a hot side facing the meniscus lenses of the collimator <b>2,</b> and may expediently be, but is not limited to being, made of a high thermal conductivity glass-ceramic material.</p><p><span class=\"paragraph-number\">[0043]   </span>The position of the thermal-IR source <b>3</b> may expediently be controlled by a computer programmed with an opportune dedicated software program.</p><p><span class=\"paragraph-number\">[0044]   </span>The thermal stability may be achieved for example by equipping the thermal-IR source 3 with an adequate heat dissipation structure, integral with the thermal-IR source <b>3.</b></p><p><span class=\"paragraph-number\">[0045]   </span><figref>Figure 4</figref> outlines the structure of the thermal-IR source <b>3,</b> and shows the presence of a specular concave surface (i.e., with low emissivity in the thermal-IR band) integral with the thermal-IR source <b>3,</b> so at to move therewith. The specular concave surface performs the dual function of heat dissipator for the thermal-IR source <b>3,</b> and, above all, due to the fact that it is provided with a concave radius of curvature, i.e. provided with optical powers, acts like a Coblenz cavity that condenses the thermal-IR radiation emitted by the collimator <b>2,</b> thus contributing to the creation of a \"cold background\" with respect to the thermal-IR source <b>3.</b> In other words, assuming that the thermal-IR source <b>3</b> is implemented by means of a Peltier cell with a hot side facing the collimator <b>2</b> and a cold side facing this concave surface, the latter will be sized (this meaning the radius of curvature and its relative position relative to the cold side of the cell) such that the thermal-IR radiation emitted by the collimator <b>2</b> is condensed on the cold side of the Peltier cell, which in this circumstance acts as a simple \"mirror\" that observes a cold trap (i.e. the side facing the cell's lenses).</p><p><span class=\"paragraph-number\">[0046]   </span>The entire opto-mechanical system must thus expediently comprise hollow walls provided with opportune baffles, to allow the flow of a fluid for thermos-regulating the lenses and the mechanical structure of the illuminator, for example, from an external chiller.</p><p><span class=\"paragraph-number\">[0047]   </span>A computer and dedicated software, an integral part of the equipment, thermally controls the thermal-IR source <b>3.</b></p><p><span class=\"paragraph-number\">[0048]   </span>The kit of masks <b>4</b> to be interchangeably coupled to the thermal-IR source <b>3</b> is formed by a series of rolled metal sheets that are appropriately perforated to provide the thermal-IR source <b>3</b> with geometries suitable for reproducing an angular apodization of the IR wavefront projected by the system to infinity.</p><p><span class=\"paragraph-number\">[0049]   </span>The masks <b>4</b> may, for example, have lateral dimensions of roughly 150÷200 mm, and may be made using a thin metal substrate, for example 100-200 µm, in particular, ferromagnetic for easy application to the thermal-IR source <b>3</b> by means of anchoring magnets opportunely arranged on the opposite side of the thermal-IR source <b>3,</b> namely that facing the Coblenz cavity, so resulting in the accessory mechanics needed for fixing the masks <b>4</b> to the thermal-IR source <b>3</b> being not seen by the collimator <b>2.</b></p><p><span class=\"paragraph-number\">[0050]   </span>The masks may be provided with any geometric shape suitable for reproducing an angular apodization. To mention a few simple examples, the masks <b>4</b> may be perforated in such way as to simulate:</p><p><ol compact=\"compact\"><li> A: an angularly-extending source with a sharp hot/cold transition,</li><br/><li> B: a point source,</li><br/><li> C: a modulated source having a cosine-type projective function that, for example, may be obtained by moving the focal plane <b>F</b> along the direction of the long side of the hole's elliptical profile,</li><br/><li> D: a multipoint source that enables better placement of the focal plane <b>F,</b> simultaneously in several points of the UUT's FOV (Field of View),</li><br/><li> E: a multi-pattern source for Modulation Transfer Function (MTF) measurements, i.e., a contrast function at different spatial frequencies, and</li><br/><li> F: more in general, any morphology suitable for reproducing an outline of any target.</li></ol></p><p><span class=\"paragraph-number\">[0051]   </span>The useful surface of the masks <b>4</b> is such as to ensure, with a margin, that the movement of the thermal-IR source <b>3</b> is within the effective UUT's FOV \"ω\".</p><p><span class=\"paragraph-number\">[0052]   </span>It is to be emphasized the set-up's flexibility, which, depending on the morphology of the masks <b>4</b> and their variable positions resulting from movement of the thermal-IR source <b>3,</b> allows thermal-IR emissions with hot-cold transitions with known transition-modulated apodization characteristics to be reproduced on the entrance pupil.</p><p><span class=\"paragraph-number\">[0053]   </span>These transitions may, in fact, be acquired by the UUT:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> both in a static mode, in which a mask <b>4</b> is stationary during acquisition according to its specific morphology, and</li><br/><li> in a controlled dynamic mode, in which a mask <b>4</b> is in motion during acquisition, thus reproducing the effect of acquisition of a transition in moving scenarios.</li></ul></p><p><span class=\"paragraph-number\">[0054]   </span>Among the possible solutions, that of producing the masks <b>4</b> in a ferromagnetic material, preferably with photolithographic methods to ensure accuracy of the geometric morphologies, with stable mechanical interfaces with the movable platform, is the one that appeared the most suitable for ensuring the correct profiling of the masks <b>4</b> and good thermal contact with the Peltier cell, which is made of a glass-ceramic material, with one or more permanent magnets located opposite to the optics (and hidden from view) for stably releasably coupling the masks <b>4</b> to the Peltier cell, thereby avoiding the use of screws, adhesives, etc., which might alter the scenario and have a negative effect on the calibration and testing of UUTs.</p><p><span class=\"paragraph-number\">[0055]   </span>Modulation of the relative intensities between the hot and cold parts is instead obtained by:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> adjusting the temperature of the Peltier cell via a current control, and</li><br/><li> adjusting the intrinsic emissivity characteristics of the material chosen for making the masks <b>4</b> (for example, alloys in ferritic steels that, among other things, possess the quality of exhibiting very low emissivity (&lt; 1%) in the thermal-IR band and heat conductivity characteristics similar to those of copper, can be expediently used).</li></ul></p><p><span class=\"paragraph-number\">[0056]   </span>With regards to the calibration of OGSE using an apparatus <b>1</b> according to the present invention, usually when trying to describe the qualities/potentialities in the presentation phase, often little or nothing is said in relation to the calibration techniques or methodologies and/or its characterization.</p><p><span class=\"paragraph-number\">[0057]   </span>To put it briefly, it is taken for granted that the OGSE, as manufactured, maintains stable geometric-radiometric characteristics over time. On the contrary, as a \"standard metre\", i.e., a radiometric and geometric reference, an apparatus with moving and emissive parts, it is necessary that it is subjected to periodic servicing or calibration, the most important of which are, in order of importance, of a radiometric type and a geometric type.</p><p><span class=\"paragraph-number\">[0058]   </span>Radiometric calibrations are those ascribed to the thermal-IR source <b>3</b> source only, statically intended, substantially to be carried out through the use of calibrated IR radiometers. The emissive elements are, by their nature, susceptible to deterioration, oxidation, and contamination from dust or simply from handling. Therefore, the OGSE is preferably equipped with suitable housings for protection against environmental contamination, and is preferably designed to be easily cleanable, interchangeable and maintainable.</p><p><span class=\"paragraph-number\">[0059]   </span>Geometric calibrations are instead those that assign, at a certain controlled x/y position of the translational platform on which the thermal-IR source <b>3</b> is mounted, a precise angular location (for example, dot-like in type B in <figref>Figure 5</figref>) produced by the thermal-IR source <b>3</b> on the entrance pupil of the electro-optical instrument to be tested or calibrated.</p><p><span class=\"paragraph-number\">[0060]   </span>Being an infrared device that, by its nature, produces EM radiations invisible to the human eye or conventional detectors, kits working in the visible bands can be expediently provided that are intended for:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> identification/materialization of the optical axis and the angular directions produced by the EM radiation,</li><br/><li> materialization of the entrance pupil plane, fatally critical if not carefully identified, and</li><br/><li> accuracy and repeatability of the translations of the servo-systems assigned to moving the focal plane <b>F.</b></li></ul></p><p><span class=\"paragraph-number\">[0061]   </span>The innovative aspects and technical advantages of the present invention may be immediately appreciated from the foregoing description, in particular:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> the telecentric characteristic of the collimator <b>2,</b> i.e., each section of the focal plane transfers the same energy to the UUT independently of the location of the emitting point within the UUT's FOV;</li><br/><li> the application to cases of any kind of morphology of angularly-extending -thermal IR sources;</li><br/><li> the aptitude for use in static mode, i.e., the profile of the mask <b>4</b> projected in a specific and known position of the UUT's FOV, and in a dynamic mode, i.e., providing the focal plane <b>F</b> with a law of motion to cause the focal plane <b>3</b> to move along a known and precise trajectory over time, in order to simulate a transitory and repeatable radiative phenomenon;</li><br/><li> the considerable extension of the application fields and of the testing configurations, without prejudice to the capacity to include all the testing conditions already carried out with conventional OGSE;</li><br/><li> the mitigation of resorting to accessory apparatuses (screens, transit blocking in areas adjacent to that where testing is carried out, periodic recalibrations as the relative positions between illuminator and UUT change, etc.; in fact, the collimator <b>2</b> is sized with an angular projection margin with respect to the UUT's FOV, thereby limiting the variations in background radiation over time and in this way ensuring stability and repeatability in taking measurements;</li><br/><li> the considerable reduction in the space necessary for carrying out testing of the UUT, as it is optically more compact (compared to the chosen focal length) with respect to conventional OGSE, constituted by offset mirror systems.</li></ul></p><p><span class=\"paragraph-number\">[0062]   </span>The apparatus <b>1</b> according to the present invention constitutes a system that, in the case of angularly-extending thermal-IR sources, significantly broadens the application fields of existing point projectors, with the possibility of reproducing dynamic scenarios in small, thermally-controlled spaces.</p><p><span class=\"paragraph-number\">[0063]   </span>In fact, the apparatus <b>1</b> enables the reproduction of real scenarios in terms both of radiative contrast and of the related trajectories, which is difficult and laborious to trace back to simple operations of mathematical convolution of point sources.</p><p><span class=\"paragraph-number\">[0064]   </span>The apparatus <b>1</b> according to the present invention is therefore assimilable to that of a high-quality IR projector, where the angular extension of the thermal-IR source can be modulated according to the form given to the masks and by the laws of motion of the targets that reproduce the operating conditions of transitory (dynamic) phenomena over time.</p><p><span class=\"paragraph-number\">[0065]   </span>The application fields of the invention are numerous and heterogeneous within the scope of the optical-performance characterizations of a UUT.</p><p><span class=\"paragraph-number\">[0066]   </span>The main application fields are summarized below:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> UUT quality testing for the measurement of its paraxial parameters (focal length, distortion, effective FOV, etc.);</li><br/><li> UUT quality testing for the measurement of space resolution parameters, such as the Modulation Transfer Function (MTF) and Encircled Energy (EE), i.e., the normalized energy circumscribed in the size of a pixel of a radiometric or image sensor, as well as radiometric resolution parameters, such as the Minimum Resolvable Temperature Difference (MRTD);</li><br/><li> UUT quality testing when simultaneously illuminated by extended bodies (the scene) and point bodies (for example, the sun superimposed on the observed scene);</li><br/><li> laboratory apparatuses for \"focusing\" operations in the UUT AIT/AIV phases;</li><br/><li> simulators of real static and dynamic (over time) radiometric scenarios for civil, space and military uses; and</li><br/><li> robustness validation of UUTs' image recognition algorithms.</li></ul></p><p><span class=\"paragraph-number\">[0067]   </span>Finally, it is important to stress that the present invention overcomes the previously described limits of existing OGSE, preserving the characteristics thereof and embracing all the existing functionality thereof, but considerably extending the performance, with performance/cost/size benefits.</p><p><span class=\"paragraph-number\">[0068]   </span>In conclusion, it is clear that various modifications can be applied to the present invention without departing from the scope of the invention as defined in the appended claims.</p>",
            "CLMS": "(EP3665454)<br/><p>1. A geometric and radiometric calibration and test apparatus (<b>1</b>) for testing electro-optical thermal-IR instruments, the apparatus being designed to simulate different angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions;<br/> the geometric and radiometric calibration and test apparatus <b>(1)</b> comprising: :<br/>  - an IR collimator (<b>2</b>) having an optical axis (<b>Z</b>), a focal plane (<b>F</b>), and a focal length (<b>f</b>);<br/>  - a thermal-IR source (<b>3</b>) mounted to be controllably movable relative to the collimator (<b>2</b>), to be arrangeable and displaceable in the focal plane (<b>F</b>) of the collimator (<b>2</b>), and to be operable to radiate towards the collimator <b>(2)</b> thermal-IR radiations,<br/>  - a kit of masks (<b>4</b>) individually interchangeably arrangeable between the thermal-IR source (3) and the collimator (2) so as to integrally move with the thermal-IR source (3) to provide the wavefront of the thermal-IR radiations from the thermal-IR source <b>(3)</b> with geometric and radiometric properties such as to cause calibration or test patterns containing different hot-cold transitions to be reproduced on the electro-optical instrument to be calibrated or tested;<br/> means for measuring ambient temperature;<br/> a computer; and<br/> means for moving the thermal-IR source (3) and mask (4);<br/> the thermal-IR source (<b>3</b>) together with the mask (4) , being movable by the means for moving under control of the computer along the optical axis <b>(Z)</b> of the IR collimator <b>(2)</b> to compensate for variations in the focal length <b>(f)</b> of the IR collimator <b>(2)</b> due to ambient temperature changes.</p><p>2. The apparatus <b>(1)</b> of claim 1, wherein the collimator <b>(2)</b> is so sized as to be telecentric.</p><p>3. The apparatus <b>(1)</b> of claim 1 or 2, wherein the collimator <b>(2)</b> comprises a pair of spherical positive meniscus lenses with concave surfaces facing the thermal-IR source <b>(3)</b> and the electro-optical instrument to be calibrated or tested, respectively.</p><p>4. The apparatus <b>(1)</b> of claim 3, wherein the meniscus lenses of the collimator <b>(2)</b> are made of high electrical and thermal conductivity optical germanium.</p><p>5. The apparatus <b>(1)</b> of any of the preceding claims, wherein the thermal-IR source <b>(3)</b> is computer-controlled to move also along a tangential direction <b>(X)</b> and a sagittal direction <b>(Y)</b> normal to the optical axis <b>(Z)</b> of the collimator <b>(2).</b></p><p>6. The apparatus <b>(1)</b> of claim 5, wherein the thermal-IR source <b>(3)</b> comprises a Peltier cell with a hot side facing the collimator <b>(2).</b></p><p>7. The apparatus <b>(1)</b> of claim 6, wherein the thermal-IR source <b>(3)</b> is thermally stabilized by a specular concave surface with a low emissivity in the thermal-IR and arranged to face a cold side of the Peltier cell, so resulting in the specular concave surface acting both as a heat dissipator and as a Coblenz cavity condensing the thermal-IR radiation emitted by the collimator <b>(2),</b> so contributing to the formation of a cold background with respect to the thermal-IR source <b>(3).</b></p><p>8. The apparatus <b>(1)</b> of any of the preceding claims, wherein the masks <b>(4)</b> are so shaped as to angularly apodize the different hot-cold transitions projected on the electro-optical instrument to be calibrated or tested, when the masks <b>(4)</b> are moved in the focal plane <b>(F)</b> of the IR collimator <b>(2)</b> together with the thermal-IR source <b>(3).</b></p><p>9. The apparatus <b>(1)</b> of claim 8, wherein the masks <b>(4)</b> are so shaped as to simulate different morphologies of thermal-IR sources <b>(3)</b> comprising:<br/> - an angularly-extending thermal-IR source representing a sharp hot/cold transition,<br/> - a thermal-IR point source,<br/> - a modulated thermal-IT source having a cosine-type projective function,<br/> - a multipoint source, and<br/> - a multi-pattern source.</p><p>10. Use of an apparatus <b>(1)</b> according to any one of the preceding claims to simulate angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions for the geometric and radiometric calibration and testing of electro-optical thermal-IR instruments.</p>",
            "NPR": "2",
            "APID": "143174938",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G01J-001/00<br/>G01J-005/04<br/>G01J-005/08<br/>G01J-005/0806<br/>G01J-005/0808<br/>G01J-005/0831<br/>G01J-005/52<br/>G01J-005/53<br/>G01J-005/80",
            "ID": "83378996",
            "AB": "(EP3665454)<br/>A geometric and radiometric calibration and test apparatus (1) for electro-optical thermal-IR (8-12 micron) instruments and designed to simulate angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing hot-cold transitions. The apparatus (1) comprises an IR collimator (2) having an optical axis (Z) and a focal plane (F); a thermal-IR source (3) movable relative to the collimator (2) to be controllably arrangeable and displaceable in the focal plane (F) of the collimator (2), and operable to radiate thermal- IR radiations towards the collimator (2); and a kit of masks (4) interchangeably arrangeable in front of the thermal-IR source (3) and having geometric and radiometric properties to cause the thermal-IR radiation reproduced on the electro-optical instrument to be calibrated or tested to contain different hot-cold transitions.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FMdqH%252BQKgqz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2018-08-09",
            "PA": "LEONARDO",
            "PAAD": "(EP3665454)<br/>(PUB:EP-3665454B1-8)NAME=Leonardo S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101602613<br/><br/>(PUB:EP-3665454A1-8)NAME=Leonardo S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101602613<br/><br/><br/>(US11187588)<br/>(PUB:US-11187588B2-1)NAME=LEONARDO S.P.A.  , CITY=Rome , COUNTRY=IT , ATYP=Non-US Company<br/><br/>(PUB:US-20200256736A1-2)NAME=LEONARDO S.P.A.  , CITY=Roma , COUNTRY=IT<br/><br/><br/>(WO201930705)<br/>(PUB:WO-2019/030705A1-3)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 00195 Roma , POSTCODE=00195 , COUNTRY=IT<br/><br/><br/>(JP7328209)<br/>(PUB:JP-7328209B2-198)NAME=LEONARDO SPA  , REG=518160436<br/><br/>(PUB:JP-2020534513A-11)NAME=LEONARDO SPA  , REG=518160436<br/><br/><br/>(IL-273218)<br/>(PUB:IL-273218B2-54)NAME=.Leonardo S.P.A Piazza Monte Grappa 4 00195 Roma Italy , COUNTRY=IT<br/><br/>(PUB:IL-273218B1-54)NAME=.Leonardo S.P.A Piazza Monte Grappa 4 00195 Roma Italy , COUNTRY=IT<br/><br/>(PUB:IL-273218A-54)NAME=.Leonardo S.P.A Piazza Monte Grappa 4 00195 Roma Italy , COUNTRY=IT<br/>",
            "FAN": "83378996",
            "TI": "Geometric and radiometric calibration and test apparatus for testing electro-optical thermal-ir instruments",
            "TECD": "Measurement",
            "EPD": "2019-02-14",
            "ICLM": "(EP3665454)<br/><p>1. A geometric and radiometric calibration and test apparatus ( 1 ) for testing electro-optical thermal-IR instruments, the apparatus being designed to simulate different angularly-extending thermal-IR sources with different geometries and with thermal-IR emissions containing different hot-cold transitions; the geometric and radiometric calibration and test apparatus (1) comprising: : - an IR collimator ( 2 ) having an optical axis ( Z ), a focal plane ( F ), and a focal length ( f ); - a thermal-IR source ( 3 ) mounted to be controllably movable relative to the collimator ( 2 ), to be arrangeable and displaceable in the focal plane ( F ) of the collimator ( 2 ), and to be operable to radiate towards the collimator (2) thermal-IR radiations, - a kit of masks ( 4 ) individually interchangeably arrangeable between the thermal-IR source (3) and the collimator (2) so as to integrally move with the thermal-IR source (3) to provide the wavefront of the thermal-IR radiations from the thermal-IR source (3) with geometric and radiometric properties such as to cause calibration or test patterns containing different hot-cold transitions to be reproduced on the electro-optical instrument to be calibrated or tested; means for measuring ambient temperature; a computer; and means for moving the thermal-IR source (3) and mask (4); the thermal-IR source ( 3 ) together with the mask (4) , being movable by the means for moving under control of the computer along the optical axis (Z) of the IR collimator (2) to compensate for variations in the focal length (f) of the IR collimator (2) due to ambient temperature changes.</p>",
            "CTN": "(EP3665454)<br/>US5265958 3937582 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>US4832451 42640727 WHO=EXAMINER SELF=N CAT=I<br/>GB2517068 67236262 WHO=EXAMINER SELF=N CAT=A<br/>US20170016771 75180194 WHO=EXAMINER SELF=N CAT=A<br/><br/>(US11187588)<br/>US4626685 42566818 WHO=EXAMINER SELF=N<br/>US5265958 3937582 WHO=EXAMINER SELF=N<br/>US5756991 42997408 WHO=EXAMINER SELF=N<br/>US5926279 580154 WHO=EXAMINER SELF=N<br/>US6414305 43253915 WHO=EXAMINER SELF=N<br/>US8593622 52157472 WHO=EXAMINER SELF=N<br/>US4832451 42640727 WHO=APPLICANT SELF=N<br/>US20170016771 75180194 WHO=APPLICANT SELF=N<br/>GB2517068 67236262 WHO=APPLICANT SELF=N<br/><br/>(WO201930705)<br/>US5265958 3937582 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>US4832451 42640727 WHO=EXAMINER SELF=N CAT=I<br/>GB2517068 67236262 WHO=EXAMINER SELF=N CAT=A<br/>US20170016771 75180194 WHO=EXAMINER SELF=N CAT=A<br/><br/>(JP7328209)<br/>JP05500268 3937582 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>JP2005164346 32220123 WHO=EXAMINER SELF=N CAT=Y<br/>JP01097833 23169468 WHO=EXAMINER SELF=N CAT=Y<br/>WO200884548 22860573 WHO=EXAMINER SELF=N CAT=Y<br/>JP2007271578 22780662 WHO=EXAMINER SELF=N CAT=Y<br/>JP08286135 28786336 WHO=EXAMINER SELF=N CAT=Y<br/>US4832451 42640727 WHO=EXAMINER SELF=N<br/><br/>(IL-273218)<br/>US5265958 3937582 WHO=EXAMINER SELF=N CAT=X<br/>US4832451 42640727 WHO=EXAMINER SELF=N CAT=X",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2021-02-09",
                    "XAP": "2018WO-IB56010",
                    "APD": "2018-08-09",
                    "APID": "135062436",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2019030705&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8MQflCahV5Kp3fK9fdjSZJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2019/030705",
                            "KIND": "A1",
                            "XPN": "WO201930705",
                            "V_PNID": "WO-2019/030705A1-3",
                            "DATE": "2019-02-14",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCCQXFnaiJZZeonVC+dywuLYLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=WO201930705&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8MQflCahV5Kp3fK9fdjSZJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2038-08-09",
                            "XAP": "2020IL-0273218",
                            "APD": "2018-08-09",
                            "APID": "143191662",
                            "REG_LINK": "http://www.ilpatsearch.justice.gov.il/UI/MainPage.aspx",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fmuvOhyirtwbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "IL273218",
                                    "KIND": "B2",
                                    "XPN": "IL-273218",
                                    "V_PNID": "IL-273218B2-54",
                                    "DATE": "2023-10-01",
                                    "STG": "Granted patent",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=q8jkuojC8RBdVxohlrG/ckDJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=IL-273218&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fmuvOhyirtwbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "IL273218",
                                    "KIND": "B1",
                                    "XPN": "IL-273218",
                                    "V_PNID": "IL-273218B1-54",
                                    "DATE": "2023-06-01",
                                    "STG": "Granted Patent",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=q8jkuojC8RBdVxohlrG/cqxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=IL-273218&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fmuvOhyirtwbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "IL273218",
                                    "KIND": "A",
                                    "XPN": "IL-273218",
                                    "V_PNID": "IL-273218A-54",
                                    "DATE": "2020-05-31",
                                    "STG": "Application of patent for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=q8jkuojC8RBdVxohlrG/cl0zzUpwOsUC6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IL-273218&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=fmuvOhyirtwbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2038-08-09",
                            "XAP": "2020JP-0507082",
                            "APD": "2018-08-09",
                            "APID": "146439786",
                            "REG_LINK": "https://www.j-platpat.inpit.go.jp/web/all/top/BTmTopEnglishPage",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=pF8kpjucJdo1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "JP7328209",
                                    "KIND": "B2",
                                    "XPN": "JP7328209",
                                    "V_PNID": "JP-7328209B2-198",
                                    "DATE": "2023-08-16",
                                    "STG": "Published granted patent (Second level)  from 01-03-1996 onwards (Published examined patent application (Second level) 1971-1996)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=h4fuNf5WSX/H0dGzuvN3ZkDJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=JP7328209&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=pF8kpjucJdo1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "JP2020534513",
                                    "KIND": "A",
                                    "XPN": "JP2020534513",
                                    "V_PNID": "JP-2020534513A-11",
                                    "DATE": "2020-11-26",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=N5221X+da3+SAyDPfVUBZwMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=JP2020534513&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Un0g%252FW19GlqI8yomRaCxVrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2038-08-09",
                            "XAP": "2018EP-0765193",
                            "APD": "2018-08-09",
                            "APID": "143174938",
                            "REG_LINK": "https://register.epo.org/application?number=EP18765193",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FMdqH%252BQKgqz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP3665454",
                                    "KIND": "B1",
                                    "XPN": "EP3665454",
                                    "V_PNID": "EP-3665454B1-8",
                                    "DATE": "2022-01-26",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=qwkfe3KJ/ttNdP60tMpsNKxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP3665454&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FMdqH%252BQKgqz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP3665454",
                                    "KIND": "A1",
                                    "XPN": "EP3665454",
                                    "V_PNID": "EP-3665454A1-8",
                                    "DATE": "2020-06-17",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=qwkfe3KJ/ttNdP60tMpsNPEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP3665454&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FMdqH%252BQKgqz4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2038-08-17",
                            "XAP": "2018US-16637582",
                            "APD": "2018-08-09",
                            "APID": "142447152",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/16637582",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=9LzQ1u1UvHV5ZQmthCEqujNfFPLuVTJ9KaVWfLIclG0%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US11187588",
                                    "KIND": "B2",
                                    "XPN": "US11187588",
                                    "V_PNID": "US-11187588B2-1",
                                    "DATE": "2021-11-30",
                                    "STG": "Granted patent as second publication",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=HCOyy4WOJl6oLgIN2ZF2hFvfaQTfGAcAHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=US11187588&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=9LzQ1u1UvHV5ZQmthCEqujNfFPLuVTJ9KaVWfLIclG0%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "US20200256736",
                                    "KIND": "A1",
                                    "XPN": "US20200256736",
                                    "V_PNID": "US-20200256736A1-2",
                                    "DATE": "2020-08-13",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcPWUYF7nFJHNl90CpEah8ymbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20200256736&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=eYrJZRIb3VEAXvPzDnO6%252FsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                }
            ],
            "REP": "EP3665454_B1",
            "EPRD": "2017-08-09",
            "PN": "EP3665454           B1 2022-01-26 [EP3665454]<br/>EP3665454           A1 2020-06-17 [EP3665454]<br/>US11187588          B2 2021-11-30 [US11187588]<br/>US20200256736       A1 2020-08-13 [US20200256736]<br/>WO2019/030705       A1 2019-02-14 [WO201930705]<br/>JP7328209           B2 2023-08-16 [JP7328209]<br/>JP2020534513        A  2020-11-26 [JP2020534513]<br/>IL273218            B2 2023-10-01 [IL-273218]<br/>IL273218            B1 2023-06-01 [IL-273218]<br/>IL273218            A  2020-05-31 [IL-273218]",
            "ADB": "(EP3665454)<br/><p>To mention a few simple examples, the masks 4 may be perforated in such way as to simulate: A: an angularly-extending source with a sharp hot/cold transition, B: a point source, C: a modulated source having a cosine-type projective function that, for example, may be obtained by moving the focal plane F along the direction of the long side of the hole's elliptical profile, D: a multipoint source that enables better placement of the focal plane F, simultaneously in several points of the UUT's FOV (Field of View), E: a multi-pattern source for Modulation Transfer Function (MTF) measurements, i.e., a contrast function at different spatial frequencies, and F: more in general, any morphology suitable for reproducing an outline of any target.</p><p>An accompanying kit of easily interchangeable masks is also provided, each of which acts as a projected object that provide the wavefront of the thermal-IR radiations emitted by the thermal-IR source with geometric and radiometric properties such as to cause the thermal-IR radiations reproduced on the UUT's entrance pupil to contain different the hot-cold transition morphologies.</p><p>The geometric and radiometric calibration and test apparatus of the present invention enables real scenarios to be reproduced in terms of radiative contrast and related trajectories, which is difficult and laborious to reduce to simple operations of mathematical convolution of point sources.</p><p>The method of projecting the source point from infinity, although general from the mathematical standpoint, is not actually easy to use for defining radiometric scenarios that are very complex, static or variable over time and in the angular directions.</p>"
        },
        {
            "FNUM": "APAGE=0<br/>NBPC=6<br/>PNAAGE=17<br/>NBPA=1; <br/>ALLCT=9; SCT=0; NSCT=9; <br/>ALLCTG=8; SCTG=0; NSCTG=8; <br/>AFS=6; ACC=6; AMCC=2; <br/>IGEN=0.92; IORG=0.84; IRAD=0.97; <br/>IMPI=3.47; MACI=0.7; PASI=2.37; PAVI=2.09; ",
            "PTCC": "(EP2893360)<br/>CC=EP EED=2033-09-05 STATUS=GRANTED APID=103800471 APD=2013-09-05 XPN=EP2893360 PD=2015-07-15 PD=2018-07-11 EPD=2015-07-15 LPD=2018-07-11 PDG=2018-07-11 <br/>CC=DE EED=2033-09-05 STATUS=GRANTED APID=103800471 XPN=EP2893360 PDG=2018-07-11 <br/>CC=ES EED=2033-09-05 STATUS=GRANTED APID=131702158 APD=2013-09-05 XPN=ES2685754 PD=2018-10-11 EPD=2018-10-11 LPD=2018-10-11 PDG=2018-10-11 <br/>CC=FR EED=2033-09-05 STATUS=GRANTED APID=103800471 XPN=EP2893360 PDG=2018-07-11 <br/>CC=GB EED=2033-09-05 STATUS=GRANTED APID=103800471 XPN=EP2893360 PDG=2018-07-11 <br/>CC=IT EED=2033-09-05 STATUS=GRANTED APID=103800471 XPN=EP2893360 PDG=2018-07-11 <br/><br/>(WO201437902)<br/>CC=CA EED=2033-09-05 STATUS=GRANTED APID=101736029 APD=2013-09-05 XPN=CA2883054 PD=2014-03-13 PD=2021-06-08 EPD=2014-03-13 LPD=2021-06-08 PDG=2021-06-08 <br/>CC=EP EED=2033-09-05 STATUS=GRANTED APID=103800471 APD=2013-09-05 XPN=EP2893360 PD=2015-07-15 PD=2018-07-11 EPD=2015-07-15 LPD=2018-07-11 PDG=2018-07-11 <br/>CC=ES EED=2033-09-05 STATUS=GRANTED APID=131702158 APD=2013-09-05 XPN=ES2685754 PD=2018-10-11 EPD=2018-10-11 LPD=2018-10-11 PDG=2018-10-11 <br/><br/>(CA2883054)<br/>CC=CA EED=2033-09-05 STATUS=GRANTED APID=101736029 APD=2013-09-05 XPN=CA2883054 PD=2014-03-13 PD=2021-06-08 EPD=2014-03-13 LPD=2021-06-08 PDG=2021-06-08 <br/><br/>(ES2685754)<br/>CC=ES EED=2033-09-05 STATUS=GRANTED APID=131702158 APD=2013-09-05 XPN=ES2685754 PD=2018-10-11 EPD=2018-10-11 LPD=2018-10-11 PDG=2018-10-11 <br/>",
            "EPN": "CA2883054",
            "CTGN": "(EP2893360)<br/>CN108593964 81479373 WHO=EXAMINER SELF=N CAT=A<br/><br/>(US20150219512)<br/>US20170329350 77782658 WHO=EXAMINER SELF=N CAT=103<br/>US10296013 77782658 WHO=EXAMINER SELF=N<br/>US20180118370 79526401 WHO=EXAMINER SELF=N CAT=103<br/>CN108593964 81479373 WHO=EXAMINER SELF=N CAT=A<br/>US10654585 79526401 WHO=EXAMINER SELF=N<br/>CN110308304B 86233597 WHO=EXAMINER SELF=N CAT=A<br/>US11796558 93913546 WHO=EXAMINER SELF=N<br/>US11808781 100307259 WHO=EXAMINER SELF=N<br/>US20220178964 100307259 WHO=EXAMINER SELF=N CAT=103<br/>US11410058 88885254 WHO=APPLICANT SELF=N<br/><br/>(WO201437902)<br/>EP2957967 71788971 WHO=EXAMINER SELF=N CAT=X CAT=A<br/>WO2017201037 77782658 WHO=EXAMINER SELF=N CAT=A<br/>US9759560 71788971 WHO=APPLICANT SELF=N<br/>EP2957967 71788971 WHO=APPLICANT SELF=N",
            "LAPD": "2013-09-05",
            "STDN": "",
            "NPN": "6",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>The present disclosure relates to a method and system of calculation and consolidation of flight parameters of an aircraft.</p><p><h1>BACKGROUND ART</h1></p><p><span class=\"paragraph-number\">[0002]   </span>Almost all operating aircraft, both civil and military, use sensors that protrude from the surfaces of the aircraft, in particular floating fins for measuring incidence and sideslip angles. The sensors are able to directly measure quantities such as flow angles and local velocities and, in general, flight parameters useful for determining the aircraft's attitude, altitude and flight speed. The algorithms used for processing the data measured by these sensors, as well as their peculiarities tied to the location of the sensors on the aircraft, their characteristics and the system reliability/redundancy requirements, are developed for virtually the sole purpose of measurement calibration.</p><p><span class=\"paragraph-number\">[0003]   </span>Static pressure sensors of the type available on the market, for example pressure sensors made using MEMS technology, have the advantage of small size and weight and do not protrude from the surface on which they are mounted. The use of such pressure sensors is therefore desirable. However, to obtain one or more of the above-mentioned flight parameters starting from static pressure measurements, complex algorithms are needed, which require considerable calculating capacity. Known algorithms for the calculation of flight parameters starting from static pressure measurements are typically based on using artificial intelligence and neural networks and guarantee functionality for calculation of the flight parameters and detection of any failures in the pressure sensors.</p><p><span class=\"paragraph-number\">[0004]   </span>Document GB2432914 relates generally to air data sensing systems, such as flush air data systems (FADS), for use on an air vehicle for providing fault isolation in artificial intelligence based air data sensing systems, such as neural network based FADS.</p><p><span class=\"paragraph-number\">[0005]   </span>Document US 2011/238373 relates to in-flight calibration of aircraft pitot-static systems by modeling pressure error as a continuous function of airspeed. Measurements of static and differential pressure and Global Positioning System (GPS)-based ground speed measurements are utilized for computing pressure errors over a range of airspeed.</p><p><span class=\"paragraph-number\">[0006]   </span>Document U.S. Pat. No. 5,423,209 relates to a truncated pyramid-shape multi-hole Pitot probe and a flight velocity detection system using the truncated pyramid-shape multi-hole Pitot probe.</p><p><span class=\"paragraph-number\">[0007]   </span>Document EP2434296 relates generally to sensor systems and more specifically to airspeed sensor systems.</p><p><span class=\"paragraph-number\">[0008]   </span>Document US 2004/011124 pertains to a process for determining aerodynamic parameters and to a process for detecting a fault with a probe used to determine the aerodynamic parameters of the airflow surrounding an aircraft.</p><p><span class=\"paragraph-number\">[0009]   </span>However, solutions of known type have the drawback of requiring a high calculating capacity (with consequent energy consumption) and, if a failure of one or more pressure sensors is detected, do not allow the exclusion of this/these sensor(s). In practice, these solutions of known type “live” with the failure. The information coming from faulty sensors is still used in the calculation of the flight parameters.</p><p><h1>DISCLOSURE OF INVENTION</h1></p><p><span class=\"paragraph-number\">[0010]   </span>The object of the present disclosure is to provide a method and system of calculation and consolidation of flight parameters of an aircraft that overcome the drawbacks of the known art.</p><p><span class=\"paragraph-number\">[0011]   </span>According to the present disclosure, a method and system of calculation and consolidation of flight parameters of an aircraft are provided as defined in the appended claims.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0012]   </span>For a better understanding of the present disclosure, some preferred embodiments will now be described, purely by way of a non-limitative example, with reference to the attached drawings, where:</p><p><span class=\"paragraph-number\">[0013]   </span><a href=\"#DRAWINGS\">FIGS. 1</a><i>a </i>and <b>1</b><i>b </i>show views from above and below of an aircraft equipped with static pressure sensors at a plurality of locations; and</p><p><span class=\"paragraph-number\">[0014]   </span><a href=\"#DRAWINGS\">FIG. 2</a> shows, by means of a flowchart, a method of calculation and validation of flight parameters according to one embodiment of the present disclosure.</p><br/><p><heading><u>TECHNICAL FIELD</u></heading></p><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a method and system of calculation and consolidation of flight parameters of an aircraft.</p><p><heading><u>BACKGROUND ART</u></heading></p><p><span class=\"paragraph-number\">[0002]   </span>Almost all operating aircraft, both civil and military, use sensors that protrude from the surfaces of the aircraft, in particular floating fins for measuring incidence and sideslip angles. The sensors are able to directly measure quantities such as flow angles and local velocities and, in general, flight parameters useful for determining the aircraft's attitude, altitude and flight speed. The algorithms used for processing the data measured by these sensors, as well as their peculiarities tied to the location of the sensors on the aircraft, their characteristics and the system reliability/redundancy requirements, are developed for virtually the sole purpose of measurement calibration.</p><p><span class=\"paragraph-number\">[0003]   </span>Static pressure sensors of the type available on the market, for example pressure sensors made using MEMS technology, have the advantage of small size and weight and do not protrude from the surface on which they are mounted. The use of such pressure sensors is therefore desirable. However, to obtain one or more of the above-mentioned flight parameters starting from static pressure measurements, complex algorithms are needed, which require considerable calculating capacity. Known algorithms for the calculation of flight parameters starting from static pressure measurements are typically based on using artificial intelligence and neural networks and guarantee functionality for calculation of the flight parameters and detection of any failures in the pressure sensors.</p><p><span class=\"paragraph-number\">[0004]   </span>Document <patcit dnum=\"GB2432914A\">GB2432914</patcit> relates generally to air data sensing systems, such as flush air data systems (FADS), for use on an air vehicle for providing fault isolation in artificial intelligence based air data sensing systems, such as neural network based FADS.</p><p><span class=\"paragraph-number\">[0005]   </span>Document <patcit dnum=\"US2011238373A\">US 2011/238373</patcit> relates to in-flight calibration of aircraft pitot-static systems by modeling pressure error as a continuous function of airspeed. Measurements of static and differential pressure and Global Positioning System (GPS)-based ground speed measurements are utilized for computing pressure errors over a range of airspeed.</p><p><span class=\"paragraph-number\">[0006]   </span>Document <patcit dnum=\"US5423209A\">US 5,423,209</patcit> relates to a truncated pyramid-shape multi-hole Pitot probe and a flight velocity detection system using the truncated pyramid-shape multi-hole Pitot probe.</p><p><span class=\"paragraph-number\">[0007]   </span>Document <patcit dnum=\"EP2434296A\">EP2434296</patcit> relates generally to sensor systems and more specifically to airspeed sensor systems.</p><p><span class=\"paragraph-number\">[0008]   </span>Document <patcit dnum=\"US2004011124A\">US 2004/011124</patcit> pertains to a process for determining aerodynamic parameters and to a process for detecting a fault with a probe used to determine the aerodynamic parameters of the airflow surrounding an aircraft.</p><p><span class=\"paragraph-number\">[0009]   </span>However, solutions of known type have the drawback of requiring a high calculating capacity (with consequent energy consumption) and, if a failure of one or more pressure sensors is detected, do not allow the exclusion of this/these sensor(s). In practice, these solutions of known type \"live\" with the failure. The information coming from faulty sensors is still used in the calculation of the flight parameters.</p><p><heading><u>DISCLOSURE OF INVENTION</u></heading></p><p><span class=\"paragraph-number\">[0010]   </span>The object of the present invention is to provide a method and system of calculation and consolidation of flight parameters of an aircraft that overcome the drawbacks of the known art.</p><p><span class=\"paragraph-number\">[0011]   </span>According to the present invention, a method and system of calculation and consolidation of flight parameters of an aircraft are provided as defined in the appended claims.</p><p><heading><u>BRIEF DESCRIPTION OF THE DRAWINGS</u></heading></p><p><span class=\"paragraph-number\">[0012]   </span>For a better understanding of the present invention, some preferred embodiments will now be described, purely by way of a non-limitative example, with reference to the attached drawings, where:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figures 1a and 1b</figref> show views from above and below of an aircraft equipped with static pressure sensors at a plurality of locations; and</li><br/><li> <figref>Figure 2</figref> shows, by means of a flowchart, a method of calculation and validation of flight parameters according to one embodiment of the present invention.</li></ul></p><p><heading><u>BEST MODE FOR CARRYING OUT THE INVENTION</u></heading></p><p><span class=\"paragraph-number\">[0013]   </span>The method according to the present invention combines improved flight parameter calculation functionality with functionality for identifying and isolating malfunctioning sensors.</p><p><span class=\"paragraph-number\">[0014]   </span>In particular, the method according to the present invention is based on the use of mathematical and physical models that bind the flight parameters to be calculated (or, more in general, state variables) to parameters measured in flight (local static pressures). The use of these models enables easier validation of the entire process with respect to the known art, with positive repercussions in terms of traceability and verification in a certification procedure.</p><p><span class=\"paragraph-number\">[0015]   </span>The local static pressure measurements are obtained by using a plurality N of pressure sensors S<sub>1</sub>-S<sub>N</sub>, of known type and available on the market, positioned in a plurality of respective locations on an aircraft. The pressure sensors can be of any type and made using any manufacturing technology (for example, MEMS technology), provided that they can be \"buried\" in the body of the aircraft in <figref>Figures 1a and 1b</figref>, in the sense that they do not significantly protrude from the surface of the aircraft's body. For example, such sensors do not significantly protrude when they do not constitute a radar signature element.</p><p><span class=\"paragraph-number\">[0016]   </span><figref>Figures 1a and 1b</figref> show an aircraft 1 by way of example, seen respectively from above and below, and comprising a plurality N of pressure sensors S<sub>1</sub>-S<sub>N</sub> with each one arranged at a respective location i<sub>1</sub>-i<sub>N</sub> on the aircraft 1 and possible housed in a respective casing able to protect each respective sensor from the external environment. In particular, each sensor S<sub>1</sub>-S<sub>N</sub> is integrated into the body of the aircraft 1 such that it is substantially coplanar with the body of the aircraft 1 at the location i<sub>1</sub>-i<sub>N</sub> in which it is positioned, or arranged within the body of the aircraft 1. In general, the sensors S<sub>1</sub>-S<sub>N</sub>, or in any case the casings that house a respective sensor S<sub>1</sub>-S<sub>N</sub>, do not protrude from the surface of the body of the aircraft 1 at the locations i<sub>1</sub>-i<sub>N</sub> where they are positioned. In order to allow the sensors S<sub>1</sub>-S<sub>N</sub> to correctly acquire static pressure information, the body of the aircraft 1 has one or more holes (not shown) at each location i<sub>1</sub>-i<sub>N</sub> that form the only interface of the pressure sensors S<sub>1</sub>-S<sub>N</sub> with the outside of the aircraft 1. The use of sensors integrated in the body of the aircraft 1 ensures a low contribution of the sensors S<sub>1</sub>-S<sub>N</sub> to the radar signature of the aircraft 1.</p><p><span class=\"paragraph-number\">[0017]   </span>As mentioned, in use, each sensor S<sub>1</sub>-S<sub>N</sub> detects a static pressure value at location i<sub>1</sub>-i<sub>N</sub>, and generates a transduced signal X<sub>1</sub>-X<sub>N</sub> indicative of the static pressure value measured at a given moment in time (or, alternatively, an average value over a predetermined period of time). The transduced signal X<sub>1</sub>-X<sub>N</sub> is, in particular, an electrical signal, suitable for being received and processed by a computer 5, placed on board the aircraft 1. The computer 5 is further configured to implement a calculation algorithm of the type shown in the flowchart in <figref>Figure 2</figref>.</p><p><span class=\"paragraph-number\">[0018]   </span>The number of sensors S<sub>1</sub>-S<sub>N</sub> is chosen so as to comply with the system's redundancy and reliability requirements and therefore so as to support a number of failures of single sensors S<sub>1</sub>-S<sub>N</sub> without compromising the calculating capacity of the flight parameters, keeping their accuracy within a required limit (depending, for example, on the required aircraft-level specifications, as provided by the aircraft's designer to ensure controllability of the aircraft, and/or on the basis of any national legislations. The static pressure information of a single sensor S<sub>1</sub>-S<sub>N</sub> actually weighs on the calculated value of the flight parameters differently according to the total number N of sensors S<sub>1</sub>-S<sub>N</sub>: the larger the total number N of sensors S<sub>1</sub>-S<sub>N</sub>, the smaller this weight. The applicant has established that an ideal number N of sensors S<sub>1</sub>-S<sub>N</sub> (in terms of accuracy of calculated flight parameter values and resilience to possible failures) is 9. In general, it is preferable to have N≥7. Nevertheless, it is clear that it is possible to calculate flight parameters according to the present invention also using a number N of sensors S<sub>1</sub>-S<sub>N</sub> less than 7, accepting a drop in the accuracy of the calculated flight parameters values and a reduced ability to compensate for the possible failure of one or more sensors S<sub>1</sub>-S<sub>N</sub>.</p><p><span class=\"paragraph-number\">[0019]   </span>The choice of the locations i<sub>1</sub>-i<sub>N</sub> for the sensors S<sub>1</sub>-S<sub>N</sub> on aircraft 1 is guided by the need to maximize the sensitivity of the acquired pressure values to variations in the flight parameters during the flight of the aircraft 1. Assessments for defining the \"best\" locations can be carried out, for example, by using computer simulators.</p><p><span class=\"paragraph-number\">[0020]   </span>The applicant has established that the areas where changes in pressure corresponding to variations in the flight parameters (i.e. the gradients) are greatest (absolute values intended) are locations i<sub>1</sub>-i<sub>N</sub> shown in <figref>Figures 1a and 1b</figref>.</p><p><span class=\"paragraph-number\">[0021]   </span><figref>Figure 2</figref> shows, by means of a flowchart, the steps a method of calculation of flight parameters starting from the pressure measurements taken by the sensors S<sub>1</sub>-S<sub>N</sub>. The mathematical model for calculation of the flight parameters is developed from the aerodynamic mathematical model, in particular the aerodynamic model in the following equation (1): </p><p><maths num=\"(1)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 14mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0001.tif&width=133mm&height=14mm\"/></maths></p><p> where P<sub>loci</sub> is the local static pressure measured by a sensor S<sub>1</sub>-S<sub>N</sub> at the respective location i<sub>1</sub>-i<sub>N</sub>, AOA is the angle of attack (sometimes called the angle of incidence) and indicated by letter α, AOS is the angle of sideslip and indicated by letter β, Mach represents the flight Mach number, Ps<sub>∞</sub> is the flight static pressure, Cp<sub>i</sub> is the pressure coefficient related to the location i<sub>1</sub>-i<sub>N</sub> considered, and γ is the ratio between specific heat at constant pressure and the specific heat at constant volume and is a constant having a value, for air, of between 1.3 and 1.5, in particular approximately 1.4 in the operating temperature range (between -40 and +40 °C).</p><p><span class=\"paragraph-number\">[0022]   </span>The pressure coefficient Cp<sub>i</sub> represents the link between the flight parameters to be calculated (state variables, Ps<sub>∞</sub>, AOA, AOS and Mach) and the local static pressures P<sub>loci</sub> measured in flight (dependent on the flight parameters AOA, AOS and Mach). The values of the pressure coefficient Cp<sub>i</sub> at the various locations i<sub>1</sub>-i<sub>N</sub> is obtained by using computer simulatorsand/or experimental testing in wind tunnels. The thus-obtained values for the pressure coefficient Cp<sub>i</sub> are then tabulated in matrix form.</p><p><span class=\"paragraph-number\">[0023]   </span>In greater detail, with regards to an experimental approach, construction of the arrays of Cp<sub>i</sub> values is achieved as specified in steps a - f below:</p><p><ol compact=\"compact\"><li> a. A Mach value is set;</li><br/><li> b. An angle of sideslip AOS value of zero is set;</li><br/><li> c. The value of the angle of attack AOA is varied in predetermined steps, generally between 0.5 degrees and 1.0 degree; a Cp<sub>i</sub> value is obtained for each pair of values (AOS; AOA) ;</li><br/><li> d. Step c is repeated, setting a non-zero value for the angle of sideslip AOS; in particular, the repetition of step c must be carried out the same number of times as the values of angle of sideslip AOS for which it is intended to collect Cp<sub>i</sub> values. In general, for AOS, values between 0 degrees and 10 degrees with a 2-degree step, both positive and negative, are selected;</li><br/><li> e. For each pair of values (AOS; AOA), a Cp<sub>i</sub> value is acquired on the basis of the previous step;</li><br/><li> f. Steps b-e are repeated, setting a Mach value different from the value set in step a; in particular the repetition of steps b-f must be carried out the same number of times as the values of Mach for which it is intended to collect Cp<sub>i</sub> values. In general, Mach values between 0.2 and the maximum envisaged by requirements are selected, with a variable step and preferably closer together near to the maximum (for example, a step of 0.1). At low Mach speeds, a step of 0.2 is adequate.</li></ol></p><p><span class=\"paragraph-number\">[0024]   </span>In this way, for each Mach value considered, it is possible to build a table (or array) M containing a plurality of pressure coefficient Cp<sub>i</sub> values for each pair of values (AOS; AOA) considered. Considering P flight Mach values, P arrays M<sub>1</sub>-M<sub>P</sub> are thus created.</p><p><span class=\"paragraph-number\">[0025]   </span>Characterizing equation (1) for each pressure sensor S<sub>1</sub>-S<sub>N</sub> present on the aircraft 1, gives a system of non-linear equations, in which the subscript \"i\" takes i values from 1 to N: </p><p><maths num=\"(2)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 10mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0002.tif&width=133mm&height=10mm\"/></maths></p><p> where the P<sub>loci</sub> variables constitute the known terms (measured by the sensors S<sub>1</sub>-S<sub>N</sub>) and Ps<sub>∞</sub>, AOA, AOS and Mach are the flight parameters to be calculated, which constitute the unknown terms of a system of equations as better expressed hereinafter. The function F<sub>i</sub> in equation (2) is the aerodynamic model as per equation (1).</p><p><span class=\"paragraph-number\">[0026]   </span>The main characteristic of this system of equations is nonlinearity, already present in the aerodynamic model, made explicit by the square of the Mach number (Mach<sup>2</sup>) and contained in the relation, defined in points and described by the arrays M<sub>1</sub>-M<sub>P</sub>, which bind the pressure coefficients Cp<sub>i</sub> and the flight parameters (Ps<sub>∞</sub>, AOA, AOS and Mach).</p><p><span class=\"paragraph-number\">[0027]   </span>Therefore, the resolution of the system of equations according to step 20 in <figref>Figure 2</figref> is interactively driven, starting from the consolidated solution at the previous time of calculation (initial condition) and performing linearization of the system. The iteration is implemented by making the system linear around the solution of the previous iteration and then calculating the variation of the state variables (in this case, the flight parameters Ps<sub>∞</sub>, AOA, AOS and Mach). The Newton-Raphson method, known in the literature, is used for this purpose.</p><p><span class=\"paragraph-number\">[0028]   </span>For a single sensor S<sub>1</sub>-S<sub>N</sub>, placed at the respective location i<sub>1</sub>-i<sub>N</sub>, the pressure variation with respect to the previous time can be written in the manner defined by the following equation (3) : </p><p><maths num=\"(3)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 149mm; height: 14mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0003.tif&width=149mm&height=14mm\"/></maths></p><p> where subscript \"i\" identifies each location i<sub>1</sub>-i<sub>N</sub>, and where VAR is the following vector: </p><p><maths num=\"(4)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0004.tif&width=133mm&height=6mm\"/></maths></p><p> where j is the index of the locations of vector VAR (i.e., for j=1, one has VAR<sub>1</sub>=Ps<sub>∞</sub>; for j=2, one has VAR<sub>2</sub>=Mach; for j=3, one has VAR<sub>3</sub>=AOA; for j=4, one has VAR<sub>4</sub>=AOS).</p><p><span class=\"paragraph-number\">[0029]   </span>By defining array J as the gradient of array F ([J] = [∇F]), the notation of equation (3) can be simplified as follows: </p><p><maths num=\"(5)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 13mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0005.tif&width=133mm&height=13mm\"/></maths></p><p><span class=\"paragraph-number\">[0030]   </span>It should be noted that quantities preceded by the symbol \"δ\" represent the perturbations with respect to values/quantities defined at the previous time of calculation. As already mentioned, the initial condition of each calculation cycle is set equal to the solution calculated at the time of the previous calculation. Backtracking, it is necessary to initialize the calculation the very first time, as there is obviously no previously calculated solution. The initialization is carried out using predetermined values, for example the values regarding the aircraft 1 when stationary (on the ground).</p><p><span class=\"paragraph-number\">[0031]   </span>Ignoring terms above the first order (i.e. performing a linearization operation) and considering equation (3) or, equivalently, equation (4), written for all the sensors and in matrix notation, it is possible to represent the system of equations (4) in the following manner: </p><p><maths num=\"(6)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 136mm; height: 27mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0006.tif&width=136mm&height=27mm\"/></maths></p><p> where the number of rows represents the number of information items (signals X<sub>1</sub>-X<sub>N</sub>) or, equivalently, the sensors S<sub>1</sub>-S<sub>N</sub> (used for calculation of the flight parameters) and the number of columns represents the number of unknown parameters (the actual flight parameters).</p><p><span class=\"paragraph-number\">[0032]   </span>Therefore, defining the flight parameters that must be calculated in the current iteration as PS<sub>∞NEW</sub>, AOA<sub>NEW</sub>, AOS<sub>NEW</sub> and Mach<sub>NEW</sub>, and those regarding the previous iteration (or the initialization parameters at the first iteration) as PS<sub>∞OLD</sub>, AOA<sub>OLD</sub>, AOS<sub>OLD</sub> and Mach<sub>OLD</sub>, gives: </p><p><maths num=\"(7)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 26mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0007.tif&width=133mm&height=26mm\"/></maths></p><p><span class=\"paragraph-number\">[0033]   </span>Formula (7) is solved iteratively until a consolidated solution is reached, as described hereinafter.</p><p><span class=\"paragraph-number\">[0034]   </span>Starting from formula (7), the state variables vector updated during the iterations (the one with the \"NEW\" suffix) is obtained by inverting array J as shown in the following formula (8): </p><p><maths num=\"(8)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 107mm; height: 24mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0008.tif&width=107mm&height=24mm\"/></maths></p><p><span class=\"paragraph-number\">[0035]   </span>For an overdetermined system (number of known parameters greater than those unknown), the inversion of array J is carried out by applying the linear or ordinary least squares method: </p><p><maths num=\"(9)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 134mm; height: 27mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0009.tif&width=134mm&height=27mm\"/></maths></p><p> where [(∇<i><sup>T</sup>F</i>)(∇<i>F</i>)]<sup><i>-</i>1</sup>∇<i><sup>T</sup>F</i> analytically represents the operation of inverting array J. This gives: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 77mm; height: 8mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0010.tif&width=77mm&height=8mm\"/></maths></p><p><span class=\"paragraph-number\">[0036]   </span>For each iteration, array J is calculated again using the CP<sub>i</sub> values stored in the P arrays M<sub>1</sub>-M<sub>P</sub>, starting from the values of the flight parameters calculated in the previous iteration (those with the \"OLD\" suffix). In other words, on the basis of the Mach, AOS and AOA values calculated in the previous iteration, for each location i<sub>1</sub>-i<sub>N</sub>, a corresponding value of Cp<sub>i</sub> is obtained from arrays M<sub>1</sub>-M<sub>P</sub>; then, using the thus-obtained value of Cp<sub>i</sub> together with the pressure value PS<sub>∞OLD</sub> in the \"F\" formula (equation (1)), it is possible to perform the operation described by formula (9). As already mentioned, these step are performed for each location i<sub>1</sub>-i<sub>N</sub>, or, in other words, for each sensor S<sub>1</sub>-S<sub>N</sub>.</p><p><span class=\"paragraph-number\">[0037]   </span>As mentioned above, on the first iteration, when current values of the flight parameters Ps<sub>∞OLD</sub>, AOA<sub>OLD</sub>, AOS<sub>OLD</sub> and Mach<sub>OLD</sub>, do not exist, the latter are considered having their ground value, with the aircraft stationary, prior to take-off. Otherwise, the values of PS<sub>∞OLD</sub>, AOA<sub>OLD</sub>, AOS<sub>OLD</sub> and Mach<sub>OLD</sub> used are the last values calculated (and stored) during the iterations.</p><p><span class=\"paragraph-number\">[0038]   </span>The convergence of the iterative calculation is evaluated by comparing the variation of the calculated flight parameters between two successive iterations and a predetermined tolerance Th: when the variation of these parameters is below the established tolerance Th, the iterative calculation has satisfied the convergence criterion. Instead, if the criterion is not satisfied, a new iteration is carried out using the updated state variables vector as the initial condition of the new iteration.</p><p><span class=\"paragraph-number\">[0039]   </span>The use of iterative algorithms makes the introduction of convergence control criteria important, these having the purpose of ensuring that it is always possible to obtain a solution for each instance of calculation.</p><p><span class=\"paragraph-number\">[0040]   </span>Therefore, in step 30 in <figref>Figure 2</figref>, an estimate is made of the plurality of static pressure measurements at the locations i<sub>1</sub>-i<sub>N</sub> of the sensors S<sub>1</sub>-S<sub>N</sub>.</p><p><span class=\"paragraph-number\">[0041]   </span>Once convergence of the iterative resolution process is achieved, the flight parameters calculated in step 20 are then used to provide an estimate of the static pressure values at the locations i<sub>1</sub>-i<sub>N</sub> by means of the aerodynamic model defined by equation (1). In practice, by inserting the values of the flight parameters Ps<sub>∞</sub>, AOA, AOS and Mach calculated in step 20 into equation (1), an estimated pressure value Y<sub>1</sub>-Y<sub>N</sub> for each sensor S<sub>1</sub>-S<sub>N</sub> is obtained.</p><p><span class=\"paragraph-number\">[0042]   </span>The comparison between these estimates Y<sub>1</sub>-Y<sub>N</sub> and the value X<sub>1</sub>-X<sub>N</sub> effectively measured at the locations i<sub>1</sub>-i<sub>N</sub> provides an indication of the quality of the solution found: the difference (or residual) between the estimated pressure values and the measured ones (X<sub>1</sub>-Y<sub>1</sub>, ..., X<sub>N</sub>-Y<sub>N</sub>) represents the calculation error or level of approximation of the flight parameters with respect to their \"real\" values.</p><p><span class=\"paragraph-number\">[0043]   </span>The comparison in step 30 enables, step 40, identifying possible failures of one or more sensors S<sub>1</sub>-S<sub>N</sub>.</p><p><span class=\"paragraph-number\">[0044]   </span>In fact, on the basis of the definition of \"residual\" (i.e., X<sub>1</sub>-Y<sub>1</sub>, ..., X<sub>N</sub>-Y<sub>N</sub>) provided in the previous paragraph, the functionality of identifying the failure of a single sensor S<sub>1</sub>-S<sub>N</sub> is obtained through the statistical analysis of these residuals, in particular by calculating the standard deviation of the residuals. To render the process of identifying individual failures effective and resilient, the residuals are calculated, as well as starting from the consolidated solution by using all \"N\" sensors S<sub>1</sub>-S<sub>N</sub> of the system, also from those obtained by the use of sensor subgroups. Each subgroup is constituted by all of the pressure sensors S<sub>1</sub>-S<sub>N</sub> less one. With this logical approach, it is possible to identify a number \"N\" of mutually different subgroups, each composed of N-1 sensors. By calculating a value of standard deviation of the residuals for each subgroup, it is possible to compare the values of standard deviation associated with each subgroup with one other. Failure identification is achieved by comparing these values of standard deviation with each another.</p><p><span class=\"paragraph-number\">[0045]   </span>The standard value associated with the subgroup that excludes the faulty sensor (i.e. that provides local static pressure values not consistent with those of the other locations) is significantly smaller than those of the other subgroups. By defining one or more thresholds, the pressure sensor missing from the subgroup having a standard value significantly smaller than those of the other subgroups is the pressure sensor that has failed.</p><p><span class=\"paragraph-number\">[0046]   </span>This monitoring of residuals enables identifying possible failure of a sensor, represented by possible \"freezing\" of the reported data or drifting in its reading.</p><p><span class=\"paragraph-number\">[0047]   </span>Once the failure of a single sensor is identified, step 50, the flight parameters that are consolidated and transmitted, for example to the flight control system, are those related to the subgroup that excludes the failed sensor, thus rendering the failure isolation functionality effective.</p><p><span class=\"paragraph-number\">[0048]   </span>From the foregoing, it is evident that the method according to the present invention represents a significant development with respect to that described in the literature and known in the state of the art.</p><p><span class=\"paragraph-number\">[0049]   </span>Application of the described methodology allows the calculation of flight parameters through the use of sensors buried in the surface of the aircraft, giving the system characteristics of low contribution to the radar signature during flight, less exposure to the risk of bird impact during flight, and easier handling for operators during ground operations (less risks of damaging the sensors).</p><p><span class=\"paragraph-number\">[0050]   </span>With regard to low radar signature aircraft, the main advantage of this methodology of calculation of the flight parameters is represented by the use of mathematical models that enable easier validation of the entire process, with positive repercussions in terms of traceability and verification in a possible certification procedure.</p><p><span class=\"paragraph-number\">[0051]   </span>Finally, it is clear that modifications and variants can be made to the invention set forth herein without departing from the scope of the present invention, as defined in the appended claims.</p>",
            "CLMS": "(EP2893360)<br/><p>1. A method for calculation and consolidation of a first plurality of flight parameters of an aircraft (1) including a second plurality, equal to or greater than said first plurality, of pressure sensors (S<sub>1</sub>-S<sub>N</sub>) arranged at respective locations (i<sub>1</sub>-i<sub>N</sub>) on the aircraft, each pressure sensor being configured to provide a transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) on the basis of a respective detected static pressure value, the method comprising the step of acquiring (10) said transduced pressure values (X<sub>1</sub>-X<sub>N</sub>) from the pressure sensors, and being <b>characterized by</b> further comprising the steps of:<br/> a- defining (20) a system of equations by associating with each transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) a respective non-linear mathematical model that is a function of said flight parameters and which defines a mathematical relationship between each transduced pressure value and the aerodynamic behaviour of the aircraft (1) at the location (i<sub>1</sub>-i<sub>N</sub>) of the pressure sensor (S<sub>1</sub>-S<sub>N</sub>) that has generated this transduced pressure value;<br/> b- iteratively solving (20) said system of equations, obtaining a current value of each of said flight parameters at each respective location (i<sub>1</sub>-i<sub>N</sub>);<br/> c- calculating (30), for each respective location (i<sub>1</sub>-i<sub>N</sub>), a respective estimated pressure value (Y<sub>1</sub>-Y<sub>N</sub>) by applying the current values of said flight parameters calculated for the respective location (i<sub>1</sub>-i<sub>N</sub>) to each mathematical model;<br/> d- comparing (30, 40) each transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) with the respective estimated pressure value (Y<sub>1</sub>-Y<sub>N</sub>), obtaining a result value; and<br/> e- detecting (40) an operation state of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) on the basis of said result value by performing statistical analysis on said result values, wherein said statistical analysis comprises:<br/>  defining a plurality of subgroups of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) different from each other, each subgroup comprising a number of sensors equal to the total number of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) minus one;<br/>  repeating steps a- to d- for each subgroup of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) ;<br/>  calculating a value of standard deviation of said result value for each subgroup; and<br/>  comparing said values of standard deviation of each subgroup with each other.</p><p>2. The method according to claim 1, wherein the step of iteratively solving said system of equations comprises solving the system of equations using the Newton-Raphson Method.</p><p>3. The method according to claim 1 or 2, wherein said flight parameters comprise an angle of attack, an angle of sideslip, a flight Mach number and a flight static pressure, said non-linear mathematical model being defined by: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 79mm; height: 10mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2893360&ekey=935&cc=EP&producerName=imgb0011.tif&width=79mm&height=10mm\"/></maths></p><p> where AOA represents the angle of attack; AOS represents the angle of sideslip; Mach represents the flight Mach number; Ps<sub>∞</sub> represents the flight static pressure; γ is a constant comprised between 1.3 and 1.5; and Cp is a function of said flight parameters that represents a pressure coefficient related to a location (i<sub>1</sub>-i<sub>N</sub>) on said aircraft (1).</p><p>4. The method according to claim 3, wherein obtaining a value of the pressure coefficient Cp comprises:<br/> h. setting a Mach value;<br/> i. setting an angle of sideslip AOS value equal to approximately zero;<br/> j. varying the angle of attack AOA value in predetermined steps, and, for each pair of AOS-AOA values, obtaining a value of the pressure coefficient Cp;<br/> k. repeating step c, setting a non-zero angle of sideslip AOS value;<br/> l. acquiring a value of Cp for each pair of AOS-AOA values, on the basis of an iteration of step d;<br/> m. repeating steps b-e, setting a Mach value different from the value set at step a;<br/> n. constructing, for each Mach value considered at steps a and f, an array (M<sub>1</sub>-M<sub>P</sub>) containing a plurality of values of the pressure coefficient Cp for each pair of AOS-AOA values considered.</p><p>5. The method according to any of the preceding claims, wherein iteratively solving (20) the system of equations, comprises:<br/> - starting from an initial condition that is the consolidated solution at the previous time of calculation;<br/> - linearizing the system of equations around the consolidated solution at the previous time of calculation;<br/> - solving said system of linear equations so as to obtain the current value of each of said flight parameters related to a location (i<sub>1</sub>-i<sub>N</sub>) .</p><p>6. The method according to any of the preceding claims, wherein iteratively solving (20) said system of equations further comprises defining a plurality of tolerance thresholds (Th), said current value of the flight parameters being obtained when the variation of said parameters during said iterations is lower than said tolerance threshold.</p><p>7. The method according to any of the preceding claims, wherein the step of calculating (30) the plurality of estimated pressure values (Y<sub>1</sub>-Y<sub>N</sub>) comprises, for each respective location (i<sub>1</sub>-i<sub>N</sub>), entering the current value of the flight parameters calculated in the mathematical model describing the aerodynamic behaviour of the aircraft (1); and solving said mathematical model.</p><p>8. The method according to any of the preceding claims, wherein the step of comparing (40) comprises performing a mathematical subtraction operation between each of the estimated pressure values (Y<sub>1</sub>-Y<sub>N</sub>) and a respective transduced pressure value (X<sub>1</sub>-X<sub>N</sub>), obtaining the respective result value that represents the calculation error of the estimated pressure values (Y<sub>1</sub>-Y<sub>N</sub>) with respect to the transduced pressure values (X<sub>1</sub>-X<sub>N</sub>).</p><p>9. The method according to any one of the preceding claims, wherein said statistical analysis comprises:<br/> - calculating, for each pressure sensor of each subgroup, the respective result value;<br/> - calculating, for each subgroup, a value of standard deviation of the obtained result values;<br/> - detecting, among the values of standard deviation calculated for each subgroup, the one having the lowest value and such that it differs from the other values of standard deviation by an amount greater than a predetermined threshold;<br/> - associating a state of failure with the pressure sensor missing in said subgroup to which the lowest value of standard deviation is associated and such that it differs from the other values of standard deviation by an amount greater than a predetermined threshold.</p><p>10. The method according to claim 9, further comprising the step of inhibiting the acquisition (10) of the transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) from the pressure sensor to which the state of failure is associated.</p><p>11. A calculation and consolidation system of a first plurality of flight parameters of an aircraft (1) that includes a second plurality, equal to or greater than said first plurality, of pressure sensors (S<sub>1</sub>-S<sub>N</sub>) arranged in respective locations (i<sub>1</sub>-i<sub>N</sub>) on the aircraft, each pressure sensor being configured to provide a transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) on the basis of a respective detected static pressure value, the system comprising processing means (5) configured to acquire (10) said transduced pressure values (X<sub>1</sub>-X<sub>N</sub>) from the pressure sensors,<br/><b>characterized in that</b> the processing means (5) is further configured to:<br/> a- define (20) a system of equations by associating with each transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) a respective non-linear mathematical model that is a function of said flight parameters and which defines a mathematical relationship between each transduced pressure value and the aerodynamic behaviour of the aircraft (1) at the location (i<sub>1</sub>-i<sub>N</sub>) of the pressure sensor (S<sub>1</sub>-S<sub>N</sub>) that has generated this transduced pressure value;<br/> b- iteratively solve (20) said system of equations, obtaining a current value of each of said flight parameters at each respective location (i<sub>1</sub>-i<sub>N</sub>);<br/> c- calculate (30), for each respective location (i<sub>1</sub>-i<sub>N</sub>), a respective estimated pressure value (Y<sub>1</sub>-Y<sub>N</sub>) by applying the current values of said flight parameters calculated for the respective location (i<sub>1</sub>-i<sub>N</sub>) to each mathematical model;<br/> d- compare (30, 40) each transduced pressure value (X<sub>1</sub>-X<sub>N</sub>) with the respective estimated pressure value (Y<sub>1</sub>-Y<sub>N</sub>), obtaining a result value;<br/> e- detect (40) an operation state of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) on the basis of said result value by performing statistical analysis on said result values,<br/>wherein the processing means (5) are configured to perform said statistical analysis by:<br/> defining a plurality of subgroups of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) different from each other, each subgroup comprising a number of sensors equal to the total number of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) minus one;<br/> repeating steps a- to d- for each subgroup of said pressure sensors (S<sub>1</sub>-S<sub>N</sub>) ;<br/> calculating a value of standard deviation of said result value for each subgroup; and<br/> comparing said values of standard deviation of each subgroup with each other.</p><p>12. A computer program product loadable in a processing means (5) and designed so that, when run on said processing means (5), the processing means are configured to implement the method according to any of claims 1-10.</p>",
            "NPR": "2",
            "APID": "103800471",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64D-043/02<br/>B64D-045/00<br/>B65D-043/02<br/>G01L-013/00<br/>G01P-003/00<br/>G01P-013/02<br/>G01P-021/00",
            "ID": "61864928",
            "AB": "(EP2893360)<br/>A method and system for calculation and consolidation of a first plurality of aircraft flight parameters including a second plurality of pressure sensors. The pressure sensors are arranged in respective aircraft locations, each pressure sensor provides a pressure value based on a respective detected static pressure value. The method comprises: acquiring the pressure values from the pressure sensors; defining an equation system by associating with each pressure value a respective non-linear mathematical model describing the aerodynamic aircraft behaviour at the pressure sensor location, each respective mathematical model being a flight parameter function; iteratively solving the equation system, obtaining a current value of each of said flight parameters; calculating a plurality of intermediate pressure values by applying the current flight parameter values to each mathematical model; comparing each pressure value with the respective intermediate pressure value, obtaining a result value; and detecting an operation state of the pressure sensors based on the result value.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=s2xYpbHJwgLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2013-09-05",
            "PA": "LEONARDO<br/>ALENIA AERMACCHI<br/>ALENIA AERMACCHI SPA<br/>LEONARDO SPA",
            "PAAD": "(EP2893360)<br/>(PUB:EP-2893360B1-0)NAME=Leonardo S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101602613<br/><br/>(PUB:EP-2893360A1-0)NAME=Alenia Aermacchi S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101476760<br/><br/><br/>(US20150219512)<br/>(PUB:US-20150219512A1-2)NAME=ALENIA AERMACCHI S.p.A.  , CITY=ROMA , COUNTRY=IT<br/><br/><br/>(WO201437902)<br/>(PUB:WO-2014037902A1-0)NAME=ALENIA AERMACCHI S.P.A. VIA Ing. Paolo Foresio, 1 Venegono Superiore , COUNTRY=IT<br/><br/><br/>(CA2883054)<br/>(PUB:CA-2883054C-14)NAME=ALENIA AERMACCHI S.P.A. PLAZA MONTE GRAPPA, 4 , CITY=ROMA , COUNTRY=IT<br/><br/>(PUB:CA-2883054A1-14)NAME=ALENIA AERMACCHI S.P.A. PLAZA MONTE GRAPPA, 4 , CITY=ROMA , COUNTRY=IT<br/><br/><br/>(BR112015004866)<br/>(PUB:BR-112015004866A8-20171121-79)NAME=ALENIA AERMACCHI S P A  , COUNTRY=IT<br/><br/>(PUB:BR-112015004866A2-79)NAME=ALENIA AERMACCHI SPA  , COUNTRY=IT<br/>",
            "FAN": "61864928",
            "TI": "Method of and system for calculation and consolidation of flight parameters of an aircraft",
            "TECD": "Handling<br/>Measurement<br/>Transport",
            "EPD": "2014-03-13",
            "ICLM": "(EP2893360)<br/><p>1. A method for calculation and consolidation of a first plurality of flight parameters of an aircraft (1) including a second plurality, equal to or greater than said first plurality, of pressure sensors (S1-SN) arranged at respective locations (i1-iN) on the aircraft, each pressure sensor being configured to provide a transduced pressure value (X1-XN) on the basis of a respective detected static pressure value, the method comprising the step of acquiring (10) said transduced pressure values (X1-XN) from the pressure sensors, and being characterized by further comprising the steps of: a- defining (20) a system of equations by associating with each transduced pressure value (X1-XN) a respective non-linear mathematical model that is a function of said flight parameters and which defines a mathematical relationship between each transduced pressure value and the aerodynamic behaviour of the aircraft (1) at the location (i1-iN) of the pressure sensor (S1-SN) that has generated this transduced pressure value; b- iteratively solving (20) said system of equations, obtaining a current value of each of said flight parameters at each respective location (i1-iN); c- calculating (30), for each respective location (i1-iN), a respective estimated pressure value (Y1-YN) by applying the current values of said flight parameters calculated for the respective location (i1-iN) to each mathematical model; d- comparing (30, 40) each transduced pressure value (X1-XN) with the respective estimated pressure value (Y1-YN), obtaining a result value; and e- detecting (40) an operation state of said pressure sensors (S1-SN) on the basis of said result value by performing statistical analysis on said result values, wherein said statistical analysis comprises: defining a plurality of subgroups of said pressure sensors (S1-SN) different from each other, each subgroup comprising a number of sensors equal to the total number of said pressure sensors (S1-SN) minus one; repeating steps a- to d- for each subgroup of said pressure sensors (S1-SN) ; calculating a value of standard deviation of said result value for each subgroup; and comparing said values of standard deviation of each subgroup with each other.</p><p>11. A calculation and consolidation system of a first plurality of flight parameters of an aircraft (1) that includes a second plurality, equal to or greater than said first plurality, of pressure sensors (S1-SN) arranged in respective locations (i1-iN) on the aircraft, each pressure sensor being configured to provide a transduced pressure value (X1-XN) on the basis of a respective detected static pressure value, the system comprising processing means (5) configured to acquire (10) said transduced pressure values (X1-XN) from the pressure sensors, characterized in that the processing means (5) is further configured to: a- define (20) a system of equations by associating with each transduced pressure value (X1-XN) a respective non-linear mathematical model that is a function of said flight parameters and which defines a mathematical relationship between each transduced pressure value and the aerodynamic behaviour of the aircraft (1) at the location (i1-iN) of the pressure sensor (S1-SN) that has generated this transduced pressure value; b- iteratively solve (20) said system of equations, obtaining a current value of each of said flight parameters at each respective location (i1-iN); c- calculate (30), for each respective location (i1-iN), a respective estimated pressure value (Y1-YN) by applying the current values of said flight parameters calculated for the respective location (i1-iN) to each mathematical model; d- compare (30, 40) each transduced pressure value (X1-XN) with the respective estimated pressure value (Y1-YN), obtaining a result value; e- detect (40) an operation state of said pressure sensors (S1-SN) on the basis of said result value by performing statistical analysis on said result values, wherein the processing means (5) are configured to perform said statistical analysis by: defining a plurality of subgroups of said pressure sensors (S1-SN) different from each other, each subgroup comprising a number of sensors equal to the total number of said pressure sensors (S1-SN) minus one; repeating steps a- to d- for each subgroup of said pressure sensors (S1-SN) ; calculating a value of standard deviation of said result value for each subgroup; and comparing said values of standard deviation of each subgroup with each other.</p>",
            "CTN": "(EP2893360)<br/>GB2432914 16997076 WHO=EXAMINER SELF=N CAT=Y<br/>US20110238373 44359192 WHO=EXAMINER SELF=N CAT=Y<br/>US5423209 21174761 WHO=EXAMINER SELF=N CAT=Y<br/>EP2434296 7621936 WHO=EXAMINER SELF=N CAT=A<br/>US20040011124 2454522 WHO=EXAMINER SELF=N CAT=A<br/>GB2432914 16997076 WHO=APPLICANT SELF=N<br/>US20110238373 44359192 WHO=APPLICANT SELF=N<br/>US5423209 21174761 WHO=APPLICANT SELF=N<br/>EP2434296 7621936 WHO=APPLICANT SELF=N<br/>US20040011124 2454522 WHO=APPLICANT SELF=N<br/><br/>(US20150219512)<br/>US6336060 21862196 WHO=EXAMINER SELF=N CAT=103<br/>US20070150122 16983651 WHO=EXAMINER SELF=N CAT=103<br/>US20070130096 16997076 WHO=EXAMINER SELF=N CAT=103<br/>US6510397 43285943 WHO=EXAMINER SELF=N CAT=103<br/>US6761057 13916962 WHO=EXAMINER SELF=N CAT=103<br/><br/>(WO201437902)<br/>GB2432914 16997076 WHO=EXAMINER SELF=N CAT=Y<br/>US20110238373 44359192 WHO=EXAMINER SELF=N CAT=Y<br/>US5423209 21174761 WHO=EXAMINER SELF=N CAT=Y<br/>EP2434296 7621936 WHO=EXAMINER SELF=N CAT=A<br/>US20040011124 2454522 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2016-03-05",
                    "XAP": "2013WO-IB58320",
                    "APD": "2013-09-05",
                    "APID": "97419575",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2014037902&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=9QyAldsnU5nbJ5J8319nIpNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2014/037902",
                            "KIND": "A1",
                            "XPN": "WO201437902",
                            "V_PNID": "WO-2014037902A1-0",
                            "DATE": "2014-03-13",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCA3reixdxf5UYnVC+dywuLYLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=WO201437902&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=9QyAldsnU5nbJ5J8319nIpNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2033-09-05",
                            "XAP": "2013CA-2883054",
                            "APD": "2013-09-05",
                            "APID": "101736029",
                            "REG_LINK": "https://www.ic.gc.ca/opic-cipo/cpd/eng/patent/2883054/summary.html?type=number_search",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=A9eyp29KshP4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CA2883054",
                                    "KIND": "C",
                                    "XPN": "CA2883054",
                                    "V_PNID": "CA-2883054C-14",
                                    "DATE": "2021-06-08",
                                    "STG": "Patent (second level)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=pp4wa/l5+Yeja3HO5b2ZlYTNbfc8CWEP6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=CA2883054&kind=C",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=A9eyp29KshP4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "CA2883054",
                                    "KIND": "A1",
                                    "XPN": "CA2883054",
                                    "V_PNID": "CA-2883054A1-14",
                                    "DATE": "2014-03-13",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=pp4wa/l5+Yeja3HO5b2ZlfEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=CA2883054&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=A9eyp29KshP4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2033-09-05",
                            "XAP": "2013EP-0792453",
                            "APD": "2013-09-05",
                            "APID": "103800471",
                            "REG_LINK": "https://register.epo.org/application?number=EP13792453",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=s2xYpbHJwgLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP2893360",
                                    "KIND": "B1",
                                    "XPN": "EP2893360",
                                    "V_PNID": "EP-2893360B1-0",
                                    "DATE": "2018-07-11",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8wokhwq5Ge9UGvTyTQVBwKxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2893360&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=s2xYpbHJwgLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP2893360",
                                    "KIND": "A1",
                                    "XPN": "EP2893360",
                                    "V_PNID": "EP-2893360A1-0",
                                    "DATE": "2015-07-15",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8wokhwq5Ge9UGvTyTQVBwPEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2893360&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=s2xYpbHJwgLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ],
                            "V_APL": [
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "GRANTED",
                                    "ACT_EED": "2033-09-05",
                                    "XAP": "2013ES-0792453T",
                                    "APD": "2013-09-05",
                                    "APID": "131702158",
                                    "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Z7lFFmGbuhn4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "ES2685754",
                                            "KIND": "T3",
                                            "XPN": "ES2685754",
                                            "V_PNID": "ES-2685754T3-0",
                                            "DATE": "2018-10-11",
                                            "STG": "Translation of granted European patent (former B3)",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=a4uVmah4rFoGwpRPaCd9RX4Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2685754&kind=T3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Z7lFFmGbuhn4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "REVOKED",
                            "ACT_EED": "2021-12-28",
                            "XAP": "2015BR-0004866",
                            "APD": "2013-09-05",
                            "APID": "107606641",
                            "REG_LINK": "https://gru.inpi.gov.br/e-inpi/internetCliente/Principal.jsp",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=MaJaNZ0GPp2mwls%252FxCCnaMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "BR112015004866",
                                    "KIND": "A8",
                                    "XPN": "BR112015004866",
                                    "V_PNID": "BR-112015004866A8-20171121-79",
                                    "DATE": "2017-11-21",
                                    "STG": "Modified first page",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOW881kMGV+oB5NFJVCyDHRn59mWXRDhcKa8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112015004866&kind=A8",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=MaJaNZ0GPp2mwls%252FxCCnaMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "BR112015004866",
                                    "KIND": "A2",
                                    "XPN": "BR112015004866",
                                    "V_PNID": "BR-112015004866A2-79",
                                    "DATE": "2017-07-04",
                                    "STG": "Application for a patent of invention / pipeline patent published without search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOW881kMGV+oB5NFJVCyDHRnTlgwbhA1i2q8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112015004866&kind=A2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=MaJaNZ0GPp2mwls%252FxCCnaMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "BR112015004866",
                                    "KIND": "A0",
                                    "XPN": "BR112015004866",
                                    "V_PNID": "BR-112015004866A1-111",
                                    "DATE": "2015-04-22",
                                    "STG": "Application filed, as announced in the Gazette published by this office",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOW881kMGV+oB5NFJVCyDHRn1rFtbI/Ao3O8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112015004866&kind=A0",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=MaJaNZ0GPp2mwls%252FxCCnaMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2018-02-12",
                            "XAP": "2013US-14425174",
                            "APD": "2013-09-05",
                            "APID": "104083295",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/14425174",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=qlAbJFRa2tIqJuBA0U7MTsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US20150219512",
                                    "KIND": "A1",
                                    "XPN": "US20150219512",
                                    "V_PNID": "US-20150219512A1-2",
                                    "DATE": "2015-08-06",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcMWDNPwmG/03YDOQ6NLC580bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20150219512&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=qlAbJFRa2tIqJuBA0U7MTsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                }
            ],
            "REP": "EP2893360_B1",
            "EPRD": "2012-09-05",
            "PN": "EP2893360           B1 2018-07-11 [EP2893360]<br/>EP2893360           A1 2015-07-15 [EP2893360]<br/>US20150219512       A1 2015-08-06 [US20150219512]<br/>WO2014/037902       A1 2014-03-13 [WO201437902]<br/>CA2883054           C  2021-06-08 [CA2883054]<br/>CA2883054           A1 2014-03-13 [CA2883054]<br/>ES2685754           T3 2018-10-11 [ES2685754]<br/>BR112015004866      A8 2017-11-21 [BR112015004866]<br/>BR112015004866      A2 2017-07-04 [BR112015004866]<br/>BR112015004866      A0 2015-04-22 [BR112015004866]",
            "ADB": "(EP2893360)<br/><p>Backtracking, it is necessary to initialize the calculation the very first time, as there is obviously no previously calculated solution.</p><p>Static pressure sensors of the type available on the market, for example pressure sensors made using MEMS technology, have the advantage of small size and weight and do not protrude from the surface on which they are mounted.</p><p>With regard to low radar signature aircraft, the main advantage of this methodology of calculation of the flight parameters is represented by the use of mathematical models that enable easier validation of the entire process, with positive repercussions in terms of traceability and verification in a possible certification procedure.</p><p>For example, such sensors do not significantly protrude when they do not constitute a radar signature element.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=5<br/>PNAAGE=13<br/>NBPA=1; <br/>ALLCT=9; SCT=0; NSCT=9; <br/>ALLCTG=9; SCTG=1; NSCTG=8; <br/>AFS=5; ACC=5; AMCC=3; <br/>IGEN=0.89; IORG=0.95; IRAD=0.97; <br/>IMPI=3.32; MACI=1.58; PASI=3.39; PAVI=3.21; ",
            "PTCC": "(EP2682836)<br/>CC=EP EED=2033-07-03 STATUS=GRANTED APID=88600249 APD=2013-07-03 XPN=EP2682836 PD=2014-01-08 PD=2016-04-20 PD=2017-12-20 EPD=2014-01-08 LPD=2017-12-20 PDG=2017-12-20 <br/>CC=DE EED=2033-07-03 STATUS=GRANTED APID=88600249 XPN=EP2682836 PDG=2017-12-20 <br/>CC=FR EED=2033-07-03 STATUS=GRANTED APID=88600249 XPN=EP2682836 PDG=2017-12-20 <br/>CC=GB EED=2033-07-03 STATUS=GRANTED APID=88600249 XPN=EP2682836 PDG=2017-12-20 <br/><br/>(US9969507)<br/>CC=US EED=2035-06-02 STATUS=GRANTED APID=88860378 APD=2013-07-02 XPN=US20140012461 PD=2014-01-09 PD=2018-05-15 EPD=2014-01-09 LPD=2018-05-15 PDG=2018-05-15 <br/><br/>(IT2012TO0588)<br/>CC=IT EED=2032-07-04 STATUS=PENDING APID=88626035 APD=2012-07-04 XPN=IT2012TO0588 PD=2014-01-05 EPD=2014-01-05 LPD=2014-01-05 <br/>",
            "EPN": "ITTO20120588",
            "CTGN": "(EP2682836)<br/>EP3229187 77385888 WHO=EXAMINER SELF=N CAT=I<br/>CN105527955B 72757474 WHO=EXAMINER SELF=N<br/>EP3584659 87092902 WHO=EXAMINER SELF=Y CAT=X<br/>IT201800006499 87092902 WHO=EXAMINER SELF=Y CAT=X<br/>EP3584659 87092902 WHO=APPLICANT SELF=Y<br/>US11436485 87092902 WHO=APPLICANT SELF=Y<br/>EP3229187 77385888 WHO=APPLICANT SELF=N<br/><br/>(US9969507)<br/>CN104803009 70380475 WHO=EXAMINER SELF=N CAT=A<br/>RU2614740 75942128 WHO=EXAMINER SELF=N<br/>US20170283085 77385888 WHO=EXAMINER SELF=N<br/>CN109752196B 84475979 WHO=EXAMINER SELF=N CAT=A<br/>JP2017202820 77385888 WHO=EXAMINER SELF=N CAT=A<br/>CN110618670 87092902 WHO=EXAMINER SELF=Y CAT=X<br/>RU2595066 73978962 WHO=EXAMINER SELF=N<br/>US20220227498 92128738 WHO=EXAMINER SELF=N<br/>US20220205870 86771099 WHO=EXAMINER SELF=N",
            "LAPD": "2013-07-03",
            "STDN": "",
            "NPN": "5",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application claims benefit of Serial No. TO2012A000588, filed 4 Jul. 2012 in Italy and which application is incorporated herein by reference. To the extent appropriate, a claim of priority is made to each of the above disclosed applications.</p><p><h1>FIELD OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates in general to a method for performing structural diagnostics, and more specifically to a method for performing diagnostics of a mechanical structure, in particular an aircraft structure, adapted to evaluate or monitor the presence of damage or defects caused in a structure by operating loads and/or events occurring while in service.</p><p><h1>BACKGROUND OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0003]   </span>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p><span class=\"paragraph-number\">[0004]   </span>According to the prior art, in the aeronautical sector the presence of damage or defects in a mechanical structure of an aircraft, such as a metal or composite structure, for example fuselage or wing structure, is diagnosed indirectly by means of a historical reconstruction of events, including events which have resulted in damage due to an accidental impact during production (impact of a tool) or while in service (impact due to hail or foreign objects), and loads withstood by the structure, or by means of estimate of the fatigue withstood by the structure, based on the knowledge of its mechanical strength properties in response to the stresses which typically occur in service conditions. In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally, but may cause considerable damage inside the structure (for example, delamination).</p><p><span class=\"paragraph-number\">[0005]   </span>This technique, however, is laborious and imprecise, because it does not reflect in real time the changes and the physical and mechanical conditions of the monitored structure.</p><p><span class=\"paragraph-number\">[0006]   </span>A method for predicting the behaviour of a structure subject to loads was developed by the same Applicant and described in the European patent application EP 2,281,224 A1. The method comprises the provision of a mathematical model of the structure, detection of the state (deformation) of the structure in a plurality of primary points and in a plurality of additional points, determination of the loads acting on the structure and associated with the state detected in the primary points on the basis of the aforementioned mathematical model, estimation, using the loads determined, of the state of the structure in the additional points, and comparison between the state of the structure estimated and that detected in the additional points, so that an intact state of the structure is determined if the estimated and detected values of the state parameter match, or a defective state of the structure if these values differ.</p><p><h1>SUMMARY OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0007]   </span>The object of the present invention is to provide an improved method for performing structural diagnostics, which is both simple and flexible and allows the physical and mechanical conditions of a structure to be estimated with continuity in a reliable manner.</p><p><span class=\"paragraph-number\">[0008]   </span>A further object of the invention is to provide a method for performing diagnostics which can be applied without the need for excessive calculation and in particular without the need to create a physical/mathematical model of the structure and which can therefore be implemented on-board an aircraft also when in service or during a mission.</p><p><span class=\"paragraph-number\">[0009]   </span>Particular embodiments form the subject of the dependent claims, the contents of which are to be understood as forming an integral or complementary part of the present description.</p><p><span class=\"paragraph-number\">[0010]   </span>The invention also relates to a system and a computer program for performing the diagnostics of a mechanical structure.</p><p><span class=\"paragraph-number\">[0011]   </span>In short, the present invention is based on the characterization of a mechanical structure being examined which is subject to operating loads able to cause local deformation thereof (or modify another parameter indicative of its state) and on the correlation in real time of real deformation data (or more generally data indicative of the real variation of the prechosen state parameter) and presumed deformation data (or more generally presumed variation of the prechosen state parameter), a comparison thereof being used to deduce the intact or defective condition of the structure.</p><p><span class=\"paragraph-number\">[0012]   </span>A defect of the structure may consist of a hole, a filled hole or other modifications to the surface or volume, for example caused by the insertion of a connection member, impact damage, delamination, porosity, or due to a zone of the structure which has a different resin or fibre intensity. A defect may be concentrated in a point with specific coordinates or spread out in a direction or over an area or within a volume of the structure.</p><p><span class=\"paragraph-number\">[0013]   </span>In a currently preferred embodiment, the structure being examined is equipped with a limited number of deformation sensors located in relevant points.</p><p><span class=\"paragraph-number\">[0014]   </span>It should be noted that, depending on the prechosen arrangement of relevant points (or detection points) on the structure a possible concentrated defect, located far from them, may not cause any variation in the state of the structure at the relevant points, so that a given load or load vector gives rise to a deformation vector which is unchanged in the presence of a defect. Obviously, the criterion for choosing the detection points must preferably take into account the sensitivity to the structural defect at said points.</p><p><span class=\"paragraph-number\">[0015]   </span>A neural network, the degree of complexity of which depends on the morphological complexity of the structure, is trained on the basis of the state conditions detected on the structure at the relevant points by means of association with at least one and preferably a plurality of different load conditions. The neural network is designed to estimate a correlation between the state or the variations in state detected in a subset of relevant points and the state or the variation in state in one or more residual relevant points.</p><p><span class=\"paragraph-number\">[0016]   </span>A presumed variation in state of the structure under examination at a relevant point depending on a given operating load is estimated by means of the neural network which has been suitably trained and is compared with the corresponding assumed real value of the state parameter measured by the sensor associated with the relevant point.</p><p><span class=\"paragraph-number\">[0017]   </span>Advantageously, by means of the neural network, for each load situation an associative prediction of the state or modification in the state is assigned to a subset of relevant points and preferably to each relevant point of the complete set of relevant points on the basis of the state or modifications in the state detected at the other points of the set. Therefore, for each point and any load situation a comparison may be performed between the value of the state parameter predicted by the neural network for that point and the real value of the state parameter detected by the associated sensor, basically performing a comparison between the expected state of the structure and the detected state.</p><p><span class=\"paragraph-number\">[0018]   </span>The diagnostic evaluation of the structure is performed by means of identification and signalling of the points where the value assumed by the state parameter detected differs from the expected value by an amount greater than a predetermined tolerance threshold. An intact state of the structure is determined if the expected and detected values of the state parameter match within the predetermined tolerance threshold, or a defective state of the structure is determined if these values differ beyond the predetermined tolerance threshold.</p><p><span class=\"paragraph-number\">[0019]   </span>The diagnostic evaluation may be conveniently verified by considering a plurality of different load situations and therefore measurements of the presumed variation of the state parameter, so that the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a plurality of load situations may be interpreted as a confirmation of the presence of damage or a defect in the structure, while the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a single load situation or in a small number of load situations together with the existence of a match condition between values predicted by means of the neural network and values detected by the sensors in a multiplicity of different load situations may be interpreted as an occasional signal.</p><p><span class=\"paragraph-number\">[0020]   </span>Mapping of the points where the presence of damage or a defect in the structure is estimated may be interpreted as a useful indication of the extent of the damage.</p><p><span class=\"paragraph-number\">[0021]   </span>Advantageously, the method according to the invention does not require the construction of a complex model of the diagnostics structure, for example finite-elements model, as described in EP 2,281,224 A1.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0022]   </span>Further characteristic features and advantages of the invention will be explained more clearly in the following detailed description of a non-limiting example of embodiment thereof, provided with reference to the accompanying drawings in which:</p><p><span class=\"paragraph-number\">[0023]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows an example of a diagnostics system according to the invention, applied to an aircraft;</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIG. 2</a> shows an example of structure and a system of forces acting thereon;</p><p><span class=\"paragraph-number\">[0025]   </span><a href=\"#DRAWINGS\">FIG. 3</a> is a flow diagram of the diagnostics method according to the invention; and</p><p><span class=\"paragraph-number\">[0026]   </span><a href=\"#DRAWINGS\">FIG. 4</a> is a diagram illustrating an example of a neural network according to the invention.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates in general to a method for performing structural diagnostics, and more specifically to a method for performing diagnostics of a mechanical structure, in particular an aircraft structure, adapted to evaluate or monitor the presence of damage or defects caused in a structure by operating loads and/or events occurring while in service.</p><p><span class=\"paragraph-number\">[0002]   </span>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p><span class=\"paragraph-number\">[0003]   </span>According to the prior art, in the aeronautical sector the presence of damage or defects in a mechanical structure of an aircraft, such as a metal or composite structure, for example fuselage or wing structure, is diagnosed indirectly by means of a historical reconstruction of events, including events which have resulted in damage due to an accidental impact during production (impact of a tool) or while in service (impact due to hail or foreign objects), and loads withstood by the structure, or by means of estimate of the fatigue withstood by the structure, based on the knowledge of its mechanical strength properties in response to the stresses which typically occur in service conditions. In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally, but may cause considerable damage inside the structure (for example, delamination).</p><p><span class=\"paragraph-number\">[0004]   </span>This technique, however, is laborious and imprecise, because it does not reflect in real time the changes and the physical and mechanical conditions of the monitored structure.</p><p><span class=\"paragraph-number\">[0005]   </span>A method for predicting the behaviour of a structure subject to loads was developed by the same Applicant and described in the European patent application <patcit dnum=\"EP2281224A1\">EP 2,281,224 A1</patcit>. The method comprises the provision of a mathematical model of the structure, detection of the state (deformation) of the structure in a plurality of primary points and in a plurality of additional points, determination of the loads acting on the structure and associated with the state detected in the primary points on the basis of the aforementioned mathematical model, estimation, using the loads determined, of the state of the structure in the additional points, and comparison between the state of the structure estimated and that detected in the additional points, so that an intact state of the structure is determined if the estimated and detected values of the state parameter match, or a defective state of the structure if these values differ.<br/>The object of the present invention is to provide an improved method for performing structural diagnostics, which is both simple and flexible and allows the physical and mechanical conditions of a structure to be estimated with continuity in a reliable manner.<br/>A further object of the invention is to provide a method for performing diagnostics which can be applied without the need for excessive calculation and in particular without the need to create a physical/mathematical model of the structure and which can therefore be implemented on-board an aircraft also when in service or during a mission. Diagnostics methods which do not make use of physical models of a structure are for instance known from the paper of <nplcit npl-type=\"s\">M. Nakamura et al., \"A method for non-parametric damage detection through the use of neural networks\", Earthquake Engineering and Structural Dynamics, vol. 27, no. 9, pages 997-1010</nplcit>.</p><p><span class=\"paragraph-number\">[0006]   </span>According to the present invention these objects are achieved by means of a method of performing diagnostics on a mechanical structure having the characteristic features defined in Claim 1.<br/>Particular embodiments form the subject of the dependent claims, the contents of which are to be understood as forming an integral or complementary part of the present description. The invention also relates to a system and a computer program for performing the diagnostics of a mechanical structure as claimed.<br/>In short, the present invention is based on the characterization of a mechanical structure being examined which is subject to operating loads able to cause local deformation thereof (or modify another parameter indicative of its state) and on the correlation in real time of real deformation data (or more generally data indicative of the real variation of the prechosen state parameter) and presumed deformation data (or more generally presumed variation of the prechosen state parameter), a comparison thereof being used to deduce the intact or defective condition of the structure.</p><p><span class=\"paragraph-number\">[0007]   </span>A defect of the structure may consist of a hole, a filled hole or other modifications to the surface or volume, for example caused by the insertion of a connection member, impact damage, delamination, porosity, or due to a zone of the structure which has a different resin or fibre density. A defect may be concentrated in a point with specific coordinates or spread out in a direction or over an area or within a volume of the structure.</p><p><span class=\"paragraph-number\">[0008]   </span>In a currently preferred embodiment, the structure being examined is equipped with a limited number of deformation sensors located in relevant points.</p><p><span class=\"paragraph-number\">[0009]   </span>It should be noted that, depending on the prechosen arrangement of relevant points (or detection points) on the structure a possible concentrated defect, located far from them, may not cause any variation in the state of the structure at the relevant points, so that a given load or load vector gives rise to a deformation vector which is unchanged in the presence of a defect. Obviously, the criterion for choosing the detection points must preferably take into account the sensitivity to the structural defect at said points.</p><p><span class=\"paragraph-number\">[0010]   </span>A neural network, the degree of complexity of which depends on the morphological complexity of the structure, is trained on the basis of the state conditions detected on the structure at the relevant points by means of association with at least one and preferably a plurality of different load conditions. The neural network is designed to estimate a correlation between the state or the variations in state detected in a subset of relevant points and the state or the variation in state in one or more residual relevant points.</p><p><span class=\"paragraph-number\">[0011]   </span>A presumed variation in state of the structure under examination at a relevant point depending on a given operating load is estimated by means of the neural network which has been suitably trained and is compared with the corresponding assumed real value of the state parameter measured by the sensor associated with the relevant point.</p><p><span class=\"paragraph-number\">[0012]   </span>Advantageously, by means of the neural network, for each load situation an associative prediction of the state or modification in the state is assigned to a subset of relevant points and preferably to each relevant point of the complete set of relevant points on the basis of the state or modifications in the state detected at the other points of the set. Therefore, for each point and any load situation a comparison may be performed between the value of the state parameter predicted by the neural network for that point and the real value of the state parameter detected by the associated sensor, basically performing a comparison between the expected state of the structure and the detected state.</p><p><span class=\"paragraph-number\">[0013]   </span>The diagnostic evaluation of the structure is performed by means of identification and signalling of the points where the value assumed by the state parameter detected differs from the expected value by an amount greater than a predetermined tolerance threshold. An intact state of the structure is determined if the expected and detected values of the state parameter match within the predetermined tolerance threshold, or a defective state of the structure is determined if these values differ beyond the predetermined tolerance threshold.</p><p><span class=\"paragraph-number\">[0014]   </span>The diagnostic evaluation may be conveniently verified by considering a plurality of different load situations and therefore measurements of the presumed variation of the state parameter, so that the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a plurality of load situations may be interpreted as a confirmation of the presence of damage or a defect in the structure, while the existence of a mismatch condition between values predicted by means of the neural network and values detected by the sensors in a single load situation or in a small number of load situations together with the existence of a match condition between values predicted by means of the neural network and values detected by the sensors in a multiplicity of different load situations may be interpreted as an occasional signal.</p><p><span class=\"paragraph-number\">[0015]   </span>Mapping of the points where the presence of damage or a defect in the structure is estimated may be interpreted as a useful indication of the extent of the damage.</p><p><span class=\"paragraph-number\">[0016]   </span>Advantageously, the method according to the invention does not require the construction of a complex model of the diagnostics structure, for example finite-elements model, as described in <patcit dnum=\"EP2281224A1\">EP 2,281,224 A1</patcit>.</p><p><span class=\"paragraph-number\">[0017]   </span>Further characteristic features and advantages of the invention will be explained more clearly in the following detailed description of a non-limiting example of embodiment thereof, provided with reference to the accompanying drawings in which:</p><p><ul compact=\"compact\" list-style=\"none\"><li> <figref>Figure 1</figref> shows an example of a diagnostics system according to the invention, applied to an aircraft;</li><br/><li> <figref>Figure 2</figref> shows an example of structure and a system of forces acting thereon;</li><br/><li> <figref>Figure 3</figref> is a flow diagram of the diagnostics method according to the invention; and</li><br/><li> <figref>Figure 4</figref> is a diagram illustrating an example of a neural network according to the invention.</li></ul></p><p><span class=\"paragraph-number\">[0018]   </span>An example of a structural diagnostics system in the preferred application to an aircraft is schematically shown in <figref>Figure 1</figref>.</p><p><span class=\"paragraph-number\">[0019]   </span>Said figure shows the aircraft, generally denoted with A, and some of its structural parts which are to be monitored with regard to their intact or defective condition, for example the fuselage S1, the wing structure S2 and the tail unit S3. A plurality of sensors, generally denoted with P, are shown located on each part in N relevant detection points suitable for detecting a parameter indicative of the state of the aircraft structures, for example in the description provided here the local static deformation (where applicable, in more than one direction).</p><p><span class=\"paragraph-number\">[0020]   </span>The sensors are connected to an electronic processing unit U to which respective signals representing the parameters detected are transmitted. A database DB is associated with the processing unit and is designed to store a plurality of vectors comprising the values assumed by at least one predetermined state parameter detected at the N points in different load conditions. For operation of the system according to the invention, conveniently in a learning step during the first stage of operation of the diagnostics structure a large number of vectors are recorded.</p><p><span class=\"paragraph-number\">[0021]   </span>The processing unit U comprises a plurality of neural networks which are designed to process data with an approach of the associative type, and the number of vectors which are conveniently recorded during a learning step depends on the number of coefficients used by the neural networks described below, and preferably this number of vectors should be at least five times the number of coefficients.</p><p><span class=\"paragraph-number\">[0022]   </span>For i-th point P<sub>i</sub>, where P lies between 1 and N, a neural network is designed to determine a correlation between the values assumed by the state parameter in the N-1 points different from the point P<sub>i</sub> and the value assumed by the state parameter in the point P<sub>i</sub>, depending on at least one and preferably a plurality of load conditions.</p><p><span class=\"paragraph-number\">[0023]   </span>Each neural network is a network with Q levels, with d<sub>Q</sub> nodes per level, as shown in <figref>Figure 4</figref>. By way of example, and with reference to the Figure, a correlation of the neural type established between N relevant points X<sub>1</sub>, X<sub>2</sub>,...., X<sub>N</sub> at the input and a relevant point X<sub>F</sub> at the output is described.</p><p><span class=\"paragraph-number\">[0024]   </span>First of all a neural box consisting of Q successive lines (for example 3), each with dimensions d<sub>1</sub>, d<sub>2</sub>,..., d<sub>Q</sub> (for example 3 nodes per line) is established. The correlative logic flow is shown in the figure, so that each node contributes to all the nodes of the next level.</p><p><span class=\"paragraph-number\">[0025]   </span>A respective correlation parameter C is defined for each relevant input point for each neuron (inner node) and for each relevant output point. A crossed correlation function φ is also established and associates with each pair of correlation parameters C<sub>a</sub>,C<sub>b</sub> a crossed correlation parameter K, where K<sub>a,b</sub> = φ (C<sub>a</sub>, C<sub>b</sub>). A function f (typically a hyperbolic function) is defined and, for each successive step, a correlation is established between the N relevant input points and the relevant output point of each calculation step indicated by X<sub>i+1,j</sub> = f((x<sub>i,1</sub>, K<sub>(i,1),(i+1,J)</sub>), (x<sub>i,2</sub>, K<sub>(i,2),(i+1,J)</sub>), ..., (x<sub>i,N</sub>, K<sub>(i,N),(i+1,J)</sub>).</p><p><span class=\"paragraph-number\">[0026]   </span>This having been defined, training of the network, based on the availability of a sufficiently large number of real situations in which the values of the relevant points upstream of the network and the corresponding value of the relevant point downstream of the network are known, consists in defining the parameters C which minimize the difference between the output value calculated by the function f and the optimized parameters C, and its real value. Minimization may be performed, for example, using criteria of the \"minimum squares\" type.</p><p><span class=\"paragraph-number\">[0027]   </span>By means of N neural networks which have been suitably trained, one for each relevant point, for each load situation in which the deformations in N-1 points are detected, the processing unit is able to provide an associative prediction of the value of the state parameter for the remaining point.</p><p><span class=\"paragraph-number\">[0028]   </span>The processing unit is connected moreover to a signalling unit D for indicating to an operator, such as the aircraft pilot or a maintenance engineer, visually by means of written information and mapped points on a screen or electronically by means of issuing of a report, the intact or defective state of the monitored structures.</p><p><span class=\"paragraph-number\">[0029]   </span>An example of a structure being examined by a diagnostics system is shown in <figref>Figure 2</figref>, in the form of a fuselage panel of an aircraft - generally denoted with 10 and shown in a top plan view and side view - which comprises a flat bottom element 20 which has on a surface 22 a series of reinforcing ribs 24.</p><p><span class=\"paragraph-number\">[0030]   </span>L<sub>1</sub>-L<sub>K</sub> indicate the vectors representing the forces acting on the structure (which is essentially two-dimensional) in a predetermined operating condition, by way of example and for the sake of simplicity having components only in the plane in which the structure lies.</p><p><span class=\"paragraph-number\">[0031]   </span>P<sub>i</sub> denotes relevant points on the surface of the structure, which are typically chosen based on a criterion of substantial periodicity, except for any clustering in the vicinity of areas which are more critical from a structural point of view (for example, the skin/stiffener bonding zone, in order to diagnose any possible detachment of the stiffeners).</p><p><span class=\"paragraph-number\">[0032]   </span>Deformation sensors of the type known per se are located in the N detection points (or relevant points of the structure) P<sub>i</sub>; these sensors may consist, for example, of surface sensors or sensors which are embedded in the structure and which are connected (electrically, optically or wirelessly) to the processing unit of the diagnostics system on-board the aircraft designed to associate the signals acquired by the sensors with deformation values of the structure.</p><p><span class=\"paragraph-number\">[0033]   </span>Known sensors may be, for example, of the strain gauge type, namely with an electrical resistance signal which is variable depending on the deformation, or of the optical-fibre type with a Bragg grating in which detection of the deformation is based on reading of the wavelength which interferes with the grating, directly correlated to the deformation.</p><p><span class=\"paragraph-number\">[0034]   </span>The diagnostics method according to the invention is described in detail with reference to the flow diagram shown in <figref>Figure 3</figref>. The diagnostics method is implemented by the on-board processing unit U designed to execute groups or modules of processing and calculation programs stored on a disk or accessible on the network, for performing the procedures described.</p><p><span class=\"paragraph-number\">[0035]   </span>First of all, in step 100, the location of the relevant points on the structure is determined and the structure state sensors are positioned at these points. The sensors may be located on the structure following determination of the topology of relevant points, or vice versa, using a network of pre-existing sensors on the structure a subset (or even the entire set) of corresponding relevant points is identified on the structure.</p><p><span class=\"paragraph-number\">[0036]   </span>During a first step, for example by means of same on-board processing unit, and in a definitive manner (except for system updates), M state vectors V<sub>Sj</sub> = [S<sub>1j</sub>, S<sub>2j</sub>, ..., S<sub>Nj</sub>] are acquired in step 200 for N relevant points and M different load conditions, with 1 &lt; j &lt; M, which are stored in the database DB.</p><p><span class=\"paragraph-number\">[0037]   </span>A state vector V<sub>S</sub> of the structure, with dimension N, is indicated as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 35mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2682836&ekey=977&cc=EP&producerName=imgb0001.tif&width=35mm&height=5mm\"/></maths></p><p> where S<sub>1</sub>, ..., S<sub>N</sub> each indicate, in abbreviated form, a value of the state parameter (in certain cases the set of three values of the components of a vectorial state parameter in a prechosen Cartesian spatial reference system) or a tupla of values of the state parameters chosen to indicate the operating condition of the structure.</p><p><span class=\"paragraph-number\">[0038]   </span>The vector V<sub>S</sub> may assume theoretically infinite values, in view of the infinite nature of the loads which may act on the structure in the different possible operating conditions, or in an infinite number of pluralities of rank-N relevant points of the structure, and with a plurality of possible intensity values.</p><p><span class=\"paragraph-number\">[0039]   </span>For the purposes of the invention it is considered that each element of V<sub>S</sub> may assume a finite discrete number of values, for example owing to measurement discretization of the sensors which are employed on the structure.</p><p><span class=\"paragraph-number\">[0040]   </span>In the currently preferred embodiment, for each load situation the processing unit U acquires N training deformation values [ε<sub>1l</sub>, ε<sub>2l</sub>, ..., ε<sub>Nl</sub>], one for each relevant point P<sub>i</sub>. For M different load conditions the processing unit therefore acquires M deformation vectors, each of N points. The M vectors of N points are stored in the database DB.</p><p><span class=\"paragraph-number\">[0041]   </span>Then, in step 300, a step for training the N neural networks is performed (one for each relevant point), setting for the neural network associated with the i-th point P<sub>i</sub> a condition of input values equal to the values of the deformation detected in the N-1 relevant points different from P<sub>i</sub> and stored in DB, and an output value representing the value of the deformation detected in the i-th relevant point P<sub>i</sub>, which is also stored in DB. Each neural network creates an association between the deformations in N-1 points and that in the relevant point P<sub>i</sub> with which it is associated, so that the processing unit has at its disposal N associative laws, of the type described above, for the value of the deformation of a point P<sub>i</sub> and each of the other N-1 points, for each value of i lying between 1 and N.</p><p><span class=\"paragraph-number\">[0042]   </span>Each neural network is configured during a training step advantageously performed during the first operating step of the structure. For training purposes preferably the data of M different load conditions are used, where M may be chosen depending on the number of coefficients C used by the neural network and should conveniently be at least five times the number of coefficients C in order to achieve satisfactory training.</p><p><span class=\"paragraph-number\">[0043]   </span>In the case of a plurality of load conditions a comparison may be made, for each point, between the predicted deformation obtained by means of the neural network during training using as an input value the other N-1 deformations in the new load condition, and that effectively detected at the point in this condition. With this approach it is possible to evaluate the degree of progress of training, which may be prolonged, if necessary, for further load conditions.</p><p><span class=\"paragraph-number\">[0044]   </span>Advantageously, for effective training the relevant points are selected based on structural and statistical (variability) criteria.</p><p><span class=\"paragraph-number\">[0045]   </span>At the end of the training procedure, operation of the neural networks may be verified in step 400 by comparing the output values envisaged by the trained network for given input values with the output values used during training, and assessing whether the difference, considered at a specific point and as an average, exceeds a fixed threshold and, in the case where incorrect operation is established (i.e. the difference exceeds, at a specific point and/or as an average, the fixed threshold of at least one or a predetermined minimum number thereof) the number of different load conditions to be used for performing detection of the state conditions in the relevant points is increased, generating new training deformation vectors [ε<sub>1l</sub>, ε<sub>2l</sub>, ..., ε<sub>Nl</sub>] which are stored in the database DB (step 200) and on which training of the neural networks (300) is carried out again.</p><p><span class=\"paragraph-number\">[0046]   </span>In the case where the incorrect operation of at least one neural network or a predetermined minimum number of such networks is determined a number of times greater than a predetermined threshold, the topology of relevant points is modified (step 100), by means of the addition or replacement of points, and then the steps for acquiring M' training deformation vectors [ε<sub>1l</sub>, ε<sub>2l</sub>, ..., ε<sub>N'l</sub>] for N' relevant points and M' different load conditions, storage thereof in the database DB and training of the N' neural networks are repeated in step 300. In the case where incorrect operation persists, in addition to prolonging the training period, it is possible to envisage modifying the number of levels and/or nodes per level of the neural network and/or modifying the function (function type) f and φ.</p><p><span class=\"paragraph-number\">[0047]   </span>If correct operation of the neural networks is established, the processing unit is configured to perform diagnostics of the structure, subject to any (for example periodic) updating of the deformation vectors, and corresponding new training of the neural networks, for example following modifications to the structure or ageing thereof.</p><p><span class=\"paragraph-number\">[0048]   </span>The operations for performing diagnostics of the structure are described below.</p><p><span class=\"paragraph-number\">[0049]   </span>Assuming that for a given load or given plurality of loads there is a distribution of deformations ε<sub>P</sub> in the grid of N relevant points P<sub>i</sub> of the structure, where 1 &lt; i &lt; N, (ε<sub>P</sub>)<sub>q</sub> indicates a distribution of deformations in the grid induced by the same load or plurality of loads in the presence of a structural defect, and more generally (ε<sub>P</sub>)<sub>d</sub> indicates a distribution of deformations detected by the sensors.</p><p><span class=\"paragraph-number\">[0050]   </span>At each instant, in step 500 the current state (ε<sub>P</sub>)<sub>d</sub> of the structure at the relevant points for a given current load condition is detected, for example the current deformations vector [ε<sub>1d</sub>, ... ε<sub>id</sub>, ..., ε<sub>Nd</sub>] is detected.</p><p><span class=\"paragraph-number\">[0051]   </span>Then, in step 600, for each point P<sub>i</sub>, with 1 &lt; i &lt; N the value of the deformation ε'<sub>i</sub> is calculated by means of the associated neural network previously trained, using inputs including the deformation values detected in the other points (ε<sub>1d</sub>, ... ε<sub>(i-1)d</sub>, ε<sub>(i+1)d</sub>, ..., ε<sub>Nd</sub>).</p><p><span class=\"paragraph-number\">[0052]   </span>Thereafter, in step 700, for each point and any load situation a comparison is carried out between the value of the state parameter predicted by the neural network and the value of the state parameter detected by the sensor. Specifically, the comparison between the value of the deformation ε<sub>id</sub> detected at the point P<sub>i</sub> and the value of the deformation ε'<sub>i</sub> calculated by the respective neural network in the same point is performed, repeating the comparison for each i, where 1 &lt; i &lt; N.</p><p><span class=\"paragraph-number\">[0053]   </span>An effective diagnostics evaluation is therefore performed by means of the comparison, at each point, between the expected structure state and the detected structure state. Identification of defects in the structure is performed for those points where the detected structure state differs from the expected state calculated by means of the respective neural network (namely there is a mismatch) beyond a predetermined percentage threshold.</p><p><span class=\"paragraph-number\">[0054]   </span>If the outcome of the comparison is the recognition of a condition where there is a substantial match of the values, taking into account a predetermined tolerance, the diagnostics method concludes that the structure is intact (800), signalling this condition by means of a signalling unit D to an operator, such as the aircraft pilot or a maintenance engineer, visually by means of written information and mapped points on a screen or electronically by means of issuing of a report, so as to indicate the intact state of the structure monitored.</p><p><span class=\"paragraph-number\">[0055]   </span>If the outcome of the comparison is the recognition of a condition where there is a substantial mismatch between the values, exceeding a predetermined tolerance, the diagnostics method interprets a possible defective condition of the structure (900). Consequently, the method repeats the step 500 for detecting the state of the structure in the relevant points selected, during a successive instant, for the current load condition. It then repeats the step 600 for each point P<sub>i</sub>, where 1 &lt; i &lt; N, calculating the value of the state parameter by means of the associated neural network previously trained and, finally, again in step 700, the comparison between the value of the state parameter detected at the point P<sub>i</sub> and the value of the state parameter calculated by the neural network at the same point, for each i, where 1 &lt; i &lt; N, is performed.</p><p><span class=\"paragraph-number\">[0056]   </span>The cycle of operations in steps 500-700 is repeated a predetermined number of times, checking whether a predetermined number of repetitions in the comparison step 1000 have been reached, unless a condition where there is substantial match between the values, and therefore an intact condition of the structure, is definitively recognized.</p><p><span class=\"paragraph-number\">[0057]   </span>If in the comparison step 1000 it is determined that the predetermined number of repetitions has been reached and the indication of a defective state of the structure remains, a signal (1100) is emitted, by means of the signalling unit D, to an operator, such as the aircraft pilot or a maintenance engineer, visually in the form of written information and mapped points on a screen or electronically by means of issuing of a report, so as to indicate the defective state of the monitored structure and its location (namely, identification of the point P<sub>i</sub> where there is no match between the value of the state parameter detected and the value of this parameter calculated by the neural network).</p><p><span class=\"paragraph-number\">[0058]   </span>The diagnostics evaluation may be further verified by considering different load situations and therefore measurements of the structure state: if the mismatch is repeated for different load conditions, this may be interpreted as a confirmation of the presence of damage or a defect in the structure which induces a variation in state. If the mismatch is not repeated, this may be interpreted as being an occasional or spurious signal, not caused by real physical factors.</p><p><span class=\"paragraph-number\">[0059]   </span>The diagnostics evaluation described above is performed for each relevant point of the structure. Mapping of the points where the presence of damage or a defect in the structure is determined provides an indication of the extent of the damage. For example, determination of damage or a defect in various adjacent points is an indication of a delaminated area.</p><p><span class=\"paragraph-number\">[0060]   </span>Obviously, as will be clear to a person skilled in the art, the method concluded as illustrated in the flow diagram shown in the figure may be cyclically repeated, for example at predetermined periodic intervals in accordance with a predetermined monitoring program.</p><p><span class=\"paragraph-number\">[0061]   </span>Advantageously, in order to allow operation of the system also in the case of damage to the structure in the vicinity of some of the detection points, i.e. where there is damage to the sensors, a surplus is created by increasing the number of relevant detection points so as to have a certain number of additional backup sensors.</p><p><span class=\"paragraph-number\">[0062]   </span>Obviously, without affecting the principle of the invention, the embodiments and the constructional details may be greatly modified with respect to that described and illustrated purely by way of a non-limiting example, without thereby departing from the scope of the invention as defined in the accompanying claims.</p>",
            "CLMS": "(EP2682836)<br/><p>1. Method for performing diagnostics of a structure (S1-S3) subject to loads, particularly an aircraft structure (A), by means of a sensor arrangement which is associated with said structure (S1-S3) and designed to detect at least one state of the structure and which comprises a matrix of sensors (P) which are located in relevant points (P<sub>i</sub>) of the structure (S1-S3) and each of which is capable of detecting a physical parameter indicative of the local state of the structure (S1-S3) and of emitting a respective electrical response signal correlated to the value assumed by said parameter,<br/>the method comprising,<br/>in a learning step (100-300):<br/> (a) based on a plurality of training data indicative of the state of the structure (S1-S3) at a plurality of relevant detection points (P<sub>i</sub>) by association with at least one load condition, establishing (300) an associative relationship, by means of at least one neural network, between the values assumed by said parameter indicative of the state of the structure in a subset of said plurality of relevant detection points and the values of the state parameter in at least a residual relevant detection point; and<br/>in an operating step:<br/> (b) detecting (500) the values assumed by said parameter indicative of the state of the structure in a plurality of relevant detection points (P<sub>i</sub>) in said at least one load condition;<br/> (c) based on the pre-established associative relationship, using the values assumed by said parameter indicative of the state of the structure in a subset of said plurality of detection points, estimating (600) the values of the state parameter in at least one residual detection point;<br/> (d) comparing (700) the estimated values and the detected values of the state parameter in said at least one residual detection point; and<br/> (e) determining an intact state of the structure (800) if the detected and the estimated values of the state parameter substantially match, taking into consideration predetermined tolerances, or determining a defective state of the structure (900, 1000) if said values of the state parameter differ, taking into consideration the predetermined tolerances.</p><p>2. Method according to Claim 1, wherein the comparison (700) between the estimated and the detected values of the state parameter is carried out for each relevant detection point (P<sub>i</sub>).</p><p>3. Method according to Claim 1 or 2, wherein said learning step (100-300) and said operating step (500-1000) are carried out in a plurality of different load conditions, whereby a defective state of the structure is determined when there is a condition of mismatch between the estimated and detected values of the state parameter in a plurality of load conditions, while occasional signalling occurs when there is a condition of mismatch between the estimated and detected values of the state parameter in only one load condition or in a number of conditions where there is a load less than a threshold.</p><p>4. Method according to any one of the preceding claims, wherein the learning step includes collecting (200) a plurality of training data in the form of vectors comprising the values assumed by at least one predetermined state parameter detected in the relevant points, in at least one load condition.</p><p>5. Method according to any one of the preceding claims, wherein a plurality of neural networks are respectively associated with said relevant points (P<sub>i</sub>) and the learning step comprises, for each neural network, determining an associative relationship between the values assumed by said parameter indicative of the state of the structure in at least one load condition in the relevant detection point corresponding to said network and the values assumed by the state parameter in the remaining plurality of relevant detection points.</p><p>6. Method according to Claim 5, wherein the learning step comprises, in the case of a plurality of load conditions, a comparison between the value of the state parameter estimated by means of the neural network during training in at least one relevant point and the value assumed by the state parameter in said at least one relevant point, in a new load condition.</p><p>7. Method according to Claim 6, comprising monitoring (400) learning of the neural networks by means of a comparison between the value of the state parameter, estimated in at least one residual relevant point based on training data indicative of the state of the structure for a subset of said plurality of relevant detection points, and the value of the training state parameter in said residual relevant point, the learning being regarded as completed if the difference between the aforementioned values is less than a predefined threshold, or otherwise unsatisfactory, whereby the number of different load conditions in which the learning step is carried out is increased, or the topology of the relevant points is modified, or else at least one from among the number of levels, the number of nodes per level and a characteristic function of the neural networks is modified.</p><p>8. Method according to any one of the preceding claims, wherein a defective state of the structure is determined if said values of the state parameter differ, taking into consideration the predetermined tolerances, after a time sequence of a predetermined number of iterations of steps (b), (c) and (d).</p><p>9. Method according to any one of the preceding claims, <b>characterized in that</b> it is repeated at predetermined periodic intervals according to a pre-established monitoring plan.</p><p>10. Method according to any one of the preceding claims, wherein mapping of the relevant points (P<sub>i</sub>) during which the defective condition of the structure is estimated is interpreted as an indication of the extent of said defective condition.</p><p>11. Method according to any one of the preceding claims, wherein said parameter indicative of the state of the structure is the local deformation of the structure.</p><p>12. Method according to any one of the preceding claims, wherein said relevant detection points (P<sub>i</sub>) are chosen based on a periodicity criterion, except for any clustering in the vicinity of areas of greater structural criticality.</p><p>13. System for performing diagnostics of a structure (S1-S3) subject to loads, particularly an aircraft structure (A), comprising:<br/> - a sensor arrangement which is associated with said structure and designed to detect at least one state of the structure and which comprises a matrix of sensors (P) which are located in relevant points (P<sub>i</sub>) of the structure (S1-S3) and each of which is capable of detecting a physical parameter indicative of the local state of the structure and of emitting a respective electrical response signal correlated to the value assumed by said parameter; and<br/> - electronic learning processing means (U) of the neural network type, arranged for implementing a method according to any one of Claims 1 to 12.</p><p>14. System according to Claim 13, wherein said processing means (U) comprise a plurality of neural networks respectively associated with said relevant points (P<sub>i</sub>), wherein each neural network is a network with Q levels, with d<sub>Q</sub> nodes per level, for each node a respective correlation parameter C being defined, a crossed correlation function φ associating a crossed correlation parameter K with each pair of correlation parameters C<sub>a</sub>, C<sub>b</sub>, with K<sub>a,b</sub> = φ (C<sub>a</sub>, C<sub>b</sub>), a hyperbolic function f determining a correlation between each node of a level X<sub>i+1,j</sub> and the nodes of the preceding level X<sub>i,j</sub> as a function of said crossed correlation parameter, as: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 107mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2682836&ekey=977&cc=EP&producerName=imgb0002.tif&width=107mm&height=5mm\"/></maths></p><p> the training of the network including determining the parameters C that minimize the difference between the calculated output value and its actual value.</p><p>15. System according to either one of Claim 13 or Claim 14, wherein said processing means (U) are connected to a signalling unit (D) for indicating to an operator the defective or intact state of the monitored structures.</p><p>16. System according to any one of Claims 13 to 15, wherein said detection sensors (P) include sensors for detecting deformation of the structure.</p><p>17. Processing program or group of programs which may be executed by a system according to any of the claims 13 to 16, comprising one or more code modules for implementing a method for performing diagnostics of a structure subject to loads, according to any one of Claims 1 to 12.</p>",
            "NPR": "1",
            "APID": "88600249",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64F-005/00<br/>G01M-007/00<br/>G05B-023/02<br/>G06N-003/08",
            "ID": "61119843",
            "AB": "(EP2682836)<br/>A method for performing diagnostics of a structure subject to loads, in particular an aircraft structure, is described, said method being implemented by means of an arrangement of sensors located at relevant points of the structure and corresponding neural networks, and comprising: training the neural network in order to establish an associative relationship between the state of the structure in a subset of relevant points and the state of the structure in at least one residual relevant point; detecting the state of the structure in a plurality of relevant points under operating conditions; estimating the state of the structure in at least one residual relevant point by means of the associated neural network on the basis of the pre-established associated relationship; and comparing the state of the estimated structure with the detected state at the residual relevant point, such that an intact state of the structure is determined if the expected and detected values of the state parameter match, or a defective state of the structure is determined if these values differ.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=R45lSTAtkAfWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2012-07-04",
            "PA": "LEONARDO<br/>ALENIA AERMACCHI<br/>ALENIYA AERMAKKI<br/>LEONARDO SPA<br/>ALENIA AERMACCHI SPA",
            "PAAD": "(EP2682836)<br/>(PUB:EP-2682836B1-0)NAME=LEONARDO S.p.A. Piazza Monte Grappa 4 , CITY=00195 Roma , COUNTRY=IT , REG=101647189<br/><br/>(PUB:EP-2682836A3-0)NAME=Alenia Aermacchi S.p.A. Via Ing. Paolo Foresio 1 , CITY=21040 Venegono Superiore (Varese) , COUNTRY=IT , REG=101148774<br/><br/>(PUB:EP-2682836A2-0)NAME=Alenia Aermacchi S.p.A. Via Ing. Paolo Foresio 1 , CITY=21040 Venegono Superiore (Varese) , COUNTRY=IT , REG=101148774<br/><br/><br/>(US9969507)<br/>(PUB:US-09969507B2-1)NAME=ALENIA AERMACCHI S.p.A.  , CITY=Venegono Superiore, Varese , COUNTRY=IT , ATYP=Non-US Company<br/><br/>(PUB:US-2014012461A1-0)NAME=ALENIA AERMACCHI S.p.A.  , CITY=Varese , COUNTRY=IT<br/><br/><br/>(RU2013130664)<br/>(PUB:RU-2013130664A-0)NAME=ALENIYA AERMAKKI S P A  , COUNTRY=IT<br/><br/><br/>(ES2663251)<br/>(PUB:ES-2663251T3-0)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "61119843",
            "TI": "Method for performing diagnostics of a structure subject to loads and system for implementing said method",
            "TECD": "Computer technology<br/>Control<br/>Measurement<br/>Transport",
            "EPD": "2014-01-05",
            "ICLM": "(EP2682836)<br/><p>1. Method for performing diagnostics of a structure (S1-S3) subject to loads, particularly an aircraft structure (A), by means of a sensor arrangement which is associated with said structure (S1-S3) and designed to detect at least one state of the structure and which comprises a matrix of sensors (P) which are located in relevant points (Pi) of the structure (S1-S3) and each of which is capable of detecting a physical parameter indicative of the local state of the structure (S1-S3) and of emitting a respective electrical response signal correlated to the value assumed by said parameter, the method comprising, in a learning step (100-300): (a) based on a plurality of training data indicative of the state of the structure (S1-S3) at a plurality of relevant detection points (Pi) by association with at least one load condition, establishing (300) an associative relationship, by means of at least one neural network, between the values assumed by said parameter indicative of the state of the structure in a subset of said plurality of relevant detection points and the values of the state parameter in at least a residual relevant detection point; and in an operating step: (b) detecting (500) the values assumed by said parameter indicative of the state of the structure in a plurality of relevant detection points (Pi) in said at least one load condition; (c) based on the pre-established associative relationship, using the values assumed by said parameter indicative of the state of the structure in a subset of said plurality of detection points, estimating (600) the values of the state parameter in at least one residual detection point; (d) comparing (700) the estimated values and the detected values of the state parameter in said at least one residual detection point; and (e) determining an intact state of the structure (800) if the detected and the estimated values of the state parameter substantially match, taking into consideration predetermined tolerances, or determining a defective state of the structure (900, 1000) if said values of the state parameter differ, taking into consideration the predetermined tolerances.</p>",
            "CTN": "(EP2682836)<br/>XP055054940 none WHO=EXAMINER SELF=N CAT=A<br/>XP055054941 none WHO=EXAMINER SELF=N CAT=A<br/>XP004656067 none WHO=EXAMINER SELF=N CAT=A<br/>US20110313726 44371725 WHO=EXAMINER SELF=N CAT=A<br/>EP2281224 1043354 WHO=APPLICANT SELF=N<br/><br/>(US9969507)<br/>US5774376 43005697 WHO=EXAMINER SELF=N<br/>US6480792 1495094 WHO=EXAMINER SELF=N<br/>US7286964 61969240 WHO=EXAMINER SELF=N<br/>US7596470 61969240 WHO=EXAMINER SELF=N CAT=102<br/>US7822697 4128385 WHO=EXAMINER SELF=N<br/>US20070260425 61969240 WHO=EXAMINER SELF=N<br/>US20110231037 4177478 WHO=EXAMINER SELF=N<br/>US20130238532 45974628 WHO=EXAMINER SELF=N CAT=102<br/>US20160091388 67855578 WHO=EXAMINER SELF=N<br/>US20110313726 44371725 WHO=APPLICANT SELF=N<br/>WO201064216 1043354 WHO=APPLICANT SELF=N<br/><br/>(IT2012TO0588)<br/>XP055054940 none WHO=EXAMINER SELF=N CAT=A<br/>XP055054941 none WHO=EXAMINER SELF=N CAT=A<br/>XP004656067 none WHO=EXAMINER SELF=N CAT=A<br/>US20110313726 44371725 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2033-07-03",
                    "XAP": "2013EP-0174839",
                    "APD": "2013-07-03",
                    "APID": "88600249",
                    "REG_LINK": "https://register.epo.org/application?number=EP13174839",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=R45lSTAtkAfWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP2682836",
                            "KIND": "B1",
                            "XPN": "EP2682836",
                            "V_PNID": "EP-2682836B1-0",
                            "DATE": "2017-12-20",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=1u0pG79XqmDc6tzwf+vaoqxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2682836&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=R45lSTAtkAfWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP2682836",
                            "KIND": "A3",
                            "XPN": "EP2682836",
                            "V_PNID": "EP-2682836A3-0",
                            "DATE": "2016-04-20",
                            "STG": "Published search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=1u0pG79XqmDc6tzwf+vaoo4J+Hxg+Ja9PJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2682836&kind=A3",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=R45lSTAtkAfWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP2682836",
                            "KIND": "A2",
                            "XPN": "EP2682836",
                            "V_PNID": "EP-2682836A2-0",
                            "DATE": "2014-01-08",
                            "STG": "Application published without search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=1u0pG79XqmDc6tzwf+vaohWceYjKUptoPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2682836&kind=A2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=R45lSTAtkAfWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2023-08-25",
                            "XAP": "2013ES-0174839T",
                            "APD": "2013-07-03",
                            "APID": "128383456",
                            "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Xvr3%252BukdTDkuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "ES2663251",
                                    "KIND": "T3",
                                    "XPN": "ES2663251",
                                    "V_PNID": "ES-2663251T3-0",
                                    "DATE": "2018-04-11",
                                    "STG": "Translation of granted European patent (former B3)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=a4uVmah4rFpFkRxlDquM/H4Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2663251&kind=T3",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Xvr3%252BukdTDkuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2016-07-04",
                    "XAP": "2013RU-0130664",
                    "APD": "2013-07-03",
                    "APID": "102960018",
                    "REG_LINK": "https://www1.fips.ru/registers-web/",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=SHP%252FXiMuk2RBpEGsgOXzzbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "RU2013130664",
                            "KIND": "A",
                            "XPN": "RU2013130664",
                            "V_PNID": "RU-2013130664A-0",
                            "DATE": "2015-01-10",
                            "STG": "Application for invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=BifV9gOYQAObtE5UjpTRlAMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=RU2013130664&kind=A",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=SHP%252FXiMuk2RBpEGsgOXzzbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2035-06-02",
                    "XAP": "2013US-13933964",
                    "APD": "2013-07-02",
                    "APID": "88860378",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/13933964",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Cur2EmKZNA3dGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US9969507",
                            "KIND": "B2",
                            "XPN": "US9969507",
                            "V_PNID": "US-09969507B2-1",
                            "DATE": "2018-05-15",
                            "STG": "Granted patent as second publication",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=z7higowfyY7hq/fgqaO8wkDJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=US9969507&kind=B2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=Cur2EmKZNA3dGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "US20140012461",
                            "KIND": "A1",
                            "XPN": "US20140012461",
                            "V_PNID": "US-2014012461A1-0",
                            "DATE": "2014-01-09",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcN/hGf0Fb7eTJByHje3bCdrbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20140012461&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=wBfwZ2w4rR9eXLb2QBXcX8RHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2032-07-04",
                    "XAP": "2012IT-TO00588",
                    "APD": "2012-07-04",
                    "APID": "88626035",
                    "REG_LINK": "",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CwowRQ4sPX4DNN2rNfwllrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "ITTO20120588",
                            "KIND": "A1",
                            "XPN": "IT2012TO0588",
                            "V_PNID": "IT-TO20120588A1-0",
                            "DATE": "2014-01-05",
                            "STG": "Application for patent of invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=PknmpDUQ+yw4Uk2Deg0TDd0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IT2012TO0588&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CwowRQ4sPX4DNN2rNfwllrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP2682836_B1",
            "EPRD": "2012-07-04",
            "PN": "EP2682836           B1 2017-12-20 [EP2682836]<br/>EP2682836           A3 2016-04-20 [EP2682836]<br/>EP2682836           A2 2014-01-08 [EP2682836]<br/>US9969507           B2 2018-05-15 [US9969507]<br/>US20140012461       A1 2014-01-09 [US20140012461]<br/>RU2013130664        A  2015-01-10 [RU2013130664]<br/>ES2663251           T3 2018-04-11 [ES2663251]<br/>ITTO20120588        A1 2014-01-05 [IT2012TO0588]",
            "ADB": "(EP2682836)<br/><p>Each neural network is configured during a training step advantageously performed during the first operating step of the structure.</p><p>In methods for carrying out the maintenance of systems (parts of products or complex products) it is of particular interest to be able to reduce unexpected faults by monitoring certain parameters indicating the state of the system.</p><p>Advantageously, in order to allow operation of the system also in the case of damage to the structure in the vicinity of some of the detection points, i.e. where there is damage to the sensors, a surplus is created by increasing the number of relevant detection points so as to have a certain number of additional backup sensors.</p><p>In a currently preferred embodiment, the structure being examined is equipped with a limited number of deformation sensors located in relevant points.</p><p>In particular, in the case of composite structures, accidental impacts produce effects which are not very visible externally, but may cause considerable damage inside the structure (for example, delamination).</p>"
        },
        {
            "FNUM": "APAGE=41<br/>NBPC=12<br/>PNAAGE=35<br/>NBPA=1; <br/>ALLCT=11; SCT=0; NSCT=11; <br/>ALLCTG=17; SCTG=0; NSCTG=17; <br/>AFS=14; ACC=13; AMCC=8; <br/>IGEN=0.93; IORG=0.92; IRAD=0.97; <br/>IMPI=4.49; MACI=2.8; PASI=5.41; PAVI=4.6; ",
            "PTCC": "(EP2812249)<br/>CC=EP EED=2032-12-21 STATUS=GRANTED APID=89110846 APD=2012-12-21 XPN=EP2812249 PD=2014-12-17 PD=2016-03-16 EPD=2014-12-17 LPD=2016-03-16 PDG=2016-03-16 <br/>CC=DE EED=2032-12-21 STATUS=GRANTED APID=89110846 XPN=EP2812249 PDG=2016-03-16 <br/>CC=ES EED=2032-12-21 STATUS=GRANTED APID=109417132 APD=2012-12-21 XPN=ES2582634 PD=2016-09-14 EPD=2016-09-14 LPD=2016-09-14 PDG=2016-09-14 <br/>CC=FR EED=2032-12-21 STATUS=GRANTED APID=89110846 XPN=EP2812249 PDG=2016-03-16 <br/>CC=GB EED=2032-12-21 STATUS=GRANTED APID=89110846 XPN=EP2812249 PDG=2016-03-16 <br/>CC=IT EED=2032-12-21 STATUS=GRANTED APID=89110846 XPN=EP2812249 PDG=2016-03-16 <br/><br/>(US9643710)<br/>CC=US EED=2033-06-26 STATUS=GRANTED APID=106015749 APD=2012-12-21 XPN=US20150367930 PD=2015-12-24 PD=2017-05-09 EPD=2015-12-24 LPD=2017-05-09 PDG=2017-05-09 <br/><br/>(WO2013117971)<br/>CC=BR EED=2032-12-21 STATUS=GRANTED APID=139490710 APD=2012-12-21 XPN=BR112014019640 PD=2014-10-21 PD=2017-06-20 PD=2017-07-11 PD=2021-05-25 EPD=2014-10-21 LPD=2021-05-25 PDG=2021-05-25 <br/>CC=CA EED=2032-12-21 STATUS=GRANTED APID=100178817 APD=2012-12-21 XPN=CA2863745 PD=2013-08-15 PD=2020-08-04 EPD=2013-08-15 LPD=2020-08-04 PDG=2020-08-04 <br/>CC=CN EED=2032-12-21 STATUS=GRANTED APID=100991047 APD=2012-12-21 XPN=CN104245514 PD=2014-12-24 PD=2016-08-17 EPD=2014-12-24 LPD=2016-08-17 PDG=2016-08-17 <br/>CC=EP EED=2032-12-21 STATUS=GRANTED APID=89110846 APD=2012-12-21 XPN=EP2812249 PD=2014-12-17 PD=2016-03-16 EPD=2014-12-17 LPD=2016-03-16 PDG=2016-03-16 <br/>CC=ES EED=2032-12-21 STATUS=GRANTED APID=109417132 APD=2012-12-21 XPN=ES2582634 PD=2016-09-14 EPD=2016-09-14 LPD=2016-09-14 PDG=2016-09-14 <br/>CC=HK EED=2032-12-21 STATUS=GRANTED APID=106160286 APD=2015-06-24 XPN=HK1205491 PD=2015-12-18 EPD=2015-12-18 LPD=2015-12-18 PDG=2015-12-18 <br/>CC=IN EED=2032-12-21 STATUS=GRANTED APID=109924945 APD=2014-08-13 XPN=IN2014CN06155 PD=2016-07-01 PD=2023-01-02 EPD=2016-07-01 LPD=2023-01-02 PDG=2023-01-02 <br/>CC=KR EED=2032-12-21 STATUS=GRANTED APID=101502312 APD=2012-12-21 XPN=KR20150001719 PD=2015-01-06 PD=2018-12-27 EPD=2015-01-06 LPD=2018-12-27 PDG=2018-12-27 <br/>CC=RU EED=2032-12-21 STATUS=GRANTED APID=107259827 APD=2012-12-21 XPN=RU2014132574 PD=2016-03-27 PD=2017-09-22 EPD=2016-03-27 LPD=2017-09-22 PDG=2017-09-22 <br/>CC=US EED=2033-06-26 STATUS=GRANTED APID=106015749 APD=2012-12-21 XPN=US20150367930 PD=2015-12-24 PD=2017-05-09 EPD=2015-12-24 LPD=2017-05-09 PDG=2017-05-09 <br/><br/>(RU2631437)<br/>CC=RU EED=2032-12-21 STATUS=GRANTED APID=107259827 APD=2012-12-21 XPN=RU2014132574 PD=2016-03-27 PD=2017-09-22 EPD=2016-03-27 LPD=2017-09-22 PDG=2017-09-22 <br/><br/>(IN-416424)<br/>CC=IN EED=2032-12-21 STATUS=GRANTED APID=109924945 APD=2014-08-13 XPN=IN2014CN06155 PD=2016-07-01 PD=2023-01-02 EPD=2016-07-01 LPD=2023-01-02 PDG=2023-01-02 <br/><br/>(BR112014019640)<br/>CC=BR EED=2032-12-21 STATUS=GRANTED APID=139490710 APD=2012-12-21 XPN=BR112014019640 PD=2014-10-21 PD=2017-06-20 PD=2017-07-11 PD=2021-05-25 EPD=2014-10-21 LPD=2021-05-25 PDG=2021-05-25 <br/><br/>(CA2863745)<br/>CC=CA EED=2032-12-21 STATUS=GRANTED APID=100178817 APD=2012-12-21 XPN=CA2863745 PD=2013-08-15 PD=2020-08-04 EPD=2013-08-15 LPD=2020-08-04 PDG=2020-08-04 <br/><br/>(KR101933253)<br/>CC=KR EED=2032-12-21 STATUS=GRANTED APID=101502312 APD=2012-12-21 XPN=KR20150001719 PD=2015-01-06 PD=2018-12-27 EPD=2015-01-06 LPD=2018-12-27 PDG=2018-12-27 <br/><br/>(ES2582634)<br/>CC=ES EED=2032-12-21 STATUS=GRANTED APID=109417132 APD=2012-12-21 XPN=ES2582634 PD=2016-09-14 EPD=2016-09-14 LPD=2016-09-14 PDG=2016-09-14 <br/><br/>(CN104245514B)<br/>CC=CN EED=2032-12-21 STATUS=GRANTED APID=100991047 APD=2012-12-21 XPN=CN104245514 PD=2014-12-24 PD=2016-08-17 EPD=2014-12-24 LPD=2016-08-17 PDG=2016-08-17 <br/><br/>(HK1205491)<br/>CC=HK EED=2032-12-21 STATUS=GRANTED APID=106160286 APD=2015-06-24 XPN=HK1205491 PD=2015-12-18 EPD=2015-12-18 LPD=2015-12-18 PDG=2015-12-18 <br/><br/>(IT2012TO0111)<br/>CC=IT EED=2032-02-09 STATUS=PENDING APID=69242919 APD=2012-02-09 XPN=IT2012TO0111 PD=2013-08-10 EPD=2013-08-10 LPD=2013-08-10 <br/>",
            "EPN": "ITTO20120111",
            "CTGN": "(US9643710)<br/>CN106903506 76647721 WHO=EXAMINER SELF=N CAT=A<br/>US20160185467 73423870 WHO=EXAMINER SELF=N CAT=103<br/>US10046866 73423870 WHO=EXAMINER SELF=N<br/>WO2019199856 86312482 WHO=EXAMINER SELF=N CAT=A<br/>CN109738002B 84446425 WHO=EXAMINER SELF=N<br/>US11989027 86312482 WHO=APPLICANT SELF=N<br/><br/>(WO2013117971)<br/>CN103991557B 67256403 WHO=EXAMINER SELF=N<br/>KR101687554 73423870 WHO=EXAMINER SELF=N<br/>KR101687562 73563410 WHO=EXAMINER SELF=N<br/>KR20160081314 73563410 WHO=EXAMINER SELF=N<br/>KR20160082412 73423870 WHO=EXAMINER SELF=N<br/>EP3168162 76038534 WHO=EXAMINER SELF=N CAT=A<br/>CN106404362 75410528 WHO=EXAMINER SELF=N CAT=A<br/>KR101841510 79229529 WHO=EXAMINER SELF=N<br/>US20160185467 73423870 WHO=EXAMINER SELF=N CAT=103<br/>EP3647207 88500127 WHO=EXAMINER SELF=N CAT=A<br/>RU-203726 93733177 WHO=EXAMINER SELF=N<br/>EP2939931 71242183 WHO=EXAMINER SELF=N<br/>US10046866 73423870 WHO=APPLICANT SELF=N<br/>US10275565 76038534 WHO=APPLICANT SELF=N<br/>US10427254 71242183 WHO=APPLICANT SELF=N<br/>US10442555 71242125 WHO=APPLICANT SELF=N<br/>US10501209 71242131 WHO=APPLICANT SELF=N<br/>US10712730 88180506 WHO=APPLICANT SELF=N<br/>US11179819 88500127 WHO=APPLICANT SELF=N<br/>US11188688 76038534 WHO=APPLICANT SELF=N<br/>US11294357 88180506 WHO=APPLICANT SELF=N<br/>US11364581 71242183 WHO=APPLICANT SELF=N<br/>US11415968 88180506 WHO=APPLICANT SELF=N<br/>US11529706 88500127 WHO=APPLICANT SELF=N<br/>EP3168162 76038534 WHO=APPLICANT SELF=N<br/><br/>(RU2631437)<br/>RU2791200 87770518 WHO=EXAMINER SELF=N<br/><br/>(CN104245514B)<br/>CN109693808B 84270648 WHO=EXAMINER SELF=N",
            "LAPD": "2015-06-24",
            "STDN": "",
            "NPN": "12",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application is a National Stage Application of PCT/IB2012/057627, filed 21 Dec. 2012, which claims benefit of Serial No. TO2012A000111, filed 9 Feb. 2012 in Italy and which applications are incorporated herein by reference. To the extent appropriate, a claim of priority is made to each of the above disclosed applications.</p><p><h1>BACKGROUND</h1></p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates to an automated system for structurally joining at least two main portions making up the chassis of a vehicle or the fuselage of an aircraft or the hull of a boat. Said system can automatically and continuously handle all the steps of the associated method for joining the portions. Said system can handle the entire kinematic/mechanic chain for manufacturing said vehicle or aircraft or boat.</p><p><span class=\"paragraph-number\">[0003]   </span>The associated method of assembly concerns the steps carried out by the system for assembling chassis or fuselage or hull portions, which steps are carried out automatically and are highly reproducible.</p><p><span class=\"paragraph-number\">[0004]   </span>Preferably, said system and the associated method are applicable for manufacturing aircraft fuselages by joining at least two fuselage sections.</p><p><span class=\"paragraph-number\">[0005]   </span>It is known that assembling the sections of an aircraft fuselage is a very complex task that requires much control in order to create an aircraft capable of passing the flight resistance tests. In fact, if such sections are not properly assembled, the resulting aircraft will suffer stability and aerodynamics problems, which may endanger the utilization of the aircraft thus assembled.</p><p><span class=\"paragraph-number\">[0006]   </span>Systems for joining at least two fuselage sections are known which comprise a plurality of sensors adapted to facilitate the steps of positioning, moving and joining said sections, which are carried out by assembly personnel. In fact, most of the steps of the methods for manufacturing an aircraft described in the prior art are carried out by human personnel with the help of electromechanical devices and sensors of various nature.</p><p><span class=\"paragraph-number\">[0007]   </span>For this reason, when manufacturing an aircraft, errors may be made due to the human component while executing one or more steps of the method for assembling and joining the aircraft sections.</p><p><span class=\"paragraph-number\">[0008]   </span>Automatic devices are known which are adapted to carry out one or more steps of the method for manufacturing an aircraft; said devices are supervised by an assembly operator. Therefore, in order to join sections of an aircraft, the operator will have to supervise a plurality of automatic devices. Manufacturing an aircraft in compliance with assembly standards strongly depends on the skills of the assembly operator, who is in charge of coordinating the various devices and possibly also supervising any manually executed operations.</p><p><span class=\"paragraph-number\">[0009]   </span>A method of this type turns out to be very costly, because it requires the use of many electromechanical devices that must be made to interact with one another, and also because of the large number of manual operations involved. In addition, such a method is also costly in terms of production time per aircraft, because the various steps must be supervised by the person in charge, although with the help of sensors of various kinds, who must supervise every critical aspect of the aircraft production process.</p><p><span class=\"paragraph-number\">[0010]   </span>Finally, this type of method, the implementation of which requires a human component, introduces an uncertain variable which makes the method hardly reproducible and which, in probabilistic terms, causes high uncertainty as to the result thereof. Such uncertainty implies increased average aircraft production costs.</p><p><span class=\"paragraph-number\">[0011]   </span>It should also be underlined that each electromechanical device used for implementing the method introduces intrinsic uncertainty in the operations it is adapted to perform; such uncertainty adds up to the uncertainties of the other electromechanical devices, because the systems known in the art do not include a central control system capable of coordinating such electromechanical devices to eliminate any errors so as to reduce the uncertainty of the entire system and, as a consequence, of the manufacturing method.</p><p><span class=\"paragraph-number\">[0012]   </span>Junction errors are also due to intrinsic physical factors, such as thermal or mechanical expansion of metal parts, depending on the temperature and humidity present in the place where the assembly process is being carried out.</p><p><span class=\"paragraph-number\">[0013]   </span>Checks are also known to be made on the junction by means of laser measurements taken at discrete instants while executing the joining method.</p><p><span class=\"paragraph-number\">[0014]   </span>However, such checks do not ensure junction repeatability and correct alignment of all of the key points required for properly joining the parts.</p><p><h1>SUMMARY</h1></p><p><span class=\"paragraph-number\">[0015]   </span>The present invention aims at solving the above-mentioned problems by providing a system for joining at least to main portions of a chassis or an aircraft fuselage or, a boat hull, which system can automatically control and manage a plurality of actuation devices through a central control unit as a function of data obtained from a plurality of sensors.</p><p><span class=\"paragraph-number\">[0016]   </span>The present invention also aims at solving the above-mentioned problems by implementing a new method for joining at least two main portions or sections in a totally automatic manner, allowing for re-alignment of all key points for the purpose of ensuring repeatability of the junction between the main portions or sections.</p><p><span class=\"paragraph-number\">[0017]   </span>One aspect of the present invention relates to an automated system for joining at least two main portions of a chassis or a fuselage or a hull.</p><p><span class=\"paragraph-number\">[0018]   </span>A further aspect of the present invention relates to a method for automatically joining at least two main portions or sections.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0019]   </span>The features and advantages of the automated system and of the associated method according to the present invention will become more apparent from the following description of at least one embodiment thereof and from the annexed drawings, wherein:</p><p><span class=\"paragraph-number\">[0020]   </span><a href=\"#DRAWINGS\">FIG. 1</a> is a schematic plan view of a joining system according to the present invention;</p><p><span class=\"paragraph-number\">[0021]   </span><a href=\"#DRAWINGS\">FIG. 2</a> is a general perspective view, of an embodiment of the joining system according to the present invention;</p><p><span class=\"paragraph-number\">[0022]   </span><a href=\"#DRAWINGS\">FIGS. 3A and 3B</a> show the actuation device; in particular, <a href=\"#DRAWINGS\">FIG. 3A</a> shows one embodiment of an actuation device, and <a href=\"#DRAWINGS\">FIG. 3B</a> shows a detail of a column;</p><p><span class=\"paragraph-number\">[0023]   </span><a href=\"#DRAWINGS\">FIG. 4</a> shows a flow chart of one implementation of the joining method according to the present invention;</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIGS. 5A, 5B</a> are perspective views showing the execution of steps g) and h) of the flow chart of <a href=\"#DRAWINGS\">FIG. 4</a>, implemented by the system shown in <a href=\"#DRAWINGS\">FIGS. 1 and 2</a>, for joining a front section of an aircraft fuselage, wherein <a href=\"#DRAWINGS\">FIG. 5A</a> shows step g) and <a href=\"#DRAWINGS\">FIG. 5B</a> shows step h);</p><p><span class=\"paragraph-number\">[0025]   </span><a href=\"#DRAWINGS\">FIG. 6</a> is a perspective view showing the positioning of a third section for assembling a fuselage by applying the joining method according to the present invention;</p><p><span class=\"paragraph-number\">[0026]   </span><a href=\"#DRAWINGS\">FIG. 7</a> is a block diagram of the control circuits comprised in the automated system according to the present invention.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to an automated system for structurally joining at least two main portions making up the chassis of a vehicle or the fuselage of an aircraft or the hull of a boat. Said system can automatically and continuously handle all the steps of the associated method for joining the portions. Said system can handle the entire kinematic/mechanic chain for manufacturing said vehicle or aircraft or boat.</p><p><span class=\"paragraph-number\">[0002]   </span>The associated method of assembly concerns the steps carried out by the system for assembling chassis or fuselage or hull portions, which steps are carried out automatically and are highly reproducible.</p><p><span class=\"paragraph-number\">[0003]   </span>Preferably, said system and the associated method are applicable for manufacturing aircraft fuselages by joining at least two fuselage sections.</p><p><span class=\"paragraph-number\">[0004]   </span>It is known that assembling the sections of an aircraft fuselage is a very complex task that requires much control in order to create an aircraft capable of passing the flight resistance tests. In fact, if such sections are not properly assembled, the resulting aircraft will suffer stability and aerodynamics problems, which may endanger the utilization of the aircraft thus assembled.</p><p><span class=\"paragraph-number\">[0005]   </span>Systems for joining at least two fuselage sections are known which comprise a plurality of sensors adapted to facilitate the steps of positioning, moving and joining said sections, which are carried out by assembly personnel. In fact, most of the steps of the methods for manufacturing an aircraft described in the prior art are carried out by human personnel with the help of electromechanical devices and sensors of various nature.</p><p><span class=\"paragraph-number\">[0006]   </span>For this reason, when manufacturing an aircraft, errors may be made due to the human component while executing one or more steps of the method for assembling and joining the aircraft sections.</p><p><span class=\"paragraph-number\">[0007]   </span>Automatic devices are known which are adapted to carry out one or more steps of the method for manufacturing an aircraft; said devices are supervised by an assembly operator. Therefore, in order to join sections of an aircraft, the operator will have to supervise a plurality of automatic devices. Manufacturing an aircraft in compliance with assembly standards strongly depends on the skills of the assembly operator, who is in charge of coordinating the various devices and possibly also supervising any manually executed operations.</p><p><span class=\"paragraph-number\">[0008]   </span>A method of this type turns out to be very costly, because it requires the use of many electromechanical devices that must be made to interact with one another, and also because of the large number of manual operations involved. In addition, such a method is also costly in terms of production time per aircraft, because the various steps must be supervised by the person in charge, although with the help of sensors of various kinds, who must supervise every critical aspect of the aircraft production process.</p><p><span class=\"paragraph-number\">[0009]   </span>Finally, this type of method, the implementation of which requires a human component, introduces an uncertain variable which makes the method hardly reproducible and which, in probabilistic terms, causes high uncertainty as to the result thereof. Such uncertainty implies increased average aircraft production costs.</p><p><span class=\"paragraph-number\">[0010]   </span>It should also be underlined that each electromechanical device used for implementing the method introduces intrinsic uncertainty in the operations it is adapted to perform; such uncertainty adds up to the uncertainties of the other electromechanical devices, because the systems known in the art do not include a central control system capable of coordinating such electromechanical devices to eliminate any errors so as to reduce the uncertainty of the entire system and, as a consequence, of the manufacturing method.</p><p><span class=\"paragraph-number\">[0011]   </span>Junction errors are also due to intrinsic physical factors, such as thermal or mechanical expansion of metal parts, depending on the temperature and humidity present in the place where the assembly process is being carried out.</p><p><span class=\"paragraph-number\">[0012]   </span>Checks are also known to be made on the junction by means of laser measurements taken at discrete instants while executing the joining method.</p><p><span class=\"paragraph-number\">[0013]   </span>The document <patcit dnum=\"FR2821778A1\">FR 2 821 778 A1</patcit> discloses the features of the preamble of claim 1.</p><p><span class=\"paragraph-number\">[0014]   </span>However, such checks do not ensure junction repeatability and correct alignment of all of the key points required for properly joining the parts.</p><p><span class=\"paragraph-number\">[0015]   </span>The present invention aims at solving the above-mentioned problems by providing a system for joining at least to main portions of a chassis or an aircraft fuselage or a boat hull, which system can automatically control and manage a plurality of actuation devices through a central control unit as a function of data obtained from a plurality of sensors.</p><p><span class=\"paragraph-number\">[0016]   </span>The present invention also aims at solving the above-mentioned problems by implementing a new method for joining at least two main portions or sections in a totally automatic manner, allowing for re-alignment of all key points for the purpose of ensuring repeatability of the junction between the main portions or sections.</p><p><span class=\"paragraph-number\">[0017]   </span>One aspect of the present invention relates to an automated system for joining at least two main portions of a chassis or a fuselage or a hull, having the features set out in the appended independent device claim 1.</p><p><span class=\"paragraph-number\">[0018]   </span>A further aspect of the present invention relates to a method for automatically joining at least two main portions or sections, having the features set out in the appended independent method claim 5.</p><p><span class=\"paragraph-number\">[0019]   </span>Auxiliary features and steps of the present invention are set out in the appended dependent claims.</p><p><span class=\"paragraph-number\">[0020]   </span>The features and advantages of the automated system and of the associated method according to the present invention will become more apparent from the following description of at least one embodiment thereof and from the annexed drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> <figref>Figure 1</figref> is a schematic plan view of a joining system according to the present invention;</li><br/><li> <figref>Figure 2</figref> is a general perspective view of an embodiment of the joining system according to the present invention;</li><br/><li> <figref>Figures 3A</figref> and <figref>3B</figref> show the actuation device; in particular, <figref>Figure 3A</figref> shows one embodiment of an actuation device, and <figref>Figure 3B</figref> shows a detail of a column;</li><br/><li> <figref>Figure 4</figref> shows a flow chart of one implementation of the joining method according to the present invention;</li><br/><li> <figref>Figures 5A</figref>, <figref>5B</figref> are perspective views showing the execution of steps g) and h) of the flow chart of <figref>Figure 4</figref>, implemented by the system shown in <figref>Figures 1</figref> and <figref>2</figref>, for joining a front section of an aircraft fuselage, wherein <figref>Figure 5A</figref> shows step g) and <figref>Figure 5B</figref> shows step h);</li><br/><li> <figref>Figure 6</figref> is a perspective view showing the positioning of a third section for assembling a fuselage by applying the joining method according to the present invention;</li><br/><li> <figref>Figure 7</figref> is a block diagram of the control circuits comprised in the automated system according to the present invention.</li></ul></p><p><span class=\"paragraph-number\">[0021]   </span>With reference to the above-mentioned drawings, the automated system for joining at least two portions of a chassis, e.g. of a vehicle or an aircraft or a boat, comprises at least one actuation device 3, preferably at least one per portion, which is adapted to move at least one portion in the space \"XYZ\" with three degrees of freedom; a central control unit 5, adapted to control each actuation device 3 as a function of a plurality of data obtained through a plurality of sensors 7.</p><p><span class=\"paragraph-number\">[0022]   </span>Said plurality of sensors 7 can continuously determine, on each chassis portion, a plurality of key points (A, B, C) which are univocal for each portion.</p><p><span class=\"paragraph-number\">[0023]   </span>For the purposes of the present invention, the expression \"measurement taken continuously\" refers to a measurement taken in a continuous manner over time, during the steps of the method according to the present invention, i.e. not only at discrete instants.</p><p><span class=\"paragraph-number\">[0024]   </span>Said central control unit 5, depending on the data obtained from said plurality of sensors 7, activates said at least one actuation device 3 in order to bring near and connect said portions, while monitoring, through said plurality of sensors 7, the relative position between said plurality of key points (A, B, C) of said portions, and the absolute position of said portions in space \"XYZ\".</p><p><span class=\"paragraph-number\">[0025]   </span>According to the preferred embodiment of the system, shown in <figref>Figures 1</figref> and <figref>2</figref>, the automated system is adapted to join at least two sections \"T\" of a fuselage of an aircraft \"V\" and comprises, for each section \"T\" , at least one actuation device 3 adapted to move said sections \"T\" in space \"XYZ\" with three degrees of freedom, and a central control unit 5 adapted to control each actuation device 3 as a function of a plurality of data obtained from a plurality of sensors 7. Said plurality of sensors 7 can continuously determine said plurality of key points (A, B, C) on each section \"T\". Said one central control unit 5, based on the data obtained from said plurality of sensors 7, activates said at least one actuation device 3 in order to move said sections \"T\", e.g. to bring near and connect said sections \"T\". Through said plurality of sensors 7, the relative position between the plurality of key points (A, B, C) and the absolute position of said sections \"T\" in space (XYZ) are monitored while each section is being moved by at least one actuation device 3.</p><p><span class=\"paragraph-number\">[0026]   </span>A plurality of key points (A, B, C) may be univocally associated with each section \"T\", which key points represent the points that must be measured and/or monitored by said plurality of sensors 7 for the purpose of allowing control unit 5 to move single sections \"T\" by means of said actuation devices 3. Said key points (A,B,C), appropriately monitored and processed, allow sections \"T\" to be properly moved and joined within aerodynamic and mechanical tolerances.</p><p><span class=\"paragraph-number\">[0027]   </span>Said key points are divided into:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> reference points \"A\", which represent section reference points which are important for the relative alignment between sections \"T\";</li><br/><li> lift points \"B\", which represent points where a scaffold or base 2 is secured to section \"T\"; said scaffold or base 2 is the interface between the section and actuation device 3;</li><br/><li> check points \"C\", which identify the proper position of section \"T\" for the joining process;</li><br/><li> point \"D\", which identifies the point where said scaffold or base 2 abuts against said actuation device 3.</li></ul></p><p><span class=\"paragraph-number\">[0028]   </span>In the embodiment shown in <figref>Figures 3A</figref> and <figref>3B</figref>, each actuation device 3 comprises at least one column 31 adapted to support and move at least one fuselage section \"T\", so as to ensure a correct junction between sections \"T\". Said actuation device 3 allows moving section \"T\" by associating therewith different degrees of freedom, preferably three degrees of freedom. Each column 31 comprises at least one support or arm 310 adapted to support said section.</p><p><span class=\"paragraph-number\">[0029]   </span>Each support 310 comprises, in turn, at least one support point 311 where point \"D\" of contact between scaffold or base 2 and actuation device 3 is located. Said scaffold or base 2 is in its turn secured to at least one lift point \"B\" of section \"T\", as aforementioned. Said support point 311 is preferably a housing, e.g. of hemispherical shape, adapted to house a striker positioned in point \"D\" of scaffold 2 and having a shape complementary to said housing. In order to secure scaffold 2 to actuation device 3, particularly to support point 311, support or arm 310 comprises at least one retaining mechanism 312 adapted to removably lock scaffold 2. Preferably, said at least one retaining element 312 is a clamp, which is moved in coordination with the movements of entire actuation device 3.</p><p><span class=\"paragraph-number\">[0030]   </span>The possibility of moving said support or arm 310, through an actuator not shown in the drawings, together with the presence of at least one support point 311, allows taking up the internal torsions and strains of section \"T\".</p><p><span class=\"paragraph-number\">[0031]   </span>Said at least one column 31 may vary the height of said support point 311 by lifting said support 310. Preferably, said support or arm 310 can be extended along a vertical axis \"Z\", e.g. through a guide (not shown in detail) comprised in column 31 itself. The extension of said arm 310 ensures the first degree of freedom.</p><p><span class=\"paragraph-number\">[0032]   </span>In embodiments not shown in the drawings, said column 31 is telescopic or slideable, automatically, along a vertical axis \"Z\".</p><p><span class=\"paragraph-number\">[0033]   </span>In the embodiment shown in <figref>Figures 1</figref> and <figref>2</figref>, each actuation device 3 comprises three columns 31, suitably arranged in such a way as to properly support section \"T\". For example, as shown in <figref>Figure 3A</figref>, two columns are aligned along a first axis \"Y\" perpendicular to vertical axis \"Z\"; preferably, the two outer columns 31' are aligned along said first axis \"Y\", whereas the third column 31\", interposed between said two outer columns, is offset relative to said axis \"Y\", e.g. located at the front along a second axis \"X\" perpendicular to the vertical axis \"Z\" and to the first axis \"Y\".</p><p><span class=\"paragraph-number\">[0034]   </span>At least one of said columns included in actuation device 3 can move on adapted first guides 30 along said second axis \"X\", driven by an actuator not shown. The movement of columns 31 on the second guides 30 ensures the second degree of freedom.</p><p><span class=\"paragraph-number\">[0035]   </span>Said support or base 310 is moved by means of an actuator, not shown, which is adapted to give at least the third degree of freedom to actuation device 3, e.g. through rotational or rototranslational movements of support point 311.</p><p><span class=\"paragraph-number\">[0036]   </span>Preferably, each actuation device, more specifically each column 31, is moved with three degrees of freedom by means of a plurality of electric motors, each one controlled by said central control unit 5.</p><p><span class=\"paragraph-number\">[0037]   </span>Said columns 31 are controlled, when moving on said guides 30 along said second axis \"X\", by said central control unit 5.</p><p><span class=\"paragraph-number\">[0038]   </span>Said joining system according to the present invention comprises at least one platform 6 adapted to allow the operator to come close to the fuselage of aircraft \"V\" in order to make the junction, or to verify the quality of the work, or to check any errors reported by central control unit 5.</p><p><span class=\"paragraph-number\">[0039]   </span>Each platform 6 comprises a plurality of extensible footboards 60, which are moved by means of actuators, preferably pneumatic and/or electric ones, controlled by said central control unit 5. Said plurality of footboards 60 are adapted to extend when in use, thus creating a continuous path from said platform 6 to at least one predetermined portion of the fuselage of aircraft \"V\". Said footboards 60 may take different positions, thus adapting themselves to the shape of the fuselage at different heights along vertical axis \"Z\" and to the different profiles of different aircrafts or vehicles or boats. Such footboards. 60, once used, are retracted into platform 6, thus allowing the automated joining system of the present invention to proceed with the next joining steps. Such footboards 60 allow the operator to come close to the aircraft fuselage with the utmost safety.</p><p><span class=\"paragraph-number\">[0040]   </span>Preferably, the system comprises a fixed platform 61, near which there is a control station 611 and a mobile platform 62, which can take an open configuration and a work configuration.</p><p><span class=\"paragraph-number\">[0041]   </span>Said mobile platform 62, when in the open configuration, allows various sections \"T\" to pass in order to be positioned on actuation devices 3, and allows sections \"T\" or the entire fuselage to be removed from the actuation devices.</p><p><span class=\"paragraph-number\">[0042]   </span>When in the work configuration, mobile platform 62 is close to various actuation devices 3, thus allowing the execution of the steps of the joining method according to the present invention.</p><p><span class=\"paragraph-number\">[0043]   </span>Control station 611 comprises a user interface between the operator and central control unit 5, which allows issuing orders for the execution of the joining method. Said control station 611 is so positioned as to allow complete visibility of the area, thus further increasing the level of safety for the personnel, the joining method and the parts being processed.</p><p><span class=\"paragraph-number\">[0044]   </span>Central control unit 5 performs continuous control with a double feedback loop and can control said plurality of sensors 7 and said plurality of actuation devices 3 through a data transfer network. A block diagram of the various interactions between central control unit 5 and the system of the present invention is shown, for example, in <figref>Figure 7</figref>.</p><p><span class=\"paragraph-number\">[0045]   </span>Depending on sections \"T to be joined, central control unit 5 can, thanks to the double feedback loop, find the optimal position of various sections \"T\" on the basis of actual data obtained from the plurality of sensors 7, of theoretical data associated with different sections \"T\", and of specified aerodynamic and mechanical tolerances.</p><p><span class=\"paragraph-number\">[0046]   </span>Central control unit 5, e.g. implemented through a PLC, allows for coordinated movements of every actuation device 3 to obtain an optimal alignment between sections \"T\".</p><p><span class=\"paragraph-number\">[0047]   </span>Said plurality of sensors 7 comprise at least one laser meter 71 adapted to measure, with high resolution and low uncertainty, the relative and absolute positions and distances of the various key points (A, B, C). The essential concepts upon which the operation of said laser meter 71 is based will not be described in detail herein because they are known to the man skilled in the art.</p><p><span class=\"paragraph-number\">[0048]   </span>Each laser meter 71 is movably mounted on at least one carriage 72, which slides on at least one second guide 70, preferably arranged along said second axis \"X\". Said at least one carriage 72 is driven by a motor, preferably an electric one (not shown), controlled by said central control unit 5.</p><p><span class=\"paragraph-number\">[0049]   </span>Said laser meter 71 is also fitted with a first actuator (not shown), which is adapted to move said laser meter 71 along axis \"Z\", and which is also controlled by said control unit 5.</p><p><span class=\"paragraph-number\">[0050]   </span>Said laser meter 71 continuously takes a plurality of measurements in said key points, particularly in reference points \"A\" and check points \"C\". The data of such measurements continuously taken by laser meter 71 are transmitted, through a data transfer network 80, to said central control unit 5.</p><p><span class=\"paragraph-number\">[0051]   </span>In the embodiment shown in <figref>Figures 1</figref> and <figref>2</figref>, the joining system comprises two laser meters 71, the second guides 70 of which are arranged in parallel along the second axis \"X\", between which there is at least one actuation device 3 adapted to move at least one section \"T\". In particular, between said second guides 70 there are three actuation devices 3, each comprising three columns 31.</p><p><span class=\"paragraph-number\">[0052]   </span>Said plurality of sensors 7 comprise motion sensors adapted to measure the single movements of each actuation device 3, particularly of each column 31. In addition, said plurality of sensors 7 comprise electronic sensors adapted to detect the variation in the power absorbed by every single actuator of every single column 31, so as to detect the presence of sections \"T\" on the single actuation device 3. Such sensors also allow to determine if forces are being exerted by mistake on every single section by every single column 31, which might damage the single section \"T\" or the entire fuselage.</p><p><span class=\"paragraph-number\">[0053]   </span>Each support 310 may comprise, e.g. in the area corresponding to support point 311, at least one load cell adapted to verify the presence of a section on actuation device 3, and possibly to evaluate the weight distribution on various columns 31.</p><p><span class=\"paragraph-number\">[0054]   </span>Said plurality of sensors 7 further comprise temperature sensors, pressure sensors and humidity sensors, so as to take a picture of the environmental situation while making each junction between two or more sections. Such environmental data, measured through said sensors (not shown), allow to foresee, and hence to adequately compensate for, any intrinsic physical behaviour of each section \"T\" dependent on the actual environmental conditions.</p><p><span class=\"paragraph-number\">[0055]   </span>Said central control unit 5 is connected, through said data transfer network 80, to at least one data storage unit 8, which is adapted to store, whether periodically or continuously, the data obtained from the single sections and from the junctions thereof, for each aircraft \"V\". Furthermore, central control unit 5 sends to said data storage unit 8 the number of sections \"T\" taken from the warehouse and the number of aircrafts manufactured, associating an identification code with each fuselage in order to ensure full traceability of the steps carried out for manufacturing the aircraft and the single components thereof.</p><p><span class=\"paragraph-number\">[0056]   </span>The data stored in said at least one data storage unit 8 allow central control unit 5 to retrieve the data relating to said key points (A,B,C,D) for every single section \"T\", even after drilling single section \"T\" or prior to the shimming step, wherein shims are levelled for properly positioning the parts that make up the section or the aircraft itself.</p><p><span class=\"paragraph-number\">[0057]   </span>Preferably, the following data are stored into said data storage unit 8:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> geometry of every single section \"T\", particularly the key points thereof;</li><br/><li> geometry of the fuselage after joining various sections \"T\";</li><br/><li> temperature, pressure and humidity of the environment;</li><br/><li> position of each support point 311 in space \"XYZ\" for every single column;</li><br/><li> every movement made by each column 31 along each axis of movement;</li><br/><li> reference system (X'Y'Z') created from the data obtained from the key points of every single section, for manufacturing each fuselage.</li><br/><li> history of the alarms occurred during the steps of the joining method;</li><br/><li> complete diagnostics of the devices included in the system;</li><br/><li> sequence and times of execution of the joining method;</li><br/><li> position and movements of each footboard of each platform.</li></ul></p><p><span class=\"paragraph-number\">[0058]   </span>The data are stored by using an appropriate compression encoding method, not shown in detail herein, in order to limit memory occupation.</p><p><span class=\"paragraph-number\">[0059]   </span>The automated joining system according to the present invention further comprises electromechanical devices for the execution of some operations or steps for making the junction between two sections \"T\", e.g. at least one robotized arm for drilling and flaring the holes where riveting will take place on the parts concerned by the junction.</p><p><span class=\"paragraph-number\">[0060]   </span>The method for automatically joining at least two portions in order to manufacture a chassis, controlled by a central control unit 5, comprises the following consecutive steps, as shown by way of example in the flow chart of <figref>Figure 4</figref>:</p><p><ol compact=\"compact\"><li> a) Positioning a first portion on a first actuation device 3;</li><br/><li> b) Detecting a plurality of key points (A,B,C) of said first portion, and sending the data to said central control unit (5);</li><br/><li> c) Creating a reference system (X'Y'Z') starting from the data obtained at step b), as a function of the characteristics of said first portion;</li><br/><li> d) Positioning a second portion on a second actuation device 3';</li><br/><li> e) Detecting a plurality of key points (A,B,C) of said second portion, and sending the data to said central control unit 5;</li><br/><li> f) Translating the data obtained at step e) into reference system (X'Y'Z') created at step c);</li><br/><li> g) Bringing said first portion and said second portion near each other through said at least one actuation device (3, 3'), while continuously monitoring, through said plurality of sensors (7), the relative position of said plurality of key points (A,B,C) of each portion, as processed by said central control unit (5);</li><br/><li> h) Joining the portions;</li><br/><li> i) Repeating steps d)-h) for each additional portion of the chassis.</li></ol></p><p><span class=\"paragraph-number\">[0061]   </span>Preferably, said method is applicable for joining at least two sections \"T\" of a fuselage of an aircraft \"V\" by carrying out the following consecutive steps:</p><p><ol compact=\"compact\"><li> a) Positioning a first section \"T\" on a first actuation device 3;</li><br/><li> b) Detecting a plurality of key points (A,B,C) of said first section \"T\", and sending the data to said central control unit (5);</li><br/><li> c) Creating a reference system (X'Y'Z') starting from the data obtained at step b), as a function of the characteristics of said first section \"T\";</li><br/><li> d) Positioning a second fuselage section \"T\" on a second actuation device 3';</li><br/><li> e) Detecting a plurality of key points (A,B,C) of said second section \"T\", and sending the data to said central control unit 5;</li><br/><li> f) Translating the data obtained at step e) into reference system (X'Y'Z') created at step c);</li><br/><li> g) Bringing said first section \"T\" and said second section \"T\" near each other through said at least one actuation device (3, 3'), while continuously monitoring, through said plurality of sensors (7), the relative position of said plurality of key points (A,B,C) of each section (T, T'), as processed by said central control unit (5) ;</li><br/><li> h) Joining the sections;</li><br/><li> i) Repeating steps d)-h) for each additional section \"T'\"' of the fuselage.</li></ol></p><p><span class=\"paragraph-number\">[0062]   </span>Preferably, the method according to the present invention further comprises the following steps:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> Moving every single section to a predetermined height along axis \"Z\";</li><br/><li> Moving the assembled fuselage;</li><br/><li> Check carried out by an operator.</li></ul></p><p><span class=\"paragraph-number\">[0063]   </span>The following will describe in detail every step included in the method of the present invention, which is preferably implemented for manufacturing aircraft fuselages.</p><p><span class=\"paragraph-number\">[0064]   </span>Prior to each step of positioning a section \"T\" on an actuation device, there is a step of moving mobile platform 62, wherein said mobile platform 62 is moved from a work configuration to an open configuration, thereby allowing section \"T\" to be moved towards actuation device 3. Once the positioning step has been completed, a further moving step is carried out, wherein said mobile platform 62 is moved from an open configuration to a work configuration.</p><p><span class=\"paragraph-number\">[0065]   </span>After having executed step a) of positioning a first section \"T\" on a first actuation device 3, and after the moving step, a step b) of detecting a plurality of key points (A,B,C) is carried out. Said step b) is executed by said plurality of sensors 7, which measure and determine reference points \"A\", lift points \"B\", and check points \"C\" as previously described. Such data are sent to said central control unit 5. Preferably, said central control unit 5 sends the data relating to said key points (A,B,C) received from the plurality of sensors 7, through said data transfer network 80, to said data storage unit 8, wherein such data are stored and univocally associated with said first section \"T\". The data relating to any one section \"T\", e.g. the first section \"T\", may be taken from said data storage unit 8 at any time, e.g. by central control unit 5 or by a remote computer connected to data transmission network 80. Preferably, each datum contained in the data storage unit may be requested for further processing by central control unit 5.</p><p><span class=\"paragraph-number\">[0066]   </span>Before proceeding with the next steps of the method according to the present invention, the data associated with every single section are compared with the theoretical data of the design drawings, which have also been stored, for example, into the same data storage unit 8. Central control unit 5 verifies if the data associated with section \"T\" are compliant with the theoretical data about the specified design tolerances, by performing a last step of checking each section, preferably before the same section is positioned in the automated joining system according to the present invention.</p><p><span class=\"paragraph-number\">[0067]   </span>This check may also be useful to determine which section \"T\" is about to enter the automated joining system, prior to carrying out the above moving step, for the purpose of identifying actuation device 3 with which it must be associated, and for determining and organizing the handling of said section \"T\" in order to position it inside the system.</p><p><span class=\"paragraph-number\">[0068]   </span>In the next step c) of creating a reference system (X'Y'Z'), said reference system may be absolute with respect to space (XYZ) where the automated assembly system is located, as well as relative with respect to said first section \"T\", already appropriately positioned in the joining system in accordance with the present invention.</p><p><span class=\"paragraph-number\">[0069]   </span>Reference system (X'Y'Z') will be determined as a function of the number of columns 31 included in actuation device 3 associated with said first section. In the specific case with three columns 31, reference system (X'Y'Z') will be defined by nine spatial coordinates, i.e. three per column 31. Once said reference system (X'Y'Z') has been defined, it will be impossible to modify said reference system until the steps of the method according to the present invention have been completed, in particular until the sections have been joined and the entire fuselage has been assembled. Determining a reference system (X'Y'Z') is useful to simplify the processing that must be carried out by central control unit 5 in order to issue proper handling commands to single actuation devices 3.</p><p><span class=\"paragraph-number\">[0070]   </span>After step c) and prior to step d), there is preferably a further step of moving section \"T\" to a predetermined height \"Z'\"'.</p><p><span class=\"paragraph-number\">[0071]   </span>Subsequently, at step d), a second section \"T'\" is positioned on a second actuation device 3', which step is substantially similar to the above-mentioned step a). In particular, it will include the steps of moving the mobile platform.</p><p><span class=\"paragraph-number\">[0072]   </span>Step d) is followed by the detection step e). This detection step e) is substantially similar to the previously described step b), and therefore will not be further described.</p><p><span class=\"paragraph-number\">[0073]   </span>The data obtained in said step e) are used in the next step f) of translating the obtained data into reference system (X'Y'Z'). During this step, the data relating to said second section \"T'\" are processed in such a way as to be expressed with respect to reference system (X'Y'Z'), for the purpose of conforming the data of every single section to said reference system.</p><p><span class=\"paragraph-number\">[0074]   </span>Preferably, said step f) is followed by a further step of moving section \"T'\" to a predetermined height \"Z\".</p><p><span class=\"paragraph-number\">[0075]   </span>A further step f1) of first alignment is then carried out, wherein said second section \"T\"' is moved, through respective actuation device 3', in a manner such that said key points (A, 3B, C) of the second section \"T\"' become substantially aligned with the corresponding key points of the first section \"T\" with respect to reference system (X'Y'Z'). For the purposes of the present invention, the expression \"substantially aligned\" means that the key points useful for joining the two sections are aligned, within the limits of allowable tolerances, along axes parallel to one axis of the reference system (X'Y'Z').</p><p><span class=\"paragraph-number\">[0076]   </span>Said alignment is possible thanks to the plurality of columns 31 of each actuation device, in particular thanks to support or arm 310 and to support point 311, which allow to move every single section with at least three degrees of freedom in an automatic, coordinated and synchronized manner. Furthermore, said alignment is made possible by the continuous detection made by the plurality of sensors 7 on the single sections. Said step f1) of first alignment is integrally controlled and managed by central control unit 5, which implements an algorithm, stored in a non-volatile memory medium, which, based on the data obtained from the key points continuously measured by said plurality of sensors 7, determines the correction to be made to the section position in order to attain a better alignment, within the limits of the allowable tolerances. The data thus processed are transformed into commands to be sent to single actuation devices.</p><p><span class=\"paragraph-number\">[0077]   </span>This leads to step g) of bringing the sections near each other by means of said actuation devices 3, as shown in <figref>Figure 5A</figref>, in particular through columns 31, which can be moved in a coordinated and synchronized manner along said second axis \"X\" on said first guides 30. During this moving step, a detection step is simultaneously and continuously carried out, which allows control unit 5 to send appropriate commands to the single actuation devices depending on the data processed by said algorithm. Preferably, said algorithm implements a solution with successive approximations to determine the optimal alignment between the sections. Said algorithm also comprises calculation functions that appropriately take into account the thermal expansions, torsions, etc. that every single section may be subject to during the moving steps and because of the physical conditions, such as humidity, temperature, etc., of the place where the joining process is being carried out.</p><p><span class=\"paragraph-number\">[0078]   </span>The aligning step g) is then followed by the joining step h), illustrated in <figref>Figure 5B</figref>. During this joining step h), two or more sections \"T\" are joined together.</p><p><span class=\"paragraph-number\">[0079]   </span>Additional steps are executed after step h), during which the following consecutive operations are carried out:</p><p><ul compact=\"compact\" list-style=\"bullet\"><li> drilling both sections;</li><br/><li> flaring the holes;</li><br/><li> riveting the sections.</li></ul></p><p><span class=\"paragraph-number\">[0080]   </span>These operations, preferably following the joining step h), may be either carried out manually by an operator or automatically, whether totally or partially, by means of, for example, electromechanical devices controlled by said central control unit 5.</p><p><span class=\"paragraph-number\">[0081]   </span>Depending on the data processed by said algorithm, control unit 5 will send handling instructions to every single column, so as to correct any alignment errors.</p><p><span class=\"paragraph-number\">[0082]   </span>The data processed by the algorithm and the resulting actions carried out on the single sections are suitably stored into said data storage unit 8. Said stored data may allow control unit 5, through a machine-learning process to be carried out after steps b) and e) have been completed for each section, to determine if, in the history of the junctions made by the automated joining system, contained in the data storage unit, two sections substantially similar to those currently under examination have already been joined, and to use such information for properly handling every single section. Said machine-learning process may allow to speed up the aircraft production process, avoiding the need for recalculating each time the best alignment by means of said algorithm. Preferably, supplementary checks are made in order to perform an additional quality check on every single junction. In particular, said checks are carried out by control unit 5 in order to verify if the data obtained from data storage unit 8 about previously made junctions are actually applicable, step by step, for making the current junction.</p><p><span class=\"paragraph-number\">[0083]   </span>This process allows making the assembly method highly repeatable with optimal results, while at the same time ensuring reduced fuselage production times.</p><p><span class=\"paragraph-number\">[0084]   </span>The handling of single section \"T\" may be either synchronized with the other sections \"T\" or independent thereof, depending on specific requirements and on the step of the method being executed. For example, a given section \"T\" may be moved independently of the remaining sections in order to allow the operator to verify some construction parameters of that single section, if necessary.</p><p><span class=\"paragraph-number\">[0085]   </span>In an alternative embodiment, by means of suitable systems for transferring data, e.g. time-multiplexed ones, from the sensors, from actuation devices 3, and from/to central control unit 5, the method according to the present invention allows to execute the steps f1)-h) in parallel for joining multiple sections \"T\" in a substantially simultaneous manner.</p><p><span class=\"paragraph-number\">[0086]   </span>For the purposes of the present invention, the expression \"substantially simultaneous junctions\" means that the steps f1)-h), thanks to the computing and processing speed of control unit 5 and to the high data transfer speed, the data being appropriately modulated, can be executed in parallel for joining multiple sections, cyclically over time.</p><p><span class=\"paragraph-number\">[0087]   </span>Preferably, each section \"T\" is placed at such a height as to allow an operator, from the at least one platform 6, to reach every point of the fuselage section through said footboards 60.</p><p><span class=\"paragraph-number\">[0088]   </span>After each step of moving one or more sections \"T\", there is at least one step of detecting a plurality of key points (A,B,C) of said first portion, which are then sent to said central control unit 5.</p><p><span class=\"paragraph-number\">[0089]   </span>The sequence of steps d) - g) is carried out for each additional section \"T''\" to be connected to the already assembled sections in order to manufacture the complete fuselage, as shown in <figref>Figure 6</figref>.</p><p><span class=\"paragraph-number\">[0090]   </span>After all sections \"T\" have been joined, there is an additional step of moving the assembled fuselage.</p><p><span class=\"paragraph-number\">[0091]   </span>A final check step is then carried out by an operator, in order to verify the obtained results. If the junction between the sections is fully compliant with the design specifications and within the tolerances assigned to a single fuselage, an identification code will be assigned, also associated with the key points, so that all the phases of production of the aircraft can be traced.</p><p><span class=\"paragraph-number\">[0092]   </span>Preferably, switching from one step of the above method to the next only occurs upon authorization by the operator in charge, who at the end of each step may, if necessary, verify the obtained data and check the progress of the method. After a system running-in phase, wherein all the necessary data are stored into the data storage unit, thanks to the machine-learning process it may be possible to totally automate the joining method by allowing control unit 5 to switch from one system step to another without waiting for the operator's authorization.</p><p><span class=\"paragraph-number\">[0093]   </span>The system, and hence the associated method, only requires one operator to supervise it in order to monitor the implementation of the method, allowing the method steps to proceed without having to verify the data obtained from the system itself, and intervening only in the event of gross errors or technical problems caused by human mistakes.</p><p><span class=\"paragraph-number\">[0094]   </span>The automated joining system and the associated method are applicable for joining portions of any chassis, whether in the aviation industry, as described herein, or in the naval industry, for manufacturing boats, or for making devices of any kind, thus considerably enhancing the production speed and repeatability of the joining process.</p><p><span class=\"paragraph-number\">[0095]   </span>The presence of a single central control device 5 allows coordinating innumerable devices in order to obtain an automated process, thus reducing the assembly uncertainty due to the human component.</p><p><heading>REFERENCE NUMERALS</heading></p><p>TABLE 1</p><p><span class=\"paragraph-number\">[0096]   </span><tables num=\"0001\"><table frame=\"none\"><tgroup cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"18mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"44mm\"/><colspec colname=\"col3\" colnum=\"3\" colwidth=\"11mm\"/><colspec colname=\"col4\" colnum=\"4\" colwidth=\"29mm\"/><tbody><row><entry>2</entry><entry/><entry/><entry>Scaffold or base</entry></row><row><entry>3</entry><entry/><entry/><entry>Actuation device</entry></row><row><entry>30</entry><entry>First guides</entry><entry/><entry/></row><row><entry>31</entry><entry>Column 31' Outer column</entry><entry/><entry>31\" Third column</entry></row><row><entry>310</entry><entry>Support or arm</entry><entry/><entry/></row><row><entry>311</entry><entry>Support point or hemisphere</entry><entry/><entry/></row><row><entry>312</entry><entry>Retaining element</entry><entry/><entry/></row><row><entry>5</entry><entry>Central control unit</entry><entry/><entry/></row><row><entry>7</entry><entry>Plurality of sensors</entry><entry/><entry/></row><row><entry>70</entry><entry>Second guides</entry><entry/><entry/></row><row><entry>71</entry><entry>Laser meter</entry><entry>72</entry><entry>Carriage</entry></row><row><entry>6</entry><entry>Platform</entry><entry>60</entry><entry>Footboards</entry></row><row><entry>61</entry><entry>Fixed platform</entry><entry>611</entry><entry>Control station</entry></row><row><entry>62</entry><entry>Mobile platform</entry><entry/><entry/></row><row><entry>8</entry><entry>Data storage unit</entry><entry/><entry/></row><row><entry>80</entry><entry>Data transfer network</entry><entry/><entry/></row><row><entry>T</entry><entry>Sections</entry><entry/><entry/></row><row><entry>V</entry><entry>Aircraft</entry><entry/><entry/></row><row><entry>(A, B, C)</entry><entry>Key points</entry><entry/><entry/></row><row><entry>A</entry><entry>Reference points</entry><entry/><entry/></row><row><entry>B</entry><entry>Lift points</entry><entry/><entry/></row><row><entry>C</entry><entry>Check points</entry><entry/><entry/></row><row><entry>D</entry><entry>Point</entry><entry/><entry/></row><row><entry>XYZ</entry><entry>Space</entry><entry/><entry/></row><row><entry>Y</entry><entry>First axis</entry><entry/><entry/></row><row><entry>X</entry><entry>Second axis</entry><entry/><entry/></row><row><entry>Z</entry><entry>Vertical axis</entry><entry/><entry/></row><row><entry>X'Y'Z'</entry><entry>Reference system</entry><entry/><entry/></row></tbody></tgroup></table></tables></p>",
            "CLMS": "(EP2812249)<br/><p>1. Automated system for joining at least two portions of a chassis, comprising;<br/> • at least one actuation device (3) adapted to move at least one portion in the space (XYZ) with three degrees of freedom;<br/> • a central control unit (5) for controlling each actuation device (3) as a function of a plurality of data obtained through a plurality of sensors (7);<br/>said plurality of sensors (7) can continuously determine, on each chassis portion, a plurality of key points (A, B, C) which are univocal for each portion;<br/>said central control unit (5), depending on the data obtained from said plurality of sensors (7), activates said at least one actuation device (3) in order to bring near and connect said at least two portions, while monitoring, through said plurality of sensors (7), the relative position between said plurality of key points (A, B, C) of said portions and the absolute position of said portions in the space (XYZ);<br/>said system is adapted to join at least two sections (T) of a fuselage of an aircraft (V);<br/>each actuation device (3) comprises at least one column (31) for supporting and moving at least one section (T), comprising at least one support or arm (310) for moving said section (T) with three degrees of freedom;<br/>said at least one column (31) can be extended, in an automatic manner, along a vertical axis (Z) and can move on adapted first guides (30) along a second axis (X), perpendicular to said vertical axis (Z);<br/>said plurality of sensors (7) comprise at least one laser meter (71) for measuring the position of the various key points (A, B, C) and the relative and absolute distances of the same key points (A, B, C).<br/><b>characterized in that</b> each laser meter (71) is movable, being associated with at least one carriage (72) that slides on at least one second guide (70) arranged along a second axis (X).</p><p>2. System according to claim 1, wherein said key points are divided into:<br/> - reference points (A), which represent section reference points for the relative alignment between the various sections (T);<br/> - lift points (B), where a scaffold or base (2) is secured to the section (T);<br/> - check points (C), which identify the proper position of the section (T) for the joining process.</p><p>3. System according to claim 1, wherein said central control unit (5) performs continuous control with a double feedback loop and, through a data transfer network (80), can control said plurality of sensors (7) and said at least one actuation device (3).</p><p>4. System according to claim 3, wherein said central control unit (5) is connected, through said data transfer network (80), to a data storage unit (8), for storing the data obtained during the steps of joining the various portions making up the chassis.</p><p>5. Method for automatically joining at least two portions in order to manufacture a chassis, using a system acording to any of claims 1-4 for implementing said method, the method comprises the following consecutive steps:<br/> a) Positioning a first portion on a first actuation device (3);<br/> b) Detecting a plurality of key points (A,B,C) of said first portion, and sending the data to said central control unit (5);<br/> c) Creating a reference system (X'Y'Z') starting from the data obtained at step b), as a function of the characteristics of said first portion;<br/> d) Positioning a second portion on a second actuation device (3');<br/> e) Detecting a plurality of key points (A,B,C) of said second portion, and sending the data to said central control unit (5);<br/> f) Translating the data obtained at step e) into the reference system (X'Y'Z') created at step c);<br/> g) Bringing said first portion and said second portion near each other through said at least one actuation device (3, 3'), while continuously monitoring, through said plurality of sensors (7), the relative position of said plurality of key points (A,B,C) of each portion, as processed by said central control unit (5);<br/> h) Joining the portions;<br/> i) Repeating steps d)-h) for each additional portion of the chassis.</p><p>6. Method according to claim 5, further comprising the steps of:<br/> • Moving every single portion to a predetermined height along a vertical axis \"Z\":<br/> • Moving the assembled chassis;<br/> • Final check carried out by an operator.</p><p>7. Method according to claim 5, comprising a data storage step, wherein the data relating to at least one chassis portion are stored into a data storage unit (8).</p>",
            "NPR": "2",
            "APID": "89110846",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B23P<br/>B23P-019/00<br/>B23P-019/10<br/>B25B-011/00<br/>B62D-021/00<br/>B62D-065/02<br/>B64C-001/06<br/>B64F<br/>B64F-005/00<br/>B64F-005/10<br/>B64F-005/50",
            "ID": "45764655",
            "AB": "(EP2812249)<br/>One aspect of the present invention relates to an automated system for joining at least two portions of a chassis, comprising at least one actuation device (3) adapted to move at least one portion in the space &quot;XYZ&quot; with three degrees of freedom; a central control unit (5) adapted to control each actuation device (3) as a function of a plurality of data obtained through a plurality of sensors (7). Said plurality of sensors (7) can continuously determine, on each chassis portion, a plurality of key points (A, B, C) which are univocal for each portion. Said central control unit (5), depending on the data obtained from said plurality of sensors (7, activates said at least one actuation device (3) in order to bring near and connect said at least two portions, while monitoring, through said plurality of sensors (7), the relative position between said plurality of key points (A, B, C) of said portions and the absolute position of said portions in the space &quot;XYZ&quot;. A second aspect of the present invention relates to a method, associated with the above-mentioned automated joining system, for automatically joining at least two portions in order to manufacture a chassis.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nnIspgeNTl01zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2012-02-09",
            "PA": "LEONARDO<br/>ALENIA AERMACCHI",
            "PAAD": "(EP2812249)<br/>(PUB:EP-2812249B1-0)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 , CITY=00195 Roma , COUNTRY=IT , REG=101613399<br/><br/>(PUB:EP-2812249A1-0)NAME=Alenia Aermacchi S.p.A. Via Ing. Paolo Foresio 1 , CITY=21040 Venegono Superiore , COUNTRY=IT , REG=101389933<br/><br/><br/>(US9643710)<br/>(PUB:US-09643710B2-1)NAME=ALENIA AERMACCHI S.P.A.  , CITY=Venegono Superiore (VA) , COUNTRY=IT , ATYP=Non-US Company<br/><br/>(PUB:US-20150367930A1-2)NAME=ALENIA AERMACCHI S.P.A.  , CITY=Venegono Superiore , COUNTRY=IT<br/><br/><br/>(WO2013117971)<br/>(PUB:WO-2013117971A1-0)NAME=ALENIA AERMACCHI S.P.A. Via Ing. Paolo Foresio, 1 I-21040 Venegono Superiore , COUNTRY=IT<br/><br/><br/>(RU2631437)<br/>(PUB:RU-2014132574A-0)NAME=Alenia Aermacchi S p A (IT)  , COUNTRY=IT<br/><br/><br/>(BR112014019640)<br/>(PUB:BR-112014019640A8-20170711-0)NAME=ALENIA AERMACCHI SPA  , COUNTRY=IT<br/><br/><br/>(CA2863745)<br/>(PUB:CA-2863745C-14)NAME=ALENIA AERMACCHI S.P.A. Via Ing. Paolo Foresio 1-I-21040 , CITY=VENEGOLO SUPERIORE , COUNTRY=IT<br/><br/>(PUB:CA-2863745A1-14)NAME=ALENIA AERMACCHI S.P.A. Via Ing. Paolo Foresio 1-I-21040 , CITY=VENEGOLO SUPERIORE , COUNTRY=IT<br/><br/><br/>(KR101933253)<br/>(PUB:KR-101933253B1-30)NAME=ALENIA AERMACCHI S.p.A.  , COUNTRY=IT<br/><br/>(PUB:KR-20150001719A-30)NAME=ALENIA AERMACCHI S.p.A.  , REG=520060430233<br/><br/><br/>(ES2582634)<br/>(PUB:ES-2582634T3-0)NAME=LEONARDO SPA  , COUNTRY=IT<br/>",
            "FAN": "45764655",
            "TI": "Automated system for joining portions of a chassis and method thereof",
            "TECD": "Machine tools<br/>Transport",
            "EPD": "2013-08-10",
            "ICLM": "(EP2812249)<br/><p>1. Automated system for joining at least two portions of a chassis, comprising; * at least one actuation device (3) adapted to move at least one portion in the space (XYZ) with three degrees of freedom; * a central control unit (5) for controlling each actuation device (3) as a function of a plurality of data obtained through a plurality of sensors (7); said plurality of sensors (7) can continuously determine, on each chassis portion, a plurality of key points (A, B, C) which are univocal for each portion; said central control unit (5), depending on the data obtained from said plurality of sensors (7), activates said at least one actuation device (3) in order to bring near and connect said at least two portions, while monitoring, through said plurality of sensors (7), the relative position between said plurality of key points (A, B, C) of said portions and the absolute position of said portions in the space (XYZ); said system is adapted to join at least two sections (T) of a fuselage of an aircraft (V); each actuation device (3) comprises at least one column (31) for supporting and moving at least one section (T), comprising at least one support or arm (310) for moving said section (T) with three degrees of freedom; said at least one column (31) can be extended, in an automatic manner, along a vertical axis (Z) and can move on adapted first guides (30) along a second axis (X), perpendicular to said vertical axis (Z); said plurality of sensors (7) comprise at least one laser meter (71) for measuring the position of the various key points (A, B, C) and the relative and absolute distances of the same key points (A, B, C). characterized in that each laser meter (71) is movable, being associated with at least one carriage (72) that slides on at least one second guide (70) arranged along a second axis (X).</p>",
            "CTN": "(EP2812249)<br/>FR2821778 16964931 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>CA2760720 14228780 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>FR2821778 16964931 WHO=APPLICANT SELF=N<br/><br/>(US9643710)<br/>US5983166 13652301 WHO=EXAMINER SELF=N<br/>US8634950 4166696 WHO=EXAMINER SELF=N<br/>CA2760720 14228780 WHO=APPLICANT SELF=N<br/>FR2821778 16964931 WHO=APPLICANT SELF=N<br/>JP2006051557 22546196 WHO=APPLICANT SELF=N<br/><br/>(WO2013117971)<br/>FR2821778 16964931 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>CA2760720 14228780 WHO=EXAMINER SELF=N CAT=X CAT=I<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N CAT=X CAT=I<br/><br/>(RU2631437)<br/>CA2760720 14228780 WHO=EXAMINER SELF=N<br/>RU2440594 1029061 WHO=EXAMINER SELF=N<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N<br/>US3698817 42154688 WHO=EXAMINER SELF=N<br/>US20060162140 14083286 WHO=EXAMINER SELF=N<br/>US5903459 60081689 WHO=EXAMINER SELF=N<br/><br/>(KR101933253)<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N<br/>JP2012525266 14228780 WHO=EXAMINER SELF=N<br/>US20110282483 4166696 WHO=EXAMINER SELF=N<br/><br/>(CN104245514B)<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N CAT=A<br/>CN102084212 4174221 WHO=EXAMINER SELF=N CAT=A<br/>CN102001451 7214428 WHO=EXAMINER SELF=N CAT=X<br/>FR2821778 16964931 WHO=EXAMINER SELF=N CAT=X<br/>CA2760720 14228780 WHO=EXAMINER SELF=N CAT=A<br/><br/>(IT2012TO0111)<br/>FR2821778 16964931 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>CA2760720 14228780 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>JP2006051557 22546196 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2015-08-09",
                    "XAP": "2012WO-IB57627",
                    "APD": "2012-12-21",
                    "APID": "69294412",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2013117971&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FJeTQ1igaKAgEkQB6YnxUrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2013/117971",
                            "KIND": "A1",
                            "XPN": "WO2013117971",
                            "V_PNID": "WO-2013117971A1-0",
                            "DATE": "2013-08-15",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCAMfgUr20xhmN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2013117971&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=%252FJeTQ1igaKAgEkQB6YnxUrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2015HK-0106020",
                            "APD": "2015-06-24",
                            "APID": "106160286",
                            "REG_LINK": "https://esearch.ipd.gov.hk/nis-pos-view/#/pt/advancedsearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=o0T%252F0Pn9ZmUuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "HK1205491",
                                    "KIND": "A1",
                                    "XPN": "HK1205491",
                                    "V_PNID": "HK-1205491A1-0",
                                    "DATE": "2015-12-18",
                                    "STG": "Patent application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=I4eyU07brsLijqaa6Q2zlvEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=HK1205491&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=o0T%252F0Pn9ZmUuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2014IN-CN06155",
                            "APD": "2014-08-13",
                            "APID": "109924945",
                            "REG_LINK": "https://iprsearch.ipindia.gov.in/PublicSearch/PublicationSearch/Eregister",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=UKMrbiutUc34%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "IN416424",
                                    "KIND": "B",
                                    "XPN": "IN-416424",
                                    "V_PNID": "IN-416424B-118",
                                    "DATE": "2023-01-02",
                                    "STG": "Patent",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=FHIU9uFKPrseDj9I7jBWCvsAsko1a5Xg6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IN-416424&kind=B",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=UKMrbiutUc34%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "IN6155/CHENP/2014",
                                    "KIND": "A",
                                    "XPN": "IN2014CN06155",
                                    "V_PNID": "IN-6155/CHENP/2014A-43",
                                    "DATE": "2016-07-01",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=/WizbbSQlgsrNkTp9r7STVq5LJ03xVJIETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IN2014CN06155&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=p7xV0KXVoYifoKIJUkEmaMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2014BR-0019640",
                            "APD": "2012-12-21",
                            "APID": "139490710",
                            "REG_LINK": "https://gru.inpi.gov.br/e-inpi/internetCliente/Principal.jsp",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=kkJtaSRxKfO1kDNW6baSs8ExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "BR112014019640",
                                    "KIND": "B1",
                                    "XPN": "BR112014019640",
                                    "V_PNID": "BR-112014019640B1-0",
                                    "DATE": "2021-05-25",
                                    "STG": "Granted patent / Granted pipeline patent",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOWRusolFOpTudIiD4SZQSJlrOySc9vnaVO8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112014019640&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=kkJtaSRxKfO1kDNW6baSs8ExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "BR112014019640",
                                    "KIND": "A8",
                                    "XPN": "BR112014019640",
                                    "V_PNID": "BR-112014019640A8-20170711-0",
                                    "DATE": "2017-07-11",
                                    "STG": "Modified first page",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOWRusolFOpTudIiD4SZQSJl59mWXRDhcKa8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112014019640&kind=A8",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=kkJtaSRxKfO1kDNW6baSs8ExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "BR112014019640",
                                    "KIND": "A2",
                                    "XPN": "BR112014019640",
                                    "V_PNID": "BR-112014019640A2-0",
                                    "DATE": "2017-06-20",
                                    "STG": "Application for a patent of invention / pipeline patent published without search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOWRusolFOpTudIiD4SZQSJlTlgwbhA1i2q8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112014019640&kind=A2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=kkJtaSRxKfO1kDNW6baSs8ExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "BR112014019640",
                                    "KIND": "A0",
                                    "XPN": "BR112014019640",
                                    "V_PNID": "BR-112014019640A1-111",
                                    "DATE": "2014-10-21",
                                    "STG": "Application filed, as announced in the Gazette published by this office",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TbRcahlFzOWRusolFOpTudIiD4SZQSJl1rFtbI/Ao3O8mcFoz1yzz1k0PkWksrrN&n=1&xpn=BR112014019640&kind=A0",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=kkJtaSRxKfO1kDNW6baSs8ExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2012CA-2863745",
                            "APD": "2012-12-21",
                            "APID": "100178817",
                            "REG_LINK": "https://www.ic.gc.ca/opic-cipo/cpd/eng/patent/2863745/summary.html?type=number_search",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=telzL%252B4lgZ%252FjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CA2863745",
                                    "KIND": "C",
                                    "XPN": "CA2863745",
                                    "V_PNID": "CA-2863745C-14",
                                    "DATE": "2020-08-04",
                                    "STG": "Patent (second level)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=pp4wa/l5+YdoxXilmhmy14TNbfc8CWEP6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=CA2863745&kind=C",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=telzL%252B4lgZ%252FjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "CA2863745",
                                    "KIND": "A1",
                                    "XPN": "CA2863745",
                                    "V_PNID": "CA-2863745A1-14",
                                    "DATE": "2013-08-15",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=pp4wa/l5+YdoxXilmhmy1/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=CA2863745&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=telzL%252B4lgZ%252FjCoOEB2EWlnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2014KR-7022419",
                            "APD": "2012-12-21",
                            "APID": "101502312",
                            "REG_LINK": "http://link.kipris.or.kr/link/main/KPAXML.jsp?APPLNO=1020147022419",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=IMXwDdz5bJOfUL6HvErXOJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "KR10-1933253",
                                    "KIND": "B1",
                                    "XPN": "KR101933253",
                                    "V_PNID": "KR-101933253B1-30",
                                    "DATE": "2018-12-27",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=TF3wXQSsXsPWlC0qakmEdCq6vml3jfM5LF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=KR101933253&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=IMXwDdz5bJOfUL6HvErXOJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "KR10-2015-0001719",
                                    "KIND": "A",
                                    "XPN": "KR20150001719",
                                    "V_PNID": "KR-20150001719A-30",
                                    "DATE": "2015-01-06",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=aJxR8iNWnooWEUph3OH5CTkuDREcUBY0ETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=KR20150001719&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=hBghTy9wXZKRwpOm8CO4HsRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2014RU-0132574",
                            "APD": "2012-12-21",
                            "APID": "107259827",
                            "REG_LINK": "https://www1.fips.ru/registers-web/",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=f7XYQa4uimTdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "RU2631437",
                                    "KIND": "C2",
                                    "XPN": "RU2631437",
                                    "V_PNID": "RU-2631437C2-0",
                                    "DATE": "2017-09-22",
                                    "STG": "Patent for invention ( 2nd publ.)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=mu6iVModSQ1X157iK1+M/gtpbYik856lPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=RU2631437&kind=C2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=f7XYQa4uimTdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "RU2014132574",
                                    "KIND": "A",
                                    "XPN": "RU2014132574",
                                    "V_PNID": "RU-2014132574A-0",
                                    "DATE": "2016-03-27",
                                    "STG": "Application for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=BifV9gOYQAP9OdPtQQk0kwMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=RU2014132574&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=5HdupsjsXB1rRrsQs8QMDLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2033-06-26",
                            "XAP": "2012US-14377795",
                            "APD": "2012-12-21",
                            "APID": "106015749",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/14377795",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=csEbNI8flVLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US9643710",
                                    "KIND": "B2",
                                    "XPN": "US9643710",
                                    "V_PNID": "US-09643710B2-1",
                                    "DATE": "2017-05-09",
                                    "STG": "Granted patent as second publication",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=vTrV/OjFPeAKOK/bPVnqm0DJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=US9643710&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=csEbNI8flVLVNtz%252BuaPnF3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "US20150367930",
                                    "KIND": "A1",
                                    "XPN": "US20150367930",
                                    "V_PNID": "US-20150367930A1-2",
                                    "DATE": "2015-12-24",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcMZxLPDLZk0MUGd4JhdgzD3bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20150367930&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=LEhCuW2x76VO8LFpYDzmscRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2012EP-0824725",
                            "APD": "2012-12-21",
                            "APID": "89110846",
                            "REG_LINK": "https://register.epo.org/application?number=EP12824725",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nnIspgeNTl01zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP2812249",
                                    "KIND": "B1",
                                    "XPN": "EP2812249",
                                    "V_PNID": "EP-2812249B1-0",
                                    "DATE": "2016-03-16",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8wokhwq5Ge8QXZBBCVsbZKxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2812249&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nnIspgeNTl01zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP2812249",
                                    "KIND": "A1",
                                    "XPN": "EP2812249",
                                    "V_PNID": "EP-2812249A1-0",
                                    "DATE": "2014-12-17",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=8wokhwq5Ge8QXZBBCVsbZPEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2812249&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=nnIspgeNTl01zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ],
                            "V_APL": [
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "GRANTED",
                                    "ACT_EED": "2032-12-21",
                                    "XAP": "2012ES-0824725T",
                                    "APD": "2012-12-21",
                                    "APID": "109417132",
                                    "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=jXiHkCJszZX4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "ES2582634",
                                            "KIND": "T3",
                                            "XPN": "ES2582634",
                                            "V_PNID": "ES-2582634T3-0",
                                            "DATE": "2016-09-14",
                                            "STG": "Translation of granted European patent (former B3)",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=bA41f2/IaysrB8lQ0sFruH4Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2582634&kind=T3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=jXiHkCJszZX4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2032-12-21",
                            "XAP": "2012CN-80071705",
                            "APD": "2012-12-21",
                            "APID": "100991047",
                            "REG_LINK": "https://pss-system.cponline.cnipa.gov.cn/conventionalSearch",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=k7hKyatvfTAvLac7VHdy5bmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CN104245514",
                                    "KIND": "B",
                                    "XPN": "CN104245514B",
                                    "V_PNID": "CN-104245514B-17",
                                    "DATE": "2016-08-17",
                                    "STG": "Granted patent for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=tO7C931onjlnqkV70o1avBj8BQAJLzMlLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=CN104245514B&kind=B",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=k7hKyatvfTAvLac7VHdy5bmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "CN104245514",
                                    "KIND": "A",
                                    "XPN": "CN104245514",
                                    "V_PNID": "CN-104245514A-17",
                                    "DATE": "2014-12-24",
                                    "STG": "Published application",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=tO7C931onjlBEZpopnakwck/FxPOolWtHlM5eRO7LRsgdJdQmwjsTA==&n=1&xpn=CN104245514&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=k7hKyatvfTD1tMT7KvRFHJNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2032-02-09",
                    "XAP": "2012IT-TO00111",
                    "APD": "2012-02-09",
                    "APID": "69242919",
                    "REG_LINK": "",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CwowRQ4sPX56Q4snKYm%252FXbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "ITTO20120111",
                            "KIND": "A1",
                            "XPN": "IT2012TO0111",
                            "V_PNID": "IT-TO20120111A1-0",
                            "DATE": "2013-08-10",
                            "STG": "Application for patent of invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=PknmpDUQ+ywxK4QYQ/nCl90P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IT2012TO0111&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=CwowRQ4sPX56Q4snKYm%252FXbmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP2812249_B1",
            "EPRD": "2012-02-09",
            "PN": "EP2812249           B1 2016-03-16 [EP2812249]<br/>EP2812249           A1 2014-12-17 [EP2812249]<br/>US9643710           B2 2017-05-09 [US9643710]<br/>US20150367930       A1 2015-12-24 [US20150367930]<br/>WO2013/117971       A1 2013-08-15 [WO2013117971]<br/>RU2631437           C2 2017-09-22 [RU2631437]<br/>RU2014132574        A  2016-03-27 [RU2014132574]<br/>IN416424            B  2023-01-02 [IN-416424]<br/>IN6155/CHENP/2014   A  2016-07-01 [IN2014CN06155]<br/>BR112014019640      B1 2021-05-25 [BR112014019640]<br/>BR112014019640      A8 2017-07-11 [BR112014019640]<br/>BR112014019640      A2 2017-06-20 [BR112014019640]<br/>BR112014019640      A0 2014-10-21 [BR112014019640]<br/>CA2863745           C  2020-08-04 [CA2863745]<br/>CA2863745           A1 2013-08-15 [CA2863745]<br/>KR10-1933253        B1 2018-12-27 [KR101933253]<br/>KR10-2015-0001719   A  2015-01-06 [KR20150001719]<br/>ES2582634           T3 2016-09-14 [ES2582634]<br/>CN104245514         B  2016-08-17 [CN104245514B]<br/>CN104245514         A  2014-12-24 [CN104245514]<br/>HK1205491           A1 2015-12-18 [HK1205491]<br/>ITTO20120111        A1 2013-08-10 [IT2012TO0111]",
            "ADB": "(EP2812249)<br/><p>In addition, such a method is also costly in terms of production time per aircraft, because the various steps must be supervised by the person in charge, although with the help of sensors of various kinds, who must supervise every critical aspect of the aircraft production process.</p><p>It is known that assembling the sections of an aircraft fuselage is a very complex task that requires much control in order to create an aircraft capable of passing the flight resistance tests.</p><p>It should also be underlined that each electromechanical device used for implementing the method introduces intrinsic uncertainty in the operations it is adapted to perform; such uncertainty adds up to the uncertainties of the other electromechanical devices, because the systems known in the art do not include a central control system capable of coordinating such electromechanical devices to eliminate any errors so as to reduce the uncertainty of the entire system and, as a consequence, of the manufacturing method.</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=3<br/>PNAAGE=17<br/>NBPA=1; <br/>ALLCT=4; SCT=0; NSCT=4; <br/>ALLCTG=2; SCTG=0; NSCTG=2; <br/>AFS=0; ACC=0; AMCC=0; <br/>IGEN=0.0; IORG=0.84; IRAD=0.92; <br/>IMPI=1.16; MACI=0.0; PASI=0.5; PAVI=0.0; ",
            "PTCC": "",
            "EPN": "GB201008104",
            "CTGN": "(WO2011141322)<br/>CN108961150 82383745 WHO=EXAMINER SELF=N CAT=A<br/>CN109696675 84323408 WHO=EXAMINER SELF=N CAT=A",
            "LAPD": "2011-05-03",
            "STDN": "",
            "NPN": "3",
            "DESC": "<p><span class=\"paragraph-number\">[0001]   </span> System and Method for Image Registration </p> <p><span class=\"paragraph-number\">[0002]   </span>The invention relates to a system and method for image registration. More specifically but not exclusively it relates to a system and method for image registration incorporating the introduction of artificial common registration control point data into a sensor field of view (FoV) which can then be shared by disparate sensors in order to provide common field of reference for the entire system. </p> <p><span class=\"paragraph-number\">[0003]   </span>In current known systems of image registration solely passive image registration methods are used, including but not limited to: </p> <p><span class=\"paragraph-number\">[0004]   </span>1. Intensity Based Image Registration </p> <p><span class=\"paragraph-number\">[0005]   </span> Intensity-based methods compare intensity patterns in images via correlation metrics. Intensity-based methods register entire images or sub images by comparing their respective intensity profiles by a given metric (e.g. Sum of Absolute Difference). If they are registered, the metric is at minima and the centre of each corresponding sub image is treated as a corresponding feature point. </p> <p><span class=\"paragraph-number\">[0006]   </span>2. Feature Based Image Registration </p> <p><span class=\"paragraph-number\">[0007]   </span> Feature-based methods find correspondence between image features such as points, lines, and contours. Feature-based method established correspondence between numbers of points in images. Knowing the correspondence between those points, a transform is then determined to map the target image to the reference images. </p> <p><span class=\"paragraph-number\">[0008]   </span>3. Frequency Based Image Registration </p> <p><span class=\"paragraph-number\">[0009]   </span> These methods use metrics in the frequency domain to compare respective images, and include methods such as phase correlation.4. Interactive Image Registration </p> <p><span class=\"paragraph-number\">[0010]   </span> This is a manual method of image registration, which requires the user to identify a series of correlated points in each input image which are then used to calculate a transform to bring all of the input images onto the same coordinate set. This can also be done by placing image registration markers into the scene for later identification for use in Feature Based Methods (see 2). </p> <p><span class=\"paragraph-number\">[0011]   </span>5. Calibrated Field of View Image Registration </p> <p><span class=\"paragraph-number\">[0012]   </span> This uses co-bore sighted sensors, often on the same platform (and even on the same optics or even sensor array), with known offsets in parallax and field of view. These are then accounted for in the calculation of the required image transform. </p> <p><span class=\"paragraph-number\">[0013]   </span>Passive methods rely upon either tightly controlled interrelated physical aspects (calibrated fields of view for example) or shared features between disparate sensors (landmarks for example). </p> <p><span class=\"paragraph-number\">[0014]   </span>Both of these become increasingly difficult in real world applications due to uncontrolled movement (vibration affecting common physical calibration for example), difficulty in common feature detection, and lack of shared features (especially in disparate band sensors - it would be very difficult to align a Terrahertz imager with an Infra Red using Feature Based methods for example, even using multi-modal registration algorithms). </p> <p><span class=\"paragraph-number\">[0015]   </span>According to the invention there is provided a system for improving image data extraction from a target image comprising a plurality of sensors having a common field of view in which at least one sensor maps a series of control data points on to the target, the remaining sensor or sensors using the control data points to calculate a transform with which to map image data output by the first sensor to image data output by the remaining sensor or sensors to allow greater information to be gained about the target area.According to a further aspect of the invention there is provided a method of improving image registration in a system having a plurality of sensors comprising the steps of superimposing a series of data control points on to a target area, extracting image data relating to the target using the sensors, and transforming the image data received from the sensors relating to the target area using the data control points superimposed on the target thereby improving the accuracy and detail of the image data received. </p> <p><span class=\"paragraph-number\">[0016]   </span>In this way, the introduction of artificial common registration control point data in to a sensor field of view which can then be shared by disparate sensors provides a common field of reference for the entire system. Phase sensitive arrays can also be used in order to allow orientation information to be passed by uniquely identifying each data point in each dataset. This provides a given number of registration markers, which can then be automatically identified and used to calculate the necessary transforms without the need for user intervention. </p> <p><span class=\"paragraph-number\">[0017]   </span>The invention will now be described with reference to the accompanying diagrammatic drawings in which: </p> <p><span class=\"paragraph-number\">[0018]   </span>Figure 1 shows a schematic drawing of the system of one form of the invention; and </p> <p><span class=\"paragraph-number\">[0019]   </span>Figure 2 shows a schematic drawing of another form of the invention showing </p> <p><span class=\"paragraph-number\">[0020]   </span>Figure 1 shows a first embodiment of the invention. In this embodiment an Unmanned Aerial Vehicle (UAV) with an integrated sensor and multiple laser designators gives a plan view of the target area and applies registration control points to the target area, which are then observed by the ground based vehicle. The ground based vehicle can then use the registration control points to calculate a transform with which to map the UAV image output to its own image outputthereby allowing greater information to be gained about the target area, including visibility of occluded areas (e.g. directly behind a tower or walls). </p> <p><span class=\"paragraph-number\">[0021]   </span>It will be appreciated that both platforms described above could be static or on the move to allow greater flexibility. These techniques can also employ unambiguous registration control patterns to ensure target area orientation is also visible to all sensors - this is particularly useful for airborne sensor platforms. </p> <p><span class=\"paragraph-number\">[0022]   </span>In a second embodiment of the invention shown in Figure 2, an Unmanned Aerial Vehicle (UAV) with integrated laser designators applies a registration control pattern to the target area, which is then observed by the ground based multi- sensor platform. The system can then use the registration control points to calculate a transform with which to map all of the sensors to one another. </p> <p><span class=\"paragraph-number\">[0023]   </span>It will be appreciated that the laser designators could equally be co-located on the multi-sensor ground platform provided they are sufficiently visible by all of the relevant sensors. </p> <p><span class=\"paragraph-number\">[0024]   </span>Furthermore, the sensors can be co-located or on disparate platforms provided they have sufficient visibility of the registration control patterns. </p> <p><span class=\"paragraph-number\">[0025]   </span>This technique could be applied to provide extraction of 3 dimensional information about a target scene by allowing more accurate calculation of the system inter-sensor parallax, or the resolution of sub-pixel scene elements by the more accurate correlation of multiple sensors. </p> <p><span class=\"paragraph-number\">[0026]   </span>Furthermore, the technique could be applied to allow more accurate registration of multi-band sensors for image fusion applications (e.g. visual and thermal band cameras - the registration control patterns will be selected to be visible by all relevant sensors).It will also be appreciated that all of these techniques can be applied both static or on the move. Moreover, these techniques can also employ unambiguous registration control patterns to ensure target area orientation is also visible to all sensors - this is particularly useful for airborne sensor platforms. </p> <p><span class=\"paragraph-number\">[0027]   </span>Previous registration methods are restricted by their reliance on information contained in the existing image space whereas the proposed method introduces additional information into that image space specifically designed to allow accurate registration of the image space from the perspective of all sensors in the system. </p> <p><span class=\"paragraph-number\">[0028]   </span>It will be appreciated that this invention can be applied to any computer vision system which uses image registration - be that temporal or spatial. This includes but is not limited to Medical, Topographical, Photographic and video image registration.</p>",
            "CLMS": "(WO2011/141322)<br/><p><heading>CLAIMS </heading></p><p>1. A system for improving image data extraction from a target image comprising a plurality of sensors having a common field of view in which at least one sensor maps a series of control data points on to the target, the remaining sensor or sensors using the control data points to calculate a transform with which to map image data output by the first sensor to image data output by the remaining sensor or sensors to allow greater information to be gained about the target area.</p><p>2. A system according to claim 1 in which the control data points comprise an unambiguous registration control pattern thereby ensuring the target area orientation is visible to all sensors in the system.</p><p>3. A system according to claim 1 or 2 in which at least one of the sensors is mounted on an aircraft and at least one of the sensors is ground based.</p><p>4. A system according to claim 3 in which the airborne sensor is mounted on a UAV.</p><p>5. A system according to any preceding claim in which the control data points comprise a registration control pattern applied to the target area by integrated laser designators, said control pattern being observable by a ground based multi-sensor platform.</p><p>6. A system according to claim 5 in which the registration control points are used to calculate a transform with which to map all of the sensors to one another.</p><p>7. A system according to claim 5 or 6 in which the laser designators are co- located on the multi-sensor ground platform such that the control pattern is visible to all of the relevant sensors.</p><p>8. A system according to any one of claim 5 to 7 in which the sensors can be co-located or on disparate platforms provided they have sufficient visibility of the registration control patterns.</p><p>9. A method of improving image registration in a system having a plurality of sensors comprising the steps of superimposing a series of data control points on to a target area, extracting image data relating to the target using the sensors, and transforming the image data received from the sensors relating to the target area using the data control points superimposed on the target thereby improving the accuracy and detail of the image data received.</p><p>10. A method of improving image registration according to claim 9 further comprising the step of utilising unambiguous registration control patterns to ensure target area orientation is also visible to all sensors.</p><p>11. A system or method as hereinbefore described with reference to the accompanying diagrammatic drawings.</p>",
            "NPR": "2",
            "APID": "22203111",
            "RELEVANCE_SCORE": "100.0",
            "IC": "G06T-007/00",
            "ID": "15079695",
            "AB": "(EP2569756)<br/>A system and method is described for improving image registration systems. A target area to be monitored is superimposed with a series of control data points by a sensor within the system. Image data output by all sensors within the system is then processed using a suitable transformation based on the positioning and visibility of the control data points by all the sensors in the system.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=G2rDIeUITpLWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2010-05-14",
            "PA": "LEONARDO MW<br/>SELEX GALILEO",
            "PAAD": "(EP2569756)<br/>(PUB:EP-2569756A1-0)NAME=Selex Galileo Limited Christopher Martin Road , CITY=Basildon, Essex SS14 3EL , COUNTRY=GB , REG=101169814<br/><br/><br/>(WO2011141322)<br/>(PUB:WO-2011141322A1-0)NAME=SELEX GALILEO LIMITED Christopher Martin Road Basildon Essex SS14 3EL , COUNTRY=GB<br/>",
            "FAN": "15079695",
            "TI": "System and method for image registration",
            "TECD": "Computer technology",
            "EPD": "2010-06-30",
            "ICLM": "(WO2011/141322)<br/><p>1. A system for improving image data extraction from a target image comprising a plurality of sensors having a common field of view in which at least one sensor maps a series of control data points on to the target, the remaining sensor or sensors using the control data points to calculate a transform with which to map image data output by the first sensor to image data output by the remaining sensor or sensors to allow greater information to be gained about the target area.</p><p>11. A system or method as hereinbefore described with reference to the accompanying diagrammatic drawings.</p><p>9. A method of improving image registration in a system having a plurality of sensors comprising the steps of superimposing a series of data control points on to a target area, extracting image data relating to the target using the sensors, and transforming the image data received from the sensors relating to the target area using the data control points superimposed on the target thereby improving the accuracy and detail of the image data received.</p>",
            "CTN": "(EP2569756)<br/>US20020114509 22651781 WHO=EXAMINER SELF=N CAT=A<br/>US20040151365 43503402 WHO=EXAMINER SELF=N CAT=A<br/>US20020122113 22333937 WHO=EXAMINER SELF=N CAT=I<br/>GB2390792 1728274 WHO=EXAMINER SELF=N CAT=I<br/>XP019248525 none WHO=EXAMINER SELF=N<br/>XP010768594 none WHO=EXAMINER SELF=N<br/>XP011306578 none WHO=EXAMINER SELF=N<br/>XP011302705 none WHO=EXAMINER SELF=N<br/><br/>(WO2011141322)<br/>US20020114509 22651781 WHO=EXAMINER SELF=N CAT=A<br/>US20040151365 43503402 WHO=EXAMINER SELF=N CAT=A<br/>XP019248525 none WHO=EXAMINER SELF=N CAT=I<br/>XP010768594 none WHO=EXAMINER SELF=N CAT=I<br/>US20020122113 22333937 WHO=EXAMINER SELF=N CAT=I<br/>GB2390792 1728274 WHO=EXAMINER SELF=N CAT=I<br/>XP011306578 none WHO=EXAMINER SELF=N CAT=I<br/>XP011302705 none WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2013-11-14",
                    "XAP": "2011WO-EP57014",
                    "APD": "2011-05-03",
                    "APID": "66999122",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2011141322&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=L3G6oqp%252BolPmK6bjBnLk%252FrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2011/141322",
                            "KIND": "A1",
                            "XPN": "WO2011141322",
                            "V_PNID": "WO-2011141322A1-0",
                            "DATE": "2011-11-17",
                            "STG": "Published application with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDOY1rag7VMqt0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2011141322&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=L3G6oqp%252BolPmK6bjBnLk%252FrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2019-09-06",
                            "XAP": "2011EP-0724137",
                            "APD": "2011-05-03",
                            "APID": "22203111",
                            "REG_LINK": "https://register.epo.org/application?number=EP11724137",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=G2rDIeUITpLWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP2569756",
                                    "KIND": "A1",
                                    "XPN": "EP2569756",
                                    "V_PNID": "EP-2569756A1-0",
                                    "DATE": "2013-03-20",
                                    "STG": "Application published with search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=MOptU6owRDOBOywZ0BPdz/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2569756&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=G2rDIeUITpLWqxLm4QBXD3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2012-01-04",
                    "XAP": "2010GB-0008104",
                    "APD": "2010-05-14",
                    "APID": "28437062",
                    "REG_LINK": "",
                    "PERMALINK": null,
                    "PUB": [
                        {
                            "PN": "GB201008104",
                            "KIND": "D0",
                            "XPN": "GB201008104",
                            "V_PNID": "GB-201008104D0-0",
                            "DATE": "2010-06-30",
                            "STG": "Patent application filed",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=/de4PfIWQtMvaiF6+4Utte40VJCBdcQTLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=GB201008104&kind=D0",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=IETkM%252Bbq8Wmtn4jhqLF70JNXe7dphUsu7KxJINoFg8I%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP2569756_A1",
            "EPRD": "2010-05-14",
            "PN": "EP2569756           A1 2013-03-20 [EP2569756]<br/>WO2011/141322       A1 2011-11-17 [WO2011141322]<br/>GB201008104         D0 2010-06-30 [GB201008104]",
            "ADB": "(WO2011/141322)<br/><p>It will be appreciated that both platforms described above could be static or on the move to allow greater flexibility.</p><p>It will be appreciated that the laser designators could equally be co-located on the multi-sensor ground platform provided they are sufficiently visible by all of the relevant sensors.</p><p>It will be appreciated that this invention can be applied to any computer vision system which uses image registration - be that temporal or spatial.</p><p>Both of these become increasingly difficult in real world applications due to uncontrolled movement (vibration affecting common physical calibration for example), difficulty in common feature detection, and lack of shared features (especially in disparate band sensors - it would be very difficult to align a Terrahertz imager with an Infra Red using Feature Based methods for example, even using multi-modal registration algorithms).</p>"
        },
        {
            "FNUM": "APAGE=12<br/>NBPC=4<br/>PNAAGE=9<br/>NBPA=1; <br/>ALLCT=13; SCT=0; NSCT=13; <br/>ALLCTG=24; SCTG=0; NSCTG=24; <br/>AFS=6; ACC=6; AMCC=3; <br/>IGEN=0.92; IORG=0.88; IRAD=0.97; <br/>IMPI=4.5; MACI=1.62; PASI=3.96; PAVI=2.88; ",
            "PTCC": "(EP2338793)<br/>CC=EP EED=2030-12-16 STATUS=GRANTED APID=21975656 APD=2010-12-16 XPN=EP2338793 PD=2011-06-29 PD=2016-08-31 PD=2017-01-11 EPD=2011-06-29 LPD=2017-01-11 PDG=2016-08-31 <br/>CC=DE EED=2030-12-16 STATUS=GRANTED APID=21975656 XPN=EP2338793 PDG=2016-08-31 <br/>CC=ES EED=2030-12-16 STATUS=GRANTED APID=111493098 APD=2010-12-16 XPN=ES2601082 PD=2017-02-14 EPD=2017-02-14 LPD=2017-02-14 PDG=2017-02-14 <br/>CC=FR EED=2030-12-16 STATUS=GRANTED APID=21975656 XPN=EP2338793 PDG=2016-08-31 <br/>CC=GB EED=2030-12-16 STATUS=GRANTED APID=21975656 XPN=EP2338793 PDG=2016-08-31 <br/><br/>(US8712608)<br/>CC=US EED=2032-08-23 STATUS=GRANTED APID=64161560 APD=2010-12-15 XPN=US20120059536 PD=2012-03-08 PD=2014-04-29 EPD=2012-03-08 LPD=2014-04-29 PDG=2014-04-29 <br/><br/>(ES2601082)<br/>CC=ES EED=2030-12-16 STATUS=GRANTED APID=111493098 APD=2010-12-16 XPN=ES2601082 PD=2017-02-14 EPD=2017-02-14 LPD=2017-02-14 PDG=2017-02-14 <br/><br/>(IT1397664)<br/>CC=IT EED=2029-12-16 STATUS=GRANTED APID=30313414 APD=2009-12-16 XPN=IT2009TO0993 PD=2011-06-17 PD=2013-01-18 EPD=2011-06-17 LPD=2013-01-18 PDG=2013-01-18 <br/>",
            "EPN": "ITTO20090993",
            "CTGN": "(EP2338793)<br/>GB2538242 70296738 WHO=EXAMINER SELF=N<br/>FR3110981 97353045 WHO=EXAMINER SELF=N CAT=I<br/>EP3879376 96076743 WHO=EXAMINER SELF=N CAT=A<br/>WO202194178 94036944 WHO=EXAMINER SELF=N CAT=Y<br/>EP3964915 97353045 WHO=EXAMINER SELF=N CAT=A<br/>FR3103036 94036944 WHO=EXAMINER SELF=N<br/>US11922660 97353045 WHO=EXAMINER SELF=N<br/>US10732648 74579210 WHO=APPLICANT SELF=N<br/>US11409309 96076743 WHO=APPLICANT SELF=N<br/>EP3964915 97353045 WHO=APPLICANT SELF=N<br/>EP3879376 96076743 WHO=APPLICANT SELF=N<br/>US11922660 97353045 WHO=APPLICANT SELF=N<br/><br/>(US8712608)<br/>US8768542 14996873 WHO=EXAMINER SELF=N<br/>US20140312165 67667400 WHO=EXAMINER SELF=N CAT=103<br/>DE102014018717 73297716 WHO=EXAMINER SELF=N<br/>US20160117936 45973599 WHO=EXAMINER SELF=N<br/>US9488979 83272668 WHO=EXAMINER SELF=N<br/>EP3093241 74593718 WHO=EXAMINER SELF=N CAT=X<br/>WO2016181117 74579210 WHO=EXAMINER SELF=N CAT=X<br/>US9641810 15073556 WHO=EXAMINER SELF=N<br/>US9037391 7806348 WHO=EXAMINER SELF=N<br/>US9910432 83272668 WHO=EXAMINER SELF=N<br/>EP3294629 74579210 WHO=EXAMINER SELF=N CAT=X<br/>US20160378786 18795671 WHO=EXAMINER SELF=N CAT=102<br/>US10365645 83272668 WHO=EXAMINER SELF=N<br/>US10654584 79984390 WHO=EXAMINER SELF=N<br/>US10732648 74579210 WHO=EXAMINER SELF=N<br/>US20110130898 14996873 WHO=EXAMINER SELF=N CAT=103<br/>US10814998 81095296 WHO=EXAMINER SELF=N<br/>US10875665 83330785 WHO=EXAMINER SELF=N<br/>WO202122236 92563201 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>US11016510 83272668 WHO=EXAMINER SELF=N<br/>US11409309 96076743 WHO=EXAMINER SELF=N<br/>EP4144651 103869905 WHO=EXAMINER SELF=N CAT=Y<br/>US20230358545 107100828 WHO=EXAMINER SELF=N CAT=103<br/>US9489852 74041267 WHO=APPLICANT SELF=N<br/>DE102014018717 73297716 WHO=APPLICANT SELF=N<br/>US9747808 74041267 WHO=APPLICANT SELF=N<br/>US10474148 78608740 WHO=APPLICANT SELF=N<br/>US11113976 74041267 WHO=APPLICANT SELF=N<br/>US12077313 111224487 WHO=APPLICANT SELF=N<br/>US12077314 111224491 WHO=APPLICANT SELF=N<br/>US12125396 74041267 WHO=APPLICANT SELF=N",
            "LAPD": "2010-12-16",
            "STDN": "",
            "NPN": "4",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a system and to a method of automatic piloting for in-flight refuelling of aircraft and to an aircraft comprising said system, in particular for governing the approach in conditions of safety of an aircraft to be refuelled to a tanker aircraft.</p><p><h1>BACKGROUND OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0002]   </span>In-flight refuelling systems of a known type envisage the transfer of fuel between a tanker aircraft and a receiver aircraft by means of a hose passing through a rigid pipe (known as “boom”) and a telescopic line. The boom is fixed to a rear portion of the fuselage of the tanker aircraft through a semi-rigid connection, which enables a certain degree of freedom of movement. It is evident that the receiver aircraft, in order to carry out successfully the operation of in-flight refuelling, must first of all carry out a correct approach to the tanker aircraft, keeping a distance not greater than the distance that can be covered by the boom and the telescopic line, and then maintain a position and a speed as conformable as possible to that of the tanker aircraft.</p><p><span class=\"paragraph-number\">[0003]   </span>A different refuelling method envisages instead the use of a hose, provided, on a terminal portion thereof, with a drogue, configured for connecting up to an inlet mouth of the refuelling system of the receiver aircraft. The receiver aircraft must execute minimal movements such as to reach the drogue of the hose and remain in a fixed position with respect to the tanker aircraft.</p><p><span class=\"paragraph-number\">[0004]   </span>The operation of approach of the receiver aircraft to the area envisaged for refuelling (known as “rendez-vous area”) and of initial positioning with respect to the tanker aircraft is currently executed by the pilot of the receiver aircraft. For experimental purposes, during the most critical operations of fine alignment (for example, engagement of the hose with the fuel-receiving line of the receiver aircraft) tests have been conducted, in which the pilot of the receiver aircraft is supported in the correct positioning by alignment systems of an optical type, in particular devices working in the visible or infrared devices, which issue an optical signal detected by appropriate optical detectors set on the receiver aircraft, in particular in the proximity of the fuel-receiving line. However, said alignment systems, used only in the terminal step of engagement with the fuel-receiving line, envisage an active intervention on the part of the pilot of the receiver aircraft in maintaining the position of the receiver aircraft stable with respect to that of the tanker aircraft during the refuelling procedure.</p><p><span class=\"paragraph-number\">[0005]   </span>A solution of a known type to this problem is described in the U.S. Pat. No. 6,669,145. In detail, this solution envisages setting on the tanker aircraft and/or on the drogue fixed to the boom a plurality of reflectors, configured for operating as polarization filters. The receiver aircraft has, instead, available a source of radiation (for example, a LED or a laser) and a detector of radiation (for example, a photodiode).</p><p><span class=\"paragraph-number\">[0006]   </span>In the final step of approach between the receiver aircraft and the tanker aircraft, the receiver aircraft issues, by means of the source of radiation, an incident radiation that propagates in the direction of the tanker aircraft and/or of the drogue. The reflectors set on the tanker aircraft and/or on the drogue reflect the incident radiation, each generating a reflected radiation of its own (characterized by a polarization of its own), which is detected by the detector of radiation set on the receiver aircraft. By analysing the reflected radiation, and in particular the polarization of the signal received, the receiver aircraft is able to know its own position with respect to each reflector, and, consequently, with respect to the tanker aircraft and/or the boom.</p><p><span class=\"paragraph-number\">[0007]   </span>The system described in U.S. Pat. No. 6,669,145 presents the disadvantage of entailing considerable modifications, including structural ones, to the tanker aircraft and to the drogue of the boom. This involves a high cost for updating existing tanker aircraft, and an increase in the production costs of tanker aircraft built according to the teaching of the document U.S. Pat. No. 6,669,145. Furthermore, according to said system, a receiver aircraft that requires in-flight refuelling, could complete successfully the steps of refuelling by interfacing only with a tanker aircraft built according to the teaching of the document U.S. Pat. No. 6,669,145, and not with a generic tanker aircraft.</p><p><span class=\"paragraph-number\">[0008]   </span>A further solution of a known type for carrying out automatic in-flight refuelling is described in US 2008/0265097. The method described in US 2008/0265097 regards control of the flight of the tanker aircraft and control of orientation of the boom. In this case, in fact, the tanker aircraft is provided with an inertial measurement unit (IMU), a GPS device, and a processor, configured for calculating a current state of inertial navigation of the tanker aircraft compensating possible errors (for example, due to phenomena of electronic noise of the IMU and GPS location errors). The tanker aircraft can moreover comprise electro-optical sensors, for acquiring images of the boom and/or of the receiver aircraft during the final step of approach for refuelling.</p><p><span class=\"paragraph-number\">[0009]   </span>Finally, the patent No. GB 2 438 218 describes a method and a system for enabling relative flight of two aircraft, in particular a tanker aircraft and a receiver aircraft that is to be refuelled. The correct position of flight of the receiver aircraft is maintained by comparing position data obtained via a GPS receiver set both on the tanker aircraft and on the receiver aircraft. The GPS measurements are integrated with further measurements obtained by means of acceleration sensors and angular-velocity sensors, set both on board the tanker aircraft and on board the receiver aircraft. This system, however, does not guarantee a high degree of precision (at least at the centimeter level) during the final step of approach and contact between the boom and the receiver aircraft (last 10 m).</p><p><h1>SUMMARY OF THE INVENTION</h1></p><p><span class=\"paragraph-number\">[0010]   </span>The aim of the present invention is to provide a system and a method of automatic piloting for in-flight refuelling of aircraft, and an aircraft comprising said system, that will enable the disadvantages of the known art to be overcome, and in particular that will enable refuelling of the receiver aircraft by automating the procedures of approach and of fine alignment between the receiver aircraft and the tanker aircraft without making structural modifications to the tanker aircraft or by making modifications with minimal structural impact to the tanker aircraft.</p><p><span class=\"paragraph-number\">[0011]   </span>Provided according to the present invention are a system and a method of automatic piloting for in-flight refuelling of aircraft, and an aircraft comprising said system, as defined in Claims <b>1</b>, <b>13</b>, and <b>34</b>, respectively.</p><br/><p><h1>BRIEF DESCRIPTION OF THE DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0012]   </span>For a better understanding of the present invention, a preferred embodiment is now described, purely by way of non-limiting example, with reference to the attached drawings, wherein:</p><p><span class=\"paragraph-number\">[0013]   </span><a href=\"#DRAWINGS\">FIG. 1</a> is a schematic illustration of a receiver aircraft provided with an automatic-piloting system according to the present invention;</p><p><span class=\"paragraph-number\">[0014]   </span><a href=\"#DRAWINGS\">FIG. 2</a> is a schematic illustration of a tanker aircraft configured for co-operating with the receiver aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> during approach of the receiver aircraft, according to the present invention;</p><p><span class=\"paragraph-number\">[0015]   </span><a href=\"#DRAWINGS\">FIG. 3</a> shows, by means of a block diagram, modules for managing the automatic-piloting system according to the present invention;</p><p><span class=\"paragraph-number\">[0016]   </span><a href=\"#DRAWINGS\">FIG. 4</a> shows, by means of a flowchart, successive steps of a method of approach of the aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> to a rendez-vous area and of approach to the tanker aircraft of <a href=\"#DRAWINGS\">FIG. 2</a> with purposes of in-flight refuelling according to the present invention;</p><p><span class=\"paragraph-number\">[0017]   </span><a href=\"#DRAWINGS\">FIG. 5</a> shows, by means of a statechart diagram, states assumed by the management modules of <a href=\"#DRAWINGS\">FIG. 3</a>;</p><p><span class=\"paragraph-number\">[0018]   </span><a href=\"#DRAWINGS\">FIG. 6</a> shows the receiver aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> during a step of approach to the tanker aircraft of <a href=\"#DRAWINGS\">FIG. 2</a>;</p><p><span class=\"paragraph-number\">[0019]   </span><a href=\"#DRAWINGS\">FIG. 7</a> shows the plot of a parameter representing the uncertainty on the GPS position data as a function of the prediction error, in meters, on the GPS position data;</p><p><span class=\"paragraph-number\">[0020]   </span><a href=\"#DRAWINGS\">FIG. 8</a> shows the time plot of a delay parameter depending upon the delay with which the GPS position data is updated;</p><p><span class=\"paragraph-number\">[0021]   </span><a href=\"#DRAWINGS\">FIG. 9</a> shows the plot of an accuracy parameter of the distance between the receiver aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> and the tanker aircraft of <a href=\"#DRAWINGS\">FIG. 2</a>, as detected through processing of images of the tanker aircraft captured by the receiver aircraft, as a function of the distance;</p><p><span class=\"paragraph-number\">[0022]   </span><a href=\"#DRAWINGS\">FIG. 10</a> shows the plot of a value of uncertainty in the measurement of distance between the receiver aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> and the tanker aircraft of <a href=\"#DRAWINGS\">FIG. 2</a>, as detected through processing of the images of the tanker aircraft captured by the receiver aircraft, as a function of the distance;</p><p><span class=\"paragraph-number\">[0023]   </span><a href=\"#DRAWINGS\">FIG. 11</a> shows the time plot of a reliability parameter of the optical measurement; and</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIG. 12</a> shows, by means of a block diagram, steps of a process of weighting and filtering of distance data between the receiver aircraft of <a href=\"#DRAWINGS\">FIG. 1</a> and the tanker aircraft of <a href=\"#DRAWINGS\">FIG. 2</a> according to the present invention.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to a system and to a method of automatic piloting for in-flight refuelling of aircraft and to an aircraft comprising said system, in particular for governing the approach in conditions of safety of an aircraft to be refuelled to a tanker aircraft.</p><p><span class=\"paragraph-number\">[0002]   </span>In-flight refuelling systems of a known type envisage the transfer of fuel between a tanker aircraft and a receiver aircraft by means of a hose passing through a rigid pipe (known as \"boom\") and a telescopic line. The boom is fixed to a rear portion of the fuselage of the tanker aircraft through a semi-rigid connection, which enables a certain degree of freedom of movement. It is evident that the receiver aircraft, in order to carry out successfully the operation of in-flight refuelling, must first of all carry out a correct approach to the tanker aircraft, keeping a distance not greater than the distance that can be covered by the boom and the telescopic line, and then maintain a position and a speed as conformable as possible to that of the tanker aircraft.</p><p><span class=\"paragraph-number\">[0003]   </span>A different refuelling method envisages instead the use of a hose, provided, on a terminal portion thereof, with a drogue, configured for connecting up to an inlet mouth of the refuelling system of the receiver aircraft. The receiver aircraft must execute minimal movements such as to reach the drogue of the hose and remain in a fixed position with respect to the tanker aircraft.</p><p><span class=\"paragraph-number\">[0004]   </span>The operation of approach of the receiver aircraft to the area envisaged for refuelling (known as \"rendez-vous area\") and of initial positioning with respect to the tanker aircraft is currently executed by the pilot of the receiver aircraft. For experimental purposes, during the most critical operations of fine alignment (for example, engagement of the hose with the fuel-receiving line of the receiver aircraft) tests have been conducted, in which the pilot of the receiver aircraft is supported in the correct positioning by alignment systems of an optical type, in particular devices working in the visible or infrared devices, which issue an optical signal detected by appropriate optical detectors set on the receiver aircraft, in particular in the proximity of the fuel-receiving line. However, said alignment systems, used only in the terminal step of engagement with the fuel-receiving line, envisage an active intervention on the part of the pilot of the receiver aircraft in maintaining the position of the receiver aircraft stable with respect to that of the tanker aircraft during the refuelling procedure.</p><p><span class=\"paragraph-number\">[0005]   </span>A solution of a known type to this problem is described in the patent No. <patcit dnum=\"US6669145B\">US 6,669,145</patcit>. In detail, this solution envisages setting on the tanker aircraft and/or on the drogue fixed to the boom a plurality of reflectors, configured for operating as polarization filters. The receiver aircraft has, instead, available a source of radiation (for example, a LED or a laser) and a detector of radiation (for example, a photodiode).</p><p><span class=\"paragraph-number\">[0006]   </span>In the final step of approach between the receiver aircraft and the tanker aircraft, the receiver aircraft issues, by means of the source of radiation, an incident radiation that propagates in the direction of the tanker aircraft and/or of the drogue. The reflectors set on the tanker aircraft and/or on the drogue reflect the incident radiation, each generating a reflected radiation of its own (characterized by a polarization of its own), which is detected by the detector of radiation set on the receiver aircraft. By analysing the reflected radiation, and in particular the polarization of the signal received, the receiver aircraft is able to know its own position with respect to each reflector, and, consequently, with respect to the tanker aircraft and/or the boom.</p><p><span class=\"paragraph-number\">[0007]   </span>The system described in <patcit dnum=\"US6669145B\">US 6,669,145</patcit> presents the disadvantage of entailing considerable modifications, including structural ones, to the tanker aircraft and to the drogue of the boom. This involves a high cost for updating existing tanker aircraft, and an increase in the production costs of tanker aircraft built according to the teaching of the document No. <patcit dnum=\"US6669145B\">US 6,669,145</patcit>. Furthermore, according to said system, a receiver aircraft that requires in-flight refuelling, could complete successfully the steps of refuelling by interfacing only with a tanker aircraft built according to the teaching of the document No. <patcit dnum=\"US6669145B\">US 6,669,145</patcit>, and not with a generic tanker aircraft.</p><p><span class=\"paragraph-number\">[0008]   </span>A further solution of a known type for carrying out automatic in-flight refuelling is described in <patcit dnum=\"US20080265097A\">US 2008/0265097</patcit>. The method described in <patcit dnum=\"US20080265097A\">US 2008/0265097</patcit> regards control of the flight of the tanker aircraft and control of orientation of the boom. In this case, in fact, the tanker aircraft is provided with an inertial measurement unit (IMU), a GPS device, and a processor, configured for calculating a current state of inertial navigation of the tanker aircraft compensating possible errors (for example, due to phenomena of electronic noise of the IMU and GPS location errors). The tanker aircraft can moreover comprise electro-optical sensors, for acquiring images of the boom and/or of the receiver aircraft during the final step of approach for refuelling.</p><p><span class=\"paragraph-number\">[0009]   </span>Patent No. <patcit dnum=\"GB2438218A\">GB 2 438 218</patcit> describes a method and a system for enabling relative flight of two aircraft, in particular a tanker aircraft and a receiver aircraft that is to be refuelled. The correct position of flight of the receiver aircraft is maintained by comparing position data obtained via a GPS receiver set both on the tanker aircraft and on the receiver aircraft. The GPS measurements are integrated with further measurements obtained by means of acceleration sensors and angular-velocity sensors, set both on board the tanker aircraft and on board the receiver aircraft. This system, however, does not guarantee a high degree of precision (at least at the centimetre level) during the final step of approach and contact between the boom and the receiver aircraft (last 10 m).</p><p><span class=\"paragraph-number\">[0010]   </span>Patent No. <patcit dnum=\"US6889941B\">US 6,889,941</patcit> discloses navigation and guidance of a follower aircraft, such as a UAV, relative to a leader aircraft and specifically to an aerial refuelling and formation flying system for UAVs.</p><p><span class=\"paragraph-number\">[0011]   </span>The aim of the present invention is to provide a system and a method of automatic piloting for in-flight refuelling of aircraft, and an aircraft comprising said system, that will enable the disadvantages of the known art to be overcome, and in particular that will enable refuelling of the receiver aircraft by automating the procedures of approach and of fine alignment between the receiver aircraft and the tanker aircraft without making structural modifications to the tanker aircraft or by making modifications with minimal structural impact to the tanker aircraft.</p><p><span class=\"paragraph-number\">[0012]   </span>Provided according to the present invention are a system and a method of automatic piloting for in-flight refuelling of aircraft, and an aircraft comprising said system, as defined in Claims 1, 9 and 25, respectively.</p><p><span class=\"paragraph-number\">[0013]   </span>For a better understanding of the present invention, a preferred embodiment is now described, purely by way of nonlimiting example, with reference to the attached drawings, wherein:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 1</figref> is a schematic illustration of a receiver aircraft provided with an automatic-piloting system according to the present invention;</li><br/><li> <figref>Figure 2</figref> is a schematic illustration of a tanker aircraft configured for co-operating with the receiver aircraft of <figref>Figure 1</figref> during approach of the receiver aircraft, according to the present invention;</li><br/><li> <figref>Figure 3</figref> shows, by means of a block diagram, modules for managing the automatic-piloting system according to the present invention;</li></ul></p><p><ul compact=\"compact\" list-style=\"dash\"><li> <figref>Figure 4</figref> shows, by means of a flowchart, successive steps of a method of approach of the aircraft of <figref>Figure 1</figref> to a rendez-vous area and of approach to the tanker aircraft of <figref>Figure 2</figref> with purposes of in-flight refuelling according to the present invention;</li><br/><li> <figref>Figure 5</figref> shows, by means of a statechart diagram, states assumed by the management modules of <figref>Figure 3</figref>;</li><br/><li> <figref>Figure 6</figref> shows the receiver aircraft of <figref>Figure 1</figref> during a step of approach to the tanker aircraft of <figref>Figure 2</figref>;</li><br/><li> <figref>Figure 7</figref> shows the plot of a parameter representing the uncertainty on the GPS position data as a function of the prediction error, in metres, on the GPS position data;</li><br/><li> <figref>Figure 8</figref> shows the time plot of a delay parameter depending upon the delay with which the GPS position data is updated;</li><br/><li> <figref>Figure 9</figref> shows the plot of an accuracy parameter of the distance between the receiver aircraft of <figref>Figure 1</figref> and the tanker aircraft of <figref>Figure 2</figref>, as detected through processing of images of the tanker aircraft captured by the receiver aircraft, as a function of the distance;</li><br/><li> <figref>Figure 10</figref> shows the plot of a value of uncertainty in the measurement of distance between the receiver aircraft of <figref>Figure 1</figref> and the tanker aircraft of <figref>Figure 2</figref>, as detected through processing of the images of the tanker aircraft captured by the receiver aircraft, as a function of the distance;</li><br/><li> <figref>Figure 11</figref> shows the time plot of a reliability parameter of the optical measurement; and</li><br/><li> <figref>Figure 12</figref> shows, by means of a block diagram, steps of a process of weighting and filtering of distance data between the receiver aircraft of <figref>Figure 1</figref> and the tanker aircraft of <figref>Figure 2</figref> according to the present invention.</li></ul></p><p><span class=\"paragraph-number\">[0014]   </span><figref>Figure 1</figref> shows a receiver aircraft 1, which may be indifferently either an unmanned aerial vehicle (UAV) or a manned aerial vehicle, configured for automatic approach of a tanker aircraft (illustrated in <figref>Figure 2</figref>) for operations of in-flight refuelling. In the case of UAVs, there may in any case be envisaged the presence, on the ground, of a remote pilot, who can govern the aircraft at a distance. In the sequel of the description, if not otherwise indicated, the term \"pilot\" refers indifferently to a pilot present on board the aircraft or one located at a distance from the aircraft and in communication therewith, for control of the course or other operations.</p><p><span class=\"paragraph-number\">[0015]   </span>The receiver aircraft 1 comprises an automatic-piloting system 15 for enabling in-flight refuelling, including: an autonomous flight device 2, configured for controlling course and flight parameters (speed, altitude, etc.) of the receiver aircraft 1; a positioning device 4, for example a GPS receiver, configured for acquiring a GPS signal in order to detect position co-ordinates of the receiver aircraft 1 during flight; a transceiver device 6, configured for communicating in reception and transmission with a respective transceiver device set on a tanker aircraft (illustrated in <figref>Figure 2</figref>); a first optical device 8 and a second optical device 10, for example a first video camera and a second video camera, each set on a respective wing of the receiver aircraft 1, preferably in a lower portion of each respective wing, and configured for acquiring films and/or images in the visible or in the infrared; a memory 12; and a microcontroller 14, connected to the memory 12, to the first and second optical devices 8 and 10, to the transceiver device 6, to the positioning device 4, and to the autonomous flight device 2. The microcontroller 14 and the memory 12 can be replaced by an integrated digital processor (not illustrated).</p><p><span class=\"paragraph-number\">[0016]   </span>According to a preferred embodiment of the present invention, the first and second optical devices 8, 10 are passive optical detectors. In this case, a passive optical detector indicates an optical device configured for acquiring a signal (in particular, an optical signal, indifferently in the spectrum of the visible or of the invisible, for example infrared) generated by a source set at a distance therefrom. The first and second optical devices 8, 10, of a passive type, are hence not configured for issuing a signal (in particular, an optical signal) and acquiring a portion of the signal issued reflected by an obstacle or by another object set at a distance. Passive optical devices are, for example, video cameras or photographic cameras.</p><p><span class=\"paragraph-number\">[0017]   </span><figref>Figure 2</figref> shows, in rear view from beneath, a tanker aircraft 20, configured for co-operating with the receiver aircraft 1 of <figref>Figure 1</figref> in order to enable in-flight refuelling of the receiver aircraft 1. In particular, the tanker aircraft 20 comprises, according to one embodiment of the present invention, a first signal source 22 and a second signal source 24, for example a first signal source and a second signal source of an active type, configured for issuing a light signal. The first and second signal sources 22, 24 are, for example, formed by optical devices configured for issuing a signal in the spectrum of the visible and/or of the infrared. This embodiment presents the advantage of requiring minimal modifications to the tanker aircraft 20 that can be made also to already existing tanker aircraft 20 in an economically advantageous way, requiring minimal modifications to existing tanker aircraft 20.</p><p><span class=\"paragraph-number\">[0018]   </span>According to a further embodiment of the present invention the first and second signal sources 22, 24 are formed by the beacon/position lights normally present on any aircraft. This embodiment presents the advantage of not requiring any modification of a structural nature or any other nature to the tanker aircraft 20.</p><p><span class=\"paragraph-number\">[0019]   </span>According to a further embodiment of the present invention, the first and second signal sources 22, 24 are sources of a passive type. In this case, the signal sources 22, 24 do not issue a light radiation but, for example, reflect the light of the surrounding environment.</p><p><span class=\"paragraph-number\">[0020]   </span>The first and second signal sources 22, 24 are set on the fuselage of the tanker aircraft 20 in a lower portion of the fuselage in such a way as to be identifiable by a receiver aircraft 1 that approaches the tanker aircraft 20 from behind and at an altitude of flight lower than the altitude of flight of the tanker aircraft 20. The first and second signal sources 22, 24 are spaced apart by a distance d chosen on the basis of the type of signal sources 22, 24 used, for example, in the case of focused light signal sources of a LED type, greater than 70 cm, preferably 1 m. The tanker aircraft 20 further comprises: a transmitter device 26 of its own, configured for communicating in transmission with the transceiver device 6 of the receiver aircraft 1; a positioning device 28, for example a GPS receiver; and a microcontroller 30, connected to the transceiver device 26 and to the positioning device 28. The first and second signal sources 22, 24 can be switched on manually by an operator present on board the tanker aircraft 20 only when necessary (i.e., during the operations of in-flight refuelling).</p><p><span class=\"paragraph-number\">[0021]   </span><figref>Figure 3</figref> shows a schematic representation, by means of functional blocks, of management modules (designated as a whole by the reference number 31) of the automatic-piloting system 15 of the receiver aircraft 1 according to the present invention. The management modules 31 can be of a software type, stored within the memory 12 and executed by the microprocessor 14, or implemented in a distributed way within appropriate memories (not illustrated) of the positioning device 4, of the transceiver device 6, and of the autonomous flight device 2 (or of the integrated digital processor, if present).</p><p><span class=\"paragraph-number\">[0022]   </span>The management modules 31 comprise a block for measuring the approach in flight 32, including a sensor-management module 33, of a software type, configured for governing acquisition of images through the first and second optical devices 8, 10 and processing them (as will be explained more fully hereinafter); a mission-management block 34, including a mission-control module 35, configured for imparting flight commands and/or mission commands to the receiver aircraft 1 (for example, by governing the autonomous flight device 2 so as to execute manoeuvres necessary for reaching the area prearranged for rendez-vous and execution of in-flight refuelling), and an uplink-switch module 36, configured for temporarily inhibiting the mission-control module 35 on the receiver aircraft 1 and enabling the pilot to govern the receiver aircraft 1 manually; a flight-management block 38, including a GPS-processing module 39, configured for receiving one or more GPS-position signals coming from one or more satellites of the GPS and processing them in order to identify position co-ordinates of the receiver aircraft 1, and a flight-control module 40, configured for receiving, via the uplink-switch module 36, the flight commands (course, direction, etc.) generated by the mission-control module 35 or received by the pilot; and a communication block 41, including a transmitter/receiver module 43, configured for enabling communication in reception with the transmitter device 26 of the tanker aircraft 20 (for example, for receiving GPS position data of the tanker aircraft 20) and a control-data-link module 42, configured for enabling exchange of command and control data of the receiver aircraft 1 between the receiver aircraft 1 itself and a remote station 37 (in which the remote pilot operates).</p><p><span class=\"paragraph-number\">[0023]   </span>In use, the first and second optical devices 8, 10 operate for acquiring images of the tanker aircraft 20, in particular when the receiver aircraft 1 is in the spatial proximity of the tanker aircraft 20. The spatial proximity of the receiver aircraft 1 to the tanker aircraft 20 is detected by detection of position data (for example, azimuth, elevation, relative distance) of the receiver aircraft 1 and of the tanker aircraft 20 via the respective positioning devices 4 and 28, and by comparison of said position data detected. The comparison of said position data is effected by the receiver aircraft 1. For the purpose, the GPS-processing module 39 is connected to the mission-control module 35, which is instead connected to the transmitter/receiver module 43. The transmitter/receiver module 43 (for example, implemented in the transceiver device 6) acquires GPS position data of the tanker aircraft 20 transmitted by the transceiver device 26 and communicates them to the mission-control module 35. The latter, on the basis of the GPS position data of the receiver aircraft 1 (acquired by the GPS-processing module 39) and of the GPS position data of the tanker aircraft 20 received by the transmitter/receiver module 43, identifies the relative positions of the aircraft 1 and 20. The mission-control module 35 is connected to the sensor-management module 33 and is configured for governing, via the sensor-management module 33, acquisition of images by the first and second optical devices 8, 10. The images acquired by the first and second optical devices 8, 10 are converted into digital format and processed by the sensor-management module 33 in order to carry out an operation of recognition of the subject of said images. In particular, this operation is aimed at recognizing, during the step of approach of the receiver aircraft 1 to the tanker aircraft 20, the type of tanker aircraft 20 that is approaching, and then detecting the position of the first and second signal sources 22, 24 of the tanker aircraft 20. In this way, it is possible to detect signal sources 22, 24 both of an active type and of a passive type.</p><p><span class=\"paragraph-number\">[0024]   </span>Image recognition can be effected by means of software of a known type, by comparing the images captured with a plurality of images present in a database, for example stored in the memory 12, as described more fully in what follows.</p><p><span class=\"paragraph-number\">[0025]   </span>It is thus possible to carry out a fine approach and complete the correct positioning of the receiver aircraft 1 with respect to the tanker aircraft 20 for carrying out in-flight refuelling.</p><p><span class=\"paragraph-number\">[0026]   </span>The measurements of position via GPS, the operations of recognition of the tanker aircraft 20, and the detection of the position of the first and second signal sources 22, 24 can be executed continuously and simultaneously; i.e., they are not mutually exclusive.</p><p><span class=\"paragraph-number\">[0027]   </span><figref>Figure 4</figref> shows, by means of a block diagram, steps 45-49 of planning of the operation of approach of the receiver aircraft 1 to the tanker aircraft 20 managed by the management modules 31 of <figref>Figure 3</figref>. Transitions between steps performed autonomously by the management modules 31 are represented in <figref>Figure 4</figref> by solid-line arrows, whereas any possible manual intervention on the part of the pilot, aimed at modifying the automatic flow between the steps, are represented by dashed arrows. In the case of no intervention on the part of the pilot, the receiver aircraft 1 would be guided in a totally automatic and autonomous way by the management modules 31 up to completion of the refuelling operation.</p><p><span class=\"paragraph-number\">[0028]   </span>Activation of the steps of approach for executing the operation of in-flight refuelling can made automatically (for example, upon detection of a minimum-fuel condition) or following upon an intervention of manual activation on the part of the pilot (command IFR_Req in <figref>Figure 4</figref>).</p><p><span class=\"paragraph-number\">[0029]   </span>During the step 45, the mission-control module 35 is in an inactive autonomous refuelling step, and the management of in-flight refuelling is of a manual type, entrusted to the pilot. The step 45 is executed, for example, during take-off, when there is no need to carry out refuelling, or when, for reasons of safety, the pilot deems it necessary to govern the receiver aircraft 1 manually. Activation of step 45 is made via direct command of the pilot, who, by communicating with the management modules 31 via the transmitter/receiver module 43 governs the uplink-switch module 36 via the control-data-link module 42 in such a way as to inhibit automatic control of the flight-control module 40 by the mission-control module 35.</p><p><span class=\"paragraph-number\">[0030]   </span>In the absence of manual control by the pilot, and in the case where in-flight refuelling is necessary (detected automatically or governed by the remote operator via the command IFR_Req), control passes from step 45 to step 46, of mission planning. During this step, the mission-control module 35 controls, via the uplink-switch module 36, the flight-control module 40, for governing the course of flight of the receiver aircraft 1 towards the rendez-vous area. In particular, on the basis of the current co-ordinates of flight position (detected automatically via the instruments proper of the autonomous flight device 2), the mission-control module 35 governs the flight-control module 40 in such a way as to impart to the receiver aircraft 1 the commands necessary for carrying out deviations of course, accelerations, decelerations, or else adoption of a more tortuous path in order to make up for conditions of delay/advance with respect to a possible rendez-vous schedule envisaged.</p><p><span class=\"paragraph-number\">[0031]   </span>Then, when the receiver aircraft 1 enters the area envisaged for the rendez-vous (known on the basis of the GPS position data continuously monitored), control passes to step 47, of entry into the area. During this step, the mission-control module 35 governs the receiver aircraft 1 so that the latter will effect, if necessary, one or more turns of fixed radius (\"loitering\"), awaiting the arrival of the tanker aircraft 20 in the rendez-vous area. Upon arrival of the tanker aircraft 20 in the rendez-vous area, control passes to step 48. In the case where the tanker aircraft 20 is already in the rendez-vous area, step 47 does not produce any effect on the flight of the receiver aircraft 1, and control passes to step 48.</p><p><span class=\"paragraph-number\">[0032]   </span>During step 48, which regards the chasing manoeuvre, the mission-control module 35 governs, via the flight-control module 40, the receiver aircraft 1 so that the latter will effect the manoeuvres necessary for positioning itself on the tail of the tanker aircraft 20 (as illustrated in <figref>Figure 6</figref> and described hereinafter with reference to said figure), for preparing for in-flight refuelling. The procedures used can be advantageously developed in accordance with the NATO ATP 56 standard.</p><p><span class=\"paragraph-number\">[0033]   </span>The correct position of the receiver aircraft 1 on the tail of the tanker aircraft 20 is verified by the mission-control module 35 by means of a comparison of the position co-ordinates of the receiver aircraft 1 obtained through GPS and of the co-ordinates of the tanker aircraft 20 received by the latter through the transmitter/receiver module 43. During step 48, the mission-control module 35 imparts to the receiver aircraft 1 commands of acceleration or deceleration such as to enable a progressive reduction of the distance from the tanker aircraft 20 and possible commands of change of direction (for example turns) or of modification of the altitude of flight (for example, starting from 1000 feet - approximately 300 metres - lower than the altitude of flight of the tanker aircraft 20) for positioning in conditions of safety on the tail of the tanker aircraft 20.</p><p><span class=\"paragraph-number\">[0034]   </span>Finally (step 49), a fine positioning of the receiver aircraft 1 is effected to enable engagement with the refuelling systems (of a known type and not illustrated) provided on the tanker aircraft 20. During this step, the distance between the receiver aircraft 1 and the tanker aircraft 20 and the difference of altitude between the two are gradually reduced, until a pre-set spatial position is reached for carrying out in-flight refuelling (depending upon various parameters, amongst which the type of tanker aircraft, and the length of the pipe, rigid or flexible, used for refuelling, etc.). The control of the distance between the receiver aircraft 1 and the tanker aircraft 20 in this case is effected both by analysing the GPS position datum and by processing the images captured by means of the optical devices 8, 10 (as will be explained more fully hereinafter with reference to <figref>Figure 5</figref>).</p><p><span class=\"paragraph-number\">[0035]   </span>Each of the steps 45-49 can be interrupted by the remote operator (command EXIT from each step), to bring the mission-control module 35 back into the inactive state of automatic refuelling of step 45. Then, control can again pass to step 46, or else, via a command of the pilot, skip directly to step 47 (command AREA_ENTRY_Comm), or else to step 48 (command CHASE_Comm), or else to step 49 (command JOINING_Comm).</p><p><span class=\"paragraph-number\">[0036]   </span>The command EXIT from each step 46-49 causes an interruption of the current step and appropriate changes of direction of the receiver aircraft 1 such as to prevent a possible collision with the tanker aircraft 20 if the latter is in the spatial proximity thereof (for example, in the case of exit from step 49, the receiver aircraft 1, being particularly close to the tanker aircraft 20, is governed in diving, and its course is governed in a direction opposite to that of the tanker aircraft 20).</p><p><span class=\"paragraph-number\">[0037]   </span><figref>Figure 5</figref> shows a statechart diagram that illustrates operation of the block for measuring the approach in flight 32, in particular during steps 48 and 49 of <figref>Figure 4</figref>.</p><p><span class=\"paragraph-number\">[0038]   </span>The sensor-management module 33 is kept in a wait state 54 (not operative, in which the video cameras are not governed for image acquisition) until arrival of a corresponding activation command (for example, a few instants after take-off or when a given altitude of flight is reached, then to pass to a data-acquisition state 56, in which the first and second optical devices 8, 10 are functioning for image acquisition). The GPS-processing module 39 is, however, already operative and in use, and passes alternately from a wait state 52 (in which the GPS position data are not processed, for example because they are not received on account of adverse meteorological conditions or temporary obscuration of the GPS satellites) to a GPS processing state 53 (during which the GPS signal is received correctly). Hence, only in the case where the GPS position signal is missing or is considered not reliable, does it enter the wait state 52.</p><p><span class=\"paragraph-number\">[0039]   </span>To return to the sensor-management module 33, the latter governs the first and second optical devices 8 and 10 for image acquisition in a continuous way for identifying at any moment, but above all when the receiver aircraft 1 is in the vicinity of the tanker aircraft 20, the presence of the tanker aircraft 20. In the first place, the spatial vicinity between the receiver aircraft 1 and the tanker aircraft 20 is judged by the receiver aircraft 1 on the basis of a comparison between the GPS position data detected by the orientation device 26 of the tanker aircraft 20 (and transmitted to the receiver aircraft 1) and the GPS position data detected by the orientation device 6 and by the GPS-processing module 39 of the receiver aircraft 1.</p><p><span class=\"paragraph-number\">[0040]   </span>During the state 56, the sensor-management module 33 cooperates with the mission-control module 35 for identifying the tanker aircraft 20 from which to carry out refuelling. The position data of the receiver aircraft 1 and the position data of the tanker aircraft 20 are continuously updated and compared with one another to define a degree of confidence of the images captured by the optical devices 8, 10 and/or for carrying out a correction of the direction of flight of the receiver aircraft 1. In the proximity of the tanker aircraft 20, it is highly likely that the images captured regard the tanker aircraft 20 itself; instead, at a distance from the tanker aircraft 20, possible images captured by the optical devices 8, 10 could regard unknown aircraft or other elements.</p><p><span class=\"paragraph-number\">[0041]   </span>Once an acceptable degree of confidence has been reached (for example higher than a certain pre-set threshold), control passes from the data-acquisition state 56 to the tracking state 58. In the tracking state 58 the images acquired by the first and second optical devices 8, 10, converted into digital signals, are processed by means of image-recognition algorithms for carrying out an automatic recognition of the type of the tanker aircraft 20. The automatic recognition of the tanker aircraft 20 from which refuelling is to be carried out can occur by means of image-recognition software of a known type and for example comprises the following steps. First of all, it is possible to execute on the images captured an operation of correction of defects originated by the optical devices 8, 10 themselves and of reduction of the noise of the image. For example, a matrix of correction operators can be used, that can be adapted according to the quality of the image. These can include radiometric corrections or corrections of homogeneity, for reducing the phenomenon of distortion or of degradation of the levels of colour or of grey, or apply a filtering of a Gaussian type for reducing high-frequency noise. For known defects of a fixed type, it is likewise possible to envisage the use of a predefined correction mask. Next, the filtered images thus obtained can be processed in such a way as to extract the contours of the elements represented in said filtered images, defined by a certain number of resolution pixels, using graphic processing techniques of a known type. The contours thus obtained (defined on the basis of the number of resolution pixels) can be easily compared with contour models previously stored in an appropriate database, for example stored in the memory 12 of the receiver aircraft 1. The contour models stored can regard portions and details of the tanker aircraft 20 (used for images captured in the proximity of the tanker aircraft 20), or its overall shape (used for images of the tanker aircraft 20 captured from a distance, which hence identify the entire shape or contour of the tanker aircraft 20). As an alternative or in addition to what has been said, it is possible to equip the tanker aircraft 20 with appropriate physical recognition features, known to the receiver aircraft 1, in such a way as to limit the steps of processing of the images to identification of said recognition features.</p><p><span class=\"paragraph-number\">[0042]   </span>By way of example, provided herein is a list of the possible portions of the tanker aircraft 20 that can be used (individually or a plurality thereof) for the purposes of recognition. For example, it is possible to consider the wingspan, the dimensions of the tailplane (width and height thereof), the position of the engines with respect to each respective wing, the width of the fuselage, with special attention paid to the thickness thereof in proportion to the wingspan according to a rear view, the length of the aircraft in side view, i.e., the nose-tail length. The expected contour characteristics for said portions of the tanker aircraft 20 can be catalogued for this purpose in the preset database from a plurality of different angles and different distances.</p><p><span class=\"paragraph-number\">[0043]   </span>The comparison of each recognition contour or feature detected with the recognition contours or features stored in the database yields a result of comparison associated to a confidence value of said result. Said confidence value can, for example, be obtained using a distribution of a Gaussian type, for example a 2-sigma Gaussian distribution, known in the literature.</p><p><span class=\"paragraph-number\">[0044]   </span>It is evident that the contours stored in the database can be stored in the most appropriate way, for example in the form of matrices. Likewise, also the contours extracted from the images captured by means of the optical devices 8, 10 can be encoded in matrix form, to render the step of comparison as fast and certain as possible.</p><p><span class=\"paragraph-number\">[0045]   </span>If the steps described for the recognition yield a negative result (the expected tanker aircraft 20 has not been recognized) control returns into the data-acquisition state 56. Otherwise, a value of distance between the receiver aircraft 1 and the tanker aircraft 20 is determined on the basis of the recognition contours and/or features detected. It is in fact possible to provide an estimate of the distance between the receiver aircraft 1 and the tanker aircraft 20 on the basis of the apparent dimensions of the recognition contours and/or features detected (i.e., the dimensions of the recognition contours and/or features as detected by the optical devices 8, 10). The estimate of distance thus obtained can be compared with the distance datum obtained via GPS or else be used for compensating any possible intrinsic inexactitude in the GPS (further details as regards compensation of the errors of the GPS datum are provided hereinafter).</p><p><span class=\"paragraph-number\">[0046]   </span>On the basis of the GPS data and of the measurement of the distance from the tanker aircraft 20 effected by means of the first and second optical devices 8, 10, the receiver aircraft 1 sets itself on the tail of the tanker aircraft 20, at an altitude of flight lower than that of the tanker aircraft 20, for the refuelling operation, as illustrated in <figref>Figure 6</figref>. Since the steps of final approach are particularly delicate given the short distance between the two aircraft 1, 20 (the aim being to prevent any collision between them), the use of the GPS data and of the estimate of distance supplied by the optical devices 8, 10 as described are unable to supply to the autonomous flight device 2 a datum that is sufficiently reliable to enable approach in conditions of safety. Consequently, for distances between the receiver aircraft 1 and the tanker aircraft 20 of less than approximately 200 m, the mission-control module 35 remains in the tracking state 58, but the identification of the distance between the receiver aircraft 1 and the tanker aircraft 20 is effected by detecting preferably the signals (for example, as has been said, light signals in the visible or in the infrared, according to the optical devices 8, 10 used) emitted by the first and second signal sources 22, 24. Since the distance d between the first and second signal sources 22, 24 is known, it is possible, via triangulation, to process a given relative distance between the receiver aircraft 1 and the tanker aircraft 20 with high precision, and the autonomous flight device 2 can govern the receiver aircraft 1 in fine approach to the tanker aircraft 20 and in appropriate alignment for carrying out the operation of in-flight refuelling.</p><p><span class=\"paragraph-number\">[0047]   </span>The operation of triangulation is made possible by the knowledge of the angles comprised between the extremes of the ideal straight line that joins the first and second signal sources 22, 24 and the respective ideal straight lines that join the first and second signal sources 22, 24 to the optical devices 8, 10. These data are obtained from the values of: azimuth, elevation, and relative distance between the aircraft 8, 20 (obtained, preliminarily, from the position data detected via GPS), on the basis of the distance, which is known, between the first and second optical devices 8, 10; the position, which is known, of installation of the optical devices 8, 10; the attitude of flight of the receiver aircraft 1; the distance d between the first and second signal sources 22, 24 set on the tanker aircraft 20; and the position of the first and second signal sources 22, 24 on the image acquired by means of the first and second optical devices 8, 10 (for example, in the case where the latter are video cameras or photographic cameras). To obtain correct values it is expedient to calibrate the first and second optical devices 8, 10 on the ground, verifying the angle of aperture for capturing images of each of them using appropriate optical targets.</p><p><span class=\"paragraph-number\">[0048]   </span>Once an optimal relative position of the two aircraft 1 and 20 is reached, it is possible to proceed with the step of in-flight refuelling (the details regarding the procedures of refuelling as such are not described herein in so far as they do not form part of the present invention).</p><p><span class=\"paragraph-number\">[0049]   </span>At the end of the operations of in-flight refuelling, the receiver aircraft 1 can abandon the rendez-vous area. The tracking state 58 is then abandoned, and the mission-control module 35 returns to the wait state 54 or to the data-acquisition state 56. Exit from the tracking step can moreover be caused by a loss of the images by one or both of the optical devices 8, 10. In this case, exit from the tracking state 58 takes to the data-acquisition state 56, to return to the tracking state 58 as soon as an image that could belong to the tanker aircraft 20 is again captured (for example, when in one and the same image there are present elements with a marked contrast with respect to one another).</p><p><span class=\"paragraph-number\">[0050]   </span>To return to <figref>Figure 5</figref>, the sensor-management module 33 can pass from the wait state 54 also to an image-storage state 60. The passage from the wait state 54 to the image-storage state 60 can occur in parallel with passage from the wait state 54 to the data-acquisition state 56 and does not interfere therewith. During the image-storage state 60, the sensor-management module 33 stores (for example, in the memory 12) images acquired during permanence in the data-acquisition state 56.</p><p><span class=\"paragraph-number\">[0051]   </span>In the case of detection of malfunctioning in any the management modules 31, both from the tracking state 58 and from the data-storage state 60 control passes to the hardware-failure state 62. If the hardware-failure state 62 persists, automatic in-flight refuelling is interrupted and the pilot can continue refuelling manually or else interrupt the process.</p><p><span class=\"paragraph-number\">[0052]   </span>Finally, it should be considered that the states 54, 56, 58 can be activated irrespective of the wait state 52 and the GPS processing state 53 (the latter are always active in alternation according to the condition of reception of the GPS signal).</p><p><span class=\"paragraph-number\">[0053]   </span>To guarantee an estimate of the distances between the receiver aircraft 1 and the tanker aircraft 20 as correct as possible, the distance datum detected via GPS is continuously integrated and compared with the distance datum calculated on the basis of the images acquired via the optical devices 8, 10.</p><p><span class=\"paragraph-number\">[0054]   </span>In practice, the processing rate of the video signal is much higher than the processing rate of the GPS signal used by common GPS reception systems (a ratio for example of approximately 30:1). There is consequently the need to guarantee at each instant a predictive value of the position of the tanker aircraft 20 such as to cover the periods of time during which the datum deriving from the optical devices 8, 10 is available, but the GPS datum is not. Similar considerations apply also in those conditions in which the GPS signal is degraded or absent.</p><p><span class=\"paragraph-number\">[0055]   </span>For this purpose, assigned to each position value (in particular, of distance between the receiver aircraft 1 and the tanker aircraft 20) detected via the GPS-processing module 39, is a reliability factor C<sub>GPS</sub> of the GPS datum. As is known, a reliability factor regards the accuracy of a measurement, and indicates the error or lack of reliability, or uncertainty of said measurement with respect to the so-called \"true value\" or \"true score\". By way of example, a generic measured value M<sub>0</sub> is given by M<sub>0</sub> = M<sub>T</sub> ± e, where M<sub>T</sub> is the true value and e is the error.</p><p><span class=\"paragraph-number\">[0056]   </span>The reliability factor C<sub>GPS</sub> of the GPS datum is based upon a plurality of parameters, namely: a precision parameter C<sub>P</sub>, based upon the parameter known as DOP (\"Dilution Of Precision\"), for example the HDOP (\"Horizontal Dilution Of Precision\"), provided by GPS reception apparatuses of a known type and representing an estimate of the precision of the GPS position datum; an uncertainty parameter C<sub>ERR</sub>, representing the uncertainty on the GPS position datum; a parameter C<sub>SAT</sub>, depending upon the number of satellites used for calculation of the GPS position datum; a delay parameter C<sub>D</sub>, depending upon the delay with which the GPS position datum is updated; and a parameter of distance from the tanker aircraft 20 as detected through the processing of the images captured by the optical devices 8, 10.</p><p><span class=\"paragraph-number\">[0057]   </span>In greater detail, the precision parameter C<sub>P</sub> is obtained by means of the following formula (1): </p><p><maths num=\"(1)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 121mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0001.tif&width=121mm&height=5mm\"/></maths></p><p> where HDOP is the parameter of \"Horizontal Dilution of Precision\", and is not valid for values smaller than or equal to zero (it would not be a reasonable value) or else higher than or equal to 6 (value considered extremely poor in qualitative terms). In both cases of invalidity, the GPS datum is rejected and not considered for subsequent processing. Values considered good for the precision parameter C<sub>P</sub> are comprised between 1 and 2.</p><p><span class=\"paragraph-number\">[0058]   </span>The uncertainty parameter C<sub>ERR</sub> is given by the following formula (2): </p><p><maths num=\"(2)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 121mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0002.tif&width=121mm&height=6mm\"/></maths></p><p> where the term err designates the prediction error (in metres) on the GPS position datum, • is a time constant, having a value for example of 0.21, and max_e is the maximum admitted prediction error, for example fixed at 15 m. On the basis of the formula (2), the plot of the uncertainty parameter C<sub>ERR</sub> as a function of the term err (prediction error) is illustrated in <figref>Figure 7</figref>.</p><p><span class=\"paragraph-number\">[0059]   </span>The parameter C<sub>SAT</sub> assumes a value comprised between 0 (very low value) and 5 (optimal value in so far as it is detected on the basis of a large number of GPS satellites). The ensuing Table 1 illustrates a possible choice of the value to be assigned to the parameter C<sub>SAT</sub> on the basis of the number of satellites available:</p><p><tables num=\"0001\"><table frame=\"all\"><title>Table 1</title><tgroup cols=\"4\"><colspec colname=\"col1\" colnum=\"1\" colwidth=\"33mm\"/><colspec colname=\"col2\" colnum=\"2\" colwidth=\"10mm\"/><colspec colname=\"col3\" colnum=\"3\" colwidth=\"10mm\"/><colspec colname=\"col4\" colnum=\"4\" colwidth=\"10mm\"/><thead><row><entry align=\"center\" valign=\"middle\">Number of Satellites</entry><entry align=\"center\" valign=\"middle\">≤ 2</entry><entry align=\"center\" valign=\"middle\">3</entry><entry align=\"center\" valign=\"middle\">≥ 4</entry></row></thead><tbody><row><entry align=\"center\" valign=\"middle\">C<sub>SAT</sub></entry><entry align=\"center\" valign=\"middle\">0</entry><entry align=\"center\" valign=\"middle\">2</entry><entry align=\"center\" valign=\"middle\">5</entry></row></tbody></tgroup></table></tables></p><p><span class=\"paragraph-number\">[0060]   </span>The delay parameter C<sub>D</sub> is given by the following formula (3): </p><p><maths num=\"(3)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 121mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0003.tif&width=121mm&height=6mm\"/></maths></p><p> where: t<sub>D</sub> identifies the delay with which the GPS position datum is updated; • is a time constant, having a value for example of 0.8; and n is the maximum admitted delay time, having a value for example of 4 s.</p><p><span class=\"paragraph-number\">[0061]   </span>Considering that the GPS datum is updated with a frequency of approximately 1 Hz, it is deemed expedient to consider a GPS datum as invalid after three absent GPS position values (lack of GPS signal) or for three consecutive values of the parameter C<sub>SAT</sub> equal to zero.</p><p><span class=\"paragraph-number\">[0062]   </span>The plot of the delay parameter C<sub>D</sub> as a function of the time t<sub>D</sub> is illustrated in <figref>Figure 8</figref>.</p><p><span class=\"paragraph-number\">[0063]   </span>Using the formulae (1)-(3), a precision parameter C<sub>P</sub>_<sub>T</sub>, an uncertainty parameter C<sub>ERR_T</sub>, a parameter C<sub>SAT</sub>_<sub>T</sub>, and a delay parameter C<sub>D</sub>_<sub>T</sub> are calculated for the tanker aircraft 20. Likewise calculated for the receiver aircraft 1 are a precision parameter C<sub>P</sub>_<sub>R</sub>, an uncertainty parameter C<sub>ERR</sub>_<sub>R</sub>, a parameter C<sub>SAT</sub>_<sub>R</sub>, and a delay parameter C<sub>D</sub>_<sub>R</sub>. On the basis of the parameters thus calculated, there are calculated, by the receiver aircraft 1, reliability factors C<sub>GPS</sub>_<sub>T</sub> and C<sub>GPS</sub>_<sub>R</sub> of the GPS datum, which regard the GPS position datum of the tanker aircraft 20 and the GPS position datum of the receiver aircraft 1, respectively.</p><p><span class=\"paragraph-number\">[0064]   </span>The reliability factor C<sub>GPS</sub>_<sub>T</sub> for the tanker aircraft 20 is given by the following formula (4): </p><p><maths num=\"(4)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0004.tif&width=133mm&height=7mm\"/></maths></p><p> whilst the reliability factor C<sub>GPS</sub>_<sub>R</sub> for the receiver aircraft 1 is given by the following formula (5): </p><p><maths num=\"(5)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0005.tif&width=133mm&height=7mm\"/></maths></p><p><span class=\"paragraph-number\">[0065]   </span>The reliability factor C<sub>GPS</sub> is finally given by the following formula (6): </p><p><maths num=\"(6)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 7mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0006.tif&width=133mm&height=7mm\"/></maths></p><p><span class=\"paragraph-number\">[0066]   </span>Since, as is known, the GPS position datum has an intrinsic error of the order of metres, it is not advisable to give priority to the measurement of the distance between the receiver aircraft 1 and the tanker aircraft 20 supplied by the GPS over the one obtained by means of the first and second optical devices 8, 10 (which is, in particular, supplied by the operation of triangulation in the steps of fine approach between the aircraft 1 and 20, for example for distances between them of less than 200 m).</p><p><span class=\"paragraph-number\">[0067]   </span>However, also the measurement of distance between the receiver aircraft 1 and the tanker aircraft 20 obtained by processing the images captured by means of the optical devices 8, 10 may not be sufficiently precise above all if obtained starting from a triangulation effected at a great distance between the receiver aircraft 1 and the tanker aircraft 20 (for example, consistently with what has been previously described, greater than 200 m).</p><p><span class=\"paragraph-number\">[0068]   </span>It is hence expedient to define a reliability factor C<sub>OPT</sub> for the measurement of optical distance made via the first and second optical devices 8, 10.</p><p><span class=\"paragraph-number\">[0069]   </span>The reliability factor C<sub>OPT</sub> is calculated on the basis of a plurality of parameters, namely: a parameter C<sub>acc</sub> of accuracy of the distance between the receiver aircraft 1 and the tanker aircraft 20 (as detected through processing of the captured images); a value C<sub>U</sub> of uncertainty on the measurement (as detected through processing of the captured images); a parameter of reliability of the optical measurement C<sub>COAST</sub>; and the state of processing of the captured images.</p><p><span class=\"paragraph-number\">[0070]   </span>In detail, the accuracy parameter C<sub>acc</sub> is given by the following formula (7): </p><p><maths num=\"(7)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 10mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0007.tif&width=133mm&height=10mm\"/></maths></p><p> where: </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 30mm; height: 9mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0008.tif&width=30mm&height=9mm\"/></maths></p><p> and </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 31mm; height: 10mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0009.tif&width=31mm&height=10mm\"/></maths></p><p> wherein r is the distance between the receiver aircraft 1 and the tanker aircraft 20 (as detected through the processing of the captured images); • is the uncertainty (root mean square - RMS) associated to the position of the tanker aircraft 20; D is a constant having a value for example of 4.5; K<sub>C</sub> is a constant having a value for example of 0.00015; and K<sub>S</sub> is a constant having a value, for example, of 0.0001.<br/><figref>Figure 9</figref> shows the plot of the accuracy parameter C<sub>acc</sub> as a function of the distance r.<br/>On the basis of the accuracy parameter C<sub>acc</sub>, the uncertainty value C<sub>U</sub> is given by the following formula (8): </p><p><maths num=\"(8)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0010.tif&width=133mm&height=5mm\"/></maths></p><p> where x is an empirical coefficient having the function of refining the tolerance with the errors of measurement themselves and has a value, for example, of 1.</p><p><span class=\"paragraph-number\">[0071]   </span><figref>Figure 10</figref> shows the plot of the uncertainty parameter C<sub>U</sub> as a function of the distance r, with • = 0.5 and x = 1.</p><p><span class=\"paragraph-number\">[0072]   </span>The reliability parameter of the optical measurement C<sub>COAST</sub> is given by the following formula (9): </p><p><maths num=\"(9)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 133mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0011.tif&width=133mm&height=6mm\"/></maths></p><p> where: T<sub>COAZT</sub> is the age of the optical datum acquired and has a value comprised between 0 and 2, for example 0.5; • is a time constant, having a value for example of 3; and z is the maximum admitted value of T<sub>COAZT</sub>, for example 2.</p><p><span class=\"paragraph-number\">[0073]   </span><figref>Figure 11</figref> shows the plot of the parameter of C<sub>COAZT</sub> as a function of the value of T<sub>COAZT</sub> , with • = 3 and z = 2.</p><p><span class=\"paragraph-number\">[0074]   </span>The recognition of the tanker aircraft 20 by the receiver aircraft 1 and the operation of triangulation carried out on the basis of the signals emitted by the first and second signal sources 22, 24 are performed on the basis of monoscopic visions (right-hand mono-vision for the images captured by the first optical device 8, and left-hand mono-vision for the images captured by the second optical device 10) and on the basis of a stereoscopic vision (using jointly the images captured by both of the optical devices 8, 10) . Associated to the position of the tanker aircraft 20, calculated on the basis of the right-hand mono-vision, the left-hand mono-vision, and the stereoscopic vision, is a respective confidence factor C<sub>IPR</sub>, C<sub>IPL</sub>, C<sub>IPS</sub>, each having a value of its own comprised between 0 (minimum confidence) and 1 (maximum confidence).</p><p><span class=\"paragraph-number\">[0075]   </span>Finally, it is possible to define a global confidence factor C<sub>RIGHT</sub>, C<sub>LEFT</sub>, C<sub>ZTEREO</sub> respectively for the optical measurements of right-hand mono-vision (measurements of distance dist_R between the receiver aircraft 1 and the tanker aircraft 20 made by triangulation on the basis of just the data acquired by means of the first optical device 8), left-hand mono-vision (measurements of distance dist_L between the receiver aircraft 1 and the tanker aircraft 20 made by triangulation on the basis of just the data acquired by means of the second optical device 10), stereoscopy (measurements of distance dist_S between the receiver aircraft 1 and the tanker aircraft 20 made by triangulation on the basis of the data acquired by both the first and the second optical devices 8, 10 operating in stereoscopy) according to the formulae (10)-(12) appearing below.</p><p><span class=\"paragraph-number\">[0076]   </span>The global confidence factor obtained via just the right-hand mono-vision is given by: </p><p><maths num=\"(10)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 136mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0012.tif&width=136mm&height=6mm\"/></maths></p><p> where C<sub>U</sub>_<sub>RIGHT</sub> is the uncertainty value for the optical measurement of right-hand mono-vision calculated according to formula (8), and C<sub>COAST</sub>_<sub>RIGHT</sub> is the reliability parameter of the optical measurement for the optical measurement of right-hand mono-vision calculated according to formula (9).</p><p><span class=\"paragraph-number\">[0077]   </span>The global confidence factor obtained via just the left-hand mono-vision is given by: </p><p><maths num=\"(11)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 136mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0013.tif&width=136mm&height=6mm\"/></maths></p><p> where C<sub>U</sub>_<sub>LEFT</sub> is the uncertainty value for the optical measurement of left-hand mono-vision calculated according to formula (8), and C<sub>COAST</sub>_<sub>LEFT</sub> is the reliability parameter of the optical measurement regarding the optical measurement of left-hand mono-vision calculated according to formula (9).</p><p><span class=\"paragraph-number\">[0078]   </span>The global confidence factor obtained via stereoscopy is given by: </p><p><maths num=\"(12)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 136mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0014.tif&width=136mm&height=6mm\"/></maths></p><p> where C<sub>U</sub>_<sub>STEREO</sub> is the uncertainty value for the optical measurement in stereoscopy calculated according to formula (8), and C<sub>COAST</sub>_<sub>STEREO</sub> is the reliability parameter of the optical measurement for the optical measurement in stereoscopy calculated according to formula (9).</p><p><span class=\"paragraph-number\">[0079]   </span>The reliability factor C<sub>OPT</sub> is given by the highest between C<sub>RIGHT</sub>, C<sub>LEFT</sub> and C<sub>STEREO</sub>, according to the following formula (13): </p><p><maths num=\"(13)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 123mm; height: 5mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0015.tif&width=123mm&height=5mm\"/></maths></p><p><span class=\"paragraph-number\">[0080]   </span>Since for close-up measurements the GPS position datum yields a reliability lower than the position datum obtained via triangulation, it follows that it is expedient to introduce a threshold below which the value of distance between the receiver aircraft 1 and the tanker aircraft 20 obtained on the basis of the data acquired via GPS is considered unreliable. In particular, the distance data obtained on the basis of the data acquired via GPS can be rejected if: the presumed distance between the receiver aircraft 1 and the tanker aircraft 20 (detected, for example, via GPS and/or via processing of the images captured through the first and second optical devices 8, 10) is less than 200 m; the deviation detected between the measurement of distance obtained via GPS and by processing the images captured by means of the optical devices 8, 10 is greater than 3 m; the reliability factor C<sub>GPS</sub> is greater than zero; and the reliability factor C<sub>OPT</sub> of the measurement of distance obtained by processing the images captured by means of the optical devices 8, 10 is greater than 0.7.</p><p><span class=\"paragraph-number\">[0081]   </span>When the conditions referred to above arise, the weight of the confidence value of the reliability factor C<sub>GPS</sub> is limited according to the following formula (14) to obtain a limited reliability factor C<sub>GPS</sub>' : </p><p><maths num=\"(14)\"><img loading=\"lazy\" decoding=\"async\" style=\"width: 148mm; height: 6mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0016.tif&width=148mm&height=6mm\"/></maths></p><p> with </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 33mm; height: 10mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2338793&ekey=990&cc=EP&producerName=imgb0017.tif&width=33mm&height=10mm\"/></maths></p><p><span class=\"paragraph-number\">[0082]   </span>Hence, as represented schematically in <figref>Figure 12</figref>, the reliability factor C<sub>GPS</sub> (or the limited reliability factor C<sub>GPS</sub>') of the GPS datum, the global confidence factor C<sub>STEREO</sub> for the optical measurements of stereoscopy, the global confidence factor C<sub>LEFT</sub> for the optical measurements of left-hand mono-vision, and the global confidence factor C<sub>RIGHT</sub> for the optical measurements of right-hand mono-vision are supplied at input to a weighting block 80 so as to be used as weights for defining a degree of reliability (likelihood of the information obtained being free from error) of the information of distance between the aircraft 1 and the aircraft 20 that is associated to said factors.</p><p><span class=\"paragraph-number\">[0083]   </span>The weighting operation can, for example, comprise the step of supplying the global confidence factors C<sub>LEFT</sub> and C<sub>RIGHT</sub> in terms of percentage values indicating the probability that the measurement to which they refer is the \"true\" measurement understood as measurement free from error. A percentage value equal to 100% (which in practice cannot be achieved) indicates an error-free measurement, whereas a percentage value close to 0% indicates a measurement highly affected by error and probably unusable.</p><p><span class=\"paragraph-number\">[0084]   </span>Each distance information associated to a respective global confidence factor forms weighted distance information. Said association is aimed at supplying a preferential indication of use of one position information with respect to another, and/or to establish a preferential importance for one or more position-information data with respect to others.</p><p><span class=\"paragraph-number\">[0085]   </span>The weighted distance data obtained are then supplied at input to a filtering block 81, configured for calculating a conditional expected value of the relative position of the receiver aircraft 1 with respect to the tanker aircraft 20, conditioned with respect to the distance data between the aircraft 1 and the aircraft 20, which are preferably weighted (said distance data are obtained, as has been said, by processing the images captured by means of the optical devices 8, 10, to obtain the optical measurements of right-hand and left-hand mono-vision).</p><p><span class=\"paragraph-number\">[0086]   </span>As is known from the fundamentals of probability and statistics, the expected value of a variable measured is based upon the measurement of probability P for that experiment.</p><p><span class=\"paragraph-number\">[0087]   </span>This measurement of probability is of a conditional type when it is conditioned on an event B for that experiment (with P(B) &gt; 0). The notation normally used to indicate the conditional expected value is E(P | B).</p><p><span class=\"paragraph-number\">[0088]   </span>The operations described for the filtering block 81 can be executed in a known way by means of an operation of Kalman filtering. The operation of Kalman filtering yields at output a highly reliable value of distance between the receiver aircraft 1 and the tanker aircraft 20. On the basis of the value of distance thus obtained, the receiver aircraft 1 varies its own co-ordinates of flight and/or flight parameters (for example, the speed, the altitude, the attitude), for approaching the tanker aircraft 20 in conditions of safety and with high precision in an autonomous way (without, that is, the need for an intervention on the part of an operator) and keeping from the tanker aircraft 20 a useful and stable distance for the purposes of execution of an in-flight refuelling procedure.</p><p><span class=\"paragraph-number\">[0089]   </span>From an examination of the characteristics of the invention obtained according to the present disclosure the advantages that it affords are evident.</p><p><span class=\"paragraph-number\">[0090]   </span>In particular, the invention according to the present disclosure makes it possible to approach a generic target with high precision (at least at a centimetre level) using commercial hardware resources, hence limiting considerably the production costs.</p><p><span class=\"paragraph-number\">[0091]   </span>Furthermore, since the procedure of approach between the aircraft is completely automatic, the workload of the pilot is considerably reduced. The present invention enables in fact management of all the steps of automatic in-flight refuelling, from the step of planning of the refuelling operation up to the final steps of chasing and fine positioning.</p><p><span class=\"paragraph-number\">[0092]   </span>Finally, the tanker aircraft does not require any modification except for the possible installation of the first and second signal sources 22, 24 and of a GPS radio modem.</p><p><span class=\"paragraph-number\">[0093]   </span>Finally, it is clear that modifications and variations may be made to the invention described and illustrated herein, without thereby departing from the sphere of protection of the present invention, as defined in the annexed claims.</p><p><span class=\"paragraph-number\">[0094]   </span>For example, it is possible to use the system and the method described to keep a flight formation of unmanned aerial vehicles automatically cohesive, or for operations known as \"sense and avoid\" for unmanned aerial vehicles, enabling the aircraft in question to detect automatically (by means of the first and second optical devices 8, 10 and by processing the captured images as described) possible obstacles or non-cooperative aircraft present on its own course and then make appropriate changes of direction (for example turns) in order to prevent a collision.</p><p><span class=\"paragraph-number\">[0095]   </span>In addition, the first and second signal sources 22, 24 may not be of a light type, but for example, be heat sources or sources of any other nature provided that they can be detected via the optical devices 8, 10 used. There may moreover be present more than two signal sources, for example a plurality of signal sources set in line with one another, or with positions staggered with respect to one another, or on a curved line.</p><p><span class=\"paragraph-number\">[0096]   </span>Furthermore, the optical devices can be present in a number other than two (for example, in a way not illustrated, there may be present just one optical device or else three or more optical devices). The optical devices can finally be set in a portion of the receiver aircraft 1 other than the wings, for example on the tail, on the bow or, in general, on the fuselage.</p><p><span class=\"paragraph-number\">[0097]   </span>In addition, the filtering block 81 can be configured for executing an operation of weighted average, using as weights the reliability factor C<sub>GPS</sub> (or the limited reliability factor C<sub>GPS</sub>') of the GPS datum, the global confidence factor C<sub>STEREO</sub> for the optical measurements of stereoscopy, the global confidence factor C<sub>LEFT</sub> for the optical measurements of left-hand mono-vision, and the global confidence factor C<sub>RIGHT</sub> for the optical measurements of right-hand mono-vision.</p><p><span class=\"paragraph-number\">[0098]   </span>Finally, the operation of triangulation can be performed by means of time-of-flight optical devices (for example, time-of-flight laser devices, of a known type) or by means of optical triangulation devices (for example, optical triangulation laser devices, which are also of a known type), which are able to offer high levels of measurement precision.</p>",
            "CLMS": "(EP2338793)<br/><p>1. An automatic-piloting system (15) configured for being arranged on a receiver aircraft (1) for controlling an in-flight refuelling operation of the receiver aircraft (1), comprising first passive optical device (8), for being arranged on the receiver aircraft (1) and configured for acquiring first geometrical information associated to a first detection area (22) and a second detection area (24) belonging to a tanker aircraft (20), said first and second detection areas being related one to another by a geometrical relation known to the automatic-piloting system (15),<br/><b>characterized by</b> further comprising:<br/> - processing means (14), configured for determining, on the basis of the first geometrical information acquired, first position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) by executing a first operation of triangulation on the basis of the first geometrical information acquired; and<br/> - an automatic-pilot device (2) coupled to said processing means (14) and configured for varying, on the basis of the first position information, flight parameters of the receiver aircraft (1), including governing the receiver aircraft in approach to, and in alignment with, the tanker aircraft for carrying out said operation of in-flight refuelling.</p><p>2. The system according to Claim 1, wherein said first passive optical device (8) and said processing means (14) are further configured for co-operating so as to acquire images of the tanker aircraft (20) and to execute an operation of automatic recognition of said first and second detection areas (22, 24).</p><p>3. The system according to Claim 2, wherein said processing means (14) are further configured for executing an operation of automatic recognition of the tanker aircraft (20) and/or of portions of the tanker aircraft (20).</p><p>4. The system according to any one of the preceding claims, further comprising a positioning device (4), configured for supplying position co-ordinates of the receiver aircraft (1) and a transceiver device (6) configured for receiving position co-ordinates of the tanker aircraft (20), and wherein the processing means (14) are moreover configured for calculating second position information of the receiver aircraft (1) with respect to the tanker aircraft (2) on the basis of said flight parameters of the receiver aircraft and of the tanker aircraft, said automatic-pilot device (2) being configured for varying the flight parameters of the receiver aircraft (1) on the basis of said first and second position information.</p><p>5. The system according to Claim 4, wherein the processing means (14) are moreover configured for:<br/> - associating a first reliability factor (C<sub>RIGHT</sub> C<sub>LEFT</sub>), indicating the accuracy of the first position information, to the first position information, obtaining first weighted position information;<br/> - associating a second reliability factor (C<sub>GPS</sub>) , indicating the accuracy of the second position information, to the second position information, obtaining second weighted position information;<br/> - executing an operation of Kalman filtering of said first and second position information to calculate a conditional expected value of the relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) conditioned with respect to the first and second weighted position information, obtaining first filtered position information,<br/>said automatic-pilot device (2) being configured for varying the flight parameters of the receiver aircraft (1) on the basis of said first filtered position information.</p><p>6. The system according to any one of the preceding claims, further comprising a second passive optical device (10) arranged on the receiver aircraft (1) and configured for acquiring second geometrical information associated to the first and second detection areas (22, 24), said processing means (14) being further configured for:<br/> - determining, on the basis of the first and second geometrical information acquired by means of the second passive optical device, third position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20),<br/>said automatic-pilot device (2) being configured for varying flight parameters of the receiver aircraft (1) on the basis of the third position information.</p><p>7. The system according to Claim 6, wherein said processing means (14) are further configured for executing a second operation of triangulation on the basis of the second geometrical information.</p><p>8. The system according to Claim 6 or Claim 7, wherein the first and second passive optical device (8, 10) are configured for operating in stereoscopy.</p><p>9. An automatic-piloting method for controlling in-flight refuelling operations of a receiver aircraft (1), comprising the step of detecting, via a first passive optical device (8) arranged on the receiver aircraft (1), first geometrical information associated to first and second detection areas (22, 24) belonging to a tanker aircraft (20), said first and second detection areas being related one to another by a geometrical relation known to the automatic-piloting system (15),<br/><b>characterized by</b> further comprising the steps of:<br/> - determining, on the basis of the first geometrical information detected, first position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20), comprising executing, by the receiver aircraft (1), a first operation of triangulation on the basis of the first geometrical information acquired; and<br/> - varying, on the basis of the first position information, flight parameters of the receiver aircraft (1) including governing the receiver aircraft in approach to, and in alignment with, the tanker aircraft for carrying out said operation of in-flight refuelling.</p><p>10. The method according to Claim 9, wherein the step of detecting first geometrical information comprises acquiring in a passive way one or more optical signals identifying said first detection area (22) and/or said second detection area (24).</p><p>11. The method according to Claim 10, further comprising the steps of:<br/> - acquiring one or more images of the tanker aircraft (20) and/or of portions of the tanker aircraft (20); and<br/> - executing an operation of automatic recognition of the tanker aircraft (20) and/or of portions of the tanker aircraft (20) on the basis of said acquired images.</p><p>12. The method according to any one of Claims 9-11, further comprising the steps of:<br/> - acquiring, by the receiver aircraft (1), its own position co-ordinates;<br/> - receiving, by the receiver aircraft (1), position co-ordinates of the tanker aircraft (20);<br/> - determining, on the basis of said position co-ordinates of the first and tanker aircraft (1, 20), second position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20),<br/>said step of varying flight parameters of the receiver aircraft (1) on the basis of the first position information comprising varying the flight parameters of the receiver aircraft (1) on the basis of said first and second position information.</p><p>13. The method according to Claim 12, further comprising the steps of:<br/> - associating a first reliability factor (C<sub>RIGHT</sub>; C<sub>LEFT</sub>), indicating the accuracy of the first position information, to the first position information, obtaining first weighted position information;<br/> - associating a second reliability factor (C<sub>GPS</sub>), indicating the accuracy of the second position information, to the second position information, obtaining second weighted position information;<br/> - executing an operation of Kalman filtering of said first and second weighted position information so as to calculate a conditional expected value of the relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) conditioned with respect to the first weighted position information and to the second weighted position information to obtain first filtered position information; and<br/> - varying the flight parameters of the receiver aircraft (1) on the basis of said first filtered position information.</p><p>14. The method according to any one of Claim 9-13, further comprising the steps of:<br/> - detecting, by a second passive optical device (10), arranged on the receiver aircraft (1), second geometrical information associated to the first and second detection areas (22, 24);<br/> - determining, on the basis of the second geometrical information, third position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20); and<br/> - said step of varying flight parameters of the receiver aircraft (1) further comprising varying flight parameters of the receiver aircraft (1) on the basis of the third position information.</p><p>15. The method according to Claim 14 when depending on Claim 13, further comprising the steps of:<br/> - associating a third reliability factor (C<sub>LEFT</sub>; C<sub>RIGHT</sub>), indicating the accuracy of the third position information, to the third position information to obtain third weighted position information,<br/>wherein the step of filtering further comprises executing an operation of Kalman filtering of said first, second and third weighted position information thus calculating a conditional expected value of the relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) conditioned with respect to the first, second, and third weighted position information, obtaining second filtered position information,<br/>said step of varying flight parameters of the receiver aircraft (1) comprising varying the flight parameters of the receiver aircraft (1) on the basis of said second filtered position information.</p><p>16. The method according to Claim 14 or Claim 15, wherein the step of detecting second geometrical information comprises acquiring in a passive way one or more optical signals identifying said first and/or second detection areas (22, 24).</p><p>17. The method according to any one of Claims 14-16, wherein said step of determining comprises executing, by the receiver aircraft (1), a second operation of triangulation on the basis of the first and second geometrical information acquired via the second passive optical device.</p><p>18. The method according to any one of Claims 14-17, wherein the step of acquiring second geometrical information associated to the first and second detection areas (22, 24) comprises detecting signals of a visible and infrared type.</p><p>19. The method according to any one of Claims 14-18, further comprising the steps of acquiring the first and second geometrical information in stereoscopy.</p><p>20. The method according to Claim 19, further comprising the steps of:<br/> - determining, on the basis of the first and second geometrical information acquired in stereoscopy, fourth position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) ;<br/> - associating a fourth reliability factor (C<sub>STEREO</sub>), indicating the accuracy of the fourth position information, to the fourth position information to obtain fourth weighted position information;<br/> - executing an operation of Kalman filtering of said first, second, third and fourth weighted position information to calculate a conditional expected value of the relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) conditioned with respect to the first, second, third, and fourth weighted position information, obtaining third filtered position information; and<br/> - varying the flight parameters of the receiver aircraft (1) on the basis of said third filtered position information.</p><p>21. The method according to Claim 20, wherein said determination step comprises executing a third operation of triangulation on the basis of the first and second geometrical information acquired in stereoscopy.</p><p>22. The method according to any one of Claims 9-21, further comprising, prior to the step of detecting first geometrical information, the steps of:<br/> - governing the flight path of the receiver aircraft (1) towards an area of encounter between the receiver aircraft (1) and the tanker aircraft (20);<br/> - in the case where the tanker aircraft (20) is not present in the area of encounter, automatically governing the flight of the receiver aircraft (1) so that the receiver aircraft awaits for arrival of the tanker aircraft (20) within the area of encounter or in the proximity thereof; and<br/> - in the presence of the tanker aircraft in the area of encounter, automatically governing the flight of the receiver aircraft (1) so that the receiver aircraft arranges itself on the tail of the tanker aircraft (20).</p><p>23. The method according to Claim 22, further comprising the step of exchanging position data between the receiver aircraft (1) and the tanker aircraft (20) for verifying the simultaneous presence of the first and tanker aircraft (1, 20) within the area of encounter.</p><p>24. The method according to Claim 22 or Claim 23, wherein the step of automatically governing the flight of the receiver aircraft (1) so that the receiver aircraft will set itself on the tail of the tanker aircraft (20) comprises:<br/> - governing the flight of the receiver aircraft (1) on the tail of the tanker aircraft (20) at an altitude lower than the altitude of flight of the tanker aircraft (20); and<br/> - increasing progressively the altitude of flight of the receiver aircraft (1) keeping it on the tail of the tanker aircraft (20).</p><p>25. An aircraft (1), comprising an automatic-piloting system (15) according to any one of Claims 1-8.</p>",
            "NPR": "1",
            "APID": "21975656",
            "RELEVANCE_SCORE": "100.0",
            "IC": "B64D-039/00<br/>G01C-023/00<br/>G06F-007/00",
            "ID": "15017914",
            "AB": "(EP2338793)<br/>An automatic-piloting system (15) configured for being set on a receiver aircraft (1) and for controlling operations of in-flight refuelling of said receiver aircraft (1), comprising: first detection means (8), set on the receiver aircraft (1) and configured for acquiring first geometrical information associated to a first detection area (22) and a second detection area (24) belonging to a tanker aircraft (20), the first and second detection areas being linked together by a geometrical relation known to the automatic-piloting system (15); processing means (14), configured for determining, on the basis of the first geometrical information acquired, first position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20); and an automatic-pilot device (2) coupled to the processing means (14) and configured for varying flight parameters of the receiver aircraft (1) on the basis of the first position information.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=FaccLQI1IXWeccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2009-12-16",
            "PA": "LEONARDO<br/>ALENIA AERMACCHI",
            "PAAD": "(EP2338793)<br/>(PUB:EP-2338793B8-20170111-0)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 , CITY=00195 Roma , COUNTRY=IT , REG=101613399<br/><br/>(PUB:EP-2338793B1-0)NAME=LEONARDO S.P.A. Piazza Monte Grappa, 4 , CITY=00195 Roma , COUNTRY=IT , REG=101613399<br/><br/>(PUB:EP-2338793A1-0)NAME=Alenia Aeronautica S.P.A. Viale dell'Aeronautica snc , CITY=80038 Pomigliano D'arco (Napoli) , COUNTRY=IT , REG=101112344<br/><br/><br/>(US8712608)<br/>(PUB:US-8712608B2-0)NAME=Alenia Aeronautics S.p.A.  , CITY=Pomigliano d'Arco , COUNTRY=IT , ATYP=Non-US Company<br/><br/><br/>(ES2601082)<br/>(PUB:ES-2601082T3-0)NAME=LEONARDO SPA  , COUNTRY=IT<br/><br/><br/>(IT1397664)<br/>(PUB:IT-1397664B1-0)NAME=ALENIA AERONAUTICA S.P.A. VIALE DELL'AERONAUTICA, S.N.C. Pomigliano d'Arco Napoli<br/>",
            "FAN": "15017914",
            "TI": "System and method of automatic piloting for in-flight refuelling of aircraft, and aircraft comprising said system",
            "TECD": "Computer technology<br/>Measurement<br/>Transport",
            "EPD": "2011-06-17",
            "ICLM": "(EP2338793)<br/><p>1. An automatic-piloting system (15) configured for being arranged on a receiver aircraft (1) for controlling an in-flight refuelling operation of the receiver aircraft (1), comprising first passive optical device (8), for being arranged on the receiver aircraft (1) and configured for acquiring first geometrical information associated to a first detection area (22) and a second detection area (24) belonging to a tanker aircraft (20), said first and second detection areas being related one to another by a geometrical relation known to the automatic-piloting system (15), characterized by further comprising: - processing means (14), configured for determining, on the basis of the first geometrical information acquired, first position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20) by executing a first operation of triangulation on the basis of the first geometrical information acquired; and - an automatic-pilot device (2) coupled to said processing means (14) and configured for varying, on the basis of the first position information, flight parameters of the receiver aircraft (1), including governing the receiver aircraft in approach to, and in alignment with, the tanker aircraft for carrying out said operation of in-flight refuelling.</p><p>9. An automatic-piloting method for controlling in-flight refuelling operations of a receiver aircraft (1), comprising the step of detecting, via a first passive optical device (8) arranged on the receiver aircraft (1), first geometrical information associated to first and second detection areas (22, 24) belonging to a tanker aircraft (20), said first and second detection areas being related one to another by a geometrical relation known to the automatic-piloting system (15), characterized by further comprising the steps of: - determining, on the basis of the first geometrical information detected, first position information associated to a relative position of the receiver aircraft (1) with respect to the tanker aircraft (20), comprising executing, by the receiver aircraft (1), a first operation of triangulation on the basis of the first geometrical information acquired; and - varying, on the basis of the first position information, flight parameters of the receiver aircraft (1) including governing the receiver aircraft in approach to, and in alignment with, the tanker aircraft for carrying out said operation of in-flight refuelling.</p>",
            "CTN": "(EP2338793)<br/>US6669145 43343427 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>US20080265097 43760829 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>GB2438218 17932191 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>US6889941 43415403 WHO=EXAMINER SELF=N CAT=X<br/>US20090045290 1843952 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>EP1424283 13929783 WHO=EXAMINER SELF=N CAT=A<br/>US4170773 42405945 WHO=EXAMINER SELF=N CAT=A<br/>US6669145 43343427 WHO=APPLICANT SELF=N<br/>US20080265097 43760829 WHO=APPLICANT SELF=N<br/>GB2438218 17932191 WHO=APPLICANT SELF=N<br/>US6889941 43415403 WHO=APPLICANT SELF=N<br/><br/>(US8712608)<br/>US20040102876 13929783 WHO=EXAMINER SELF=N<br/>US20050116109 791949 WHO=EXAMINER SELF=N<br/>US20060216674 68859888 WHO=EXAMINER SELF=N<br/>US20080099628 43797276 WHO=EXAMINER SELF=N<br/>US20080114544 14905634 WHO=EXAMINER SELF=N<br/>US20080265097 43760829 WHO=EXAMINER SELF=N<br/>US20080270027 43710975 WHO=EXAMINER SELF=N<br/>US20090015436 14940885 WHO=EXAMINER SELF=N<br/>US20090248225 43760829 WHO=EXAMINER SELF=N<br/>US4170773 42405945 WHO=APPLICANT SELF=N<br/>US6669145 43343427 WHO=APPLICANT SELF=N<br/>US6889941 43415403 WHO=APPLICANT SELF=N<br/>US20090045290 1843952 WHO=APPLICANT SELF=N<br/>EP1424283 13929783 WHO=APPLICANT SELF=N<br/>GB2438218 17932191 WHO=APPLICANT SELF=N<br/><br/>(IT1397664)<br/>US6669145 43343427 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>US20080265097 43760829 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>GB2438218 17932191 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>EP1424283 13929783 WHO=EXAMINER SELF=N CAT=A<br/>US4170773 42405945 WHO=EXAMINER SELF=N CAT=A",
            "V_APL": [
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2030-12-16",
                    "XAP": "2010EP-0195529",
                    "APD": "2010-12-16",
                    "APID": "21975656",
                    "REG_LINK": "https://register.epo.org/application?number=EP10195529",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=FaccLQI1IXWeccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "EP2338793",
                            "KIND": "B8",
                            "XPN": "EP2338793",
                            "V_PNID": "EP-2338793B8-20170111-0",
                            "DATE": "2017-01-11",
                            "STG": "Modified first page granted patent",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=NoFk66ibPDRBgn16rX94Dh+DD5PwTl0EPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2338793&kind=B8",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=FaccLQI1IXWeccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP2338793",
                            "KIND": "B1",
                            "XPN": "EP2338793",
                            "V_PNID": "EP-2338793B1-0",
                            "DATE": "2016-08-31",
                            "STG": "Patent specification",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=NoFk66ibPDRBgn16rX94DqxaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2338793&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=FaccLQI1IXWeccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "EP2338793",
                            "KIND": "A1",
                            "XPN": "EP2338793",
                            "V_PNID": "EP-2338793A1-0",
                            "DATE": "2011-06-29",
                            "STG": "Application published with search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=NoFk66ibPDRBgn16rX94DvEZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2338793&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=FaccLQI1IXWeccOAsqvWAnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2030-12-16",
                            "XAP": "2010ES-0195529T",
                            "APD": "2010-12-16",
                            "APID": "111493098",
                            "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=VPuQqWnLQ0iseLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "ES2601082",
                                    "KIND": "T3",
                                    "XPN": "ES2601082",
                                    "V_PNID": "ES-2601082T3-0",
                                    "DATE": "2017-02-14",
                                    "STG": "Translation of granted European patent (former B3)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=a4uVmah4rFrgKq4jehbn+H4Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2601082&kind=T3",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=VPuQqWnLQ0iseLHW8WjXjnfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2032-08-23",
                    "XAP": "2010US-12968692",
                    "APD": "2010-12-15",
                    "APID": "64161560",
                    "REG_LINK": "https://patentcenter.uspto.gov/applications/12968692",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=6A5rSslWwH8bWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "US8712608",
                            "KIND": "B2",
                            "XPN": "US8712608",
                            "V_PNID": "US-8712608B2-0",
                            "DATE": "2014-04-29",
                            "STG": "Granted patent as second publication",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=5gwRdmuHOZoyHoXttipf2kDJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=US8712608&kind=B2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=6A5rSslWwH8bWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "US20120059536",
                            "KIND": "A1",
                            "XPN": "US20120059536",
                            "V_PNID": "US-2012059536A1-0",
                            "DATE": "2012-03-08",
                            "STG": "Application published",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcNwTyMj2VJRUl90CpEah8ymbS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20120059536&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=7v19TOof9vmF%252BvqUozjCicRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "GRANTED",
                    "ACT_EED": "2029-12-16",
                    "XAP": "2009IT-TO00993",
                    "APD": "2009-12-16",
                    "APID": "30313414",
                    "REG_LINK": "",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ffok4%252FxlD%252BP4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "IT1397664",
                            "KIND": "B1",
                            "XPN": "IT1397664",
                            "V_PNID": "IT-1397664B1-0",
                            "DATE": "2013-01-18",
                            "STG": "Granted patent",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=dTVZjASq43/3irpd7LuTw6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=IT1397664&kind=B1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=ffok4%252FxlD%252BP4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "ITTO20090993",
                            "KIND": "A1",
                            "XPN": "IT2009TO0993",
                            "V_PNID": "IT-TO20090993A1-0",
                            "DATE": "2011-06-17",
                            "STG": "Application for patent of invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=PknmpDUQ+ywr36xYjXmhid0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IT2009TO0993&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=MLerSbbf4wYFAVh9ZsocSrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP2338793_B8",
            "EPRD": "2009-12-16",
            "PN": "EP2338793           B8 2017-01-11 [EP2338793]<br/>EP2338793           B1 2016-08-31 [EP2338793]<br/>EP2338793           A1 2011-06-29 [EP2338793]<br/>US8712608           B2 2014-04-29 [US8712608]<br/>US20120059536       A1 2012-03-08 [US20120059536]<br/>ES2601082           T3 2017-02-14 [ES2601082]<br/>IT1397664           B1 2013-01-18 [IT1397664]<br/>ITTO20090993        A1 2011-06-17 [IT2009TO0993]",
            "ADB": "(EP2338793)<br/><p>In particular, the invention according to the present disclosure makes it possible to approach a generic target with high precision (at least at a centimetre level) using commercial hardware resources, hence limiting considerably the production costs.</p><p>The present invention enables in fact management of all the steps of automatic in-flight refuelling, from the step of planning of the refuelling operation up to the final steps of chasing and fine positioning.</p><p>The procedures used can be advantageously developed in accordance with the NATO ATP 56 standard.</p><p>Hence, only in the case where the GPS position signal is missing or is considered not reliable, does it enter the wait state 52.</p><p>The system described in US 6,669,145 presents the disadvantage of entailing considerable modifications, including structural ones, to the tanker aircraft and to the drogue of the boom.</p><p>When the conditions referred to above arise, the weight of the confidence value of the reliability factor CGPS is limited according to the following formula (14) to obtain a limited reliability factor CGPS' : C GPS = G GPS − δ with δ = 2 3 C OPT − 0.5.</p>"
        },
        {
            "FNUM": "APAGE=31<br/>NBPC=12<br/>PNAAGE=32<br/>NBPA=1; <br/>ALLCT=6; SCT=0; NSCT=6; <br/>ALLCTG=13; SCTG=0; NSCTG=13; <br/>AFS=7; ACC=7; AMCC=2; <br/>IGEN=0.94; IORG=0.88; IRAD=0.95; <br/>IMPI=3.47; MACI=2.03; PASI=4.02; PAVI=0.46; ",
            "PTCC": "(EP2137481)<br/>CC=EP EED=2028-04-09 STATUS=GRANTED APID=21773923 APD=2008-04-09 XPN=EP2137481 PD=2009-12-30 PD=2010-11-17 EPD=2009-12-30 LPD=2010-11-17 PDG=2010-11-17 <br/>CC=ES EED=2028-04-09 STATUS=GRANTED APID=23072869 APD=2008-04-09 XPN=ES2356798 PD=2011-04-13 EPD=2011-04-13 LPD=2011-04-13 PDG=2011-04-13 <br/>CC=FR EED=2028-04-09 STATUS=GRANTED APID=21773923 XPN=EP2137481 PDG=2010-11-17 <br/>CC=GB EED=2028-04-09 STATUS=GRANTED APID=21773923 XPN=EP2137481 PDG=2010-11-17 <br/>CC=NL EED=2028-04-09 STATUS=GRANTED APID=21773923 XPN=EP2137481 PDG=2010-11-17 <br/><br/>(WO2008129435)<br/>CC=EP EED=2028-04-09 STATUS=GRANTED APID=21773923 APD=2008-04-09 XPN=EP2137481 PD=2009-12-30 PD=2010-11-17 EPD=2009-12-30 LPD=2010-11-17 PDG=2010-11-17 <br/>CC=IL EED=2028-04-09 STATUS=GRANTED APID=29084479 APD=2009-09-24 XPN=IL-201197 PD=2010-05-17 PD=2013-07-31 EPD=2010-05-17 LPD=2013-07-31 PDG=2013-07-31 <br/>CC=IN EED=2028-04-09 STATUS=GRANTED APID=88258303 APD=2009-11-17 XPN=IN2009CN06761 PD=2010-03-05 PD=2017-07-07 EPD=2010-03-05 LPD=2017-07-07 PDG=2017-07-07 <br/><br/>(IN-284809)<br/>CC=IN EED=2028-04-09 STATUS=GRANTED APID=88258303 APD=2009-11-17 XPN=IN2009CN06761 PD=2010-03-05 PD=2017-07-07 EPD=2010-03-05 LPD=2017-07-07 PDG=2017-07-07 <br/><br/>(IL-201197)<br/>CC=IL EED=2028-04-09 STATUS=GRANTED APID=29084479 APD=2009-09-24 XPN=IL-201197 PD=2010-05-17 PD=2013-07-31 EPD=2010-05-17 LPD=2013-07-31 PDG=2013-07-31 <br/><br/>(ES2356798)<br/>CC=ES EED=2028-04-09 STATUS=GRANTED APID=23072869 APD=2008-04-09 XPN=ES2356798 PD=2011-04-13 EPD=2011-04-13 LPD=2011-04-13 PDG=2011-04-13 <br/><br/>(IT2007TO0272)<br/>CC=IT EED=2027-04-18 STATUS=PENDING APID=30298912 APD=2007-04-18 XPN=IT2007TO0272 PD=2008-10-19 EPD=2008-10-19 LPD=2008-10-19 <br/>",
            "EPN": "ITTO20070272",
            "CTGN": "(US8260734)<br/>EP2600096 45346134 WHO=EXAMINER SELF=N CAT=X CAT=A CAT=I<br/>US9897417 69554635 WHO=EXAMINER SELF=N<br/>US10343776 77853484 WHO=EXAMINER SELF=N<br/>US10557686 77641766 WHO=EXAMINER SELF=N<br/>US20200208945 82268378 WHO=EXAMINER SELF=N CAT=103<br/>CN110049760B 79220456 WHO=EXAMINER SELF=N CAT=A<br/>CN108966674B 75304009 WHO=EXAMINER SELF=N<br/>US10203691 69553581 WHO=APPLICANT SELF=N<br/>US10051178 69553928 WHO=APPLICANT SELF=N<br/>EP2600096 45346134 WHO=APPLICANT SELF=N<br/><br/>(WO2008129435)<br/>EP3239646 77611103 WHO=EXAMINER SELF=N CAT=A<br/>WO2017187144 77641766 WHO=EXAMINER SELF=N CAT=A<br/>EP3407004 82190252 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>WO2018215738 82268378 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>EP3449203 77641766 WHO=EXAMINER SELF=N CAT=A<br/>EP3631344 82268378 WHO=EXAMINER SELF=N CAT=X CAT=Y<br/>GB2563011 76751062 WHO=EXAMINER SELF=N<br/>US10557686 77641766 WHO=APPLICANT SELF=N<br/>US11029130 82268378 WHO=APPLICANT SELF=N<br/>EP3449203 77641766 WHO=APPLICANT SELF=N<br/>AU2018273014 82268378 WHO=UNKNOWN SELF=N<br/><br/>(RU2473861)<br/>RU2751433 95411300 WHO=EXAMINER SELF=N",
            "LAPD": "2009-11-17",
            "STDN": "",
            "NPN": "12",
            "DESC": "<p><h1>TECHNICAL FIELD</h1></p><p><span class=\"paragraph-number\">[0001]   </span>This application is a National Stage Application of PCT/IB2008/051341, filed 9 Apr. 2008, which claims benefit of Ser. No. TO2007A000272, filed 18 Apr. 2007 in Italy and which applications are incorporated herein by reference. To the extent appropriate, a claim of priority is made to each of the above disclosed applications.</p><p><span class=\"paragraph-number\">[0002]   </span>The present invention relates to the integration of a military load with an aircraft and, more specifically, to the estimation of the time of flight and of the area of impact on the earth's surface of a smart load launched from an aircraft.</p><p><span class=\"paragraph-number\">[0003]   </span>The area of impact of a smart load on the ground is the area in which a target must be situated in order to be struck successfully by the load. The size and shape of the area depend on the flight conditions of the aircraft at release of the load, upon atmospheric conditions (for example, temperature, humidity and wind) and upon predetermined conditions of impact on the target (for example, direction of arrival and angle of attack of the load relative to the target, desired impact speed).</p><p><span class=\"paragraph-number\">[0004]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows some examples of shapes of possible impact areas according to different release and impact conditions of a load.</p><p><span class=\"paragraph-number\">[0005]   </span>When a ballistic load is to be released onto a target there is a single release point for which, theoretically, it can strike the target. In practice, the point of impact of the load on the ground will have a Gaussian distribution around a mean impact point which only rarely coincides with the target. The error may be due to a variation in load characteristics (weight, centre of gravity, moments of inertia) or to limitations of the release algorithm (parameters not modelled), or even to inaccuracies in the estimation of environmental factors (wind, air density, etc.).</p><p><span class=\"paragraph-number\">[0006]   </span>Currently, there are several known algorithms for the calculation or estimation of the impact area, which are used by aeronautical companies for the integration of a load with an aircraft.</p><p><span class=\"paragraph-number\">[0007]   </span>For a “smart” load, the situation is more complex since that load has the capability to navigate in order to reach a predefined target with a certain degree of accuracy. If the release position, the aircraft flight parameters (for example, speed, accelerations, attitude), the conditions of impact on the target and the atmospheric conditions are known, it is thus necessary to determine whether the load has the capability to “guide itself” onto the predefined target.</p><p><span class=\"paragraph-number\">[0008]   </span>The area of impact on the ground in which the predefined target must be in order to be reached successfully by the load is therefore a dynamic area which varies as the known conditions change.</p><p><span class=\"paragraph-number\">[0009]   </span>During the planning on the ground of a mission which requires the release of a load, the impact area can be calculated with the use of a system for simulating the performance of the load but, for the success of the mission, it is necessary also to have a system for estimating the impact area in flight, which takes account of the fact that the impact area may vary during the mission.</p><p><span class=\"paragraph-number\">[0010]   </span>The problem of estimating the impact area of a smart load in real time is complex and highly non-linear, depending on the conditions of release from the aircraft and of the impact of the load on the target.</p><p><span class=\"paragraph-number\">[0011]   </span>The most highly-developed tools for planning on the ground use complex models, for example, numerical calculation models with six degrees of freedom, to predict the trajectory of a load from the release point to the target.</p><p><span class=\"paragraph-number\">[0012]   </span>A model with six degrees of freedom is adapted to calculate the trajectory of the load on the basis of the rotational and translational parameters of the load, of the environmental parameters, and of a control model of the flight of the load. Moreover, the model is refined with the use of data obtained by load release tests in order to reduce the error of the prediction with respect to the actual event. The accuracy of the model is very good and the possible error is limited to within a few metres.</p><p><span class=\"paragraph-number\">[0013]   </span>However, since this model makes intensive use of the resources of the processing system which governs its execution, it cannot be used for real-time applications on board an aircraft, for example, during a mission.</p><p><span class=\"paragraph-number\">[0014]   </span>For real-time applications, it is necessary to use parametric models which match the results of the model with six degrees of freedom with the smallest possible tolerance.</p><p><span class=\"paragraph-number\">[0015]   </span>A further disadvantage of the prior art is that models with six degrees of freedom calculate polygonal impact areas which are defined by a notably variable number of vertices.</p><p><span class=\"paragraph-number\">[0016]   </span>In order to simplify the simulation tool so as to make it available also for real-time applications, it is desirable to reduce the possible shapes of the impact areas to polygonal shapes with a uniform and limited number of vertices.</p><p><span class=\"paragraph-number\">[0017]   </span>The object of the invention is to provide a method and a system for estimating the impact area of a smart load, which are adapted to be executed or installed, respectively, on board an aircraft and for performing the estimation calculations in real time.</p><p><span class=\"paragraph-number\">[0018]   </span>In summary, the subjects of the invention are a processing method and system for estimating, on board an aircraft, in real time, the impact area of a smart load and the respective time of flight.</p><p><span class=\"paragraph-number\">[0019]   </span>The method is implemented by means of a computer program or set of programs or calculation routines constituting a software application which can be executed by a plurality of processing modules of a complex processing system, adapted to provide a pilot and/or a navigator of an aircraft engaged in a mission with a graphical representation of the estimated impact area of a load on the ground in real time.</p><p><span class=\"paragraph-number\">[0020]   </span>Among the possible techniques that can be used for the development of a methodology for the real-time estimation of impact areas, which include mathematical approaches based on linear regressions, non-linear regressions, and neural networks, the present application makes intensive use of the neural network technique so that it can advantageously be implemented on a non-experimental flying platform. Of the various known neural network architectures (GRNN, recursive, and BPN architectures), the neural network architecture which is considered to best approximate the performance of a model with six degrees of freedom for the estimation of the time of flight and of impact areas of a load is a BPN architecture.</p><p><span class=\"paragraph-number\">[0021]   </span>The task of calculating the time of flight and the impact areas is advantageously divided into a group of tasks for calculating time of flight and coordinates relating to a predetermined number of boundary points (vertices) of the impact area, respectively.</p><p><span class=\"paragraph-number\">[0022]   </span>Tests have been carried out with various types of impact-area modelling that can reduce the number of vertices of the area to 8, 10 or 12 vertices, which can be obtained from the intersections of a corresponding number of straight lines extending through the centroid point of the impact area with the edge of the area.</p><p><span class=\"paragraph-number\">[0023]   </span>The best compromise between accuracy of the model and computational requirements was found to be modelling with 8 points at fixed angles.</p><p><span class=\"paragraph-number\">[0024]   </span><a href=\"#DRAWINGS\">FIG. 2</a> gives an example of how an impact area with 8 points can be represented in accordance with the coordinates (Cx, Cy) of a centroid point and the modules of radii R1-R8, and <a href=\"#DRAWINGS\">FIG. 3</a> shows the typical shapes of impact areas of <a href=\"#DRAWINGS\">FIG. 1</a> modelled with eight radii at fixed angles.</p><p><span class=\"paragraph-number\">[0025]   </span>Like known models with six degrees of freedom, the processing system of the invention is advantageously arranged to distinguish between conditions which allow an impact area and those which do not allow an impact area. The recognition of the conditions which allow an impact area considerably improves the performance of the system, helping to achieve an appreciable reduction in calculation times and in the employment of computational resources, as well as in the risk of estimating false impact areas, and therefore contributes to an increase in the conditions of use of the load.</p><p><span class=\"paragraph-number\">[0026]   </span>The function of recognizing the load release and impact envelope zones which allow an impact area is advantageously managed in a different way from that used in known estimation techniques which, since they cannot perform such recognition, have to reduce the ranges of the parameters input to the estimator at the design stage and consequently reduce the possible load release and impact conditions.</p><br/><p><h1>BRIEF DESCRIPTION OF DRAWINGS</h1></p><p><span class=\"paragraph-number\">[0027]   </span>Further characteristics and advantages of the invention will be described in greater detail in the following detailed description of an embodiment thereof which is given by way of non-limiting example with reference to the appended drawings, in which:</p><p><span class=\"paragraph-number\">[0028]   </span><a href=\"#DRAWINGS\">FIG. 1</a> shows a series of different possible shapes of impact areas,</p><p><span class=\"paragraph-number\">[0029]   </span><a href=\"#DRAWINGS\">FIG. 2</a> is an example of the modelling of an impact area having eight radii with fixed angles,</p><p><span class=\"paragraph-number\">[0030]   </span><a href=\"#DRAWINGS\">FIG. 3</a> is a collection of possible impact area shapes modelled with eight radii at fixed angles,</p><p><span class=\"paragraph-number\">[0031]   </span><a href=\"#DRAWINGS\">FIG. 4</a> is a block diagram representing the processing system of the invention,</p><p><span class=\"paragraph-number\">[0032]   </span><a href=\"#DRAWINGS\">FIG. 5</a> is a representation of a backpropagation neural network with five layers on which the processing modules of the system of the invention are based,</p><p><span class=\"paragraph-number\">[0033]   </span><a href=\"#DRAWINGS\">FIG. 6</a> is a block diagram of the architecture of the processing system of the system of the invention, and</p><p><span class=\"paragraph-number\">[0034]   </span><a href=\"#DRAWINGS\">FIG. 7</a> shows a series of impact-area shapes estimated in accordance with a known model with six degrees of freedom, with a known model with eight points, and with the model based on the neural networks of the invention.</p><br/><p><span class=\"paragraph-number\">[0001]   </span>The present invention relates to the integration of a military load with an aircraft and, more specifically, to the estimation of the time of flight and of the area of impact on the earth's surface of a smart load launched from an aircraft.</p><p><span class=\"paragraph-number\">[0002]   </span>The area of impact of a ballistic or smart load on the ground is the area in which a target must be situated in order to be struck successfully by the load. The size and shape of the area depend on the flight conditions of the aircraft at release of the load, upon atmospheric conditions (for example, temperature, humidity and wind) and upon predetermined conditions of impact on the target (for example, direction of arrival and angle of attack of the load relative to the target, desired impact speed).</p><p><span class=\"paragraph-number\">[0003]   </span><figref>Figure 1</figref> shows some examples of shapes of possible impact areas according to different release and impact conditions of a load.</p><p><span class=\"paragraph-number\">[0004]   </span>When a ballistic load is to be released onto a target there is a single release point for which, theoretically, it can strike the target. In practice, the point of impact of the load on the ground will have a Gaussian distribution around a mean impact point which only rarely coincides with the target. The error may be due to a variation in load characteristics (weight, centre of gravity, moments of inertia) or to limitations of the release algorithm (parameters not modelled), or even to inaccuracies in the estimation of environmental factors (wind, air density, etc.).</p><p><span class=\"paragraph-number\">[0005]   </span>Currently, there are several known algorithms for the calculation or estimation of the impact area, which are used by aeronautical companies for the integration of a load with an aircraft.</p><p><span class=\"paragraph-number\">[0006]   </span>For a \"smart\" load, the situation is more complex since that load has the capability to navigate in order to reach a predefined target with a certain degree of accuracy. If the release position, the aircraft flight parameters (for example, speed, accelerations, attitude), the conditions of impact on the target and the atmospheric conditions are known, it is thus necessary to determine whether the load has the capability to \"guide itself\" onto the predefined target.</p><p><span class=\"paragraph-number\">[0007]   </span>The area of impact on the ground in which the predefined target must be in order to be reached successfully by the load is therefore a dynamic area which varies as the known conditions change.</p><p><span class=\"paragraph-number\">[0008]   </span>During the planning on the ground of a mission which requires the release of a load, the impact area can be calculated with the use of a system for simulating the performance of the load but, for the success of the mission, it is necessary also to have a system for estimating the impact area in flight, which takes account of the fact that the impact area may vary during the mission.</p><p><span class=\"paragraph-number\">[0009]   </span>The problem of estimating the impact area of a smart load in real time is complex and highly non-linear, depending on the conditions of release from the aircraft and of the impact of the load on the target.</p><p><span class=\"paragraph-number\">[0010]   </span>The most highly-developed tools for planning on the ground use complex models, for example, numerical calculation models with six degrees of freedom, to predict the trajectory of a load from the release point to the target.</p><p><span class=\"paragraph-number\">[0011]   </span>A model with six degrees of freedom is adapted to calculate the trajectory of the load on the basis of the rotational and translational parameters of the load, of the environmental parameters, and of a control model of the flight of the load. Moreover, the model is refined with the use of data obtained by load release tests in order to reduce the error of the prediction with respect to the actual event. The accuracy of the model is very good and the possible error is limited to within a few metres.</p><p><span class=\"paragraph-number\">[0012]   </span>However, since this model makes intensive use of the resources of the processing system which governs its execution, it cannot be used for real-time applications on board an aircraft, for example, during a mission.</p><p><span class=\"paragraph-number\">[0013]   </span>For real-time applications, it is necessary to use parametric models which match the results of the model with six degrees of freedom with the smallest possible tolerance.</p><p><span class=\"paragraph-number\">[0014]   </span>A further disadvantage of the prior art is that models with six degrees of freedom calculate polygonal impact areas which are defined by a notably variable number of vertices.</p><p><span class=\"paragraph-number\">[0015]   </span>In order to simplify the simulation tool so as to make it available also for real-time applications, it is desirable to reduce the possible shapes of the impact areas to polygonal shapes with a uniform and limited number of vertices.</p><p><span class=\"paragraph-number\">[0016]   </span>The object of the invention is to provide a method and a system for estimating the impact area of a smart load, which are adapted to be executed or installed, respectively, on board an aircraft and for performing the estimation calculations in real time.</p><p><span class=\"paragraph-number\">[0017]   </span>For this purpose, the subjects of the invention are a system having the characteristics defined by Claim 1 and a method having the characteristics defined by Claim 8.</p><p><span class=\"paragraph-number\">[0018]   </span>Specific embodiments form the subjects of the dependent claims.</p><p><span class=\"paragraph-number\">[0019]   </span>A further subject of the invention is a processing program or set of programs as claimed.</p><p><span class=\"paragraph-number\">[0020]   </span>In summary, the subjects of the invention are a processing method and system for estimating, on board an aircraft, in real time, the impact area of a smart load and the respective time of flight.</p><p><span class=\"paragraph-number\">[0021]   </span>The method is implemented by means of a computer program or set of programs or calculation routines constituting a software application which can be executed by a plurality of processing modules of a complex processing system, adapted to provide a pilot and/or a navigator of an aircraft engaged in a mission with a graphical representation of the estimated impact area of a load on the ground in real time.</p><p><span class=\"paragraph-number\">[0022]   </span>Among the possible techniques that can be used for the development of a methodology for the real-time estimation of impact areas, which include mathematical approaches based on linear regressions, non-linear regressions, and neural networks, the present application makes intensive use of the neural network technique so that it can advantageously be implemented on a non-experimental flying platform. Of the various known neural network architectures (GRNN, recursive, and BPN architectures), the neural network architecture which is considered to best approximate the performance of a model with six degrees of freedom for the estimation of the time of flight and of impact areas of a load is a BPN architecture.</p><p><span class=\"paragraph-number\">[0023]   </span>The task of calculating the time of flight and the impact areas is advantageously divided into a group of tasks for calculating time of flight and coordinates relating to a predetermined number of boundary points (vertices) of the impact area, respectively.</p><p><span class=\"paragraph-number\">[0024]   </span>Tests have been carried out with various types of impact-area modelling that can reduce the number of vertices of the area to 8, 10 or 12 vertices, which can be obtained from the intersections of a corresponding number of straight lines extending through the centroid point of the impact area with the edge of the area.</p><p><span class=\"paragraph-number\">[0025]   </span>The best compromise between accuracy of the model and computational requirements was found to be modelling with 8 points at fixed angles.</p><p><span class=\"paragraph-number\">[0026]   </span><figref>Figure 2</figref> gives an example of how an impact area with 8 points can be represented in accordance with the coordinates (Cx, Cy) of a centroid point and the modules of radii R1-R8, and <figref>Figure 3</figref> shows the typical shapes of impact areas of <figref>Figure 1</figref> modelled with eight radii at fixed angles.</p><p><span class=\"paragraph-number\">[0027]   </span>Like known models with six degrees of freedom, the processing system of the invention is advantageously arranged to distinguish between conditions which allow an impact area and those which do not allow an impact area. The recognition of the conditions which allow an impact area considerably improves the performance of the system, helping to achieve an appreciable reduction in calculation times and in the employment of computational resources, as well as in the risk of estimating false impact areas, and therefore contributes to an increase in the conditions of use of the load.</p><p><span class=\"paragraph-number\">[0028]   </span>The function of recognizing the load release and impact envelope zones which allow an impact area is advantageously managed in a different way from that used in known estimation techniques which, since they cannot perform such recognition, have to reduce the ranges of the parameters input to the estimator at the design stage and consequently reduce the possible load release and impact conditions.</p><p><span class=\"paragraph-number\">[0029]   </span>Further characteristics and advantages of the invention will be described in greater detail in the following detailed description of an embodiment thereof which is given by way of non-limiting example with reference to the appended drawings, in which:</p><p><ul compact=\"compact\" list-style=\"none\"><li> <figref>Figure 1</figref> shows a series of different possible shapes of impact areas,</li><br/><li> <figref>Figure 2</figref> is an example of the modelling of an impact area having eight radii with fixed angles,</li><br/><li> <figref>Figure 3</figref> is a collection of possible impact area shapes modelled with eight radii at fixed angles,</li><br/><li> <figref>Figure 4</figref> is a block diagram representing the processing system of the invention,</li><br/><li> <figref>Figure 5</figref> is a representation of a backpropagation neural network with five layers on which the processing modules of the system of the invention are based,</li><br/><li> <figref>Figure 6</figref> is a block diagram of the architecture of the processing system of the system of the invention, and</li><br/><li> <figref>Figure 7</figref> shows a series of impact-area shapes estimated in accordance with a known model with six degrees of freedom, with a known model with eight points, and with the model based on the neural networks of the invention.</li></ul></p><p><span class=\"paragraph-number\">[0030]   </span>A block diagram of the processing system of the invention is shown in <figref>Figure 4</figref>.</p><p><span class=\"paragraph-number\">[0031]   </span>In detail, it comprises a first input-parameter management module 10, adapted to receive data or signals indicative of the flight conditions of the aircraft carrying the load (for example, information on the altitude, speed, angle of climb, and direction of travel of the aircraft) and of the conditions of impact on the target (for example, target height, impact angle, impact azimuth).</p><p><span class=\"paragraph-number\">[0032]   </span>A plurality of processing modules 12, 14, 16, 18, 20, 22, 24 are associated therewith.</p><p><span class=\"paragraph-number\">[0033]   </span>An input-range checking calculation module 12 is arranged for checking the ranges of the input parameters and calculating the values to be supplied as inputs to the subsequent estimation modules.</p><p><span class=\"paragraph-number\">[0034]   </span>The module 12 is connected directly to a filter module 14 which is also connected to the module 10 for receiving the input parameters and is arranged to estimate whether or not an impact area exists.</p><p><span class=\"paragraph-number\">[0035]   </span>The output of the module 14 is taken to an activation input of the impact-area estimation module 16, adapted to receive, at the input, data or signals indicative of the aircraft flight conditions upon the release of the load and conditions of impact on the target and is arranged to estimate the coordinates of the centroid of the impact area and a predetermined number (for example, eight in the currently-preferred embodiment) of radii of the extent of the impact area, extending from the centroid.</p><p><span class=\"paragraph-number\">[0036]   </span>An area filter module 18 receives, at the input, the output of the module 16 and is arranged to calculate the surface area of the estimated impact area, considering it to be non-existent if it is below a predetermined threshold (for example, 1 square kilometre). If a valid impact area is present, the module is arranged to calculate the distances between the vertices of the area and the release point to be used as a datum for subsequent flight-time reduction calculations.</p><p><span class=\"paragraph-number\">[0037]   </span>An impact-area reduction module 20, the activation of which is controlled by the filter module 18, is arranged to receive, at its input, the results produced by the module 18 and to reduce the estimated impact area. This module is advantageously adapted to reduce the front radii (with respect to the direction of travel of the aircraft) of the area by a first factor and the rear radii of the area by a second factor (for example of 20% and 10%, respectively) in order to be more conservative and to take account of the effect of the wind and any other flight or release conditions which differ from the nominal conditions. The module is arranged to calculate the coordinates of the vertices of the reduced impact area, which constitute the output of the estimation system of the invention. The module 20 is also arranged to calculate the new distances between the vertices of the reduced impact area and the load release point and is adapted to output this result for the calculation of the reduction of the time of flight.</p><p><span class=\"paragraph-number\">[0038]   </span>A time of flight calculation module 22, the activation of which is controlled by the filter module 18, is adapted to receive, at its input, data or signals indicative of the aircraft flight conditions and of the conditions of impact on the target and is arranged to estimate the time of flight of the load to the vertices of the calculated impact area.</p><p><span class=\"paragraph-number\">[0039]   </span>A flight-time reduction module 24 is arranged to calculate the time of flight to the vertices of the reduced impact area.</p><p><span class=\"paragraph-number\">[0040]   </span>The estimated and reduced time of flight for each vertex of the reduced impact area are output from the module 24.</p><p><span class=\"paragraph-number\">[0041]   </span>The set of data of the coordinates of the centroid and of the vertices of the reduced impact area and of time of flight for each vertex of the area constitutes the output of the estimation system of the invention and is managed by a module for presenting the information to the user, for example, for the display, on an on-board screen, of a geometrical representation of the impact area which can advantageously be superimposed on a geographical map of the region overflown.</p><p><span class=\"paragraph-number\">[0042]   </span>The impact-area and flight-time estimator described in the present invention is a processing system based on neural networks in which the information necessary to define an impact area and the respective time of flight of the load are calculated by backpropagation neural networks, each of which is adapted to calculate a specific datum.</p><p><span class=\"paragraph-number\">[0043]   </span>Neural networks are non-linear systems which can modify their behaviour according to the inputs they receive. A neural network is a set of parallel processors connected to one another in the form of a directed graph which has the ability to learn by means of suitable training.</p><p><span class=\"paragraph-number\">[0044]   </span>In particular, in the currently-preferred embodiment, the system is based on supervised neural networks, that is, networks which are trained by examples each of which describes an impact area (output datum) for a predetermined release and ground impact condition of the load (input datum).</p><p><span class=\"paragraph-number\">[0045]   </span>The advantage of the neural network technique lies, briefly, in the capability to reduce processing times and costs, to introduce advanced functional capabilities, to reduce the costs of the system, and to increase its operative efficiency.</p><p><span class=\"paragraph-number\">[0046]   </span>In order to achieve good performance from a neural network, it is necessary to define the network architecture which is most suitable to represent the problem. This consists in defining the number of layers of the network, the number of neurons per hidden layer, the transfer functions of the layers, and the type of network training.</p><p><span class=\"paragraph-number\">[0047]   </span>It is fundamental to create a training file which is adequate for representing the phenomenon under examination. In fact, the set of training data must be complete, particularly when it is extremely non-linear. Moreover, the set of test data for checking the performance of a network must contain inputs other than those on which the network has been trained.</p><p><span class=\"paragraph-number\">[0048]   </span>In selecting the network architecture and the set of training data, it must be remembered that, although the performance of the neural network may improve if the above-described factors are varied, it is necessary to avoid an excessive increase in the training times and response times of the network that is being produced. The final selection should therefore be the result of a trade-off of these two aspects, depending on the application of the available hardware and software resources.</p><p><span class=\"paragraph-number\">[0049]   </span>According to the invention, it is preferable to use backpropagation neural networks with from 3 to 5 layers and with a single output.</p><p><span class=\"paragraph-number\">[0050]   </span><figref>Figure 5</figref> shows concisely a model of a multi-layered backpropagation network with five layers such as that used in the processing modules of the system of the invention.</p><p><span class=\"paragraph-number\">[0051]   </span>In detail, the processing system for the estimation of the impact areas and of the time of flight of a load comprises three sets of BPN-type neural networks:</p><p><ul compact=\"compact\" list-style=\"dash\"><li> a first group of neural networks adapted to estimate whether or not the impact area exists according to the aircraft flight conditions upon the release of the load and the conditions of impact of the load on the target; the non-existence of the impact area indicates that, with the specific flight condition upon release of the load, it is not possible to satisfy the required impact conditions;</li><br/><li> a second group of neural networks for the calculation of the impact area, comprising a plurality of networks arranged for estimating the coordinates of the centroid of the impact area and the radii of the area, respectively;</li><br/><li> a third group of neural networks for calculating the time of flight, comprising a plurality of networks arranged for estimating the time of flight to a respective one of the vertices of the impact area.</li></ul></p><p><span class=\"paragraph-number\">[0052]   </span>In particular, each of these networks comprises transfer functions indicated <b>f</b><sup>1</sup>, <b>f</b><sup>2</sup>, <b>f</b><sup>3</sup>, <b>f</b><sup>4</sup> of the internal layers, which are selected from the group comprising linear, sine, hyperbolic tangent, Gaussian, or complementary Gaussian transfer functions.</p><p><span class=\"paragraph-number\">[0053]   </span>Linear transfer functions are used for the normalization of the input and the de-normalization of the output. When the variables are loaded into a neural network they have to be scaled to a numerical range which the neural network can process efficiently. There are two ranges with which networks generally operate, that is, a range between 0 and 1 or a range between -1 and 1. The ranges may be of two types, that is, a \"closed\" range ([0, 1] or [-1, 1]), for which its values are strictly included within the range or an \"open\" range, for which its values may be greater than or less than the limits of the range.</p><p><span class=\"paragraph-number\">[0054]   </span>An \"open\" range is advantageously used in the design of the neural networks of the estimator of the invention.</p><p><span class=\"paragraph-number\">[0055]   </span>The hyperbolic tangent transfer function is </p><p><maths><img loading=\"lazy\" decoding=\"async\" style=\"width: 37mm; height: 15mm\" src=\"https://sobj.orbit.com/sobj/getImageByName?format=png&key=EP2137481&ekey=938&cc=EP&producerName=imgb0001.tif&width=37mm&height=15mm\"/></maths></p><p><span class=\"paragraph-number\">[0056]   </span>The Gaussian transfer function is <i>G</i>(<i>x</i>) = <i>e</i><sup>-<i>x</i><sup>2</sup></sup>, and the complementary Gaussian transfer function is <i>GC</i>(<i>x</i>) =1-<i>e</i><sup><i>-x</i><sup>2</sup></sup>.</p><p><span class=\"paragraph-number\">[0057]   </span>In one embodiment of a neural network, the transfer functions indicated <b>f</b><sup>1</sup>, <b>f</b><sup>2</sup>, <b>f</b><sup>3</sup>, <b>f</b><sup>4</sup>, are, in succession, a hyperbolic tangent transfer function, a Gaussian transfer function, a complementary Gaussian transfer function, and a linear transfer function, respectively.</p><p><span class=\"paragraph-number\">[0058]   </span>The impact-area and flight-time estimation system is advantageously constructed and incorporated in the main processing system of the aircraft carrying the load.</p><p><span class=\"paragraph-number\">[0059]   </span>A system architecture the main unit of which is the central processor of the aircraft is shown in <figref>Figure 6</figref>.</p><p><span class=\"paragraph-number\">[0060]   </span>A main processor, indicated 100, is arranged to perform the functions of navigation, management of the attack procedures, initialization of loads, and calculation of launch envelopes (that is, the estimation of the impact areas), as well as the functions of management of the presentation of information to the pilot and management of the implementation of the pilot's commands.</p><p><span class=\"paragraph-number\">[0061]   </span>Connected to the input of the processor 100 are a plurality of sensors 120 for the acquisition of data indicative of the aircraft flight conditions and load-release conditions, a multi-functional keyboard interface device 140, a solid-state data substrate or memory 160, and a load control system 180.</p><p><span class=\"paragraph-number\">[0062]   </span>The interface 140 is arranged, for example, for the input and/or modification of the target coordinates, of the conditions of impact on the target, and of the aircraft course and attack selection data.</p><p><span class=\"paragraph-number\">[0063]   </span>The data substrate 160 stores the target coordinates, the conditions of impact on the target, and the aircraft course, which are preset during the preparation of the mission on the ground or are modified in run-time for chance targets.</p><p><span class=\"paragraph-number\">[0064]   </span>The load control system 180 is arranged to identify and select the load, to authorize release, and to manage release sequence and timing. A load-release push-button 200 is conventionally associated therewith.</p><p><span class=\"paragraph-number\">[0065]   </span>The main processor 100 is also connected to a screen 220 for presenting the mission and attack data to the pilot or to the navigator of the aircraft.</p><p><span class=\"paragraph-number\">[0066]   </span>The load control system 180 is adapted to activate the cartridges 240 of a load by means of a respective release command signal and the main processor is adapted to control the load C by supplying it with target coordinate data, alignment data, and an activation signal.</p><p><span class=\"paragraph-number\">[0067]   </span>In the description, the processing assembly upon which the system is based has been identified as a microprocessor electronic processing unit provided with at least one storage module for storing respective processing parameters but, in this connection, it is pointed out that, for the purposes of the invention, a plurality of processing units connected in parallel and storage modules should be considered wholly equivalent.</p><p><span class=\"paragraph-number\">[0068]   </span>With reference to <figref>Figure 7</figref>, this shows some examples of comparisons of the impact area calculated by a conventional simulation model with six degrees of freedom (also shown with a model with eight points) and by the model of the invention.</p><p><span class=\"paragraph-number\">[0069]   </span>Advantageously, the real-time estimation system implemented on board the aircraft can calculate an impact area in a time two orders of magnitude less than the time taken by an offline simulator according to the prior art.</p><p><span class=\"paragraph-number\">[0070]   </span>The results obtained in terms of calculation speed and performance of the system and method of the invention advantageously confirm the validity of the approach taken, and the efficacy of the neural networks technique and also of the system architecture designed and described above.</p><p><span class=\"paragraph-number\">[0071]   </span>Naturally, the principle of the invention remaining the same, the forms of embodiment and the details of construction may be varied widely with respect to those described and illustrated purely by way of non-limiting example, without thereby departing from the scope of protection of the present invention defined by the appended claims.</p>",
            "CLMS": "(EP2137481)<br/><p>1. A system for estimating the impact area of a smart load that can be launched from an aircraft, comprising a processing assembly including:<br/> means for acquiring first data or signals indicative of the aircraft flight conditions upon release of the load; and<br/> processing means including a plurality of neural networks, for estimating the target impact point of the load<br/> <b>characterized in that</b> said processing assembly further includes means for acquiring second data or signals indicative of predetermined conditions of impact on the target, and<br/> <b>in that</b> the processing means are arranged for determining a polygonal impact area as a function of the first and second data or signals, said processing means including a plurality of first neural networks, arranged for calculating the coordinates of a central point of the impact area and of a predetermined number of vertices of the area, respectively.</p><p>2. A system according to Claim 1, in which the first neural networks are arranged for the calculation of the radii which extend from the central point of the impact area, which are adapted to define the predetermined number of vertices.</p><p>3. A system according to Claim 1 or Claim 2, in which the processing means include a plurality of second neural networks which are arranged for the calculation of the time of flight to the vertices of the impact area.</p><p>4. A system according to any one of the preceding claims, in which the processing means for determining an impact area include a plurality of third neural networks which are arranged to estimate the existence of the impact area as a function of the first and second data or signals indicative of the aircraft flight conditions upon release of the load and of the predetermined conditions of impact on the target.</p><p>5. A system according to Claim 4, in which the first, second and third neural networks are backpropagation neural networks with from 3 to 5 layers and comprise transfer functions between the layers which are selected from the group comprising linear, sine, hyperbolic tangent, Gaussian, and complementary Gaussian transfer functions.</p><p>6. A system according to Claim 5, in which the first, second and third neural networks comprise 5-layer backpropagation neural networks with 3 hidden layers, having a hyperbolic tangent transfer function of the first hidden layer, a Gaussian transfer function of the second hidden layer, a complementary Gaussian transfer function of the third hidden layer, and a linear output transfer function, respectively.</p><p>7. A system according to any one of the preceding claims, in which the processing means are arranged for reducing the value of the radii of the impact area particularly for applying a first factor for the reduction of the front radii of the impact area, with respect to the direction of travel of the aircraft, and for applying a second factor for the reduction of the rear radii of the impact area, for calculating the coordinates of the predetermined number of vertices of a reduced impact area, and for calculating the time of flights of the load to the vertices of the reduced impact area.</p><p>8. A method of estimating the impact area of a smart load that can be launched from an aircraft, the method being adapted to be implemented by means of an electronic processing assembly comprising means for determining a polygonal impact area defined by the coordinates of a central point and of a predetermined number of vertices, as a function of first and second data or signals indicative of the aircraft flight conditions upon release of the load and of predetermined conditions of impact of the target, respectively,<br/>the means including a plurality of first neural networks arranged for calculating the coordinates of the central point of the impact area and of the predetermined number of vertices of the area, respectively,<br/>the method comprising:<br/> a learning stage in which the processing assembly receives first and second input training data or signals indicative of the aircraft flight conditions upon release of the load and of the predetermined conditions of impact on the target respectively, as well as associated output training data indicative of the coordinates of a central point and of a predetermined number of vertices of an impact area, and determines the transfer functions between the layers of the first neural networks as a function of the input and output training data, and<br/> an execution stage in which the processing assembly receives, as inputs, first and second measurement data or signals and calculates an impact-area estimate as a result of the application of the transfer functions.</p><p>9. A method according to Claim 8, in which the first neural networks are arranged for calculating the radii.which extend from the central point of the impact area, which are adapted to define the predetermined number of vertices.</p><p>10. A method according to Claim 8 or Claim 9, in which the means include a plurality of second neural networks arranged for calculating the time of flight to the vertices of the impact area, respectively,<br/>the method comprising:<br/> a learning stage in which the processing assembly receives first input training data or signals indicative of the aircraft flight conditions upon release of the load and second input training data or signals indicative of the predetermined conditions of impact on the target, as well as associated output training data indicative of the time of fight to the vertices of the impact area, and determines the transfer functions between the layers of the second neural networks as a function of the input and output training data, and<br/> an execution stage in which the processing assembly receives, as inputs, first and second measurement data or signals and calculates an estimate of time of flight to the vertices<br/>of the impact area as a result of the application of the transfer functions.</p><p>11. A method according to any one of Claims 8 to 10, in which the means include a plurality of third neural networks arranged for estimating the existence of the impact area, respectively,<br/>the method comprising:<br/> a learning stage in which the processing assembly receives first input training data or signals indicative of the aircraft flight conditions upon release of the load and second input training data or signals indicative of the predetermined conditions of impact on the target, as well as associated output training data indicative of the existence of an impact area, and determines the transfer functions between the layers of the third neural networks as a function of the input and output training data, and<br/> an execution stage in which the processing assembly receives, as inputs, first and second measurement data or signals and determines the presence or absence of an impact area as a result of the application of the transfer functions.</p><p>12. A method according to any one of Claims 8 to 11, in which the first, second and third neural networks are backpropagation neural networks with from 3 to 5 layers and comprise transfer functions between the layers which are selected from the group comprising linear, sine, hyperbolic tangent, Gaussian, and complementary Gaussian transfer functions.</p><p>13. A method according to Claim 12, in which the first, second and third neural networks comprise 5-layer backpropagation neural networks with 3 hidden layers having a hyperbolic tangent transfer function of the first hidden layer, a Gaussian transfer function of the second hidden layer, a complementary Gaussian transfer function of the third hidden layer, and a linear output transfer function, respectively.</p><p>14. A method according to any one of the preceding claims, comprising the reduction of the value of the radii of the impact area, the calculation of the coordinates of the predetermined number of vertices of a reduced impact area, and the calculation of the time of flights of the load to the vertices of the reduced impact area, wherein the reduction of the value of the radii of the impact area comprises the application of a first reduction factor to the front radii of the impact area, with respect to the direction of travel of the aircraft, and the application of a second reduction factor to the rear radii of the impact area.</p><p>15. A processing program or set of programs adapted to be executed by a processing system and which<br/>is adapted to carry out the method according to claim 8.</p>",
            "NPR": "2",
            "APID": "21773923",
            "RELEVANCE_SCORE": "100.0",
            "IC": "F41G<br/>F41G-007/00<br/>G06N-003/02<br/>G06N-003/08",
            "ID": "986998",
            "AB": "(EP2137481)<br/>A system and a method are for the estimation of the impact area of a smart load that can be launched from an aircraft as a function of data or signals indicative of the aircraft flight conditions upon release of the load and of predetermined impact conditions on the target. The estimation of a polygonal impact area defined by the coordinates of a central point and of a predetermined number of vertices is by corresponding neural networks.",
            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=2MJneNJQHyYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=",
            "EAPD": "2007-04-18",
            "PA": "ALENIA AERMACCHI<br/>ALENIJA AEHRONAUTIKA",
            "PAAD": "(EP2137481)<br/>(PUB:EP-2137481B1-0)NAME=Alenia Aeronautica S.p.A. Viale dell'Aeronautica s.n.c. , CITY=80038 Pomigliano d'Arco (Napoli) , COUNTRY=IT , REG=100074258<br/><br/>(PUB:EP-2137481A2-0)NAME=Alenia Aeronautica S.p.A. Viale Dell'Aeronautica s.n.c. , CITY=80038 Pomigliano D'Arco (Napoli) , COUNTRY=IT , REG=04022020<br/><br/><br/>(US8260734)<br/>(PUB:US-8260734B2-0)NAME=Alenia Aeronautica S.p.A.  , CITY=Pomigliano d'Arco, Napoli , COUNTRY=IT , ATYP=Non-US Company<br/><br/>(PUB:US-2010094789A1-0)NAME=ALENIA AERONAUTICA S.P.A.  , CITY=Pomigliano D'arco, Napoli , COUNTRY=IT , ATYP=Non-US Company<br/><br/><br/>(WO2008129435)<br/>(PUB:WO-2008129435A2-0)NAME=ALENIA AERONAUTICA SPA Viale dell'Aeronautica s.n.c., I-80038 Pomigliano D'arco (Napoli) , COUNTRY=IT<br/><br/><br/>(RU2473861)<br/>(PUB:RU-2473861C2-0)NAME=ALENIJA AEHRONAUTIKA SPA  , COUNTRY=IT<br/><br/>(PUB:RU-2009142412A-0)NAME=ALENIJA AEHRONAUTIKA SPA  , COUNTRY=IT<br/><br/><br/>(IN-284809)<br/>(PUB:IN-6761/CHENP/2009A-43)NAME=ALENIA AERONAUTICA S P A VIALE DELL'AERONAUTICA S.N.C., I-80038 POMIGLIANO D'ARCO (NAPOLI) , COUNTRY=IT<br/><br/><br/>(CA2683934)<br/>(PUB:CA-2683934C-14)NAME=ALENIA AERONAUTICA SPA Viale dell'Aeronautica s.n.c. I-80038 , CITY=POMIGLIANO D'ARCO , COUNTRY=IT<br/><br/>(PUB:CA-2683934A1-0)NAME=ALENIA AERONAUTICA SPA Viale dell'Aeronautica s.n.c. I-80038 , CITY=POMIGLIANO D'ARCO , COUNTRY=IT<br/><br/><br/>(IL-201197)<br/>(PUB:IL-201197A-0)NAME=ALENIA AERONAUTICA S.P.A. VIALE DELL' AERONAUTICA S.N.C. I-80038 POMIGLIANO D'ARCO (NAPOLI) , COUNTRY=IT<br/>",
            "FAN": "986998",
            "TI": "A method and a system for estimating the impact area of a military load launched from an aircraft",
            "TECD": "Computer technology<br/>Other special machines",
            "EPD": "2008-10-19",
            "ICLM": "(EP2137481)<br/><p>1. A system for estimating the impact area of a smart load that can be launched from an aircraft, comprising a processing assembly including: means for acquiring first data or signals indicative of the aircraft flight conditions upon release of the load; and processing means including a plurality of neural networks, for estimating the target impact point of the load characterized in that said processing assembly further includes means for acquiring second data or signals indicative of predetermined conditions of impact on the target, and in that the processing means are arranged for determining a polygonal impact area as a function of the first and second data or signals, said processing means including a plurality of first neural networks, arranged for calculating the coordinates of a central point of the impact area and of a predetermined number of vertices of the area, respectively.</p><p>8. A method of estimating the impact area of a smart load that can be launched from an aircraft, the method being adapted to be implemented by means of an electronic processing assembly comprising means for determining a polygonal impact area defined by the coordinates of a central point and of a predetermined number of vertices, as a function of first and second data or signals indicative of the aircraft flight conditions upon release of the load and of predetermined conditions of impact of the target, respectively, the means including a plurality of first neural networks arranged for calculating the coordinates of the central point of the impact area and of the predetermined number of vertices of the area, respectively, the method comprising: a learning stage in which the processing assembly receives first and second input training data or signals indicative of the aircraft flight conditions upon release of the load and of the predetermined conditions of impact on the target respectively, as well as associated output training data indicative of the coordinates of a central point and of a predetermined number of vertices of an impact area, and determines the transfer functions between the layers of the first neural networks as a function of the input and output training data, and an execution stage in which the processing assembly receives, as inputs, first and second measurement data or signals and calculates an impact-area estimate as a result of the application of the transfer functions.</p>",
            "CTN": "(EP2137481)<br/>US6254031 43193423 WHO=EXAMINER SELF=N CAT=Y<br/>WO200036362 602398 WHO=EXAMINER SELF=N CAT=Y<br/>EP-482427 82586103 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/>US6629085 13696879 WHO=EXAMINER SELF=N CAT=A<br/><br/>(US8260734)<br/>US6254031 43193423 WHO=EXAMINER SELF=N<br/>US6629085 13696879 WHO=EXAMINER SELF=N<br/>US6629085 13696879 WHO=APPLICANT SELF=N<br/>EP-482427 82586103 WHO=APPLICANT SELF=N<br/>WO200036362 602398 WHO=APPLICANT SELF=N<br/><br/>(WO2008129435)<br/>US6254031 43193423 WHO=EXAMINER SELF=N CAT=Y<br/>US6629085 13696879 WHO=EXAMINER SELF=N CAT=A<br/>WO200036362 602398 WHO=EXAMINER SELF=N CAT=Y<br/>EP-482427 82586103 WHO=EXAMINER SELF=N CAT=Y CAT=A<br/><br/>(RU2473861)<br/>US6254031 43193423 WHO=EXAMINER SELF=N<br/>EP-482427 82586103 WHO=EXAMINER SELF=N<br/>US6629085 13696879 WHO=EXAMINER SELF=N<br/>EP1455199 14829231 WHO=EXAMINER SELF=N<br/>US6882992 43411557 WHO=EXAMINER SELF=N<br/>WO200036362 602398 WHO=EXAMINER SELF=N<br/><br/>(AU2008242213)<br/>US6254031 43193423 WHO=EXAMINER SELF=N<br/>WO200036362 602398 WHO=EXAMINER SELF=N<br/>WO2000036362 none WHO=UNKNOWN SELF=N",
            "V_APL": [
                {
                    "ACT_STATE": "DEAD",
                    "ACT_STATUS": "LAPSED",
                    "ACT_EED": "2010-10-18",
                    "XAP": "2008WO-IB51341",
                    "APD": "2008-04-09",
                    "APID": "66274900",
                    "REG_LINK": "http://www.wipo.int/patentscope/search/en/detail.jsf?docId=WO2008129435&redirectedID=true",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=c%252FjapiqkjWim7YdEm97M%252FLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "WO2008/129435",
                            "KIND": "A3",
                            "XPN": "WO2008129435",
                            "V_PNID": "WO-2008129435A3-20081218-0",
                            "DATE": "2008-12-18",
                            "STG": "Later publication of ISR with revised front page",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDuoI3AJQpBTQNwwKC8dCjRETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2008129435&kind=A3",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=c%252FjapiqkjWim7YdEm97M%252FLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        },
                        {
                            "PN": "WO2008/129435",
                            "KIND": "A2",
                            "XPN": "WO2008129435",
                            "V_PNID": "WO-2008129435A2-0",
                            "DATE": "2008-10-30",
                            "STG": "International application published without international search report",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=icjTorqguCDuoI3AJQpBTeiQLCGMC3a3ETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=WO2008129435&kind=A2",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=c%252FjapiqkjWim7YdEm97M%252FLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ],
                    "V_APL": [
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2028-04-09",
                            "XAP": "2009IN-CN06761",
                            "APD": "2009-11-17",
                            "APID": "88258303",
                            "REG_LINK": "https://iprsearch.ipindia.gov.in/PublicSearch/PublicationSearch/Eregister",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=htsatx6z0Zw1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "IN284809",
                                    "KIND": "B",
                                    "XPN": "IN-284809",
                                    "V_PNID": "IN-284809B-43",
                                    "DATE": "2017-07-07",
                                    "STG": "Patent",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=zGWrpTs4DxAfey0l8sHs0/sAsko1a5Xg6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IN-284809&kind=B",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=htsatx6z0Zw1zTc2PWcWRHfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "IN6761/CHENP/2009",
                                    "KIND": "A",
                                    "XPN": "IN2009CN06761",
                                    "V_PNID": "IN-6761/CHENP/2009A-43",
                                    "DATE": "2010-03-05",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=/WizbbSQlgsj5Tynq3ifopByHje3bCdrETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IN2009CN06761&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=tBGbfKE5qtSVNOx%252FtmxMJMRHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2020-08-31",
                            "XAP": "2008CA-2683934",
                            "APD": "2008-04-09",
                            "APID": "5786237",
                            "REG_LINK": "https://www.ic.gc.ca/opic-cipo/cpd/eng/patent/2683934/summary.html?type=number_search",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=olCWkTuQTvj4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "CA2683934",
                                    "KIND": "C",
                                    "XPN": "CA2683934",
                                    "V_PNID": "CA-2683934C-14",
                                    "DATE": "2015-06-16",
                                    "STG": "Patent (second level)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=zHwB0zw1NryG9UNvNPhYP4TNbfc8CWEP6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=CA2683934&kind=C",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=olCWkTuQTvj4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "CA2683934",
                                    "KIND": "A1",
                                    "XPN": "CA2683934",
                                    "V_PNID": "CA-2683934A1-0",
                                    "DATE": "2008-10-30",
                                    "STG": "Application laid open",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=zHwB0zw1NryG9UNvNPhYP/EZzQ94rBiHPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=CA2683934&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=olCWkTuQTvj4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2028-04-09",
                            "XAP": "2009IL-0201197",
                            "APD": "2008-04-09",
                            "APID": "29084479",
                            "REG_LINK": "http://www.ilpatsearch.justice.gov.il/UI/MainPage.aspx",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=SBRIjhJpXtzdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "IL201197",
                                    "KIND": "B",
                                    "XPN": "IL-201197",
                                    "V_PNID": "IL-201197A-0",
                                    "DATE": "2013-07-31",
                                    "STG": "Published Examined Application Laid Open for Public Inspection",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=q8jkuojC8RBDU43uVU4it/sAsko1a5Xg6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IL-201197&kind=B",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=SBRIjhJpXtzdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "IL201197",
                                    "KIND": "A",
                                    "XPN": "IL-201197",
                                    "V_PNID": "IL-201197D0-0",
                                    "DATE": "2010-05-17",
                                    "STG": "Application of patent for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=q8jkuojC8RBDU43uVU4it10zzUpwOsUC6HbQoUdvKcq17ed+ZXyWdQ==&n=1&xpn=IL-201197&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=SBRIjhJpXtzdGqGyRhNS9XfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "EXPIRED",
                            "ACT_EED": "2020-11-05",
                            "XAP": "2008AU-0242213",
                            "APD": "2008-04-09",
                            "APID": "2493567",
                            "REG_LINK": "http://pericles.ipaustralia.gov.au/ols/auspat/quickSearch.do?queryString=2008242213",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x6UmqlZAPhIIG%252BVrhRlzBLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "AU2008242213",
                                    "KIND": "B2",
                                    "XPN": "AU2008242213",
                                    "V_PNID": "AU-2008242213B2-0",
                                    "DATE": "2013-03-28",
                                    "STG": "Patent proceeded by OPI",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=OseQCaeVQ7zAGxPkf/MFqN7SBXZErAkqETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=AU2008242213&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x6UmqlZAPhIIG%252BVrhRlzBLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "AU2008242213",
                                    "KIND": "A1",
                                    "XPN": "AU2008242213",
                                    "V_PNID": "AU-2008242213A1-0",
                                    "DATE": "2008-10-30",
                                    "STG": "Open to public inspection",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=OseQCaeVQ7zAGxPkf/MFqN0P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=AU2008242213&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x6UmqlZAPhIIG%252BVrhRlzBLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2020-04-10",
                            "XAP": "2009RU-0142412",
                            "APD": "2008-04-09",
                            "APID": "51175634",
                            "REG_LINK": "https://www1.fips.ru/registers-web/",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=pLa1UrXelfYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "RU2473861",
                                    "KIND": "C2",
                                    "XPN": "RU2473861",
                                    "V_PNID": "RU-2473861C2-0",
                                    "DATE": "2013-01-27",
                                    "STG": "Patent for invention ( 2nd publ.)",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=10hK6B73bpn/SJXex5oPQQtpbYik856lPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=RU2473861&kind=C2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=pLa1UrXelfYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "RU2009142412",
                                    "KIND": "A",
                                    "XPN": "RU2009142412",
                                    "V_PNID": "RU-2009142412A-0",
                                    "DATE": "2011-05-27",
                                    "STG": "Application for invention",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=BifV9gOYQAOnC9ugQ/esVAMqfaYWomYVLF0MMAHB5Nj4AYwFZA0hcsEHRbsnLuLp&n=1&xpn=RU2009142412&kind=A",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=bGIaQ6Fd8fO8M7De2tMIhLmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2020-10-12",
                            "XAP": "2008US-12596416",
                            "APD": "2008-04-09",
                            "APID": "62666200",
                            "REG_LINK": "https://patentcenter.uspto.gov/applications/12596416",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8%252BcjexmU88D4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "US8260734",
                                    "KIND": "B2",
                                    "XPN": "US8260734",
                                    "V_PNID": "US-8260734B2-0",
                                    "DATE": "2012-09-04",
                                    "STG": "Granted patent as second publication",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=HF4wYPMzHk3rnIMlKbq39EDJGjHFOylzPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=US8260734&kind=B2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=8%252BcjexmU88D4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "US20100094789",
                                    "KIND": "A1",
                                    "XPN": "US20100094789",
                                    "V_PNID": "US-2010094789A1-0",
                                    "DATE": "2010-04-15",
                                    "STG": "Application published",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=lOckPE/DvcPEpjUyhU/x9jkuDREcUBY0bS9pDLpcD1vy9uBHwA8/uxHPkIFjihe/&n=1&xpn=US20100094789&kind=A1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=BrTM%252F3T%252F4fXV7oPEgrvfv8RHIQdPpfyajIQBIFKxQPE%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "ALIVE",
                            "ACT_STATUS": "GRANTED",
                            "ACT_EED": "2028-04-09",
                            "XAP": "2008EP-0763029",
                            "APD": "2008-04-09",
                            "APID": "21773923",
                            "REG_LINK": "https://register.epo.org/application?number=EP08763029",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=2MJneNJQHyYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "EP2137481",
                                    "KIND": "B1",
                                    "XPN": "EP2137481",
                                    "V_PNID": "EP-2137481B1-0",
                                    "DATE": "2010-11-17",
                                    "STG": "Patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=EVho024Sjd9PySx4rc/Jo6xaknS/Ov5DPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2137481&kind=B1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=2MJneNJQHyYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                },
                                {
                                    "PN": "EP2137481",
                                    "KIND": "A2",
                                    "XPN": "EP2137481",
                                    "V_PNID": "EP-2137481A2-0",
                                    "DATE": "2009-12-30",
                                    "STG": "Application published without search report",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=EVho024Sjd9PySx4rc/JoxWceYjKUptoPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=EP2137481&kind=A2",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=2MJneNJQHyYuw56Xk6cpNXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ],
                            "V_APL": [
                                {
                                    "ACT_STATE": "ALIVE",
                                    "ACT_STATUS": "GRANTED",
                                    "ACT_EED": "2028-04-09",
                                    "XAP": "2008ES-0763029T",
                                    "APD": "2008-04-09",
                                    "APID": "23072869",
                                    "REG_LINK": "http://consultas2.oepm.es/ceo/jsp/busqueda/busqInvencionesResultados.xhtml",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x6Von%252FlyhDAbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "ES2356798",
                                            "KIND": "T3",
                                            "XPN": "ES2356798",
                                            "V_PNID": "ES-2356798T3-0",
                                            "DATE": "2011-04-13",
                                            "STG": "Translation of granted European patent (former B3)",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=xLUVCFO7WBe6WNyMAUgZoH4Wg7sNFBWnPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ES2356798&kind=T3",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=x6Von%252FlyhDAbWDK85JFymXfDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                },
                                {
                                    "ACT_STATE": "DEAD",
                                    "ACT_STATUS": "LAPSED",
                                    "ACT_EED": "2020-11-03",
                                    "XAP": "2008DE-60003556",
                                    "APD": "2008-04-09",
                                    "APID": "19205779",
                                    "REG_LINK": "http://www.orbit.com/getDPMARegisterUrl?PN=DE602008003556",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=640OqL6d1fm0b4230jT5YMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLPAT",
                                    "PUB": [
                                        {
                                            "PN": "DE602008003556",
                                            "KIND": "D1",
                                            "XPN": "DE602008003556",
                                            "V_PNID": "DE-602008003556D1-0",
                                            "DATE": "2010-12-30",
                                            "STG": "Grant (no unexamined application published) patent law 81",
                                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=o/R9q79InDQrUtVFn4Xedxc0Gk9KAu1RRw53pukcGdq8mcFoz1yzz1k0PkWksrrN&n=1&xpn=DE602008003556&kind=D1",
                                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=640OqL6d1fm0b4230jT5YMExnvIz5kLrfqHome9U%252B8A%3D%26n%3D1&id=0&base=FULLTEXT"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "ACT_STATE": "DEAD",
                            "ACT_STATUS": "LAPSED",
                            "ACT_EED": "2011-05-15",
                            "XAP": "2008AT-0763029T",
                            "APD": "2008-04-09",
                            "APID": "1051720",
                            "REG_LINK": "https://see-ip.patentamt.at/NPatentSuche",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=aURcJyU75dr4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLPAT",
                            "PUB": [
                                {
                                    "PN": "ATE488744",
                                    "KIND": "T1",
                                    "XPN": "ATE488744",
                                    "V_PNID": "AT-488744T-0",
                                    "DATE": "2010-12-15",
                                    "STG": "Translation of an European patent specification",
                                    "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=FeGGlZHv40NBYxqMZMOV7K4qTfdTGTOdPJycrm26hB7Tvutnxh+q7A==&n=1&xpn=ATE488744&kind=T1",
                                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=aURcJyU75dr4%252BC%252F5M6pym3fDUqlXTJ5uwQdFuycu4uk%3D%26n%3D1&id=0&base=FULLTEXT"
                                }
                            ]
                        }
                    ]
                },
                {
                    "ACT_STATE": "ALIVE",
                    "ACT_STATUS": "PENDING",
                    "ACT_EED": "2027-04-18",
                    "XAP": "2007IT-TO00272",
                    "APD": "2007-04-18",
                    "APID": "30298912",
                    "REG_LINK": "",
                    "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=yObfPeV2f9uMQvV%252F%252FQWo%252FrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLPAT",
                    "PUB": [
                        {
                            "PN": "ITTO20070272",
                            "KIND": "A1",
                            "XPN": "IT2007TO0272",
                            "V_PNID": "IT-TO20070272A1-0",
                            "DATE": "2008-10-19",
                            "STG": "Application for patent of invention",
                            "PDF_LINK": "https://www.orbit.com/GetPDF?gui=crypt&callingapp=EDOFF&key=PknmpDUQ+ywDNKnBlfNC290P/F2Pwh1EETKOYJ6GDpFkB36ua0eF+VLSWUEn8FA9&n=1&xpn=IT2007TO0272&kind=A1",
                            "PERMALINK": "https://permalink.orbit.com/RenderStaticFirstPage?XPN=yObfPeV2f9uMQvV%252F%252FQWo%252FrmsLuw%252FR4oY%252BQgpgFzVRnM%3D%26n%3D1&id=0&base=FULLTEXT"
                        }
                    ]
                }
            ],
            "REP": "EP2137481_B1",
            "EPRD": "2007-04-18",
            "PN": "EP2137481           B1 2010-11-17 [EP2137481]<br/>EP2137481           A2 2009-12-30 [EP2137481]<br/>US8260734           B2 2012-09-04 [US8260734]<br/>US20100094789       A1 2010-04-15 [US20100094789]<br/>WO2008/129435       A3 2008-12-18 [WO2008129435]<br/>WO2008/129435       A2 2008-10-30 [WO2008129435]<br/>DE602008003556      D1 2010-12-30 [DE602008003556]<br/>RU2473861           C2 2013-01-27 [RU2473861]<br/>RU2009142412        A  2011-05-27 [RU2009142412]<br/>IN284809            B  2017-07-07 [IN-284809]<br/>IN6761/CHENP/2009   A  2010-03-05 [IN2009CN06761]<br/>CA2683934           C  2015-06-16 [CA2683934]<br/>CA2683934           A1 2008-10-30 [CA2683934]<br/>IL201197            B  2013-07-31 [IL-201197]<br/>IL201197            A  2010-05-17 [IL-201197]<br/>AU2008242213        B2 2013-03-28 [AU2008242213]<br/>AU2008242213        A1 2008-10-30 [AU2008242213]<br/>ES2356798           T3 2011-04-13 [ES2356798]<br/>ATE488744           T1 2010-12-15 [ATE488744]<br/>ITTO20070272        A1 2008-10-19 [IT2007TO0272]",
            "ADB": "(EP2137481)<br/><p>Among the possible techniques that can be used for the development of a methodology for the real-time estimation of impact areas, which include mathematical approaches based on linear regressions, non-linear regressions, and neural networks, the present application makes intensive use of the neural network technique so that it can advantageously be implemented on a non-experimental flying platform.</p><p>Like known models with six degrees of freedom, the processing system of the invention is advantageously arranged to distinguish between conditions which allow an impact area and those which do not allow an impact area.</p><p>The task of calculating the time of flight and the impact areas is advantageously divided into a group of tasks for calculating time of flight and coordinates relating to a predetermined number of boundary points (vertices) of the impact area, respectively.</p><p>For a \"smart\" load, the situation is more complex since that load has the capability to navigate in order to reach a predefined target with a certain degree of accuracy.</p><p>The accuracy of the model is very good and the possible error is limited to within a few metres.</p><p>The problem of estimating the impact area of a smart load in real time is complex and highly non-linear, depending on the conditions of release from the aircraft and of the impact of the load on the target.</p>"
        }
    ]
}